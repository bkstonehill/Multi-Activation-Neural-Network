{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243fa3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "%reload_ext tensorboard\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Data containers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Manipulation and Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Deep_Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# This code snippet forces tensorflow to not automatically allocate all GPU ram which can be an issue in notebook environment\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "tf.debugging.disable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807a397",
   "metadata": {},
   "source": [
    "### Define the Custom Layer for multiple activation functions per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom Layer\n",
    "class MultiActivationLayer(keras.layers.Layer):\n",
    "    '''\n",
    "    Multiple Activation Layer\n",
    "    \n",
    "    A neural network layer in which every node has a different activation function applied\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, out_features, activations, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.out_features = out_features\n",
    "        self.activations = activations\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        z = tf.matmul(inputs, self.w) + self.b\n",
    "        shape = tf.shape(z)[0]\n",
    "        \n",
    "        # Apply activation function to ouput features from nodes (columns) separately with different activation functions\n",
    "        #, reshape to 2-D array and concatenate the results from each node in the same order\n",
    "        nodes = [tf.reshape(self.activations[i%len(self.activations)](z[:,i]), (shape, 1)) for i in range(self.out_features)]\n",
    "        z = tf.concat(nodes, 1)\n",
    "        return z\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"out_features\": self.out_features,\n",
    "            \"activations\": self.activations,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af3559",
   "metadata": {},
   "source": [
    "## Define method for creating the testing models with equivalent architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2799d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom architecture using the new layer\n",
    "def create_model(activations, option='multi', num_classes=1, dropout=False, dropout_rate=0.2, task='classification'):\n",
    "    if option == 'uniform':\n",
    "        if not dropout:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[0], name='layers_dense_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[0], name='layers_dense_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[0], name='layers_dense_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[0], name='layers_dense_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                 return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[0], name='layers_dense_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[0], name='layers_dense_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[0], name='layers_dense_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[0], name='layers_dense_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "        else:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[0], name='layers_dense_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[0], name='layers_dense_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[0], name='layers_dense_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[0], name='layers_dense_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[0], name='layers_dense_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[0], name='layers_dense_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[0], name='layers_dense_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[0], name='layers_dense_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "    elif option == 'multi':\n",
    "        if not dropout:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    MultiActivationLayer(25, activations, name='layers_multi_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(20, activations, name='layers_multi_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(15, activations, name='layers_multi_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(10, activations, name='layers_multi_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(5, activations, name='layers_multi_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                 return keras.models.Sequential([\n",
    "                    MultiActivationLayer(25, activations, name='layers_multi_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(20, activations, name='layers_multi_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(15, activations, name='layers_multi_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(10, activations, name='layers_multi_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(5, activations, name='layers_multi_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "        else:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    MultiActivationLayer(25, activations, name='layers_multi_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(20, activations, name='layers_multi_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(15, activations, name='layers_multi_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(10, activations, name='layers_multi_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(5, activations, name='layers_multi_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                return keras.models.Sequential([\n",
    "                    MultiActivationLayer(25, activations, name='layers_multi_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(20, activations, name='layers_multi_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(15, activations, name='layers_multi_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(10, activations, name='layers_multi_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(5, activations, name='layers_multi_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "    elif option == 'sequential':\n",
    "        if len(activations) < 5: raise RuntimeError()\n",
    "        if not dropout:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[1], name='layers_dense_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[2], name='layers_dense_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[3], name='layers_dense_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[4], name='layers_dense_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                 return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[1], name='layers_dense_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[2], name='layers_dense_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[3], name='layers_dense_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[4], name='layers_dense_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "        else: \n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[1], name='layers_dense_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[2], name='layers_dense_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[3], name='layers_dense_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[4], name='layers_dense_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[1], name='layers_dense_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[2], name='layers_dense_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[3], name='layers_dense_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[4], name='layers_dense_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "    else:\n",
    "        raise RuntimeError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4fda5",
   "metadata": {},
   "source": [
    "## Define method for training all testing models on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define testing function for generating and running tests\n",
    "def test(X, y, num_classes, task='classification', epochs=100, batch_size=32):\n",
    "    \n",
    "    if task == 'classification':\n",
    "    \n",
    "        # Create our model\n",
    "        MANN = create_model(activations=[tf.nn.sigmoid, tf.nn.tanh, tf.nn.leaky_relu, tf.nn.elu, tf.nn.swish], dropout=False, num_classes=num_classes, task=task)\n",
    "        MANN.compile(optimizer=keras.optimizers.legacy.RMSprop(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "        # Create our model with dropout\n",
    "        MANN_drop = create_model(activations=[tf.nn.sigmoid, tf.nn.tanh, tf.nn.leaky_relu, tf.nn.elu, tf.nn.swish], dropout=True, num_classes=num_classes, task=task)\n",
    "        MANN_drop.compile(optimizer=keras.optimizers.legacy.RMSprop(),\n",
    "                         loss=keras.losses.CategoricalCrossentropy(),\n",
    "                         metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "        # Create uniform model for each activation function\n",
    "        UANN1 = create_model(activations=[tf.nn.sigmoid], option='uniform', num_classes=num_classes, task=task)\n",
    "        UANN1.compile(optimizer=keras.optimizers.legacy.RMSprop(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        UANN2 = create_model(activations=[tf.nn.tanh], option='uniform', num_classes=num_classes, task=task)\n",
    "        UANN2.compile(optimizer=keras.optimizers.legacy.RMSprop(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        UANN3 = create_model(activations=[tf.nn.leaky_relu], option='uniform', num_classes=num_classes, task=task)\n",
    "        UANN3.compile(optimizer=keras.optimizers.legacy.RMSprop(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        UANN4 = create_model(activations=[tf.nn.elu], option='uniform', num_classes=num_classes, task=task)\n",
    "        UANN4.compile(optimizer=keras.optimizers.legacy.RMSprop(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        UANN5 = create_model(activations=[tf.nn.swish], option='uniform', num_classes=num_classes, task=task)\n",
    "        UANN5.compile(optimizer=keras.optimizers.legacy.RMSprop(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        # Create sequential activation network\n",
    "        SANN = create_model(activations=[tf.nn.swish, tf.nn.elu, tf.nn.leaky_relu, tf.nn.tanh, tf.nn.sigmoid], option='sequential', dropout=False, num_classes=num_classes, task=task)\n",
    "        SANN.compile(optimizer=keras.optimizers.legacy.RMSprop(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        # Split data into training and testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "        train_dataset = train_dataset.shuffle(1000).batch(256)\n",
    "        test_dataset = test_dataset.batch(256)\n",
    "        \n",
    "        # Fit the data to the models for a set number of epochs\n",
    "        print(\"Training Multi Activation Neural Network...\")\n",
    "        MANN.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, verbose=0)\n",
    "        print('')\n",
    "        \n",
    "        print(\"Training Multi Activation Neural Network w/ Dropout...\")\n",
    "        MANN_drop.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, verbose=0)\n",
    "        print('Finished.')\n",
    "        \n",
    "        \n",
    "        print(\"Training Sigmoid Uniform Activation Neural Network...\")\n",
    "        UANN1.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, verbose=0)\n",
    "        print('Finished.')\n",
    "        \n",
    "        print(\"Training Tanh Uniform Activation Neural Network...\")\n",
    "        UANN2.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, verbose=0)\n",
    "        print('Finished.')\n",
    "        \n",
    "        print(\"Training Leaky ReLU Uniform Activation Neural Network...\")\n",
    "        UANN3.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, verbose=0)\n",
    "        print('Finished.')\n",
    "        \n",
    "        print(\"Training ELU Uniform Activation Neural Network...\")\n",
    "        UANN4.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, verbose=0)\n",
    "        print('Finished.')\n",
    "        \n",
    "        print(\"Training Swish Uniform Activation Neural Network...\")\n",
    "        UANN5.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, verbose=0)\n",
    "        print('Finished.')\n",
    "        \n",
    "        print(\"Training Sequential Activation Neural Network...\")\n",
    "        SANN.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, verbose=0)\n",
    "        print('Finished.')\n",
    "        \n",
    "        # Create dictionaries to return for models and scores\n",
    "        models = {\n",
    "            'Multi': MANN,\n",
    "            'Multi, Dropout': MANN_drop,\n",
    "            'Uniform, Sigmoid': UANN1,\n",
    "            'Uniform, Tanh': UANN2,\n",
    "            'Uniform, Leaky ReLU': UANN3,\n",
    "            'Uniform, ELU': UANN4,\n",
    "            'Uniform, Swish': UANN5,\n",
    "            'Sequential': SANN\n",
    "        }\n",
    "        \n",
    "        return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a3361",
   "metadata": {},
   "source": [
    "## Regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1c511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load datasets and view\n",
    "df = pd.read_csv('Stroke_Dataset_Normalized.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67fb00b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='classification', corner=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['classification'].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "y = np.asarray(encoder.fit_transform(y.reshape((y.shape[0], 1))).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = test(X, y, len(encoder.categories_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0377ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

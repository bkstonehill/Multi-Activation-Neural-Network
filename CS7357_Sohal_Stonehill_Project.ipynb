{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "243fa3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Braden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Braden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Braden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Braden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Import needed libraries\n",
    "%reload_ext tensorboard\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Data containers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Manipulation and Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Deep_Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# This code snippet forces tensorflow to not automatically allocate all GPU ram which can be an issue in notebook environment\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "tf.debugging.disable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ddb706",
   "metadata": {},
   "source": [
    "### Define the Custom Layer for multiple activation functions per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3be6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom Layer\n",
    "class MultiActivationLayer(keras.layers.Layer):\n",
    "    '''\n",
    "    Multiple Activation Layer\n",
    "    \n",
    "    A neural network layer in which every node has a different activation function applied\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, out_features, activations, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.out_features = out_features\n",
    "        self.activations = activations\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        z = tf.matmul(inputs, self.w) + self.b\n",
    "        shape = tf.shape(z)[0]\n",
    "        \n",
    "        # Apply activation function to ouput features from nodes (columns) separately with different activation functions\n",
    "        #, reshape to 2-D array and concatenate the results from each node in the same order\n",
    "        nodes = [tf.reshape(self.activations[i%len(self.activations)](z[:,i]), (shape, 1)) for i in range(self.out_features)]\n",
    "        z = tf.concat(nodes, 1)\n",
    "        return z\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"out_features\": self.out_features,\n",
    "            \"activations\": self.activations,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c3f711",
   "metadata": {},
   "source": [
    "## Define method for creating the testing models with equivalent architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2799d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom architecture using the new layer\n",
    "def create_model(activations, option='multi', num_classes=1, dropout=False, dropout_rate=0.2, task='classification'):\n",
    "    if option == 'uniform':\n",
    "        if not dropout:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[0], name='layers_dense_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[0], name='layers_dense_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[0], name='layers_dense_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[0], name='layers_dense_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                 return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[0], name='layers_dense_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[0], name='layers_dense_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[0], name='layers_dense_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[0], name='layers_dense_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "        else:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[0], name='layers_dense_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[0], name='layers_dense_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[0], name='layers_dense_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[0], name='layers_dense_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[0], name='layers_dense_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[0], name='layers_dense_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[0], name='layers_dense_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[0], name='layers_dense_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "    elif option == 'multi':\n",
    "        if not dropout:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    MultiActivationLayer(25, activations, name='layers_multi_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(20, activations, name='layers_multi_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(15, activations, name='layers_multi_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(10, activations, name='layers_multi_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(5, activations, name='layers_multi_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                 return keras.models.Sequential([\n",
    "                    MultiActivationLayer(25, activations, name='layers_multi_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(20, activations, name='layers_multi_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(15, activations, name='layers_multi_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(10, activations, name='layers_multi_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(5, activations, name='layers_multi_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "        else:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    MultiActivationLayer(25, activations, name='layers_multi_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(20, activations, name='layers_multi_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(15, activations, name='layers_multi_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(10, activations, name='layers_multi_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(5, activations, name='layers_multi_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                return keras.models.Sequential([\n",
    "                    MultiActivationLayer(25, activations, name='layers_multi_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(20, activations, name='layers_multi_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(15, activations, name='layers_multi_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(10, activations, name='layers_multi_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    MultiActivationLayer(5, activations, name='layers_multi_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "    elif option == 'sequential':\n",
    "        if len(activations) < 5: raise RuntimeError()\n",
    "        if not dropout:\n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[1], name='layers_dense_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[2], name='layers_dense_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[3], name='layers_dense_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[4], name='layers_dense_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                 return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[1], name='layers_dense_2'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[2], name='layers_dense_3'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[3], name='layers_dense_4'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[4], name='layers_dense_5'),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "        else: \n",
    "            if task == 'classification':\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[1], name='layers_dense_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[2], name='layers_dense_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[3], name='layers_dense_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[4], name='layers_dense_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(num_classes, activation='sigmoid' if num_classes < 2 else 'softmax', name='layers_dense')\n",
    "                ])\n",
    "            else:\n",
    "                return keras.models.Sequential([\n",
    "                    keras.layers.Dense(25, activation=activations[0], name='layers_dense_1'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(20, activation=activations[1], name='layers_dense_2'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(15, activation=activations[2], name='layers_dense_3'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(10, activation=activations[3], name='layers_dense_4'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(5, activation=activations[4], name='layers_dense_5'),\n",
    "                    keras.layers.Dropout(dropout_rate),\n",
    "                    keras.layers.BatchNormalization(),\n",
    "                    keras.layers.Dense(1, name='layers_dense')\n",
    "                ])\n",
    "    else:\n",
    "        raise RuntimeError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c0ecb",
   "metadata": {},
   "source": [
    "## Define method for training all testing models on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4444daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define testing function for generating and running tests\n",
    "def test(X, y, num_classes=None, X_test=None, y_test=None, task='classification', epochs=100, batch_size=32, task_name=''):\n",
    "    \n",
    "    MANN, MANN_drop, UANN1, UANN2, UANN3, UANN4, UANN5, SANN = None, None, None, None, None, None, None, None\n",
    "    \n",
    "    if X_test is None or y_test is None:\n",
    "        # Split data into training and testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    else:\n",
    "        X_train, y_train = X, y\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "    train_dataset = train_dataset.shuffle(1000).batch(batch_size)\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "        \n",
    "    \n",
    "    if task == 'classification':\n",
    "        if num_classes is None:\n",
    "            raise RuntimeError()\n",
    "            \n",
    "        if task_name == 'NLP':\n",
    "            vectorization_layer = keras.layers.TextVectorization(output_sequence_length=15000)\n",
    "            vectorization_layer.adapt(X_train)\n",
    "    \n",
    "        # Create our model\n",
    "        MANN = create_model(activations=[tf.nn.sigmoid, tf.nn.tanh, tf.nn.leaky_relu, tf.nn.elu, tf.nn.swish], dropout=False, num_classes=num_classes, task=task)\n",
    "        if task_name == 'NLP':\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "            model.add(vectorization_layer)\n",
    "            model.add(keras.layers.Embedding(input_dim=vectorization_layer.vocabulary_size(), output_dim=50))\n",
    "            model.add(keras.layers.Flatten())\n",
    "            for layer in MANN.layers:\n",
    "                model.add(layer)\n",
    "            MANN = model\n",
    "        MANN.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "        # Create our model with dropout\n",
    "        MANN_drop = create_model(activations=[tf.nn.sigmoid, tf.nn.tanh, tf.nn.leaky_relu, tf.nn.elu, tf.nn.swish], dropout=True, num_classes=num_classes, task=task)\n",
    "        if task_name == 'NLP':\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "            model.add(vectorization_layer)\n",
    "            model.add(keras.layers.Embedding(input_dim=vectorization_layer.vocabulary_size(), output_dim=50))\n",
    "            model.add(keras.layers.Flatten())\n",
    "            for layer in MANN_drop.layers:\n",
    "                model.add(layer)\n",
    "            MANN_drop = model\n",
    "        MANN_drop.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                         loss=keras.losses.CategoricalCrossentropy(),\n",
    "                         metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "        # Create uniform model for each activation function\n",
    "        UANN1 = create_model(activations=[tf.nn.sigmoid], option='uniform', num_classes=num_classes, task=task)\n",
    "        if task_name == 'NLP':\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "            model.add(vectorization_layer)\n",
    "            model.add(keras.layers.Embedding(input_dim=vectorization_layer.vocabulary_size(), output_dim=50))\n",
    "            model.add(keras.layers.Flatten())\n",
    "            for layer in UANN1.layers:\n",
    "                model.add(layer)\n",
    "            UANN1 = model\n",
    "        UANN1.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        UANN2 = create_model(activations=[tf.nn.tanh], option='uniform', num_classes=num_classes, task=task)\n",
    "        if task_name == 'NLP':\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "            model.add(vectorization_layer)\n",
    "            model.add(keras.layers.Embedding(input_dim=vectorization_layer.vocabulary_size(), output_dim=50))\n",
    "            model.add(keras.layers.Flatten())\n",
    "            for layer in UANN2.layers:\n",
    "                model.add(layer)\n",
    "            UANN2 = model\n",
    "        UANN2.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        UANN3 = create_model(activations=[tf.nn.leaky_relu], option='uniform', num_classes=num_classes, task=task)\n",
    "        if task_name == 'NLP':\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "            model.add(vectorization_layer)\n",
    "            model.add(keras.layers.Embedding(input_dim=vectorization_layer.vocabulary_size(), output_dim=50))\n",
    "            model.add(keras.layers.Flatten())\n",
    "            for layer in UANN3.layers:\n",
    "                model.add(layer)\n",
    "            UANN3 = model\n",
    "        UANN3.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        UANN4 = create_model(activations=[tf.nn.elu], option='uniform', num_classes=num_classes, task=task)\n",
    "        if task_name == 'NLP':\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "            model.add(vectorization_layer)\n",
    "            model.add(keras.layers.Embedding(input_dim=vectorization_layer.vocabulary_size(), output_dim=50))\n",
    "            model.add(keras.layers.Flatten())\n",
    "            for layer in UANN4.layers:\n",
    "                model.add(layer)\n",
    "            UANN4 = model\n",
    "        UANN4.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        UANN5 = create_model(activations=[tf.nn.swish], option='uniform', num_classes=num_classes, task=task)\n",
    "        if task_name == 'NLP':\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "            model.add(vectorization_layer)\n",
    "            model.add(keras.layers.Embedding(input_dim=vectorization_layer.vocabulary_size(), output_dim=50))\n",
    "            model.add(keras.layers.Flatten())\n",
    "            for layer in UANN5.layers:\n",
    "                model.add(layer)\n",
    "            UANN5 = model\n",
    "        UANN5.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "        # Create sequential activation network\n",
    "        SANN = create_model(activations=[tf.nn.swish, tf.nn.elu, tf.nn.leaky_relu, tf.nn.tanh, tf.nn.sigmoid], option='sequential', dropout=False, num_classes=num_classes, task=task)\n",
    "        if task_name == 'NLP':\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "            model.add(vectorization_layer)\n",
    "            model.add(keras.layers.Embedding(input_dim=vectorization_layer.vocabulary_size(), output_dim=50))\n",
    "            model.add(keras.layers.Flatten())\n",
    "            for layer in SANN.layers:\n",
    "                model.add(layer)\n",
    "            SANN = model\n",
    "        SANN.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "        \n",
    "    elif task == 'regression':\n",
    "        # Create our model\n",
    "        MANN = create_model(activations=[tf.nn.sigmoid, tf.nn.tanh, tf.nn.leaky_relu, tf.nn.elu, tf.nn.swish], dropout=False, task=task)\n",
    "        MANN.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.MeanSquaredError())\n",
    "\n",
    "        # Create our model with dropout\n",
    "        MANN_drop = create_model(activations=[tf.nn.sigmoid, tf.nn.tanh, tf.nn.leaky_relu, tf.nn.elu, tf.nn.swish], dropout=True, task=task)\n",
    "        MANN_drop.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.MeanSquaredError())\n",
    "        \n",
    "        # Create uniform model for each activation function\n",
    "        UANN1 = create_model(activations=[tf.nn.sigmoid], option='uniform', task=task)\n",
    "        UANN1.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.MeanSquaredError())\n",
    "        \n",
    "        UANN2 = create_model(activations=[tf.nn.tanh], option='uniform', task=task)\n",
    "        UANN2.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.MeanSquaredError())\n",
    "        \n",
    "        UANN3 = create_model(activations=[tf.nn.leaky_relu], option='uniform', task=task)\n",
    "        UANN3.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.MeanSquaredError())\n",
    "        \n",
    "        UANN4 = create_model(activations=[tf.nn.elu], option='uniform', task=task)\n",
    "        UANN4.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.MeanSquaredError())\n",
    "        \n",
    "        UANN5 = create_model(activations=[tf.nn.swish], option='uniform', task=task)\n",
    "        UANN5.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.MeanSquaredError())\n",
    "        \n",
    "        # Create sequential activation network\n",
    "        SANN = create_model(activations=[tf.nn.swish, tf.nn.elu, tf.nn.leaky_relu, tf.nn.tanh, tf.nn.sigmoid], option='sequential', task=task)\n",
    "        SANN.compile(optimizer=keras.optimizers.legacy.Nadam(),\n",
    "                     loss=keras.losses.MeanSquaredError())\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "    \n",
    "    # Fit the data to the models for a set number of epochs\n",
    "    print(\"Training Multi Activation Neural Network...\")\n",
    "    path=f'{task_name}.MANN.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_loss',\n",
    "                                                                    mode='min',\n",
    "                                                                    save_best_only=True)\n",
    "    MANN_hist = MANN.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, callbacks=[model_checkpoint_callback])\n",
    "    print('')\n",
    "\n",
    "    print(\"Training Multi Activation Neural Network w/ Dropout...\")\n",
    "    path=f'{task_name}.MANN_dropout.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_loss',\n",
    "                                                                    mode='min',\n",
    "                                                                    save_best_only=True)\n",
    "    MANN_drop_hist = MANN_drop.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, callbacks=[model_checkpoint_callback])\n",
    "    print('Finished.')\n",
    "\n",
    "\n",
    "    print(\"Training Sigmoid Uniform Activation Neural Network...\")\n",
    "    path=f'{task_name}.Sigmoid.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_loss',\n",
    "                                                                    mode='min',\n",
    "                                                                    save_best_only=True)\n",
    "    UANN1_hist = UANN1.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, callbacks=[model_checkpoint_callback])\n",
    "    print('Finished.')\n",
    "\n",
    "    print(\"Training Tanh Uniform Activation Neural Network...\")\n",
    "    path=f'{task_name}.Tanh.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_loss',\n",
    "                                                                    mode='min',\n",
    "                                                                    save_best_only=True)\n",
    "    UANN2_hist = UANN2.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, callbacks=[model_checkpoint_callback])\n",
    "    print('Finished.')\n",
    "\n",
    "    print(\"Training Leaky ReLU Uniform Activation Neural Network...\")\n",
    "    path=f'{task_name}.LeakyReLU.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_loss',\n",
    "                                                                    mode='min',\n",
    "                                                                    save_best_only=True)\n",
    "    UANN3_hist = UANN3.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, callbacks=[model_checkpoint_callback])\n",
    "    print('Finished.')\n",
    "\n",
    "    print(\"Training ELU Uniform Activation Neural Network...\")\n",
    "    path=f'{task_name}.ELU.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_loss',\n",
    "                                                                    mode='min',\n",
    "                                                                    save_best_only=True)\n",
    "    UANN4_hist = UANN4.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, callbacks=[model_checkpoint_callback])\n",
    "    print('Finished.')\n",
    "\n",
    "    print(\"Training Swish Uniform Activation Neural Network...\")\n",
    "    path=f'{task_name}.Swish.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_loss',\n",
    "                                                                    mode='min',\n",
    "                                                                    save_best_only=True)\n",
    "    UANN5_hist = UANN5.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, callbacks=[model_checkpoint_callback])\n",
    "    print('Finished.')\n",
    "\n",
    "    print(\"Training Sequential Activation Neural Network...\")\n",
    "    path=f'{task_name}.Sequential.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_loss',\n",
    "                                                                    mode='min',\n",
    "                                                                    save_best_only=True)\n",
    "    SANN_hist = SANN.fit(x=train_dataset, batch_size=batch_size, epochs=epochs, validation_data=test_dataset, callbacks=[model_checkpoint_callback])\n",
    "    print('Finished.')\n",
    "\n",
    "    # Create dictionaries to return for models and scores\n",
    "    models = {\n",
    "        'MANN': MANN,\n",
    "        'MANN_Dropout': MANN_drop,\n",
    "        'Sigmoid': UANN1,\n",
    "        'Tanh': UANN2,\n",
    "        'LeakyReLU': UANN3,\n",
    "        'ELU': UANN4,\n",
    "        'Swish': UANN5,\n",
    "        'Sequential': SANN\n",
    "    }\n",
    "    \n",
    "    histories = {\n",
    "        'MANN': MANN_hist,\n",
    "        'MANN_dropout': MANN_drop_hist,\n",
    "        'Sigmoid': UANN1_hist,\n",
    "        'Tanh': UANN2_hist,\n",
    "        'LeakyReLU': UANN3_hist,\n",
    "        'ELU': UANN4_hist,\n",
    "        'Swish': UANN5_hist,\n",
    "        'Sequential': SANN_hist\n",
    "    }\n",
    "\n",
    "    return models, histories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52668e88",
   "metadata": {},
   "source": [
    "## Regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "32c3df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split into testing and training for processing\n",
    "data = pd.read_csv('./Datasets/Regression/train.csv')\n",
    "features = data.drop('TARGET(PRICE_IN_LACS)', axis=1)\n",
    "target = data['TARGET(PRICE_IN_LACS)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "66ec3512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNDER_CONSTRUCTION</th>\n",
       "      <th>RERA</th>\n",
       "      <th>BHK_NO.</th>\n",
       "      <th>SQUARE_FT</th>\n",
       "      <th>READY_TO_MOVE</th>\n",
       "      <th>RESALE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>TARGET(PRICE_IN_LACS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29451.000000</td>\n",
       "      <td>29451.000000</td>\n",
       "      <td>29451.000000</td>\n",
       "      <td>2.945100e+04</td>\n",
       "      <td>29451.000000</td>\n",
       "      <td>29451.000000</td>\n",
       "      <td>29451.000000</td>\n",
       "      <td>29451.000000</td>\n",
       "      <td>29451.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.179756</td>\n",
       "      <td>0.317918</td>\n",
       "      <td>2.392279</td>\n",
       "      <td>1.980217e+04</td>\n",
       "      <td>0.820244</td>\n",
       "      <td>0.929578</td>\n",
       "      <td>21.300255</td>\n",
       "      <td>76.837695</td>\n",
       "      <td>142.898746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.383991</td>\n",
       "      <td>0.465675</td>\n",
       "      <td>0.879091</td>\n",
       "      <td>1.901335e+06</td>\n",
       "      <td>0.383991</td>\n",
       "      <td>0.255861</td>\n",
       "      <td>6.205306</td>\n",
       "      <td>10.557747</td>\n",
       "      <td>656.880713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-37.713008</td>\n",
       "      <td>-121.761248</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000211e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.452663</td>\n",
       "      <td>73.798100</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.175057e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>77.324137</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.550688e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.900926</td>\n",
       "      <td>77.828740</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.545455e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.912884</td>\n",
       "      <td>152.962676</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UNDER_CONSTRUCTION          RERA       BHK_NO.     SQUARE_FT  \\\n",
       "count        29451.000000  29451.000000  29451.000000  2.945100e+04   \n",
       "mean             0.179756      0.317918      2.392279  1.980217e+04   \n",
       "std              0.383991      0.465675      0.879091  1.901335e+06   \n",
       "min              0.000000      0.000000      1.000000  3.000000e+00   \n",
       "25%              0.000000      0.000000      2.000000  9.000211e+02   \n",
       "50%              0.000000      0.000000      2.000000  1.175057e+03   \n",
       "75%              0.000000      1.000000      3.000000  1.550688e+03   \n",
       "max              1.000000      1.000000     20.000000  2.545455e+08   \n",
       "\n",
       "       READY_TO_MOVE        RESALE     LONGITUDE      LATITUDE  \\\n",
       "count   29451.000000  29451.000000  29451.000000  29451.000000   \n",
       "mean        0.820244      0.929578     21.300255     76.837695   \n",
       "std         0.383991      0.255861      6.205306     10.557747   \n",
       "min         0.000000      0.000000    -37.713008   -121.761248   \n",
       "25%         1.000000      1.000000     18.452663     73.798100   \n",
       "50%         1.000000      1.000000     20.750000     77.324137   \n",
       "75%         1.000000      1.000000     26.900926     77.828740   \n",
       "max         1.000000      1.000000     59.912884    152.962676   \n",
       "\n",
       "       TARGET(PRICE_IN_LACS)  \n",
       "count           29451.000000  \n",
       "mean              142.898746  \n",
       "std               656.880713  \n",
       "min                 0.250000  \n",
       "25%                38.000000  \n",
       "50%                62.000000  \n",
       "75%               100.000000  \n",
       "max             30000.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c903464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSTED_BY</th>\n",
       "      <th>UNDER_CONSTRUCTION</th>\n",
       "      <th>RERA</th>\n",
       "      <th>BHK_NO.</th>\n",
       "      <th>BHK_OR_RK</th>\n",
       "      <th>SQUARE_FT</th>\n",
       "      <th>READY_TO_MOVE</th>\n",
       "      <th>RESALE</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>TARGET(PRICE_IN_LACS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Owner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BHK</td>\n",
       "      <td>1300.236407</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ksfc Layout,Bangalore</td>\n",
       "      <td>12.969910</td>\n",
       "      <td>77.597960</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dealer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BHK</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Vishweshwara Nagar,Mysore</td>\n",
       "      <td>12.274538</td>\n",
       "      <td>76.644605</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Owner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BHK</td>\n",
       "      <td>933.159722</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jigani,Bangalore</td>\n",
       "      <td>12.778033</td>\n",
       "      <td>77.632191</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BHK</td>\n",
       "      <td>929.921143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sector-1 Vaishali,Ghaziabad</td>\n",
       "      <td>28.642300</td>\n",
       "      <td>77.344500</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dealer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BHK</td>\n",
       "      <td>999.009247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>New Town,Kolkata</td>\n",
       "      <td>22.592200</td>\n",
       "      <td>88.484911</td>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POSTED_BY  UNDER_CONSTRUCTION  RERA  BHK_NO. BHK_OR_RK    SQUARE_FT  \\\n",
       "0     Owner                   0     0        2       BHK  1300.236407   \n",
       "1    Dealer                   0     0        2       BHK  1275.000000   \n",
       "2     Owner                   0     0        2       BHK   933.159722   \n",
       "3     Owner                   0     1        2       BHK   929.921143   \n",
       "4    Dealer                   1     0        2       BHK   999.009247   \n",
       "\n",
       "   READY_TO_MOVE  RESALE                      ADDRESS  LONGITUDE   LATITUDE  \\\n",
       "0              1       1        Ksfc Layout,Bangalore  12.969910  77.597960   \n",
       "1              1       1    Vishweshwara Nagar,Mysore  12.274538  76.644605   \n",
       "2              1       1             Jigani,Bangalore  12.778033  77.632191   \n",
       "3              1       1  Sector-1 Vaishali,Ghaziabad  28.642300  77.344500   \n",
       "4              0       1             New Town,Kolkata  22.592200  88.484911   \n",
       "\n",
       "   TARGET(PRICE_IN_LACS)  \n",
       "0                   55.0  \n",
       "1                   51.0  \n",
       "2                   43.0  \n",
       "3                   62.5  \n",
       "4                   60.5  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9a2e6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\AppData\\Local\\Temp\\ipykernel_26904\\3635932901.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train.append(pd.DataFrame(data=one_hot.fit_transform(X_train[['POSTED_BY', 'BHK_OR_RK']]), columns=one_hot.get_feature_names_out()))\n",
      "C:\\Users\\Braden\\AppData\\Local\\Temp\\ipykernel_26904\\3635932901.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_test.append(pd.DataFrame(data=one_hot.transform(X_test[['POSTED_BY', 'BHK_OR_RK']]), columns=one_hot.get_feature_names_out()))\n"
     ]
    }
   ],
   "source": [
    "# Process and normalize the data\n",
    "one_hot = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# One-Hot encode categorical columns\n",
    "X_train.append(pd.DataFrame(data=one_hot.fit_transform(X_train[['POSTED_BY', 'BHK_OR_RK']]), columns=one_hot.get_feature_names_out()))\n",
    "X_test.append(pd.DataFrame(data=one_hot.transform(X_test[['POSTED_BY', 'BHK_OR_RK']]), columns=one_hot.get_feature_names_out()))\n",
    "\n",
    "# Drop the transformed columns and unneeded columns\n",
    "X_train.drop(['POSTED_BY', 'BHK_OR_RK', 'ADDRESS'], axis = 1, inplace=True)\n",
    "X_test.drop(['POSTED_BY', 'BHK_OR_RK', 'ADDRESS'], axis=1, inplace=True)\n",
    "\n",
    "# Normalize numerical columns\n",
    "scaler = StandardScaler()\n",
    "X_train[['BHK_NO.', 'SQUARE_FT', 'LONGITUDE', 'LATITUDE']]= scaler.fit_transform(X_train[['BHK_NO.', 'SQUARE_FT', 'LONGITUDE', 'LATITUDE']])\n",
    "X_test[['BHK_NO.', 'SQUARE_FT', 'LONGITUDE', 'LATITUDE']] = scaler.transform(X_test[['BHK_NO.', 'SQUARE_FT', 'LONGITUDE', 'LATITUDE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d2fffed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNDER_CONSTRUCTION</th>\n",
       "      <th>RERA</th>\n",
       "      <th>BHK_NO.</th>\n",
       "      <th>SQUARE_FT</th>\n",
       "      <th>READY_TO_MOVE</th>\n",
       "      <th>RESALE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684258</td>\n",
       "      <td>-0.007035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>1.098189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684258</td>\n",
       "      <td>-0.006865</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.150735</td>\n",
       "      <td>0.025204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.444198</td>\n",
       "      <td>-0.007191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.179616</td>\n",
       "      <td>0.050227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684258</td>\n",
       "      <td>-0.006587</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529079</td>\n",
       "      <td>-0.298616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28825</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.444198</td>\n",
       "      <td>-0.007128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226822</td>\n",
       "      <td>1.101250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UNDER_CONSTRUCTION  RERA   BHK_NO.  SQUARE_FT  READY_TO_MOVE  RESALE  \\\n",
       "21992                   0     0  0.684258  -0.007035              1       1   \n",
       "29060                   0     0  0.684258  -0.006865              1       1   \n",
       "6778                    0     0 -0.444198  -0.007191              1       1   \n",
       "4730                    0     0  0.684258  -0.006587              1       1   \n",
       "28825                   1     0 -0.444198  -0.007128              0       1   \n",
       "\n",
       "       LONGITUDE  LATITUDE  \n",
       "21992   0.192071  1.098189  \n",
       "29060   1.150735  0.025204  \n",
       "6778    1.179616  0.050227  \n",
       "4730    0.529079 -0.298616  \n",
       "28825   0.226822  1.101250  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf71e787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multi Activation Neural Network...\n",
      "Epoch 1/500\n",
      "185/185 [==============================] - 5s 14ms/step - loss: 423427.3125 - val_loss: 564641.1250\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 422645.6875 - val_loss: 563635.8750\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 421426.8125 - val_loss: 562573.6875\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 419603.7188 - val_loss: 561218.3750\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 417275.2188 - val_loss: 558726.3125\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 414859.5312 - val_loss: 555996.1875\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 412485.7188 - val_loss: 553492.8750\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 409847.8750 - val_loss: 551916.7500\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 407348.5938 - val_loss: 549686.8125\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 404976.9062 - val_loss: 547515.6875\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 402311.3438 - val_loss: 545703.0000\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 399079.2188 - val_loss: 543629.6875\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 395416.1562 - val_loss: 540871.2500\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 391604.4062 - val_loss: 539279.2500\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 387993.9062 - val_loss: 536359.8125\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 383648.0000 - val_loss: 527470.0000\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 377750.1250 - val_loss: 526158.3750\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 3s 14ms/step - loss: 373471.3438 - val_loss: 521820.8125\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 368196.9688 - val_loss: 512602.2500\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 363599.4062 - val_loss: 499892.6562\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 3s 14ms/step - loss: 356615.8750 - val_loss: 498455.6250\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 353575.8750 - val_loss: 490328.0312\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 346865.0938 - val_loss: 484170.2188\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 340372.6875 - val_loss: 482784.7188\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 334409.9062 - val_loss: 471380.9688\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 327821.3125 - val_loss: 464398.4688\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 322899.2500 - val_loss: 451013.8125\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 317151.1562 - val_loss: 449473.1250\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 315787.5625 - val_loss: 450445.5938\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 309137.7188 - val_loss: 441676.7812\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 303450.0000 - val_loss: 447817.8438\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 296799.5625 - val_loss: 438505.2188\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 293806.5938 - val_loss: 428156.8125\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 284293.0625 - val_loss: 443792.7812\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 288080.8750 - val_loss: 413469.2812\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 284376.9375 - val_loss: 403733.4375\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 278453.3125 - val_loss: 435774.5625\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 277569.5938 - val_loss: 417795.8125\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 278258.5312 - val_loss: 408808.5312\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 269496.3750 - val_loss: 407341.0625\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 257826.8438 - val_loss: 397060.7500\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 257377.4688 - val_loss: 396884.9062\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 254353.5625 - val_loss: 398648.3750\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 246783.6250 - val_loss: 402826.7500\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 241712.2031 - val_loss: 388662.9688\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 240070.3906 - val_loss: 385720.9375\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 236988.9844 - val_loss: 376571.3125\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 229958.1562 - val_loss: 374914.7500\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 226332.5938 - val_loss: 410342.2812\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 218226.0312 - val_loss: 377268.5625\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 217470.1250 - val_loss: 391964.5625\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 213045.2031 - val_loss: 374948.4688\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 216915.4219 - val_loss: 387516.9062\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 199518.5156 - val_loss: 399556.5000\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 203808.2656 - val_loss: 416387.7500\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 204178.8125 - val_loss: 388799.5938\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 187196.7656 - val_loss: 372745.5312\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 183074.9844 - val_loss: 379997.3438\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 184637.3281 - val_loss: 375996.8125\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 187806.1250 - val_loss: 372068.3438\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 180895.7969 - val_loss: 414473.5938\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 175831.4375 - val_loss: 393699.6562\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 163586.7656 - val_loss: 385648.7812\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 169467.1875 - val_loss: 392406.5312\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 166994.1094 - val_loss: 401105.0625\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 165311.1875 - val_loss: 334969.5312\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 149662.5312 - val_loss: 410701.6875\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 153516.7188 - val_loss: 427316.0625\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 154918.9062 - val_loss: 373824.2812\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 146466.8125 - val_loss: 423761.4688\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 144355.8438 - val_loss: 400063.6562\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 145380.7500 - val_loss: 429570.4375\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 136720.6094 - val_loss: 456264.3125\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 134755.1406 - val_loss: 382180.5000\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 134179.4375 - val_loss: 445325.8750\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 136415.9062 - val_loss: 471453.0625\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 117067.8984 - val_loss: 437929.2188\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 119963.8594 - val_loss: 429092.9688\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 125237.1328 - val_loss: 473376.1250\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 114908.2656 - val_loss: 412584.0000\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 118272.1094 - val_loss: 523582.4375\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 115239.2891 - val_loss: 483971.5938\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 113352.3750 - val_loss: 571018.8125\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 115439.6250 - val_loss: 387454.3750\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 109283.4688 - val_loss: 408677.7812\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 108508.3672 - val_loss: 399298.2500\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 104896.1953 - val_loss: 451940.2812\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 107119.2422 - val_loss: 433096.5625\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 104948.8516 - val_loss: 475264.3125\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 102640.7656 - val_loss: 418262.4688\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 99261.5078 - val_loss: 447060.7500\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 92204.3438 - val_loss: 462319.7188\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 93218.6406 - val_loss: 666185.1875\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 89286.8984 - val_loss: 504318.1250\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 89112.1250 - val_loss: 539421.5625\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 82205.0781 - val_loss: 620040.0625\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 92976.3672 - val_loss: 478961.5000\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 83926.5391 - val_loss: 394817.7812\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 87836.2969 - val_loss: 512722.7500\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 79700.1094 - val_loss: 492014.7812\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 83754.9531 - val_loss: 542093.1250\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 75233.1016 - val_loss: 534779.7500\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 79953.3281 - val_loss: 525609.6875\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 77809.7734 - val_loss: 502831.8750\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 74741.8359 - val_loss: 445827.4062\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 77651.4375 - val_loss: 558731.5000\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 76795.9453 - val_loss: 603697.6250\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 70769.6875 - val_loss: 487522.6562\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 76453.3047 - val_loss: 491376.1562\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 79884.6875 - val_loss: 516624.2500\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 85211.9766 - val_loss: 520622.5938\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 75755.2109 - val_loss: 673687.5000\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 68886.6094 - val_loss: 432775.8125\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 69539.2344 - val_loss: 454763.8125\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 69433.5156 - val_loss: 503381.0938\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 71612.3672 - val_loss: 421963.1875\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 62669.9727 - val_loss: 496449.8438\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 65848.1328 - val_loss: 448475.3750\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 69383.3906 - val_loss: 454846.4375\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 64772.7500 - val_loss: 407810.6875\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 61386.7695 - val_loss: 560935.6250\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 64757.2109 - val_loss: 533328.9375\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 64505.8398 - val_loss: 473686.3438\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 60565.8672 - val_loss: 452114.6562\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 66496.4766 - val_loss: 473615.9375\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 69933.6562 - val_loss: 436550.6250\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 67623.0859 - val_loss: 432142.5625\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 66347.3672 - val_loss: 436074.2188\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 67791.1719 - val_loss: 389047.1250\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 64643.2695 - val_loss: 421474.3438\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 60752.9297 - val_loss: 445447.3438\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 63809.1797 - val_loss: 630585.5000\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 65323.4531 - val_loss: 541912.8750\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 65636.9844 - val_loss: 487101.5625\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 62109.5703 - val_loss: 489224.5312\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 60433.3203 - val_loss: 469343.8750\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 68190.3594 - val_loss: 557565.3750\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 70516.8438 - val_loss: 523247.8438\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 63563.5234 - val_loss: 422878.0938\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 59508.6523 - val_loss: 393668.7812\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 64145.3242 - val_loss: 418188.7188\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 62230.9336 - val_loss: 504149.7500\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 67844.2891 - val_loss: 570328.1875\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 60231.7305 - val_loss: 411579.8750\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 2s 13ms/step - loss: 59128.2383 - val_loss: 480541.8438\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 65309.8633 - val_loss: 491143.0625\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 58619.7891 - val_loss: 447345.0625\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 61983.5000 - val_loss: 436483.6562\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 59951.3984 - val_loss: 444821.7188\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 59781.6719 - val_loss: 383834.3438\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 67542.0859 - val_loss: 431895.8438\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 68028.1172 - val_loss: 591669.2500\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 59754.3867 - val_loss: 594006.8125\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 67535.6719 - val_loss: 339111.1562\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 60964.1875 - val_loss: 535333.6250\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 58862.3828 - val_loss: 391088.3125\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 56642.4766 - val_loss: 364226.6250\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 58867.3125 - val_loss: 426133.9688\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 60198.3984 - val_loss: 367917.0938\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 58271.1523 - val_loss: 358424.6562\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 3s 14ms/step - loss: 61266.8125 - val_loss: 351398.7500\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 61258.5781 - val_loss: 403990.0000\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 61253.3281 - val_loss: 317686.0938\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 56422.1133 - val_loss: 313770.9688\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 60174.3320 - val_loss: 337660.3125\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54574.2461 - val_loss: 355842.0938\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 57518.2812 - val_loss: 370861.4688\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 58828.9727 - val_loss: 409747.7188\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 59891.7109 - val_loss: 361782.1250\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 55503.1406 - val_loss: 336316.4688\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 58098.6953 - val_loss: 312496.9375\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 55682.2891 - val_loss: 325980.8438\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 2s 9ms/step - loss: 56558.1367 - val_loss: 320335.8750\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 53954.4648 - val_loss: 338071.9062\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 53832.4375 - val_loss: 327299.6562\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 59031.9766 - val_loss: 379656.5312\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 60152.1602 - val_loss: 321375.8125\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 55933.1602 - val_loss: 467844.1875\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 56292.6055 - val_loss: 354463.2812\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 64581.8906 - val_loss: 451393.8750\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 56828.4258 - val_loss: 414485.2188\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 64213.2930 - val_loss: 298146.4062\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 60645.5430 - val_loss: 391270.1250\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 57748.7227 - val_loss: 323438.6250\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 57428.3828 - val_loss: 370910.6250\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 53606.1953 - val_loss: 365127.0938\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 58896.7891 - val_loss: 326340.0312\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 54770.0195 - val_loss: 282040.7500\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 53715.1289 - val_loss: 275115.8750\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 55720.3789 - val_loss: 274410.7188\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 52784.6680 - val_loss: 278703.6562\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 58545.0977 - val_loss: 351023.9062\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 52080.1680 - val_loss: 363049.6875\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 52709.3359 - val_loss: 350148.3125\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 60100.7500 - val_loss: 314035.8125\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 58481.1797 - val_loss: 298324.2188\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 57071.8906 - val_loss: 309578.7812\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 58157.6641 - val_loss: 290208.5000\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 51511.1719 - val_loss: 350549.9688\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 58242.8516 - val_loss: 290819.8125\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 56847.4023 - val_loss: 297379.3125\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 57338.0273 - val_loss: 344196.7500\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 60073.0391 - val_loss: 296836.9688\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 56963.8945 - val_loss: 518592.5000\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 51602.8086 - val_loss: 377788.9375\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 56917.9375 - val_loss: 307463.1875\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 52971.9922 - val_loss: 343517.5312\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54024.6836 - val_loss: 357633.5312\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 51063.1836 - val_loss: 287811.7188\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 53727.5039 - val_loss: 282848.4375\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 55013.3789 - val_loss: 274117.1875\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 52984.9492 - val_loss: 283472.4688\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 49829.2500 - val_loss: 327948.9062\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 55682.4844 - val_loss: 357066.2500\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54284.7227 - val_loss: 285924.2188\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 57527.9258 - val_loss: 399130.4688\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 54247.9062 - val_loss: 270420.7812\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 55171.2227 - val_loss: 284891.3125\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 52618.3672 - val_loss: 276246.8125\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 52841.8164 - val_loss: 280314.5625\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 52793.7344 - val_loss: 280066.3125\n",
      "Epoch 222/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 55117.2227 - val_loss: 280265.6250\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54601.2852 - val_loss: 316614.3750\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50343.1758 - val_loss: 283861.5000\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54645.1836 - val_loss: 264886.2812\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 55558.2422 - val_loss: 263673.0625\n",
      "Epoch 227/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 56725.8633 - val_loss: 258411.0312\n",
      "Epoch 228/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 53514.5469 - val_loss: 277224.5000\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 47831.6875 - val_loss: 302968.0000\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54962.5625 - val_loss: 341184.5312\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 51523.7109 - val_loss: 323859.2188\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 50753.5859 - val_loss: 292470.0312\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 47720.5234 - val_loss: 361966.8125\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 52448.0430 - val_loss: 335762.1250\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48383.1211 - val_loss: 316255.0938\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 62313.9805 - val_loss: 356824.7500\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 49626.5078 - val_loss: 355775.3438\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 49914.8320 - val_loss: 304392.1875\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 56425.9766 - val_loss: 307575.4062\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 59117.7109 - val_loss: 365086.3438\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 51764.7969 - val_loss: 308303.1875\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 52008.7969 - val_loss: 286055.5625\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48124.1172 - val_loss: 299677.5312\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 51351.9648 - val_loss: 307069.0312\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 51954.9492 - val_loss: 300245.9688\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 49952.1914 - val_loss: 343316.9375\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50024.6641 - val_loss: 310072.4062\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50463.7070 - val_loss: 322395.0312\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 47764.9219 - val_loss: 304970.5625\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50790.5625 - val_loss: 323338.8750\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50222.8359 - val_loss: 331136.4375\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 52268.3438 - val_loss: 332387.3750\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 73167.0625 - val_loss: 292355.6875\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 49105.4844 - val_loss: 340724.5938\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 51171.0156 - val_loss: 334705.2500\n",
      "Epoch 256/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48336.7773 - val_loss: 318694.3438\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 47538.5039 - val_loss: 319215.9375\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 49420.4805 - val_loss: 338686.4375\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 52014.2891 - val_loss: 327761.2188\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48872.6719 - val_loss: 330991.4062\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 53951.4961 - val_loss: 308499.9688\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 51063.7422 - val_loss: 296843.4375\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48752.2969 - val_loss: 306108.4062\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 46900.0039 - val_loss: 301852.5938\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 46440.2578 - val_loss: 252856.7969\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50778.3984 - val_loss: 289071.5938\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 51349.3359 - val_loss: 370916.5312\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 51250.3047 - val_loss: 284272.0000\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 52433.9023 - val_loss: 318456.9062\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 51988.6719 - val_loss: 293790.9688\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50962.1953 - val_loss: 273973.1562\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50556.6250 - val_loss: 294633.0000\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48332.6523 - val_loss: 299012.6562\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48735.3633 - val_loss: 281350.5938\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48093.3320 - val_loss: 297559.4062\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50672.0820 - val_loss: 301869.3125\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48083.4102 - val_loss: 344643.0938\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54074.7578 - val_loss: 462104.1250\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50044.6875 - val_loss: 409578.3125\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50961.4180 - val_loss: 350698.1875\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 52209.1992 - val_loss: 315819.9062\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54101.4805 - val_loss: 358884.5312\n",
      "Epoch 283/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 44407.4609 - val_loss: 316059.0312\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 46945.0938 - val_loss: 290942.4062\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 46999.8242 - val_loss: 384439.7812\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48072.2305 - val_loss: 361336.5625\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 45512.6055 - val_loss: 326398.5312\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 45494.9648 - val_loss: 377487.5000\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 2s 10ms/step - loss: 50291.7422 - val_loss: 259486.5312\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 49423.2539 - val_loss: 406668.8125\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43377.8047 - val_loss: 339292.4375\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48749.1328 - val_loss: 283783.1562\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 46692.9258 - val_loss: 312741.6875\n",
      "Epoch 294/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43408.1758 - val_loss: 408070.1250\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 47267.7656 - val_loss: 274216.9062\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50955.2578 - val_loss: 295305.3750\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 56684.7930 - val_loss: 251819.5156\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48072.8672 - val_loss: 252365.3125\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 46703.1211 - val_loss: 256323.2344\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 49137.8164 - val_loss: 291033.1875\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54557.0430 - val_loss: 284153.8750\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 44660.1250 - val_loss: 299206.0000\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 45895.2383 - val_loss: 285988.0625\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42245.4570 - val_loss: 267975.6250\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 45938.7109 - val_loss: 257353.0938\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 46374.8398 - val_loss: 264490.8750\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43535.2891 - val_loss: 256695.9219\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 47526.4922 - val_loss: 268168.2188\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 46799.6016 - val_loss: 270395.5938\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43567.9336 - val_loss: 310064.5312\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 54047.0664 - val_loss: 659531.6875\n",
      "Epoch 312/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 43442.0664 - val_loss: 132796.0156\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 41643.7656 - val_loss: 108078.5000\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 48386.2812 - val_loss: 200085.5156\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 44250.2852 - val_loss: 231955.2656\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 46876.8594 - val_loss: 426389.2188\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43332.5820 - val_loss: 363313.6562\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48198.2109 - val_loss: 316852.2812\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 47703.9961 - val_loss: 355262.8438\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43617.4180 - val_loss: 161749.5781\n",
      "Epoch 321/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43625.6367 - val_loss: 337971.0938\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43681.2930 - val_loss: 226847.4844\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 44018.6211 - val_loss: 391085.8125\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 41558.4297 - val_loss: 314838.8125\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42092.1094 - val_loss: 145039.6719\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42955.0977 - val_loss: 206221.6094\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50508.2344 - val_loss: 490656.5625\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 49218.5977 - val_loss: 220634.8906\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42452.3555 - val_loss: 100565.9141\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 44737.8125 - val_loss: 153996.9531\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 44565.5586 - val_loss: 143132.9375\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43104.0742 - val_loss: 132429.8125\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 45130.7500 - val_loss: 568715.8750\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42054.0586 - val_loss: 260114.0625\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 44475.5352 - val_loss: 146663.2969\n",
      "Epoch 336/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43373.0273 - val_loss: 206299.1094\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 41926.4258 - val_loss: 207736.7188\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 40880.8633 - val_loss: 192952.4688\n",
      "Epoch 339/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 41608.1211 - val_loss: 189912.5156\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 48135.8828 - val_loss: 238315.7656\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 42003.6680 - val_loss: 261295.8594\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 43517.2734 - val_loss: 290892.6875\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 50591.2070 - val_loss: 120304.9062\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 51597.9336 - val_loss: 148802.6719\n",
      "Epoch 345/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 41416.8867 - val_loss: 139293.0781\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42360.8086 - val_loss: 145622.2969\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42071.8203 - val_loss: 178169.6875\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 43350.7539 - val_loss: 474866.0000\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 48024.6484 - val_loss: 185306.4062\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 44208.7227 - val_loss: 314921.8750\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42693.0117 - val_loss: 112701.5000\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42655.1406 - val_loss: 123203.4453\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 44485.6250 - val_loss: 120727.5000\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43903.2656 - val_loss: 115924.6641\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43404.3477 - val_loss: 156580.0469\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39750.7383 - val_loss: 147557.3438\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 40466.4141 - val_loss: 130552.1797\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 43861.1406 - val_loss: 149653.8125\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 46790.3789 - val_loss: 420432.6562\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 41568.4414 - val_loss: 100067.0391\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 42012.0430 - val_loss: 199447.9062\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 46612.0352 - val_loss: 203629.4688\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 46646.4336 - val_loss: 94578.9453\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 40997.8828 - val_loss: 83836.5156\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 43856.1992 - val_loss: 127950.0938\n",
      "Epoch 366/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 55578.6484 - val_loss: 104461.9062\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39106.4531 - val_loss: 98989.4219\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42723.7383 - val_loss: 91460.4844\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 45258.1328 - val_loss: 108980.8438\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 41280.9414 - val_loss: 121748.3672\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 44777.2188 - val_loss: 118544.6094\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 44460.4531 - val_loss: 89353.6562\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 40273.9336 - val_loss: 100486.3750\n",
      "Epoch 374/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 40563.4727 - val_loss: 89200.9531\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 40518.2969 - val_loss: 125514.4844\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 40883.8516 - val_loss: 104468.5000\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36443.7031 - val_loss: 176044.0625\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 41957.1055 - val_loss: 179378.6719\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 47243.8164 - val_loss: 77689.3672\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 45484.6992 - val_loss: 90181.5547\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 42983.3320 - val_loss: 89784.5859\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 42172.1289 - val_loss: 81655.0234\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37872.0625 - val_loss: 76019.3984\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 42943.8789 - val_loss: 72904.6875\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 40149.6172 - val_loss: 75703.1172\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 39994.5273 - val_loss: 68352.7734\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 38359.6641 - val_loss: 82370.0000\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38901.0078 - val_loss: 80653.9453\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38763.8281 - val_loss: 73629.0156\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37679.2109 - val_loss: 88380.6250\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 42651.4141 - val_loss: 114556.3516\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37292.0938 - val_loss: 90026.6172\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39963.6172 - val_loss: 325327.4375\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 38627.2422 - val_loss: 298295.3125\n",
      "Epoch 395/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39102.9805 - val_loss: 309155.3438\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 58888.3945 - val_loss: 87583.2656\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 41343.9023 - val_loss: 98634.2891\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 49589.9883 - val_loss: 228582.0312\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37303.1055 - val_loss: 137201.0469\n",
      "Epoch 400/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39804.7500 - val_loss: 103904.9609\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39433.9492 - val_loss: 121939.8516\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38617.3594 - val_loss: 108722.7656\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 41326.3242 - val_loss: 91796.2578\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39724.5781 - val_loss: 97181.1797\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 41184.1602 - val_loss: 96363.1328\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 41291.9766 - val_loss: 112370.9609\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39442.3594 - val_loss: 143715.8125\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 40287.7812 - val_loss: 119304.0703\n",
      "Epoch 409/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 39397.1953 - val_loss: 137697.3750\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 37386.6211 - val_loss: 122016.8750\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 38962.7930 - val_loss: 120123.9297\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 38707.8320 - val_loss: 96550.1562\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42618.5859 - val_loss: 101279.1875\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 40481.0938 - val_loss: 219905.6562\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35933.9609 - val_loss: 179770.6719\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35064.8594 - val_loss: 103874.5938\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38890.0469 - val_loss: 125184.1719\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38195.8906 - val_loss: 121697.1328\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39369.6836 - val_loss: 228140.1875\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36219.6445 - val_loss: 113690.3672\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38602.8633 - val_loss: 123283.6094\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37283.0156 - val_loss: 146714.4844\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37750.8984 - val_loss: 118269.3281\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34671.0977 - val_loss: 158430.4062\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37606.8750 - val_loss: 135641.8438\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 42178.7227 - val_loss: 134134.7188\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36459.1172 - val_loss: 137896.1406\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35348.3125 - val_loss: 164036.1875\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38058.9453 - val_loss: 168240.7344\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34381.4258 - val_loss: 145184.2969\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37188.0820 - val_loss: 121015.3438\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38459.4219 - val_loss: 152820.2344\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37115.4961 - val_loss: 103236.6484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39336.0352 - val_loss: 98082.5547\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36070.7383 - val_loss: 123752.0234\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39510.7188 - val_loss: 107198.2109\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 40799.8906 - val_loss: 169756.9844\n",
      "Epoch 438/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39900.8125 - val_loss: 111768.8984\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37687.0898 - val_loss: 95693.6484\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36541.0859 - val_loss: 84565.0469\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35997.7148 - val_loss: 93169.6562\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38564.4492 - val_loss: 272417.9375\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 41061.4844 - val_loss: 116529.0547\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 40791.8867 - val_loss: 105160.5703\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36864.5117 - val_loss: 89695.7031\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36643.5664 - val_loss: 65544.9922\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36052.6875 - val_loss: 103015.4375\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36302.2031 - val_loss: 100786.5703\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35486.8164 - val_loss: 138232.8906\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37607.3242 - val_loss: 127883.6328\n",
      "Epoch 451/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36851.9922 - val_loss: 133241.8125\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35999.9648 - val_loss: 115138.9219\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34753.2070 - val_loss: 160158.1719\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34871.3867 - val_loss: 146241.1875\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34749.7383 - val_loss: 158822.9062\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35177.9023 - val_loss: 146937.4219\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36459.8711 - val_loss: 154614.4844\n",
      "Epoch 458/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35331.7773 - val_loss: 128503.8516\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36474.0273 - val_loss: 110071.0781\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35874.5664 - val_loss: 137091.5156\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38931.1055 - val_loss: 136510.2656\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 33734.6523 - val_loss: 131694.6562\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36174.9844 - val_loss: 147390.5156\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34433.4258 - val_loss: 119971.8594\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35260.4922 - val_loss: 108973.6328\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34400.7539 - val_loss: 119721.2188\n",
      "Epoch 467/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 38506.9336 - val_loss: 125005.3594\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34310.2852 - val_loss: 118287.2734\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34527.3438 - val_loss: 131576.3438\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37436.1445 - val_loss: 130988.9688\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34345.0430 - val_loss: 109677.1172\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34461.6328 - val_loss: 110979.6953\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37875.2773 - val_loss: 83825.7812\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34964.7578 - val_loss: 98792.0781\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34330.1484 - val_loss: 100304.9453\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 33708.9297 - val_loss: 188929.9375\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39920.9102 - val_loss: 191693.8750\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35676.3828 - val_loss: 95961.1250\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34518.0078 - val_loss: 152117.5312\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37004.1484 - val_loss: 123698.5391\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 33559.3516 - val_loss: 127596.9766\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 35106.1445 - val_loss: 126218.3281\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 33587.5781 - val_loss: 126878.0859\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 33687.4414 - val_loss: 114998.5781\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35799.6328 - val_loss: 127792.6797\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 33917.1719 - val_loss: 125254.0000\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 34065.6172 - val_loss: 138095.3281\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35604.8281 - val_loss: 126003.7266\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35781.1289 - val_loss: 114668.7734\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 39445.5430 - val_loss: 112556.2891\n",
      "Epoch 491/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 33782.6211 - val_loss: 139031.0625\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 33802.1680 - val_loss: 134786.6250\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 36849.3711 - val_loss: 129281.5391\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35743.7070 - val_loss: 177064.2500\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37842.4844 - val_loss: 128050.0469\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 35288.9492 - val_loss: 149625.1406\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 37009.0625 - val_loss: 122400.7656\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 34930.0781 - val_loss: 128927.4297\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 32096.9961 - val_loss: 145986.7812\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 32231.7832 - val_loss: 121123.3750\n",
      "\n",
      "Training Multi Activation Neural Network w/ Dropout...\n",
      "Epoch 1/500\n",
      "185/185 [==============================] - 4s 13ms/step - loss: 423599.0625 - val_loss: 564550.5625\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 423297.6562 - val_loss: 564081.3750\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 422771.7500 - val_loss: 563612.9375\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 421997.7500 - val_loss: 562715.8750\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 420944.6562 - val_loss: 561730.3750\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 419722.6562 - val_loss: 560589.4375\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 418142.3125 - val_loss: 559087.8125\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 416418.4688 - val_loss: 557410.1250\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 414424.5938 - val_loss: 555091.0625\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 412432.9375 - val_loss: 553257.8750\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 410053.1562 - val_loss: 550722.4375\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 408161.0000 - val_loss: 548242.3750\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 405968.9375 - val_loss: 546505.2500\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 404302.8438 - val_loss: 544094.3750\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 402091.7812 - val_loss: 542939.8750\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 400133.0938 - val_loss: 540289.8750\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 398481.7812 - val_loss: 538802.1875\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 396437.2500 - val_loss: 536487.3750\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 394680.3750 - val_loss: 534742.1250\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 392935.7500 - val_loss: 533012.2500\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 391411.0938 - val_loss: 531699.8125\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 389789.4375 - val_loss: 529532.8750\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 388994.8750 - val_loss: 528001.5625\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 387440.2812 - val_loss: 526970.0625\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 386843.3750 - val_loss: 525844.6250\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 384902.7812 - val_loss: 524796.3125\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 383165.0625 - val_loss: 523961.9375\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 383347.8750 - val_loss: 522054.4062\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 383707.0000 - val_loss: 521884.0000\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 382556.1562 - val_loss: 521165.3438\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 382315.6250 - val_loss: 520197.0938\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 381058.0938 - val_loss: 518500.9062\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 379527.7500 - val_loss: 518516.4688\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 380358.7188 - val_loss: 517642.2188\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 379371.9688 - val_loss: 517398.8438\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 379963.1250 - val_loss: 517115.6875\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 379733.6250 - val_loss: 515776.0312\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 380222.7188 - val_loss: 514625.3125\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 378347.0000 - val_loss: 514740.1250\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 378268.8125 - val_loss: 514471.1250\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 377284.1875 - val_loss: 513827.1250\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 379640.3438 - val_loss: 511506.0000\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 377035.0312 - val_loss: 511351.1875\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 376598.0000 - val_loss: 514279.2188\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 378131.9375 - val_loss: 513535.5938\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 375306.6562 - val_loss: 514250.6250\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 377213.0312 - val_loss: 514500.9062\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 378717.8438 - val_loss: 513241.4688\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 378669.0000 - val_loss: 513395.0625\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 376554.8750 - val_loss: 512309.0938\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 374756.9375 - val_loss: 512930.3438\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 375612.9375 - val_loss: 512364.3438\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 375396.9375 - val_loss: 513671.7188\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 375591.1562 - val_loss: 512577.7812\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 373730.5625 - val_loss: 514092.9688\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 374726.4688 - val_loss: 513474.6875\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 375851.0312 - val_loss: 513391.8125\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 378273.9375 - val_loss: 509390.5625\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 373574.4062 - val_loss: 513323.6875\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 373186.1875 - val_loss: 513663.0938\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 372677.3125 - val_loss: 511834.7812\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 371598.3438 - val_loss: 511021.1562\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 372385.3438 - val_loss: 508124.5938\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 371360.8438 - val_loss: 512909.7188\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 372363.5312 - val_loss: 513190.6562\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 368664.3438 - val_loss: 515149.9688\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 369691.9375 - val_loss: 514119.5000\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 366899.5938 - val_loss: 514668.8125\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 367414.5000 - val_loss: 512203.1875\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 368385.8750 - val_loss: 512257.5938\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 367980.4375 - val_loss: 508362.5000\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 368130.3125 - val_loss: 508310.6562\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 363204.0938 - val_loss: 511317.0312\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 364639.2812 - val_loss: 500766.0000\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 364594.3750 - val_loss: 475795.8750\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 364633.5312 - val_loss: 503048.5312\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 361670.9688 - val_loss: 509197.6875\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 2s 10ms/step - loss: 356987.4375 - val_loss: 509630.5000\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 362936.9375 - val_loss: 501078.3438\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 362606.2812 - val_loss: 493375.8438\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 356809.3125 - val_loss: 506282.7500\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 358633.0000 - val_loss: 507635.5312\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 359918.2812 - val_loss: 505611.9062\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 352109.5000 - val_loss: 490158.7500\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 349955.1562 - val_loss: 500816.7500\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 354261.3750 - val_loss: 497337.1562\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 351152.5938 - val_loss: 483914.1250\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 351518.2188 - val_loss: 490631.0938\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 351883.0312 - val_loss: 450523.0938\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 344043.9375 - val_loss: 478742.6875\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 349839.8438 - val_loss: 485782.0938\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 340747.0938 - val_loss: 485451.5312\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 331688.7500 - val_loss: 493084.2500\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 334782.7500 - val_loss: 487433.9062\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 332988.4688 - val_loss: 489884.4375\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 336691.1250 - val_loss: 484801.5000\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 325417.0000 - val_loss: 484855.1250\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 334312.5000 - val_loss: 477178.4688\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 331364.2812 - val_loss: 472112.4688\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 323210.8438 - val_loss: 479675.9062\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 338888.8750 - val_loss: 470927.4375\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 320436.4688 - val_loss: 482555.4062\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 327570.9062 - val_loss: 457603.6875\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 327602.3750 - val_loss: 478004.3750\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 323254.5312 - val_loss: 478666.2812\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 329219.5312 - val_loss: 438582.8125\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 324301.0625 - val_loss: 455670.1875\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 306353.0625 - val_loss: 456298.9062\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 317780.0625 - val_loss: 428047.6875\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 314401.8438 - val_loss: 312646.0000\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 315031.5312 - val_loss: 265532.7500\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 316003.7812 - val_loss: 468369.0625\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 300134.1250 - val_loss: 466662.3750\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 306227.4688 - val_loss: 461972.5625\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 287390.1562 - val_loss: 472505.3750\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 301264.9375 - val_loss: 465209.4375\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 296666.2188 - val_loss: 463280.5938\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 308650.4062 - val_loss: 468733.1875\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 292745.0938 - val_loss: 460381.5312\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 292518.2500 - val_loss: 463521.8438\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 294014.0312 - val_loss: 460901.7812\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 299477.2188 - val_loss: 457611.3750\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 291358.3438 - val_loss: 455182.6875\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 287057.0938 - val_loss: 462367.8125\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 295285.9688 - val_loss: 453934.8125\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 282896.0312 - val_loss: 454387.0000\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 286813.4375 - val_loss: 455715.9375\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 294274.3125 - val_loss: 452141.8438\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 282253.3438 - val_loss: 459108.6562\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 298849.3750 - val_loss: 464955.5938\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 280995.8438 - val_loss: 449543.6562\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 274417.9688 - val_loss: 457009.1875\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 285466.5312 - val_loss: 442728.3750\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 267209.7188 - val_loss: 451372.4688\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 275295.4375 - val_loss: 453874.6875\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 296262.8750 - val_loss: 440538.0938\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 279980.5625 - val_loss: 445634.5625\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 261780.8594 - val_loss: 452181.7500\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 284907.0938 - val_loss: 444594.9375\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 278649.7500 - val_loss: 449597.6562\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 274841.7500 - val_loss: 454264.5938\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 257119.2500 - val_loss: 446118.7812\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 267986.5938 - val_loss: 443152.9062\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 264819.8750 - val_loss: 455141.6250\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 279829.2812 - val_loss: 417257.7812\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 254855.1094 - val_loss: 450273.4375\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 267993.6875 - val_loss: 446595.6875\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 264688.7812 - val_loss: 445664.3125\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 259415.0625 - val_loss: 433354.8438\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 275752.5312 - val_loss: 440111.9375\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 243646.5156 - val_loss: 440151.1250\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 260626.3906 - val_loss: 434230.4375\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 253178.1562 - val_loss: 435807.4688\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 248355.0156 - val_loss: 422412.1250\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 263342.3438 - val_loss: 403767.8750\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 255448.7344 - val_loss: 437101.3438\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 260587.8906 - val_loss: 436386.5625\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 248119.3281 - val_loss: 431438.8750\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 306075.9062 - val_loss: 454100.2500\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 274378.1250 - val_loss: 454766.5938\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 269617.8750 - val_loss: 441278.2188\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 250644.3125 - val_loss: 431725.0625\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 253427.5312 - val_loss: 431356.4375\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 242742.2656 - val_loss: 420875.3750\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 253973.3125 - val_loss: 457293.0000\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 249528.8906 - val_loss: 421845.2812\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 261261.6094 - val_loss: 352398.2188\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 234530.9062 - val_loss: 418241.1250\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 239923.7188 - val_loss: 414475.8750\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 224737.9688 - val_loss: 427069.3125\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 226252.9688 - val_loss: 418444.0000\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 240449.4531 - val_loss: 424298.7188\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 246495.1250 - val_loss: 417656.9688\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 230551.5625 - val_loss: 409576.7188\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 233466.9844 - val_loss: 384063.7500\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 217490.0625 - val_loss: 416628.5000\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 226170.9531 - val_loss: 406154.0938\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 239702.2031 - val_loss: 399034.8750\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 230376.7969 - val_loss: 409939.7500\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 259883.1406 - val_loss: 447398.6562\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 231368.1719 - val_loss: 388558.6250\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 215319.8125 - val_loss: 385667.6250\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 229814.8125 - val_loss: 399940.1250\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 219354.4688 - val_loss: 383459.5312\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 232235.3594 - val_loss: 413664.3750\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 342810.7500 - val_loss: 456683.5000\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 290144.3438 - val_loss: 417698.3438\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 248888.5312 - val_loss: 386449.9688\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 227542.8594 - val_loss: 405332.8750\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 233202.4688 - val_loss: 367172.7500\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 227269.2344 - val_loss: 365766.8438\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 218329.3750 - val_loss: 386533.5938\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 212292.5781 - val_loss: 408152.3125\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 221894.9062 - val_loss: 362849.8750\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 213058.8906 - val_loss: 385681.0000\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 207209.4844 - val_loss: 402421.6875\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 222204.3750 - val_loss: 365516.2500\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 231590.1250 - val_loss: 395319.8438\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 201277.6094 - val_loss: 369973.1875\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 227890.7188 - val_loss: 338141.0312\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 217568.1562 - val_loss: 385449.5625\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 199115.5625 - val_loss: 383442.1562\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 195392.2812 - val_loss: 370480.4062\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 206518.5469 - val_loss: 379695.0312\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 237665.3594 - val_loss: 386569.5625\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 252812.6719 - val_loss: 411383.7812\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 211615.0469 - val_loss: 391458.1250\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 210357.1094 - val_loss: 382631.1875\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 216123.9375 - val_loss: 378865.0000\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 201599.0156 - val_loss: 397137.6875\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 213608.8594 - val_loss: 383478.3438\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 206145.3906 - val_loss: 393292.8438\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 178751.2969 - val_loss: 399466.1250\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 185066.0938 - val_loss: 401111.4062\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 212020.5000 - val_loss: 396863.1562\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 196836.8594 - val_loss: 404233.5938\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 182579.0625 - val_loss: 409780.3125\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 232213.4219 - val_loss: 366242.9062\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 178365.9531 - val_loss: 392409.4062\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 199997.7188 - val_loss: 383195.9688\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 191421.3906 - val_loss: 416629.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 187372.5469 - val_loss: 389339.0938\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 176572.7812 - val_loss: 397963.0312\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 182567.0781 - val_loss: 396936.0625\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 208043.9375 - val_loss: 389601.6562\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 183484.3438 - val_loss: 419839.5938\n",
      "Epoch 227/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 179619.5469 - val_loss: 397200.0938\n",
      "Epoch 228/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 157648.8906 - val_loss: 399140.9062\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 197863.1562 - val_loss: 373669.0000\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 196335.6406 - val_loss: 358556.4688\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 193417.2188 - val_loss: 381253.2188\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 187967.2188 - val_loss: 396454.7500\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 176084.3125 - val_loss: 393301.4375\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 182062.8438 - val_loss: 380984.2812\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 193339.0469 - val_loss: 385745.1875\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 200054.5625 - val_loss: 363404.7500\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 191369.7969 - val_loss: 373743.1250\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 201056.3438 - val_loss: 365922.7812\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 185431.5312 - val_loss: 371719.7500\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 187996.8594 - val_loss: 387103.6875\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 195037.2500 - val_loss: 386079.9375\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 198031.8281 - val_loss: 386716.3125\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 210773.3906 - val_loss: 369295.5938\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 170536.9375 - val_loss: 375474.1250\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 180240.3906 - val_loss: 380189.1875\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 170632.0469 - val_loss: 398485.2812\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 177288.0938 - val_loss: 380864.8125\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 202834.3438 - val_loss: 405165.6875\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 183522.4062 - val_loss: 387717.2500\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 173672.2344 - val_loss: 433310.3125\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 174939.1719 - val_loss: 399209.1562\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 169321.6875 - val_loss: 407551.3125\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 204235.6250 - val_loss: 389151.7812\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 199830.6406 - val_loss: 392023.1875\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 186510.0000 - val_loss: 373561.1562\n",
      "Epoch 256/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 187271.5156 - val_loss: 370927.5312\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 181442.6250 - val_loss: 383181.4062\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 164453.1719 - val_loss: 373875.4688\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 175071.6875 - val_loss: 362345.8125\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 201856.0469 - val_loss: 387080.8125\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 161797.7500 - val_loss: 370734.2500\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 177922.9844 - val_loss: 373295.4688\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 192252.2656 - val_loss: 380290.8750\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 205764.2344 - val_loss: 380188.1875\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 189409.9844 - val_loss: 403166.7188\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 173880.3906 - val_loss: 416398.0000\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 178320.6094 - val_loss: 378583.4062\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 199017.3750 - val_loss: 376678.0000\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 161132.9688 - val_loss: 356400.0938\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 176433.2188 - val_loss: 364719.6875\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 166498.9062 - val_loss: 387805.3750\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 181760.7969 - val_loss: 400953.3125\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 158758.3125 - val_loss: 386018.5312\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 160339.5625 - val_loss: 374114.2188\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 137760.4531 - val_loss: 369201.7500\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 169100.4844 - val_loss: 383459.2812\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 178839.7031 - val_loss: 380936.9375\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 189883.7031 - val_loss: 362142.1250\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 180879.4219 - val_loss: 362388.6250\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 196315.9844 - val_loss: 381971.0625\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 135504.4219 - val_loss: 375126.5938\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 171845.3594 - val_loss: 360315.8438\n",
      "Epoch 283/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 168088.1250 - val_loss: 362894.2188\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 157007.1719 - val_loss: 365728.7812\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 142550.1250 - val_loss: 383900.0000\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 176678.0781 - val_loss: 356969.0000\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 171055.3438 - val_loss: 365216.8438\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 141779.1406 - val_loss: 362991.6875\n",
      "Epoch 289/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 178037.8438 - val_loss: 365088.5625\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 163981.0625 - val_loss: 389257.5312\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 159638.6562 - val_loss: 326916.7188\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 158084.2812 - val_loss: 361274.6875\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 165974.4531 - val_loss: 384534.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 171419.0938 - val_loss: 384833.5000\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 147361.6406 - val_loss: 396465.3125\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 158483.5156 - val_loss: 365217.2812\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 174646.0000 - val_loss: 366067.6562\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 160723.7188 - val_loss: 352045.0625\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 159597.3594 - val_loss: 383151.8750\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 152532.5625 - val_loss: 393118.3438\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 164385.7344 - val_loss: 382852.0938\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 178261.1406 - val_loss: 368072.4688\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 175722.6094 - val_loss: 352624.5625\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 171670.1875 - val_loss: 363363.4688\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 165281.1875 - val_loss: 382349.7500\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 160359.7031 - val_loss: 376732.2812\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 169801.3906 - val_loss: 311327.6250\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 178095.0781 - val_loss: 354312.0000\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 183676.7188 - val_loss: 367370.1562\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 159234.4375 - val_loss: 363377.2188\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 168929.6875 - val_loss: 340078.3125\n",
      "Epoch 312/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 169552.4375 - val_loss: 362728.4688\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 133699.9688 - val_loss: 366523.4688\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 139277.6406 - val_loss: 365862.8125\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 149084.0625 - val_loss: 359395.9688\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 160288.2656 - val_loss: 386842.2188\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 194476.0312 - val_loss: 363373.9062\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 140608.5000 - val_loss: 352050.5938\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 159393.3438 - val_loss: 363972.7812\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 174951.4688 - val_loss: 359101.8438\n",
      "Epoch 321/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 157291.0469 - val_loss: 475278.6562\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 160358.4375 - val_loss: 367552.0312\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 155219.3281 - val_loss: 387832.0625\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 152326.8594 - val_loss: 387765.6875\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 148908.0469 - val_loss: 374708.7188\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 162566.6719 - val_loss: 370108.3750\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 167149.9688 - val_loss: 358403.6875\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 149858.2031 - val_loss: 362045.9375\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 159833.2812 - val_loss: 366793.9062\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 151462.9375 - val_loss: 371834.5312\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 138652.9531 - val_loss: 369282.9375\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 160686.9375 - val_loss: 373986.3125\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 158400.3750 - val_loss: 407197.9688\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 179007.5781 - val_loss: 353315.1250\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 144614.1094 - val_loss: 362344.7500\n",
      "Epoch 336/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 150004.7500 - val_loss: 373855.3750\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 157860.1094 - val_loss: 361201.5312\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 135135.8750 - val_loss: 375720.0938\n",
      "Epoch 339/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 169267.5625 - val_loss: 365814.0000\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 157603.5625 - val_loss: 379268.5312\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 159845.7969 - val_loss: 360000.4375\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 151518.3281 - val_loss: 417085.1875\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 151766.4219 - val_loss: 362304.7812\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 163102.8906 - val_loss: 404604.3125\n",
      "Epoch 345/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 122785.3438 - val_loss: 351224.4062\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 168606.9062 - val_loss: 341157.4062\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 140289.9375 - val_loss: 387761.0938\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 142694.7812 - val_loss: 362630.8438\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 130946.0625 - val_loss: 359740.0000\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 153076.4219 - val_loss: 388683.4062\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 140796.5625 - val_loss: 363264.8125\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 139963.8125 - val_loss: 352202.9062\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 163343.7500 - val_loss: 380534.8438\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 146283.8438 - val_loss: 393911.8750\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 147748.6406 - val_loss: 357991.4375\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 174075.8438 - val_loss: 365420.5000\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 176787.0938 - val_loss: 382442.1875\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 167180.7969 - val_loss: 368566.1562\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 167903.3750 - val_loss: 439775.5938\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 138298.9531 - val_loss: 381905.1562\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 135576.3438 - val_loss: 375792.4062\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 150635.3594 - val_loss: 381097.4062\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 145424.0625 - val_loss: 369186.1250\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 136309.2812 - val_loss: 324414.5312\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 148638.0938 - val_loss: 378387.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 159554.9062 - val_loss: 332192.7500\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 122088.7891 - val_loss: 331561.3125\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 162219.7656 - val_loss: 322056.9062\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 151475.8750 - val_loss: 341388.0625\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 128571.3047 - val_loss: 327792.7188\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 154469.2656 - val_loss: 326057.4062\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 138802.1094 - val_loss: 331171.1250\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 162338.9219 - val_loss: 326423.1250\n",
      "Epoch 374/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 148467.7500 - val_loss: 325271.1875\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 162211.8281 - val_loss: 342915.4688\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 140580.5312 - val_loss: 340822.4062\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 140001.8750 - val_loss: 301826.3438\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 161446.5781 - val_loss: 320661.7188\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 149301.4062 - val_loss: 378074.0625\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 135726.9531 - val_loss: 322013.0625\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 157230.8125 - val_loss: 363826.6250\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 164579.1562 - val_loss: 332422.8125\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 156787.9531 - val_loss: 324911.0312\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 150275.6406 - val_loss: 308737.7500\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 140648.6250 - val_loss: 323910.1250\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 153130.4062 - val_loss: 319436.0625\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 140130.7344 - val_loss: 312842.8750\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 148509.0625 - val_loss: 317057.6875\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 140735.9375 - val_loss: 328756.7500\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 149949.9531 - val_loss: 326729.7812\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 125608.7109 - val_loss: 328583.3750\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 153307.9375 - val_loss: 490402.4688\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 144333.5781 - val_loss: 306889.4062\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 164818.1406 - val_loss: 325974.3125\n",
      "Epoch 395/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 147178.9531 - val_loss: 331197.2188\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 163753.5469 - val_loss: 515769.2188\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 156070.6250 - val_loss: 322649.9062\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 138768.2812 - val_loss: 317181.7500\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 162337.5625 - val_loss: 324105.7188\n",
      "Epoch 400/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 137627.6406 - val_loss: 329599.1875\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 151027.8594 - val_loss: 323550.3125\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 129987.8828 - val_loss: 326514.9375\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 147282.4062 - val_loss: 330731.4375\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 139969.3750 - val_loss: 328632.8125\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 133973.2031 - val_loss: 323460.8438\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 150030.2812 - val_loss: 327595.1875\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 151360.7188 - val_loss: 336386.3750\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 133257.3594 - val_loss: 322104.9062\n",
      "Epoch 409/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 154120.8594 - val_loss: 357604.6250\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 144492.9844 - val_loss: 328432.3125\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 144888.3906 - val_loss: 325710.9062\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 153174.4219 - val_loss: 328590.3125\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 154535.6094 - val_loss: 318440.5625\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 130621.4141 - val_loss: 333525.3438\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 164602.8594 - val_loss: 333900.3125\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 141222.7188 - val_loss: 327426.5000\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 145244.2031 - val_loss: 321839.0938\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 147825.5156 - val_loss: 322189.0000\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 158053.7969 - val_loss: 293323.1250\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 138273.1562 - val_loss: 313371.2500\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 149038.7188 - val_loss: 312179.3438\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 130442.4297 - val_loss: 331802.6250\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 131301.6250 - val_loss: 364258.9688\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 134467.8906 - val_loss: 331237.4688\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 159458.9688 - val_loss: 327315.7812\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 147566.8281 - val_loss: 319242.7188\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 135965.9844 - val_loss: 312029.6875\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 123828.6016 - val_loss: 316064.5625\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 138345.1562 - val_loss: 305662.0625\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 138308.6250 - val_loss: 298623.4062\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 134081.7656 - val_loss: 294610.2500\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 130716.9062 - val_loss: 295279.8125\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 145863.4375 - val_loss: 268047.2500\n",
      "Epoch 434/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 135897.5156 - val_loss: 287648.9688\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 125389.2969 - val_loss: 294636.0000\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 123539.7578 - val_loss: 264409.7812\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 231335.7031 - val_loss: 303828.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 161458.9688 - val_loss: 401358.2500\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 139902.6094 - val_loss: 335025.2812\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 144231.0625 - val_loss: 336972.7500\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 149774.2812 - val_loss: 316890.0625\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 145645.1719 - val_loss: 308568.9062\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 142728.6094 - val_loss: 306587.4062\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 141170.0312 - val_loss: 336198.6250\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 161359.9219 - val_loss: 308281.6875\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 141442.4062 - val_loss: 314033.5312\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 134022.4375 - val_loss: 315365.0938\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 132448.0156 - val_loss: 299234.2188\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 126522.6406 - val_loss: 292541.3438\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 122989.3438 - val_loss: 305975.4375\n",
      "Epoch 451/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 137789.0938 - val_loss: 304517.0938\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 135818.9219 - val_loss: 317714.8438\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 133761.6562 - val_loss: 295237.1250\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 145824.6406 - val_loss: 302615.7500\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 144785.1719 - val_loss: 301407.3438\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 120836.0625 - val_loss: 302188.3750\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 152902.8750 - val_loss: 332941.5000\n",
      "Epoch 458/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 131462.7188 - val_loss: 332203.7812\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 124777.5859 - val_loss: 312359.2500\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 140456.5781 - val_loss: 310750.7500\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 138229.1094 - val_loss: 334108.1250\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 144364.5781 - val_loss: 389657.2188\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 120074.6719 - val_loss: 361911.0000\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 147449.0000 - val_loss: 361455.5000\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 141814.0312 - val_loss: 301819.8125\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 140948.5469 - val_loss: 309950.0000\n",
      "Epoch 467/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 162492.2500 - val_loss: 304437.9375\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 156056.9531 - val_loss: 333529.6875\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 142857.8594 - val_loss: 335204.5625\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 155719.0469 - val_loss: 364497.6250\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 140434.1250 - val_loss: 323362.5625\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 134975.2812 - val_loss: 314930.1875\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 139192.7031 - val_loss: 307106.1250\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 138190.5000 - val_loss: 340396.6875\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 126926.7969 - val_loss: 315889.2812\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 145400.5938 - val_loss: 325793.6562\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 154339.2656 - val_loss: 257526.8594\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 138207.5938 - val_loss: 316242.0625\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 128743.9844 - val_loss: 297836.0000\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 137497.2031 - val_loss: 294419.1562\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 134855.9375 - val_loss: 270665.8125\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 136649.6562 - val_loss: 290508.3750\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 138059.8750 - val_loss: 261171.5781\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 145026.2344 - val_loss: 256324.5781\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 138316.8594 - val_loss: 268897.4062\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 125854.2812 - val_loss: 232581.2969\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 147405.0000 - val_loss: 292299.5625\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 127596.7344 - val_loss: 243156.9531\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 125973.9375 - val_loss: 261210.2344\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 142792.0781 - val_loss: 223829.5156\n",
      "Epoch 491/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 147433.7344 - val_loss: 250326.5156\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 127220.4531 - val_loss: 253521.8281\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 144794.6250 - val_loss: 247578.7500\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 136696.2812 - val_loss: 264942.4062\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 146860.4844 - val_loss: 252145.0469\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 128474.4453 - val_loss: 306793.8125\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 145256.1250 - val_loss: 329071.6562\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 119394.0938 - val_loss: 329422.4062\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 148973.9375 - val_loss: 292394.9688\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 145293.0000 - val_loss: 296139.9375\n",
      "Finished.\n",
      "Training Sigmoid Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "185/185 [==============================] - 3s 8ms/step - loss: 423083.8125 - val_loss: 564653.5000\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 422265.9062 - val_loss: 564329.1875\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 420754.4375 - val_loss: 564407.8125\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 417467.6250 - val_loss: 561167.2500\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 413682.3125 - val_loss: 554672.3125\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 409835.3438 - val_loss: 546909.6250\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 406346.5312 - val_loss: 543666.6250\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 401760.6562 - val_loss: 535719.3750\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 396990.1875 - val_loss: 533906.8125\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 392615.9062 - val_loss: 528509.0000\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 386636.5312 - val_loss: 514262.0312\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 382980.1250 - val_loss: 518508.0625\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 377273.7500 - val_loss: 510329.5000\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 371395.9375 - val_loss: 507257.7500\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 366662.8438 - val_loss: 497299.2812\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 362178.7188 - val_loss: 496732.0312\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 357894.4688 - val_loss: 485447.9062\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 351307.5938 - val_loss: 481703.0938\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 346708.0000 - val_loss: 473888.1875\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 343493.8438 - val_loss: 470647.9062\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 337628.4375 - val_loss: 463815.1875\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 330465.1562 - val_loss: 489730.8125\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 328121.9062 - val_loss: 455565.1875\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 322068.1562 - val_loss: 449093.2188\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 320716.0625 - val_loss: 440262.6875\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 312518.9375 - val_loss: 434603.6875\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 312750.9688 - val_loss: 427695.4375\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 303733.3750 - val_loss: 419283.2812\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 295241.3125 - val_loss: 415429.7812\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 295724.7812 - val_loss: 408482.4375\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 291714.4375 - val_loss: 400970.8438\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 286543.6250 - val_loss: 395758.4375\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 280527.6250 - val_loss: 392729.5625\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 279090.7500 - val_loss: 384083.3125\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 273431.6250 - val_loss: 380487.6875\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 270572.6875 - val_loss: 373617.5938\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 265482.0312 - val_loss: 369567.0938\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 263513.8750 - val_loss: 365880.6250\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 261321.2969 - val_loss: 356632.9375\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 257611.7500 - val_loss: 357042.7500\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 253868.5000 - val_loss: 346377.2500\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 245961.2969 - val_loss: 339409.7500\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 246447.2656 - val_loss: 336915.7500\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 238259.3281 - val_loss: 329926.2188\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 232772.6719 - val_loss: 325562.5938\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 224839.2969 - val_loss: 322859.2188\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 221501.9375 - val_loss: 316981.5312\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 220399.5469 - val_loss: 309698.8438\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 219721.6719 - val_loss: 307526.8125\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 212840.9375 - val_loss: 302023.1875\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 207535.3281 - val_loss: 296208.7188\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 205029.2031 - val_loss: 289931.2188\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 196447.0156 - val_loss: 286697.0000\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 191669.0469 - val_loss: 281062.1250\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 189018.5781 - val_loss: 278285.2812\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 182176.7656 - val_loss: 272971.9062\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 193434.7344 - val_loss: 278229.0312\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 182217.0469 - val_loss: 264902.1562\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 169653.8281 - val_loss: 259674.2188\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 170128.2812 - val_loss: 254670.8281\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 162365.8438 - val_loss: 255680.3125\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 174993.1562 - val_loss: 249848.8438\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 163534.0781 - val_loss: 244477.2344\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 164238.0781 - val_loss: 241303.3281\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 152737.4531 - val_loss: 237145.6094\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 152101.9062 - val_loss: 235011.0000\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 153803.2188 - val_loss: 250337.3906\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 144920.9844 - val_loss: 226463.1562\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 143029.3906 - val_loss: 225090.0312\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 136299.0781 - val_loss: 222489.6250\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 124535.8906 - val_loss: 220982.7812\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 134357.3438 - val_loss: 214835.7188\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 134268.9219 - val_loss: 214807.6875\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 118048.0859 - val_loss: 213489.9062\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 123985.4375 - val_loss: 211245.5469\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 123265.9141 - val_loss: 208700.4531\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 119548.5234 - val_loss: 210572.3438\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 118408.0625 - val_loss: 207326.3594\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 114726.4297 - val_loss: 202718.7188\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 128144.3125 - val_loss: 203188.0312\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 105966.3750 - val_loss: 198129.0781\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 112739.9844 - val_loss: 196227.7656\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 113363.3750 - val_loss: 196239.7500\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 102408.4609 - val_loss: 194610.1875\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 112417.6328 - val_loss: 191246.7812\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 99881.3047 - val_loss: 181374.5781\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 97990.2891 - val_loss: 180702.1406\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 98726.4531 - val_loss: 169524.1875\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 102438.7266 - val_loss: 273317.7500\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 105935.6562 - val_loss: 171297.2812\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 98280.7109 - val_loss: 173292.4219\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 90240.7344 - val_loss: 168015.2188\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 86338.9844 - val_loss: 167233.2031\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 80165.4219 - val_loss: 170668.7344\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 84127.3750 - val_loss: 171946.5156\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 90038.0234 - val_loss: 173037.9844\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 84159.3359 - val_loss: 168649.8125\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85071.3750 - val_loss: 166771.5312\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 77528.4219 - val_loss: 169119.5312\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 76483.3828 - val_loss: 162446.8750\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 78135.1953 - val_loss: 168576.5781\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 81271.8828 - val_loss: 158989.0312\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70231.1797 - val_loss: 157879.7031\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 75809.4375 - val_loss: 156080.3281\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71824.5547 - val_loss: 169006.4688\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 76109.4922 - val_loss: 168342.8750\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71162.7734 - val_loss: 170568.9375\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 73314.9375 - val_loss: 166725.0469\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68832.7422 - val_loss: 163166.9375\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 79976.2422 - val_loss: 175101.5156\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67728.6875 - val_loss: 168361.0156\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69826.3828 - val_loss: 155312.8594\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71101.2031 - val_loss: 159592.5156\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 66840.0156 - val_loss: 158079.3906\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 78286.1797 - val_loss: 216181.1094\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 95334.2031 - val_loss: 158327.5625\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 72761.6797 - val_loss: 159585.0625\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68656.1172 - val_loss: 160750.4375\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62350.8594 - val_loss: 159326.5000\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59045.8984 - val_loss: 160012.3750\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59546.0117 - val_loss: 158470.0000\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66453.9609 - val_loss: 157021.2031\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61692.5352 - val_loss: 160107.0938\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69477.3516 - val_loss: 161148.4844\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61908.9219 - val_loss: 162496.5312\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61300.8477 - val_loss: 160849.5625\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64183.9141 - val_loss: 160890.1406\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57706.3008 - val_loss: 161028.5156\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61131.3711 - val_loss: 161496.0781\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64321.8867 - val_loss: 161132.4062\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62872.0078 - val_loss: 184877.1875\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 78383.4688 - val_loss: 165336.3750\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65287.0234 - val_loss: 157998.7344\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58262.4531 - val_loss: 162108.0625\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60249.3320 - val_loss: 160909.9844\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 84712.1094 - val_loss: 285640.8438\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 72403.1797 - val_loss: 223383.4844\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 74152.2891 - val_loss: 198918.6875\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 75624.3672 - val_loss: 164946.6094\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62725.3750 - val_loss: 160864.1719\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61723.2695 - val_loss: 161811.8906\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63546.6641 - val_loss: 160054.7500\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 59050.7617 - val_loss: 162471.7344\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 65392.6523 - val_loss: 159829.3750\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 55818.9648 - val_loss: 157705.8438\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58625.1211 - val_loss: 160379.0938\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 63870.7656 - val_loss: 165577.8281\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64168.5586 - val_loss: 166214.4219\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60989.3359 - val_loss: 159240.8281\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63471.1680 - val_loss: 160394.8594\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61541.8555 - val_loss: 157402.9062\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65473.5703 - val_loss: 161471.7031\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58495.0586 - val_loss: 164760.6250\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59062.4258 - val_loss: 161369.4219\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63426.8516 - val_loss: 157673.0156\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58834.5117 - val_loss: 163096.5469\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56019.2773 - val_loss: 161441.5625\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68062.8203 - val_loss: 160923.7344\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60011.7070 - val_loss: 169696.4375\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62109.1055 - val_loss: 162602.8438\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59431.6055 - val_loss: 161938.7344\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57310.9180 - val_loss: 162397.9375\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57416.5469 - val_loss: 162715.6406\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63707.4688 - val_loss: 166130.9688\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58793.9648 - val_loss: 156861.5312\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63316.0312 - val_loss: 161514.4219\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 61323.6094 - val_loss: 155578.5469\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 61570.4570 - val_loss: 163501.2500\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54691.1523 - val_loss: 160237.4219\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61243.2031 - val_loss: 168776.3594\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62488.3398 - val_loss: 154728.6562\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62205.7617 - val_loss: 170934.2188\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57840.0859 - val_loss: 163469.7188\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60150.0469 - val_loss: 160513.5938\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53264.8359 - val_loss: 163426.8281\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56294.4375 - val_loss: 153859.3594\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65849.0000 - val_loss: 166022.6562\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 72313.8594 - val_loss: 184477.3281\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63043.3047 - val_loss: 183891.2812\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 61618.3359 - val_loss: 169526.4844\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63822.7344 - val_loss: 161123.0000\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66084.0938 - val_loss: 165236.3281\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60334.3320 - val_loss: 155872.4062\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64176.1680 - val_loss: 161583.1875\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53357.5664 - val_loss: 160110.5781\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 55826.6172 - val_loss: 162380.2969\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55856.1758 - val_loss: 162638.4062\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55560.5469 - val_loss: 159684.8594\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59580.8828 - val_loss: 146615.4219\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55323.0781 - val_loss: 146720.8125\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56333.4375 - val_loss: 149581.5469\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55823.9180 - val_loss: 153593.6094\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53023.9570 - val_loss: 144962.1875\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59050.3242 - val_loss: 143973.3750\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53646.7773 - val_loss: 140628.5625\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55212.1055 - val_loss: 135988.5312\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57899.6211 - val_loss: 134176.4531\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57006.0703 - val_loss: 136556.6562\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57905.5039 - val_loss: 136514.7031\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57290.6016 - val_loss: 133717.2656\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53344.7109 - val_loss: 134515.1719\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53359.5547 - val_loss: 129617.0156\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53980.6094 - val_loss: 132668.0469\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52125.3867 - val_loss: 136242.2500\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54538.7617 - val_loss: 194200.6562\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70276.3672 - val_loss: 139466.1406\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53977.5781 - val_loss: 133226.8438\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55133.1953 - val_loss: 128730.8359\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50841.0664 - val_loss: 131257.7812\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55802.7969 - val_loss: 129789.1641\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58161.5195 - val_loss: 130127.9062\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49221.6562 - val_loss: 131568.7500\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64494.2188 - val_loss: 146135.9062\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58229.4883 - val_loss: 131122.2812\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50882.4062 - val_loss: 130756.8906\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51607.7031 - val_loss: 129670.1484\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53248.4766 - val_loss: 128461.6562\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50578.3359 - val_loss: 128679.0312\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47605.0898 - val_loss: 129166.6875\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49906.4336 - val_loss: 128506.2500\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54167.0586 - val_loss: 131011.9766\n",
      "Epoch 222/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54793.7969 - val_loss: 127395.8828\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57015.9492 - val_loss: 126925.8516\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57307.5703 - val_loss: 126494.0859\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48767.8203 - val_loss: 125354.5469\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60670.4297 - val_loss: 127421.1172\n",
      "Epoch 227/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56303.9844 - val_loss: 125519.0000\n",
      "Epoch 228/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 66396.1406 - val_loss: 129167.1016\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61649.7422 - val_loss: 127613.5156\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60686.1094 - val_loss: 124132.1484\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47266.6719 - val_loss: 125185.4141\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52922.2422 - val_loss: 127292.6016\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51286.8555 - val_loss: 126199.3828\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 49535.5430 - val_loss: 124824.4453\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 46810.5781 - val_loss: 126059.3672\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52561.8867 - val_loss: 125641.5078\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 49726.5508 - val_loss: 125413.8750\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51417.6641 - val_loss: 124054.9219\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52769.2812 - val_loss: 126481.3516\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52318.0781 - val_loss: 125032.9375\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49520.1250 - val_loss: 122112.1406\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 49960.2539 - val_loss: 124828.5391\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44856.0703 - val_loss: 122446.5703\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 51489.1523 - val_loss: 123052.4141\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 46675.6133 - val_loss: 124788.8438\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47043.0039 - val_loss: 122603.4219\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 56352.8320 - val_loss: 131975.8750\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 49820.7773 - val_loss: 122641.2812\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47937.2500 - val_loss: 124053.6719\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45099.8867 - val_loss: 123454.0312\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 48674.9844 - val_loss: 125314.1094\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 49198.7070 - val_loss: 127819.1875\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48552.3438 - val_loss: 120222.5156\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49899.3008 - val_loss: 116438.3594\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49051.3945 - val_loss: 117362.4922\n",
      "Epoch 256/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52807.2031 - val_loss: 111318.8047\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45122.7422 - val_loss: 113780.2578\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50359.8125 - val_loss: 110576.0391\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44945.8594 - val_loss: 113231.1797\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43576.9688 - val_loss: 114162.2891\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48491.3281 - val_loss: 109880.8750\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47040.1133 - val_loss: 111546.0000\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 48781.6484 - val_loss: 110504.9375\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45889.6562 - val_loss: 109691.2969\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46235.6523 - val_loss: 110703.3984\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46596.5625 - val_loss: 110939.9062\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42523.2539 - val_loss: 110528.7422\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47582.3281 - val_loss: 110549.6641\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42970.3047 - val_loss: 110210.8281\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42418.2344 - val_loss: 111327.7266\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 49533.2070 - val_loss: 111034.0469\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46889.5664 - val_loss: 110565.3750\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 46994.1992 - val_loss: 112463.8750\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47594.9531 - val_loss: 114226.6797\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 48119.6172 - val_loss: 110410.9844\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44136.5273 - val_loss: 109513.1797\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 48012.4531 - val_loss: 114972.4766\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44976.4844 - val_loss: 111810.0625\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43292.2695 - val_loss: 110171.0938\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42575.9141 - val_loss: 109276.7344\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40873.9141 - val_loss: 110172.7500\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42681.7891 - val_loss: 120761.4688\n",
      "Epoch 283/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46663.5508 - val_loss: 110284.8828\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41551.4414 - val_loss: 128528.5859\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43086.3086 - val_loss: 112278.9375\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44183.6641 - val_loss: 112769.2734\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43186.9219 - val_loss: 121971.5703\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43126.2500 - val_loss: 114064.6641\n",
      "Epoch 289/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40827.7461 - val_loss: 112217.3672\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47426.1445 - val_loss: 112739.1016\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 48296.4102 - val_loss: 113813.7500\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41817.4219 - val_loss: 112858.3672\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40457.0742 - val_loss: 113720.5156\n",
      "Epoch 294/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42778.6797 - val_loss: 112947.7812\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45581.1680 - val_loss: 113244.6719\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 46158.8750 - val_loss: 112590.2031\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42919.2305 - val_loss: 117408.8203\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47667.7656 - val_loss: 111096.2031\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41511.2891 - val_loss: 135598.1250\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47328.3359 - val_loss: 112878.4844\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44701.2930 - val_loss: 114475.7578\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44927.2109 - val_loss: 115227.1719\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40589.7852 - val_loss: 115357.5078\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40191.3672 - val_loss: 118361.8203\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40365.9766 - val_loss: 115064.2344\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40189.4844 - val_loss: 116127.4375\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41888.3125 - val_loss: 116693.8125\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44444.2539 - val_loss: 122594.9297\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45271.1289 - val_loss: 117323.3281\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40814.0898 - val_loss: 110361.0234\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46735.9570 - val_loss: 113583.2344\n",
      "Epoch 312/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41390.6836 - val_loss: 116772.9609\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47880.0742 - val_loss: 117623.3203\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42484.6055 - val_loss: 112174.2031\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44929.8047 - val_loss: 116126.0312\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40642.3633 - val_loss: 119197.3516\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40540.9961 - val_loss: 119784.9219\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43451.2148 - val_loss: 119897.6172\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40931.7695 - val_loss: 117668.8906\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46263.4492 - val_loss: 118601.0156\n",
      "Epoch 321/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45910.4180 - val_loss: 118127.2344\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42196.7031 - val_loss: 117452.9844\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42375.8242 - val_loss: 118821.5234\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40679.5938 - val_loss: 119961.0938\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44246.5312 - val_loss: 126516.6250\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41336.4375 - val_loss: 117136.1250\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40132.9023 - val_loss: 119883.9844\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41240.9766 - val_loss: 118836.8203\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43605.4336 - val_loss: 119431.1172\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44187.2383 - val_loss: 122138.2188\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38761.6133 - val_loss: 119735.3125\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38670.7539 - val_loss: 123955.2578\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41711.1680 - val_loss: 121881.6484\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40652.1445 - val_loss: 119462.4062\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44302.3086 - val_loss: 125794.7031\n",
      "Epoch 336/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42559.9609 - val_loss: 111763.4453\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43579.2109 - val_loss: 121265.9453\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40810.8281 - val_loss: 121358.2422\n",
      "Epoch 339/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38043.1367 - val_loss: 126255.1172\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40724.9297 - val_loss: 125064.1484\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39847.7422 - val_loss: 121221.2344\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40884.6211 - val_loss: 122123.2578\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45839.6758 - val_loss: 223766.7656\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46751.7930 - val_loss: 129523.2656\n",
      "Epoch 345/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39979.2070 - val_loss: 123844.2031\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38583.1250 - val_loss: 123744.4375\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38380.8984 - val_loss: 128456.4766\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38798.3711 - val_loss: 127176.3203\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39225.1094 - val_loss: 126397.6641\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38161.6445 - val_loss: 129003.7422\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37868.0000 - val_loss: 129609.1719\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40975.7773 - val_loss: 129859.2891\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41772.2266 - val_loss: 174639.6094\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43347.8203 - val_loss: 132331.9688\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40115.9375 - val_loss: 125812.1250\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38804.9844 - val_loss: 134974.7656\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40844.3086 - val_loss: 130336.1250\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37078.6250 - val_loss: 130360.7422\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39456.2266 - val_loss: 131895.5938\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38684.3828 - val_loss: 130695.6172\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37892.3047 - val_loss: 129021.6953\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38677.6758 - val_loss: 130354.4766\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45748.9453 - val_loss: 128596.1875\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37894.3047 - val_loss: 126372.7969\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38053.1719 - val_loss: 131740.0156\n",
      "Epoch 366/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37244.8125 - val_loss: 132784.0938\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40302.1328 - val_loss: 136659.8438\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38350.7461 - val_loss: 133337.5469\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39354.7148 - val_loss: 132054.0938\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38949.2070 - val_loss: 134765.7188\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38807.8086 - val_loss: 147216.1406\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40358.8789 - val_loss: 129852.1641\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45158.7148 - val_loss: 132732.9531\n",
      "Epoch 374/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 39320.3477 - val_loss: 129886.5078\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39813.7305 - val_loss: 133820.0781\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42087.0977 - val_loss: 133542.9844\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37041.8398 - val_loss: 133610.4844\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38183.8242 - val_loss: 138412.8438\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37582.3203 - val_loss: 138957.3281\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41620.5117 - val_loss: 132050.6250\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39724.8633 - val_loss: 138881.0781\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36039.2852 - val_loss: 146147.2656\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40437.9141 - val_loss: 139143.6562\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39538.8945 - val_loss: 136454.2344\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40673.6445 - val_loss: 147008.6250\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37250.6641 - val_loss: 141784.0938\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38325.8477 - val_loss: 141950.4062\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37643.0742 - val_loss: 149805.1406\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37333.4375 - val_loss: 144511.9375\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42102.1680 - val_loss: 140867.0625\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36025.8867 - val_loss: 149521.7812\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43136.1289 - val_loss: 144662.8750\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36440.0430 - val_loss: 146836.8438\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44385.7891 - val_loss: 137906.7031\n",
      "Epoch 395/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44179.4648 - val_loss: 140962.6875\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 70640.5703 - val_loss: 262326.4062\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 62497.9727 - val_loss: 260230.9531\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 55949.4453 - val_loss: 151861.0938\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 55210.1445 - val_loss: 142645.4688\n",
      "Epoch 400/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39777.9531 - val_loss: 144628.0312\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35876.7773 - val_loss: 146182.6562\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37806.0508 - val_loss: 117609.7812\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36971.3203 - val_loss: 141522.1406\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35079.5156 - val_loss: 143860.1406\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38592.4961 - val_loss: 143215.9375\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36199.8516 - val_loss: 143686.6406\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34705.8789 - val_loss: 154730.5312\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36043.6914 - val_loss: 149464.6719\n",
      "Epoch 409/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35481.0273 - val_loss: 155339.0781\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37409.9961 - val_loss: 150841.7500\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36957.2656 - val_loss: 145121.2656\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37727.6914 - val_loss: 151676.9688\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40708.2695 - val_loss: 149297.2031\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37031.2969 - val_loss: 143760.7031\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37389.7773 - val_loss: 152766.7344\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35351.7617 - val_loss: 152337.1875\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36569.0820 - val_loss: 148881.9844\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35869.6875 - val_loss: 145883.0156\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37873.8398 - val_loss: 161174.8750\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33891.1719 - val_loss: 155847.3125\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38031.3594 - val_loss: 153276.8125\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34816.0117 - val_loss: 153760.1094\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40673.9570 - val_loss: 157218.9531\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40426.2617 - val_loss: 159109.3281\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37867.4648 - val_loss: 163423.5156\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35876.5039 - val_loss: 156372.2031\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34344.6641 - val_loss: 154880.7188\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36322.7852 - val_loss: 160528.5781\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36030.3984 - val_loss: 158201.4531\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34486.2227 - val_loss: 162605.8906\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40121.6133 - val_loss: 170342.4375\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34778.6875 - val_loss: 168787.9219\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36416.3711 - val_loss: 167337.4531\n",
      "Epoch 434/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34148.6094 - val_loss: 167081.0625\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40119.8672 - val_loss: 169541.1719\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36506.5312 - val_loss: 166353.2812\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35091.5273 - val_loss: 163490.9531\n",
      "Epoch 438/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36017.9141 - val_loss: 166096.1875\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35014.0430 - val_loss: 168409.0156\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36699.9570 - val_loss: 175200.9219\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34476.1836 - val_loss: 150188.6875\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35589.7578 - val_loss: 163368.4688\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37071.5820 - val_loss: 250173.8750\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39098.2852 - val_loss: 178163.4062\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38541.8477 - val_loss: 172238.0625\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41253.5938 - val_loss: 175109.0156\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37356.6602 - val_loss: 172969.0156\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34296.5273 - val_loss: 179630.8594\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36122.4219 - val_loss: 180064.7812\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32107.5781 - val_loss: 178530.6406\n",
      "Epoch 451/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37639.4609 - val_loss: 178792.5625\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37653.8828 - val_loss: 175392.7812\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33510.8047 - val_loss: 176570.8438\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34964.3555 - val_loss: 177375.1719\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33181.5352 - val_loss: 179937.2812\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34079.5195 - val_loss: 171729.3750\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41308.6523 - val_loss: 186481.3281\n",
      "Epoch 458/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37743.4414 - val_loss: 181376.5312\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33633.9453 - val_loss: 183966.0000\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34849.6719 - val_loss: 178672.5156\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35089.3398 - val_loss: 153205.1719\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38077.8594 - val_loss: 170685.3906\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34267.2031 - val_loss: 178525.7969\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35625.5586 - val_loss: 180572.2344\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33323.9219 - val_loss: 177694.3438\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34982.9883 - val_loss: 179546.4062\n",
      "Epoch 467/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 33454.0352 - val_loss: 186886.2969\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37125.0352 - val_loss: 176387.6562\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35427.7773 - val_loss: 183870.1406\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31739.4824 - val_loss: 181834.2500\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33610.9766 - val_loss: 156914.3906\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36471.4102 - val_loss: 179345.3594\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33350.0469 - val_loss: 187267.0000\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35682.9336 - val_loss: 180439.9375\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33500.9180 - val_loss: 181155.4688\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33740.2773 - val_loss: 188480.7656\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36067.6211 - val_loss: 140099.9688\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34948.7656 - val_loss: 172214.5469\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34365.0977 - val_loss: 187501.8750\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31404.9570 - val_loss: 182695.3125\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32543.9707 - val_loss: 206853.6250\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37602.3398 - val_loss: 189257.5781\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32462.0723 - val_loss: 192857.7344\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38208.3359 - val_loss: 182455.4688\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36160.5273 - val_loss: 184791.5469\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32003.7324 - val_loss: 194549.0781\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37633.4062 - val_loss: 187232.9688\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32459.7266 - val_loss: 193788.4531\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38540.6289 - val_loss: 190891.8906\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31259.9395 - val_loss: 195495.6250\n",
      "Epoch 491/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31970.5859 - val_loss: 194947.7344\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33352.5234 - val_loss: 192850.5938\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34232.2969 - val_loss: 198894.7500\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30503.5898 - val_loss: 193898.3438\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34797.8555 - val_loss: 191850.5938\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38180.6523 - val_loss: 204447.7812\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31807.6387 - val_loss: 202133.9688\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35349.4141 - val_loss: 180225.8750\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29777.6465 - val_loss: 196259.1719\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34986.6250 - val_loss: 208881.4375\n",
      "Finished.\n",
      "Training Tanh Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "185/185 [==============================] - 3s 8ms/step - loss: 422702.6875 - val_loss: 564336.3125\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 421390.7188 - val_loss: 562376.1875\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 419495.9375 - val_loss: 562549.7500\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 415721.6562 - val_loss: 558601.6250\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 410864.2812 - val_loss: 550142.8125\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 406023.6875 - val_loss: 542955.3125\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 402294.4688 - val_loss: 536547.0000\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 398007.0625 - val_loss: 531784.1250\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 392672.4375 - val_loss: 526383.5625\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 387936.2812 - val_loss: 522939.2500\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 383980.0938 - val_loss: 520099.3438\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 379257.4375 - val_loss: 509605.2500\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 373672.6875 - val_loss: 499105.4062\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 366512.8438 - val_loss: 494939.5625\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 371378.0312 - val_loss: 520187.9062\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 361187.9375 - val_loss: 491495.5000\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 351610.0000 - val_loss: 479052.7500\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 347319.2500 - val_loss: 470043.4688\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 341025.2812 - val_loss: 472014.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 341527.4688 - val_loss: 461086.8125\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 332146.0312 - val_loss: 451350.1250\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 325553.0938 - val_loss: 446342.1875\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 321073.6875 - val_loss: 440674.7812\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 319272.2188 - val_loss: 451781.1562\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 312120.1562 - val_loss: 427239.2812\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 311528.6250 - val_loss: 415036.4062\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 300377.4062 - val_loss: 406774.7812\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 296549.3438 - val_loss: 401587.5938\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 292472.8750 - val_loss: 394410.8750\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 290663.6250 - val_loss: 386234.5938\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 288850.9688 - val_loss: 400359.9375\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 284336.6250 - val_loss: 375584.2500\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 275258.1562 - val_loss: 367393.0625\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 282497.9062 - val_loss: 388612.9688\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 265974.4688 - val_loss: 362501.2500\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 262788.6562 - val_loss: 355720.3438\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 265315.9375 - val_loss: 345071.5000\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 249616.9531 - val_loss: 340017.2500\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 251841.5156 - val_loss: 334537.8125\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 244271.0312 - val_loss: 322324.0625\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 244030.7656 - val_loss: 321568.9062\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 239872.5000 - val_loss: 314563.5625\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 230150.0156 - val_loss: 308914.5938\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 223913.9688 - val_loss: 303104.4688\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 221024.5312 - val_loss: 297101.1250\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 218506.6094 - val_loss: 293888.7188\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 220980.8906 - val_loss: 285599.0312\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 219499.1875 - val_loss: 285656.7188\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 217570.6562 - val_loss: 273655.9062\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 207904.9844 - val_loss: 271381.9688\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 192016.7500 - val_loss: 267040.0625\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 194237.3125 - val_loss: 262084.3125\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 187867.0625 - val_loss: 255931.7812\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 180492.3594 - val_loss: 250963.2188\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 179937.3281 - val_loss: 248014.1719\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 178959.5469 - val_loss: 245670.9531\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 173906.9219 - val_loss: 234929.4375\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 166707.2188 - val_loss: 232178.3906\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 161947.1250 - val_loss: 234506.6719\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 162810.8906 - val_loss: 228762.3125\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 158495.1562 - val_loss: 218470.2344\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 168584.5156 - val_loss: 218030.2969\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 156638.2656 - val_loss: 211607.4844\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 147818.5781 - val_loss: 207186.7812\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 152622.6094 - val_loss: 201442.6406\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 146177.5781 - val_loss: 197999.5938\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 137254.5156 - val_loss: 199060.7031\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 134072.4844 - val_loss: 194371.2969\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 135762.1719 - val_loss: 194409.5938\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 117165.7812 - val_loss: 199223.2500\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 123614.3047 - val_loss: 184715.5781\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 119523.8047 - val_loss: 183870.6875\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 110274.8359 - val_loss: 178751.0312\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 106656.1875 - val_loss: 178201.0781\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 115099.1328 - val_loss: 177849.3125\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 105232.8750 - val_loss: 177149.3750\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 97242.8203 - val_loss: 170985.1562\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 101934.5781 - val_loss: 177736.0469\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 113016.2109 - val_loss: 168994.5312\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 99403.6719 - val_loss: 168501.3906\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 96870.5938 - val_loss: 166558.6250\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89193.4297 - val_loss: 165187.0156\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 97080.0000 - val_loss: 162266.7969\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85320.6406 - val_loss: 159517.4219\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 93031.3359 - val_loss: 184478.7031\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 91961.1250 - val_loss: 166731.0312\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 87263.0312 - val_loss: 167169.6562\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 76610.4375 - val_loss: 177439.4219\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85878.6953 - val_loss: 174713.5938\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 76498.0078 - val_loss: 152985.3281\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 82746.1875 - val_loss: 153526.9062\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 93857.2578 - val_loss: 161225.0781\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 82950.8281 - val_loss: 162497.3906\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 84789.2109 - val_loss: 162162.3906\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 75671.3594 - val_loss: 166133.8906\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 75483.3750 - val_loss: 168567.8750\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 77842.0156 - val_loss: 164248.8594\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65604.9766 - val_loss: 160530.9062\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68705.2188 - val_loss: 162243.2969\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68302.8125 - val_loss: 162585.6250\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66078.6875 - val_loss: 166575.6875\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70308.9453 - val_loss: 159932.3750\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 76498.4141 - val_loss: 169837.4062\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66968.9531 - val_loss: 169890.5312\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65924.2031 - val_loss: 170918.8594\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65412.8477 - val_loss: 175427.0625\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 75822.2109 - val_loss: 173051.3125\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71472.6719 - val_loss: 172352.8281\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62517.2695 - val_loss: 170742.8438\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58243.1719 - val_loss: 170825.9531\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64973.8594 - val_loss: 189393.6562\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 72695.2656 - val_loss: 179478.6250\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70144.5312 - val_loss: 186380.9531\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59854.3086 - val_loss: 181728.8594\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64149.1172 - val_loss: 177057.1250\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 72494.3672 - val_loss: 182133.8750\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56215.7188 - val_loss: 179268.0469\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66981.8672 - val_loss: 183325.8594\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66217.3672 - val_loss: 193652.8125\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64469.5156 - val_loss: 187015.4531\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63021.4453 - val_loss: 203471.1094\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63048.3867 - val_loss: 197101.1875\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57041.5859 - val_loss: 212749.2500\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64754.5469 - val_loss: 225216.1250\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 76348.4297 - val_loss: 172336.7188\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66016.9297 - val_loss: 168561.0781\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58729.5508 - val_loss: 165231.1875\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 59351.6758 - val_loss: 164047.2812\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 54956.6211 - val_loss: 159080.1094\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59800.7148 - val_loss: 168462.3438\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61299.5977 - val_loss: 180800.0469\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67166.7578 - val_loss: 168320.3125\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58732.4648 - val_loss: 176636.3594\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55418.8438 - val_loss: 177097.0781\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 57775.9883 - val_loss: 181269.1250\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 56518.3906 - val_loss: 195526.7969\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 57582.5781 - val_loss: 224896.6250\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56120.8711 - val_loss: 225026.7812\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58498.7500 - val_loss: 246839.9688\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55609.5781 - val_loss: 248690.7969\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60337.1562 - val_loss: 261977.0000\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52296.7461 - val_loss: 276488.6875\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57865.9844 - val_loss: 272605.4375\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54305.0039 - val_loss: 259781.1406\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59032.3125 - val_loss: 263707.1562\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 100330.5938 - val_loss: 291957.5938\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58318.1211 - val_loss: 290527.3125\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59040.1406 - val_loss: 262396.5625\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57011.3906 - val_loss: 255441.9531\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53416.3945 - val_loss: 269985.2812\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58306.9766 - val_loss: 253802.2969\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52591.0039 - val_loss: 266519.6250\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 51986.7344 - val_loss: 261786.0781\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 61632.6289 - val_loss: 263745.8125\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53272.5469 - val_loss: 255482.2344\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53869.2500 - val_loss: 252960.2188\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 53087.9883 - val_loss: 263548.7500\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51792.4688 - val_loss: 256659.6406\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57682.7383 - val_loss: 266257.3750\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53705.3164 - val_loss: 255524.1562\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54654.5273 - val_loss: 251663.3125\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51135.9062 - val_loss: 257556.4062\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49205.2734 - val_loss: 258152.9844\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46514.0703 - val_loss: 261143.9062\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47960.5859 - val_loss: 267551.3438\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 56510.9727 - val_loss: 264454.2812\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46231.2422 - val_loss: 237444.2812\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59207.2695 - val_loss: 273247.9375\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63996.2344 - val_loss: 224671.8750\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52842.3281 - val_loss: 238698.7969\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47521.4766 - val_loss: 244401.2188\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43722.8047 - val_loss: 247742.5312\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49998.5508 - val_loss: 246466.4688\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49147.9180 - val_loss: 221366.8438\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50386.0039 - val_loss: 198643.2188\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50094.2500 - val_loss: 273760.0938\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50931.0195 - val_loss: 269710.3125\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45763.6992 - val_loss: 263806.4688\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45923.7227 - val_loss: 264143.4062\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47770.6797 - val_loss: 262502.0938\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43192.7812 - val_loss: 267865.8750\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43608.2539 - val_loss: 268703.6562\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49400.1875 - val_loss: 269019.5312\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47139.5859 - val_loss: 268667.4062\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45914.3164 - val_loss: 255520.8906\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 50662.4453 - val_loss: 256189.7344\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43813.1055 - val_loss: 254155.4219\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42376.6602 - val_loss: 239660.7656\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43147.1289 - val_loss: 248377.0938\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51652.4062 - val_loss: 265039.5312\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45348.2070 - val_loss: 268432.6250\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50947.5156 - val_loss: 264509.7812\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42856.7539 - val_loss: 266545.6562\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51024.1211 - val_loss: 253920.6406\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46888.3008 - val_loss: 241685.0781\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46014.5234 - val_loss: 249311.2500\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46399.5977 - val_loss: 260527.0000\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46377.8164 - val_loss: 221525.7969\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46638.1406 - val_loss: 197595.1250\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43088.5234 - val_loss: 240723.1094\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42765.5273 - val_loss: 133333.5156\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53917.2227 - val_loss: 197753.9844\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44032.5391 - val_loss: 188929.0156\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42723.0117 - val_loss: 265083.1250\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45110.1484 - val_loss: 271931.1875\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44552.2227 - val_loss: 271568.3750\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41162.4141 - val_loss: 283988.8750\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52729.2578 - val_loss: 269067.3125\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46497.4492 - val_loss: 291030.3750\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42890.4883 - val_loss: 273184.6562\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47858.4180 - val_loss: 273870.7188\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40649.8789 - val_loss: 273197.8438\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40403.9805 - val_loss: 277545.9375\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40657.2734 - val_loss: 276396.6250\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41259.3945 - val_loss: 278133.7812\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43485.5664 - val_loss: 270622.0312\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40968.7617 - val_loss: 264966.0000\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42856.6836 - val_loss: 264743.1250\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42267.1797 - val_loss: 271007.4375\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41708.2734 - val_loss: 259779.0938\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50545.3320 - val_loss: 277614.0625\n",
      "Epoch 222/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45943.2305 - val_loss: 252810.6406\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44507.5703 - val_loss: 275877.8750\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42067.1875 - val_loss: 279914.2188\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38469.6250 - val_loss: 278537.3125\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39630.7695 - val_loss: 274275.4688\n",
      "Epoch 227/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42357.7656 - val_loss: 281635.7500\n",
      "Epoch 228/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49597.2070 - val_loss: 278485.6875\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43201.7930 - val_loss: 273008.4062\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38892.7227 - val_loss: 245662.1406\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41533.7305 - val_loss: 259378.8438\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42738.1641 - val_loss: 232299.2656\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42026.9648 - val_loss: 244174.4844\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38858.7891 - val_loss: 233707.8125\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39299.4023 - val_loss: 267027.5312\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40043.9883 - val_loss: 271691.4375\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44392.2305 - val_loss: 256212.2031\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46596.3906 - val_loss: 276868.4688\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38667.2500 - val_loss: 290517.1875\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42631.5000 - val_loss: 280116.9375\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38850.6016 - val_loss: 287206.8750\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40059.7695 - val_loss: 282339.1875\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44997.7500 - val_loss: 279224.3750\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38071.6406 - val_loss: 276365.8125\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39511.2461 - val_loss: 282380.0312\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36345.8945 - val_loss: 292017.3438\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39572.6602 - val_loss: 292320.5312\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37668.4062 - val_loss: 277975.9375\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36525.3867 - val_loss: 287879.8750\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40026.0625 - val_loss: 285564.6250\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56939.0508 - val_loss: 282939.0312\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47669.9180 - val_loss: 271434.9062\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46538.1797 - val_loss: 262920.1562\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37265.0039 - val_loss: 264971.7188\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37043.1914 - val_loss: 274032.1250\n",
      "Epoch 256/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37085.9961 - val_loss: 272832.1875\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40075.1172 - val_loss: 286327.0000\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37187.9336 - val_loss: 275121.0312\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40479.7891 - val_loss: 278023.8125\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36212.5430 - val_loss: 278297.8750\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36445.6758 - val_loss: 282120.6562\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42120.4922 - val_loss: 278156.2500\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40577.0391 - val_loss: 276957.0312\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38823.0859 - val_loss: 276343.8125\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37908.0391 - val_loss: 276487.0938\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40877.3984 - val_loss: 279149.4375\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37700.5430 - val_loss: 278589.4375\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41550.8086 - val_loss: 279736.3438\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34339.3359 - val_loss: 283122.1875\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40764.4023 - val_loss: 282680.9375\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41698.0781 - val_loss: 277449.1875\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36638.7344 - val_loss: 288226.9375\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37746.3398 - val_loss: 278776.7500\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39668.1680 - val_loss: 280347.6875\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36685.9102 - val_loss: 278242.3438\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41181.4219 - val_loss: 273262.7812\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40075.7422 - val_loss: 273174.6875\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36290.6094 - val_loss: 265327.1875\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42836.3125 - val_loss: 274756.0000\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39458.5859 - val_loss: 283352.0000\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37068.1680 - val_loss: 273896.7812\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37983.4414 - val_loss: 271969.4062\n",
      "Epoch 283/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37957.6445 - val_loss: 282542.4062\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36206.1367 - val_loss: 274419.3750\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36428.4648 - val_loss: 283857.9688\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40144.8164 - val_loss: 280693.6562\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37130.2344 - val_loss: 279554.8125\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39679.0586 - val_loss: 285749.6562\n",
      "Epoch 289/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38532.4805 - val_loss: 283115.8438\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38679.4531 - val_loss: 285264.8125\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35365.1875 - val_loss: 279492.1875\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36596.5039 - val_loss: 321879.5938\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42482.7109 - val_loss: 281006.8750\n",
      "Epoch 294/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37435.5781 - val_loss: 288683.6875\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37256.1289 - val_loss: 288661.2812\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40040.4336 - val_loss: 289970.0938\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36939.3633 - val_loss: 285589.5312\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34725.2188 - val_loss: 278308.2500\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43065.3008 - val_loss: 296896.2500\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36348.7773 - val_loss: 287993.3438\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40939.3281 - val_loss: 280530.0000\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37043.9102 - val_loss: 289397.4688\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36496.1484 - val_loss: 293036.4688\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37649.6992 - val_loss: 282430.0625\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41564.5000 - val_loss: 301761.2188\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36890.4570 - val_loss: 283544.5625\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33864.1562 - val_loss: 281034.6875\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35187.1328 - val_loss: 297601.7812\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36387.9492 - val_loss: 292052.0000\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35458.0195 - val_loss: 280930.4375\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33690.2148 - val_loss: 292039.4062\n",
      "Epoch 312/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 37816.6641 - val_loss: 281049.9375\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35288.5859 - val_loss: 282839.1250\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40816.3086 - val_loss: 277122.9688\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36321.3867 - val_loss: 278467.6562\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39314.3047 - val_loss: 284795.5000\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33687.5156 - val_loss: 277703.0625\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35265.6992 - val_loss: 287302.7812\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49036.9375 - val_loss: 538931.6875\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33352.3398 - val_loss: 280131.5938\n",
      "Epoch 321/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36275.2500 - val_loss: 279794.4375\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37583.0312 - val_loss: 279174.5000\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34343.7656 - val_loss: 277898.9375\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35136.6055 - val_loss: 279057.4375\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33528.5586 - val_loss: 281807.4062\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33014.3438 - val_loss: 281302.7500\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34779.4219 - val_loss: 283576.0625\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46003.2812 - val_loss: 197615.2500\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34164.6680 - val_loss: 206771.9062\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34899.0547 - val_loss: 181937.4688\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34458.1523 - val_loss: 159974.2188\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31706.6777 - val_loss: 112316.8750\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36364.7852 - val_loss: 159153.7344\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32260.3633 - val_loss: 164915.0156\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37781.4102 - val_loss: 140738.0469\n",
      "Epoch 336/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32666.4590 - val_loss: 174246.2656\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33402.8945 - val_loss: 259162.1094\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33002.1250 - val_loss: 285711.7500\n",
      "Epoch 339/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33216.0039 - val_loss: 250041.1250\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33439.6758 - val_loss: 279142.0000\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34421.5977 - val_loss: 273764.6562\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39175.8555 - val_loss: 241831.3906\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33101.4062 - val_loss: 57286.2969\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31817.5723 - val_loss: 27985.3496\n",
      "Epoch 345/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33810.9297 - val_loss: 76228.3672\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33573.0742 - val_loss: 87338.0547\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34171.4922 - val_loss: 298087.5625\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34590.2422 - val_loss: 157623.7188\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34337.8594 - val_loss: 181227.6562\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36095.9414 - val_loss: 180545.4062\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37172.7422 - val_loss: 122706.9766\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37016.1172 - val_loss: 207228.7344\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 31967.0273 - val_loss: 299141.6875\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44050.6172 - val_loss: 98909.2031\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38648.7227 - val_loss: 259104.1719\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35541.9531 - val_loss: 273661.4375\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35910.9414 - val_loss: 279780.6250\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32725.2539 - val_loss: 287948.1250\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35366.3398 - val_loss: 296246.7188\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33541.4844 - val_loss: 282974.7188\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33442.4219 - val_loss: 304697.2188\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36992.8320 - val_loss: 62399.2656\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34929.6172 - val_loss: 56251.3164\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35578.0586 - val_loss: 56551.3555\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36048.9219 - val_loss: 168577.2969\n",
      "Epoch 366/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33203.4180 - val_loss: 141507.2500\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32772.8984 - val_loss: 142486.2812\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 31840.5508 - val_loss: 99388.7109\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47175.5586 - val_loss: 209304.7969\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34592.6875 - val_loss: 169271.8594\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32455.1777 - val_loss: 237082.7188\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31003.6562 - val_loss: 282686.3750\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 31973.3984 - val_loss: 276437.8750\n",
      "Epoch 374/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33502.3438 - val_loss: 29341.1016\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31939.5254 - val_loss: 149076.2188\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31109.7695 - val_loss: 142810.7969\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33450.8594 - val_loss: 139998.1875\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31044.7559 - val_loss: 148659.5000\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 31290.9102 - val_loss: 144995.1406\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34560.7422 - val_loss: 172319.7344\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32498.8379 - val_loss: 157714.7031\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34053.4922 - val_loss: 139647.2031\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35113.5469 - val_loss: 156124.4219\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33913.0312 - val_loss: 145280.0625\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32194.0078 - val_loss: 154595.1875\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33331.4766 - val_loss: 162071.7344\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 31043.1113 - val_loss: 158645.3281\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32511.4785 - val_loss: 161170.0938\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33804.4297 - val_loss: 186762.4531\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33777.2227 - val_loss: 214135.0312\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34416.9102 - val_loss: 156280.2500\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30019.1758 - val_loss: 176069.7656\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30699.9570 - val_loss: 154315.3750\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 30461.5195 - val_loss: 169477.8281\n",
      "Epoch 395/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31167.0898 - val_loss: 163178.0625\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31944.5547 - val_loss: 173761.3125\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30369.5801 - val_loss: 161573.5781\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33126.9062 - val_loss: 162730.0312\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29001.0781 - val_loss: 170658.3281\n",
      "Epoch 400/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32635.9629 - val_loss: 171459.4062\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35104.4219 - val_loss: 225719.1094\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33187.1094 - val_loss: 228695.0000\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34649.3086 - val_loss: 171071.0312\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31888.0137 - val_loss: 162463.7031\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 29722.5723 - val_loss: 156635.0781\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33695.3008 - val_loss: 289579.0000\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37116.5703 - val_loss: 143909.6719\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32131.2852 - val_loss: 138397.1406\n",
      "Epoch 409/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35572.0547 - val_loss: 150090.2969\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30857.4258 - val_loss: 153470.0000\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30156.2168 - val_loss: 152076.3750\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31420.1855 - val_loss: 150353.5625\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32544.2285 - val_loss: 144800.5938\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33832.9492 - val_loss: 151669.7500\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31652.5312 - val_loss: 160806.1094\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33724.8398 - val_loss: 159386.1094\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31860.7344 - val_loss: 137627.2969\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31582.8379 - val_loss: 127889.5234\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35834.6445 - val_loss: 427968.3750\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31210.4590 - val_loss: 130945.4922\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30509.9844 - val_loss: 146722.8906\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35551.0508 - val_loss: 147517.5938\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32411.9121 - val_loss: 150370.0938\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 28408.7578 - val_loss: 150353.5781\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33743.8984 - val_loss: 155687.0625\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 30312.7422 - val_loss: 143295.5938\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30936.7832 - val_loss: 144198.7969\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27926.7539 - val_loss: 168487.8906\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31390.9023 - val_loss: 134410.1094\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40832.1680 - val_loss: 283896.6250\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57849.3711 - val_loss: 135501.2812\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38815.8789 - val_loss: 26857.0977\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36707.7266 - val_loss: 38328.6641\n",
      "Epoch 434/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31107.0527 - val_loss: 70798.1797\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32668.4414 - val_loss: 26422.4297\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32825.4805 - val_loss: 262309.0938\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30136.3906 - val_loss: 277329.6250\n",
      "Epoch 438/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33454.1172 - val_loss: 293414.0000\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29175.1680 - val_loss: 84384.0000\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33334.1445 - val_loss: 118521.8828\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32120.4648 - val_loss: 128526.0703\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29538.2148 - val_loss: 132346.0938\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28243.0508 - val_loss: 70666.9609\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32027.1152 - val_loss: 45317.9219\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30531.1504 - val_loss: 47453.5664\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29616.2520 - val_loss: 59085.4062\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28307.5508 - val_loss: 125657.8359\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30704.4707 - val_loss: 79466.8359\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30979.9492 - val_loss: 107067.5859\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32318.7812 - val_loss: 95646.4297\n",
      "Epoch 451/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32382.2324 - val_loss: 173223.7656\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33580.6328 - val_loss: 39009.8281\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28209.9453 - val_loss: 34500.0781\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28567.8242 - val_loss: 304212.0938\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32594.1250 - val_loss: 140551.5156\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33484.2070 - val_loss: 286182.5625\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33094.1953 - val_loss: 298326.9375\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 30417.6113 - val_loss: 262384.3438\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29225.1562 - val_loss: 103353.2422\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30007.3652 - val_loss: 256914.6406\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36642.5469 - val_loss: 199726.1094\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32056.7637 - val_loss: 125635.0938\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33283.4102 - val_loss: 122300.8359\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32086.6191 - val_loss: 89857.7188\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33507.5469 - val_loss: 109431.0156\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30067.6445 - val_loss: 60991.3555\n",
      "Epoch 467/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29865.2461 - val_loss: 34107.4844\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28432.3457 - val_loss: 36852.9180\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30214.6992 - val_loss: 49718.4844\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29022.2129 - val_loss: 157684.3281\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28270.7285 - val_loss: 88768.2578\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31587.1016 - val_loss: 49438.6953\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 26853.9082 - val_loss: 124590.0625\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49856.7891 - val_loss: 143344.8594\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32717.0117 - val_loss: 126163.0312\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29475.5918 - val_loss: 155464.2969\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29431.0352 - val_loss: 149612.8750\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32525.6992 - val_loss: 166123.7656\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30486.9805 - val_loss: 200425.2500\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28924.7695 - val_loss: 137869.6406\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31815.4043 - val_loss: 159678.9062\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28462.6250 - val_loss: 154939.5000\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 26994.9961 - val_loss: 165639.7188\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30095.4805 - val_loss: 167881.4375\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27729.8555 - val_loss: 203531.7812\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 31308.7617 - val_loss: 176237.1250\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 30095.2402 - val_loss: 158128.8281\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 27453.4824 - val_loss: 177642.9688\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 29967.8242 - val_loss: 200169.0625\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33012.8125 - val_loss: 197063.2969\n",
      "Epoch 491/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 30798.6035 - val_loss: 183060.8125\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 27908.2539 - val_loss: 194717.8750\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 29490.4941 - val_loss: 202838.5156\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30329.3555 - val_loss: 178252.7812\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 29529.1680 - val_loss: 160111.4375\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 31739.8105 - val_loss: 183636.4062\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 24491.5918 - val_loss: 184698.2656\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30463.9316 - val_loss: 206073.1719\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32029.8223 - val_loss: 198313.4531\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29448.1816 - val_loss: 205258.9375\n",
      "Finished.\n",
      "Training Leaky ReLU Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "185/185 [==============================] - 2s 7ms/step - loss: 422373.7188 - val_loss: 562914.1875\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 421230.4375 - val_loss: 553633.9375\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 419939.2188 - val_loss: 524790.0625\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 417229.3125 - val_loss: 416123.5312\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 412610.3125 - val_loss: 323685.6250\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 408335.7188 - val_loss: 347981.2500\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 403371.6875 - val_loss: 423451.7812\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 398710.3438 - val_loss: 577542.3750\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 394905.1562 - val_loss: 695735.6875\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 389006.0312 - val_loss: 773394.8125\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 384387.5938 - val_loss: 967904.4375\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 378935.5938 - val_loss: 1226179.3750\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 373938.5625 - val_loss: 1481554.0000\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 367600.4688 - val_loss: 1607708.1250\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 363211.6250 - val_loss: 1340844.6250\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 360166.8750 - val_loss: 1651471.6250\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 353689.3438 - val_loss: 2047796.2500\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 346155.4062 - val_loss: 2786046.2500\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 341786.6562 - val_loss: 2899167.0000\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 339240.2812 - val_loss: 2078783.7500\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 331013.1562 - val_loss: 2674551.7500\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 327930.5312 - val_loss: 3090183.0000\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 320856.1562 - val_loss: 3038488.0000\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 319879.5312 - val_loss: 2021859.2500\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 313242.2188 - val_loss: 1394354.7500\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 307366.3438 - val_loss: 1569092.0000\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 304760.7500 - val_loss: 2126332.5000\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 298186.5312 - val_loss: 460738.3438\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 296998.5625 - val_loss: 1035357.7500\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 293743.6250 - val_loss: 794416.8750\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 284023.4688 - val_loss: 585331.4375\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 285056.2500 - val_loss: 402474.5312\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 281132.5625 - val_loss: 330509.4688\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 271250.4062 - val_loss: 270005.8750\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 272219.2812 - val_loss: 317353.2500\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 265168.7812 - val_loss: 275738.0625\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 261551.9375 - val_loss: 292020.8125\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 256271.3594 - val_loss: 261047.0312\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 253100.8125 - val_loss: 382643.1562\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 252399.7500 - val_loss: 305308.1562\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 241718.0938 - val_loss: 376324.5938\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 231816.8438 - val_loss: 396350.0000\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 229348.2344 - val_loss: 270871.2188\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 230472.2812 - val_loss: 308618.3750\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 227906.0625 - val_loss: 885071.1250\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 223884.0625 - val_loss: 287003.0625\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 216712.5156 - val_loss: 299042.0938\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 211241.3281 - val_loss: 1132457.3750\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 216662.5312 - val_loss: 390036.4375\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 205956.4844 - val_loss: 2069552.1250\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 198577.2656 - val_loss: 697219.3750\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 199141.2500 - val_loss: 2069653.1250\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 193064.1562 - val_loss: 584157.9375\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 187962.8438 - val_loss: 313003.2500\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 181316.7656 - val_loss: 341080.5312\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 180501.6562 - val_loss: 279646.0938\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 173762.8438 - val_loss: 309138.0000\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 171893.2812 - val_loss: 415739.4375\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 171074.9688 - val_loss: 386146.2500\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 161866.9375 - val_loss: 456441.4688\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 156696.8594 - val_loss: 269962.5000\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 154576.9219 - val_loss: 435846.7500\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 149943.6875 - val_loss: 293316.5625\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 143032.0938 - val_loss: 278690.4062\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 141179.1719 - val_loss: 290251.1875\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 139489.8750 - val_loss: 339996.5000\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 138754.8750 - val_loss: 268934.3125\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 150382.5000 - val_loss: 333214.9062\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 131672.5781 - val_loss: 274213.4062\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 123802.7188 - val_loss: 346744.2500\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 121929.4844 - val_loss: 565232.2500\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 126184.2344 - val_loss: 567358.8125\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 115301.5938 - val_loss: 342152.0938\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 116073.0859 - val_loss: 332246.9688\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 115289.6250 - val_loss: 573516.9375\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 102024.6484 - val_loss: 801070.8750\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 104184.9375 - val_loss: 795215.8125\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 104769.2734 - val_loss: 725962.1875\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 112531.1250 - val_loss: 372741.5625\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 95418.4688 - val_loss: 496855.3125\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 94404.5000 - val_loss: 942958.6250\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 96137.7891 - val_loss: 850370.8750\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 87464.9062 - val_loss: 527330.5000\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 99975.5312 - val_loss: 329901.6875\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 95053.3750 - val_loss: 396298.0000\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 84373.7344 - val_loss: 449518.2188\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 90004.8984 - val_loss: 406053.9062\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 78521.0000 - val_loss: 869696.5625\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 86999.9766 - val_loss: 327905.3750\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 72883.5078 - val_loss: 376791.3750\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 73609.9453 - val_loss: 332873.8438\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 76561.4531 - val_loss: 645488.5000\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 77866.4531 - val_loss: 374543.7812\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85752.6406 - val_loss: 500456.1875\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88192.2578 - val_loss: 394486.3125\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 76941.2031 - val_loss: 724580.7500\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70142.1328 - val_loss: 698751.6875\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 75909.2422 - val_loss: 691225.8125\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67610.4219 - val_loss: 947124.9375\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71808.0938 - val_loss: 350943.5312\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 72910.0547 - val_loss: 626095.0000\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66438.2344 - val_loss: 665721.1250\n",
      "Epoch 103/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 67839.0469 - val_loss: 1899293.3750\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67117.3828 - val_loss: 2184486.0000\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69950.6328 - val_loss: 1214378.5000\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68422.7656 - val_loss: 872907.4375\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65942.4141 - val_loss: 714239.6250\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 63599.6758 - val_loss: 641787.3750\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64616.1055 - val_loss: 572479.2500\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64106.0273 - val_loss: 1050013.5000\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 68452.8438 - val_loss: 695564.5625\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 58328.0938 - val_loss: 357160.8125\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 64222.2891 - val_loss: 850864.9375\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60833.1133 - val_loss: 1168292.2500\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67137.8438 - val_loss: 496746.1250\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 61728.7617 - val_loss: 1481932.3750\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 59169.9883 - val_loss: 981662.8750\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 57813.6250 - val_loss: 766655.1250\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 59284.6172 - val_loss: 822008.9375\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 53831.3398 - val_loss: 536982.6875\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 57732.2109 - val_loss: 609329.6250\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 63445.6719 - val_loss: 573351.9375\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60885.8906 - val_loss: 475540.2812\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 58506.4922 - val_loss: 781935.0625\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 54137.4766 - val_loss: 2205481.5000\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 56830.9336 - val_loss: 883256.0625\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52523.9141 - val_loss: 594423.2500\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 54275.8477 - val_loss: 825391.3750\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52074.5664 - val_loss: 1200563.6250\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 58444.9414 - val_loss: 1910129.7500\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60513.8047 - val_loss: 1262197.8750\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 50728.1836 - val_loss: 712995.5625\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54756.3633 - val_loss: 564264.4375\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50235.0508 - val_loss: 840022.2500\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54646.2852 - val_loss: 501670.5312\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 55179.8164 - val_loss: 592369.3750\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 57507.0156 - val_loss: 1045028.9375\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56015.0312 - val_loss: 841753.6250\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53468.2070 - val_loss: 501342.9375\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52241.4883 - val_loss: 553043.7500\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 54436.2812 - val_loss: 922735.9375\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67954.0938 - val_loss: 348018.4375\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 53857.0547 - val_loss: 379027.8438\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 53743.3086 - val_loss: 373533.7812\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55140.5586 - val_loss: 392857.8750\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58375.9492 - val_loss: 769233.7500\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60140.8320 - val_loss: 1033559.3125\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52822.1484 - val_loss: 1313440.8750\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53040.2109 - val_loss: 910053.8750\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52587.6797 - val_loss: 1432031.7500\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 53551.3477 - val_loss: 1214059.6250\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49091.9297 - val_loss: 670927.7500\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 58004.8359 - val_loss: 1475671.2500\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 57421.5352 - val_loss: 1504486.5000\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 56402.9102 - val_loss: 865601.2500\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56519.3984 - val_loss: 1705685.3750\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53812.2109 - val_loss: 404323.0312\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49060.6289 - val_loss: 342630.4062\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53383.9102 - val_loss: 2279269.0000\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55876.5273 - val_loss: 2582968.2500\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51168.6914 - val_loss: 2426898.7500\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50442.4844 - val_loss: 1315811.1250\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 49160.2461 - val_loss: 2530792.2500\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52138.1523 - val_loss: 2678539.0000\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 48299.6914 - val_loss: 2422107.5000\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48857.8984 - val_loss: 2046499.2500\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47074.7969 - val_loss: 1919514.5000\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48691.8320 - val_loss: 2155145.7500\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53346.9766 - val_loss: 2202525.5000\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50623.8359 - val_loss: 1964929.2500\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51724.2188 - val_loss: 2221769.7500\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50547.8672 - val_loss: 1255470.5000\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53130.6328 - val_loss: 2061619.8750\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50114.0859 - val_loss: 1913189.8750\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48394.9531 - val_loss: 1389050.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52212.3242 - val_loss: 1708694.7500\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47049.4102 - val_loss: 1063806.0000\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49100.8633 - val_loss: 1337993.3750\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53344.6641 - val_loss: 1567043.3750\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52158.2344 - val_loss: 1798710.8750\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52322.2148 - val_loss: 770551.9375\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51910.9414 - val_loss: 1278201.8750\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51938.6367 - val_loss: 1198554.2500\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47138.7695 - val_loss: 1048432.2500\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51505.5312 - val_loss: 1661104.6250\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47793.1562 - val_loss: 577494.3125\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51216.0000 - val_loss: 409828.6250\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45314.7812 - val_loss: 414906.9375\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54950.2109 - val_loss: 526314.5000\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55484.2148 - val_loss: 850317.8750\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45836.5000 - val_loss: 407488.0625\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54557.5703 - val_loss: 677388.7500\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51131.1797 - val_loss: 967354.7500\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49630.5391 - val_loss: 739982.4375\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48178.1992 - val_loss: 1215386.3750\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48973.8359 - val_loss: 790128.3750\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48422.9375 - val_loss: 1183144.6250\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50294.0977 - val_loss: 604858.6250\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45097.4648 - val_loss: 832642.1250\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48492.8867 - val_loss: 849578.3750\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51901.3633 - val_loss: 1516349.3750\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44120.4023 - val_loss: 1003648.0000\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48052.2930 - val_loss: 1321674.6250\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46167.6172 - val_loss: 827545.5625\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42734.0664 - val_loss: 788313.9375\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48501.0977 - val_loss: 2161612.2500\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47193.8789 - val_loss: 1347073.3750\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45976.5781 - val_loss: 1212821.3750\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44488.7969 - val_loss: 1396718.1250\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43529.3047 - val_loss: 1375077.2500\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 50048.6523 - val_loss: 1678607.0000\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43025.6992 - val_loss: 1198461.0000\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43048.9062 - val_loss: 1524381.2500\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45498.7031 - val_loss: 1384243.8750\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46494.3359 - val_loss: 1600385.7500\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43426.1211 - val_loss: 1925195.6250\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45516.2500 - val_loss: 1755248.6250\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48740.6133 - val_loss: 1243142.6250\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43135.3203 - val_loss: 1099418.7500\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43652.6562 - val_loss: 1117178.5000\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43307.7500 - val_loss: 571890.2500\n",
      "Epoch 222/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44115.5859 - val_loss: 607379.4375\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44792.6328 - val_loss: 1013393.9375\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43532.0352 - val_loss: 1175913.0000\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42891.6094 - val_loss: 2314301.5000\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43075.1172 - val_loss: 1837481.1250\n",
      "Epoch 227/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42674.4375 - val_loss: 1309244.1250\n",
      "Epoch 228/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45851.1055 - val_loss: 1621223.1250\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41893.7930 - val_loss: 971057.1250\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47361.5859 - val_loss: 1125239.7500\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43070.8750 - val_loss: 816075.4375\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45922.3516 - val_loss: 1211629.2500\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50238.6055 - val_loss: 1530163.1250\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42680.9648 - val_loss: 467803.5625\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45480.2383 - val_loss: 1357041.5000\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47468.5703 - val_loss: 1899315.6250\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42215.7812 - val_loss: 1438433.5000\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42163.3672 - val_loss: 1529242.3750\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41411.8555 - val_loss: 1555623.0000\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43395.8438 - val_loss: 1167999.0000\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43431.2539 - val_loss: 1061122.0000\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44460.0469 - val_loss: 1081938.7500\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41357.8086 - val_loss: 1156205.0000\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41009.5312 - val_loss: 1548802.8750\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43375.4961 - val_loss: 1142852.0000\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43302.5078 - val_loss: 1123781.2500\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42832.7969 - val_loss: 934066.6875\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 49268.1602 - val_loss: 945722.0625\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43631.7734 - val_loss: 876753.4375\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40128.3594 - val_loss: 1686399.2500\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 46030.1406 - val_loss: 1573307.3750\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44536.6523 - val_loss: 1629941.0000\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44258.7148 - val_loss: 377799.1250\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47116.3750 - val_loss: 853886.1250\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41034.1016 - val_loss: 808586.1250\n",
      "Epoch 256/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43299.9453 - val_loss: 828729.9375\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40958.5352 - val_loss: 990317.7500\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40802.8555 - val_loss: 1027302.3125\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44914.7227 - val_loss: 743625.1875\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38879.6836 - val_loss: 469826.5000\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39407.7422 - val_loss: 703215.9375\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41212.2891 - val_loss: 743625.7500\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39614.7617 - val_loss: 494815.8750\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40770.3398 - val_loss: 567918.6250\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44442.8594 - val_loss: 438007.6562\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40603.5586 - val_loss: 583549.5625\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39976.7070 - val_loss: 466104.5625\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44355.7812 - val_loss: 962714.6875\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40286.4766 - val_loss: 437931.6562\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42075.5938 - val_loss: 488930.5938\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45787.3008 - val_loss: 564814.0625\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40929.1406 - val_loss: 487246.3125\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44124.3750 - val_loss: 1052583.5000\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38800.1484 - val_loss: 955871.5625\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43691.4727 - val_loss: 1044349.8125\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46236.7148 - val_loss: 534278.7500\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43030.1211 - val_loss: 568968.8750\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45800.4922 - val_loss: 1634863.7500\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49265.0391 - val_loss: 1501325.6250\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42839.8008 - val_loss: 844995.0000\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41425.3164 - val_loss: 342425.6562\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38873.7383 - val_loss: 355829.4062\n",
      "Epoch 283/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39041.1523 - val_loss: 412644.5000\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44724.8555 - val_loss: 592792.6250\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42342.0625 - val_loss: 390853.8125\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40658.6953 - val_loss: 375983.0938\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43233.7891 - val_loss: 496277.6562\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38327.7461 - val_loss: 490204.8438\n",
      "Epoch 289/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39294.0508 - val_loss: 767383.0000\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42897.6094 - val_loss: 411393.9062\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38598.2031 - val_loss: 474978.0312\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42086.2227 - val_loss: 633141.2500\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39398.9102 - val_loss: 548583.1250\n",
      "Epoch 294/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39760.6914 - val_loss: 432830.4375\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43975.2891 - val_loss: 380436.0625\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40895.1562 - val_loss: 397231.3750\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40925.4727 - val_loss: 403158.5312\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39301.0703 - val_loss: 527746.7500\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41031.9570 - val_loss: 477201.2500\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39561.5664 - val_loss: 404059.5938\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38939.4375 - val_loss: 377507.4375\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39340.0508 - val_loss: 457965.0938\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39300.0938 - val_loss: 425857.6250\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39598.5234 - val_loss: 432800.3438\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39627.6758 - val_loss: 443976.3438\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42641.2031 - val_loss: 501222.7500\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39661.6914 - val_loss: 443937.8125\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37877.5391 - val_loss: 515681.9375\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38415.3477 - val_loss: 448919.0625\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41346.9023 - val_loss: 375742.4375\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38438.4453 - val_loss: 466840.0938\n",
      "Epoch 312/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38107.8477 - val_loss: 457483.2188\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40211.2305 - val_loss: 598300.8750\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36867.4023 - val_loss: 467623.6250\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38707.1875 - val_loss: 390861.2812\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41623.5156 - val_loss: 431379.4688\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37123.6875 - val_loss: 452032.5000\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39885.1680 - val_loss: 467403.5625\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40123.5898 - val_loss: 445501.9688\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 44484.7656 - val_loss: 436893.7500\n",
      "Epoch 321/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 8ms/step - loss: 44441.4141 - val_loss: 500363.5000\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38937.1797 - val_loss: 625797.5625\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39506.3867 - val_loss: 530415.6250\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43840.2266 - val_loss: 589637.6875\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41831.0820 - val_loss: 2165921.5000\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38810.2266 - val_loss: 874334.6875\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38225.4453 - val_loss: 434113.6875\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37329.1328 - val_loss: 403690.3125\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37240.3672 - val_loss: 497894.1875\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41113.8633 - val_loss: 497659.0938\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38030.8633 - val_loss: 586267.7500\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38556.5703 - val_loss: 407520.6250\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39197.0234 - val_loss: 438725.3750\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41661.5352 - val_loss: 475889.2188\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37136.3047 - val_loss: 463261.3438\n",
      "Epoch 336/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38716.2695 - val_loss: 430217.7188\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39770.4570 - val_loss: 486991.8438\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38181.8008 - val_loss: 589147.5000\n",
      "Epoch 339/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41230.3320 - val_loss: 498630.4062\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38147.1992 - val_loss: 443589.1250\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37152.1719 - val_loss: 488568.8438\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38131.8555 - val_loss: 537346.1875\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44011.5820 - val_loss: 505257.9688\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40792.1055 - val_loss: 558181.6250\n",
      "Epoch 345/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39963.1602 - val_loss: 485328.1250\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37096.5938 - val_loss: 458379.1562\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37973.4531 - val_loss: 465017.0625\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41385.6797 - val_loss: 647746.2500\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36765.6719 - val_loss: 526976.9375\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36805.4023 - val_loss: 530251.5000\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43122.9570 - val_loss: 472735.5312\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40325.3906 - val_loss: 547920.7500\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38885.1797 - val_loss: 473056.5312\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39512.5586 - val_loss: 529842.5625\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45597.1875 - val_loss: 1096902.3750\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44647.2070 - val_loss: 721192.7500\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40018.1836 - val_loss: 708351.8125\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42742.2305 - val_loss: 626475.0625\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40180.5469 - val_loss: 975331.8125\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42719.1289 - val_loss: 628604.8750\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37333.3516 - val_loss: 509601.4688\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36648.0742 - val_loss: 557219.0000\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37601.6602 - val_loss: 509999.1875\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36818.6367 - val_loss: 479949.6875\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41791.2031 - val_loss: 513613.8750\n",
      "Epoch 366/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38088.5312 - val_loss: 430508.0312\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37685.6523 - val_loss: 467390.5938\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37098.9922 - val_loss: 428808.9062\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37503.3359 - val_loss: 794494.3125\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36922.7109 - val_loss: 973122.6250\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 36440.6797 - val_loss: 726992.3750\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36455.2188 - val_loss: 484784.6562\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37099.3125 - val_loss: 558692.6250\n",
      "Epoch 374/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 35722.5234 - val_loss: 466388.5938\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39958.7930 - val_loss: 538961.0625\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36543.5273 - val_loss: 615740.1250\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37417.4414 - val_loss: 506676.0938\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37015.6484 - val_loss: 714395.2500\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40793.3281 - val_loss: 756751.5000\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36512.9648 - val_loss: 573496.6875\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37116.1289 - val_loss: 524657.4375\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37762.5117 - val_loss: 509285.0938\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38254.2812 - val_loss: 460941.1562\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36470.6953 - val_loss: 473578.9375\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42949.4336 - val_loss: 661421.0625\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35912.8242 - val_loss: 651944.9375\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37481.0586 - val_loss: 482614.5938\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37893.7070 - val_loss: 554768.2500\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40191.3008 - val_loss: 520650.3750\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36924.7227 - val_loss: 465121.6250\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36520.7617 - val_loss: 461764.7812\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36626.8164 - val_loss: 491051.1562\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35753.3828 - val_loss: 461762.5625\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38450.2969 - val_loss: 506093.1875\n",
      "Epoch 395/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36293.7305 - val_loss: 487545.6875\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36178.3945 - val_loss: 481275.1875\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36738.5820 - val_loss: 423246.2500\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36428.2773 - val_loss: 447693.1562\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38070.6914 - val_loss: 507247.1562\n",
      "Epoch 400/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36748.0508 - val_loss: 454602.1562\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41633.6289 - val_loss: 492049.6562\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34383.6055 - val_loss: 470192.3750\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37722.1289 - val_loss: 487935.0938\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38312.7539 - val_loss: 450492.6875\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36444.5352 - val_loss: 436452.9375\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34993.2969 - val_loss: 418661.9375\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34499.0898 - val_loss: 417982.1250\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40669.0820 - val_loss: 575556.3750\n",
      "Epoch 409/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34809.8516 - val_loss: 444919.0625\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38028.4570 - val_loss: 477162.4062\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38425.1133 - val_loss: 451804.1875\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37553.3984 - val_loss: 421213.4688\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35499.7812 - val_loss: 456231.1250\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34705.7031 - val_loss: 469288.4688\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38161.7461 - val_loss: 563562.0000\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36530.9453 - val_loss: 476231.4375\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35432.0000 - val_loss: 693152.6875\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35538.8672 - val_loss: 773730.0625\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37905.7969 - val_loss: 640254.5000\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34973.1328 - val_loss: 473036.3750\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36701.6250 - val_loss: 526216.0000\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35717.0703 - val_loss: 477831.1875\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38706.0586 - val_loss: 474652.0000\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34244.7812 - val_loss: 591313.9375\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37678.2812 - val_loss: 456844.7500\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34859.8047 - val_loss: 425902.4375\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35622.4258 - val_loss: 546366.7500\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36138.5391 - val_loss: 473861.6562\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35524.6758 - val_loss: 468551.6875\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38392.3281 - val_loss: 453541.6875\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33772.1719 - val_loss: 473413.2188\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40556.2500 - val_loss: 561061.5625\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38083.1602 - val_loss: 489048.5938\n",
      "Epoch 434/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35332.1367 - val_loss: 453867.0000\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35357.6680 - val_loss: 437311.8438\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36460.4453 - val_loss: 476696.9062\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35862.0586 - val_loss: 466688.0312\n",
      "Epoch 438/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34164.8008 - val_loss: 454439.7188\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35367.8516 - val_loss: 450843.9062\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45119.2617 - val_loss: 507658.4688\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36556.5898 - val_loss: 635355.0625\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34341.6211 - val_loss: 599059.3125\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34945.7344 - val_loss: 673949.5000\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37265.8789 - val_loss: 489095.7500\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39916.0820 - val_loss: 548468.3125\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35015.9102 - val_loss: 483516.0000\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40855.3594 - val_loss: 517178.4062\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36985.8867 - val_loss: 503941.9688\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34928.1758 - val_loss: 502207.2500\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42570.3125 - val_loss: 511173.7188\n",
      "Epoch 451/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36643.1836 - val_loss: 480057.8750\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34073.3945 - val_loss: 531385.8750\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35683.9102 - val_loss: 706673.5625\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34764.7695 - val_loss: 993123.0625\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39927.9648 - val_loss: 2051521.6250\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34923.8008 - val_loss: 1014382.5625\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34015.7500 - val_loss: 819855.6875\n",
      "Epoch 458/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35188.6484 - val_loss: 948414.7500\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37424.4375 - val_loss: 624527.3750\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34639.2266 - val_loss: 477619.3125\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37455.4727 - val_loss: 707912.1875\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37259.0039 - val_loss: 1106412.1250\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35682.2773 - val_loss: 537867.9375\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36540.2734 - val_loss: 452000.2812\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34555.4336 - val_loss: 416892.9062\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34320.3633 - val_loss: 457301.4062\n",
      "Epoch 467/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 6ms/step - loss: 34333.2070 - val_loss: 444149.6562\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42015.9062 - val_loss: 597528.0000\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45651.4219 - val_loss: 930099.3125\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35519.9336 - val_loss: 371805.9062\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34837.4258 - val_loss: 394163.1250\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34761.6523 - val_loss: 596368.0625\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34223.2461 - val_loss: 629725.0000\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34913.8945 - val_loss: 415627.7500\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37617.5508 - val_loss: 434381.1562\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41067.1914 - val_loss: 438199.1562\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33299.6953 - val_loss: 807951.5625\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 34358.8164 - val_loss: 987533.3750\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38522.7070 - val_loss: 946324.2500\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38305.2109 - val_loss: 1207270.8750\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33753.4492 - val_loss: 1063667.0000\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33525.6758 - val_loss: 1000548.5625\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35670.1328 - val_loss: 763362.0000\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41344.3438 - val_loss: 489665.9062\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33856.0000 - val_loss: 1217243.3750\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38158.4961 - val_loss: 1440130.3750\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33802.7852 - val_loss: 1270554.7500\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35124.2227 - val_loss: 822236.0000\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34682.6016 - val_loss: 1273858.1250\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34045.6133 - val_loss: 698555.8125\n",
      "Epoch 491/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39737.4062 - val_loss: 956115.8750\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35300.2109 - val_loss: 1308360.3750\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38037.2891 - val_loss: 953446.8125\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36729.5195 - val_loss: 575321.4375\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33136.6641 - val_loss: 1215199.8750\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33796.1758 - val_loss: 1106139.2500\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35531.0195 - val_loss: 619907.0000\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37625.4492 - val_loss: 688584.0000\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34809.1445 - val_loss: 440216.8438\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32423.4453 - val_loss: 520755.0312\n",
      "Finished.\n",
      "Training ELU Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "185/185 [==============================] - 2s 7ms/step - loss: 423016.1875 - val_loss: 562723.1250\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 421993.1250 - val_loss: 554299.8750\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 419610.0625 - val_loss: 503733.3750\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 416267.5938 - val_loss: 423630.6875\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 412843.2500 - val_loss: 400874.0625\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 408974.0312 - val_loss: 370129.2812\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 404933.3125 - val_loss: 365181.5000\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 400248.2500 - val_loss: 351568.1875\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 395965.9062 - val_loss: 345007.4688\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 391447.7812 - val_loss: 323753.0000\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 387559.4375 - val_loss: 344729.4375\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 381871.9062 - val_loss: 324950.4375\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 378118.3438 - val_loss: 324682.1250\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 371925.2188 - val_loss: 309491.6562\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 368087.7812 - val_loss: 306096.2812\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 363472.0000 - val_loss: 343885.7500\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 356730.2500 - val_loss: 303348.0312\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 352449.0938 - val_loss: 288932.1250\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 344486.3438 - val_loss: 276662.9062\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 343006.9375 - val_loss: 268654.9062\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 334884.8438 - val_loss: 270130.2188\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 328914.4375 - val_loss: 266857.0000\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 326553.3750 - val_loss: 258414.7500\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 322533.1875 - val_loss: 255737.2656\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 315452.6875 - val_loss: 251073.3125\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 312639.5625 - val_loss: 257511.5156\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 305225.7812 - val_loss: 239198.4688\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 300343.8438 - val_loss: 248577.1250\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 298175.1250 - val_loss: 246387.3125\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 297359.3750 - val_loss: 234464.5781\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 290604.7188 - val_loss: 224646.3438\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 284336.4375 - val_loss: 223993.8750\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 279455.7812 - val_loss: 271377.2812\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 283175.0938 - val_loss: 201188.9062\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 274469.1250 - val_loss: 196576.5312\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 270156.5625 - val_loss: 207334.2500\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 264048.0000 - val_loss: 205116.7344\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 261332.1719 - val_loss: 228104.2188\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 258556.3438 - val_loss: 205331.7969\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 252143.4844 - val_loss: 248025.7188\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 243383.8281 - val_loss: 214167.4375\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 243189.7188 - val_loss: 184859.9844\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 240374.3281 - val_loss: 158059.8906\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 231258.6875 - val_loss: 210736.4062\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 233411.2656 - val_loss: 148338.2969\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 226433.1562 - val_loss: 159054.4219\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 219610.6250 - val_loss: 145192.0625\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 217833.9844 - val_loss: 238930.0000\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 216858.3594 - val_loss: 168830.4375\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 212592.0781 - val_loss: 187647.7031\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 199096.2031 - val_loss: 205636.5469\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 203450.7812 - val_loss: 151860.9531\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 191973.5938 - val_loss: 678541.8750\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 185670.9375 - val_loss: 712941.1875\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 184434.2500 - val_loss: 537365.1875\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 171053.2188 - val_loss: 475131.6250\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 183869.3281 - val_loss: 890095.9375\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 173920.5625 - val_loss: 661154.0000\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 171481.8125 - val_loss: 322827.8125\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 171618.9375 - val_loss: 279240.6562\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 161391.7969 - val_loss: 236257.6875\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 151164.6719 - val_loss: 150374.6875\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 151850.1562 - val_loss: 193335.3438\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 143084.1562 - val_loss: 219012.0000\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 153555.2031 - val_loss: 367655.4688\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 144182.2812 - val_loss: 360352.8438\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 138113.9844 - val_loss: 395416.7500\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 136099.9219 - val_loss: 1341263.5000\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 144414.2344 - val_loss: 104446.6094\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 133312.1562 - val_loss: 130298.8828\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 125802.9062 - val_loss: 106298.1094\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 116847.6719 - val_loss: 278902.6562\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 123864.7812 - val_loss: 738102.6250\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 113526.1328 - val_loss: 707823.5625\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 114506.3516 - val_loss: 387140.7812\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 117347.2578 - val_loss: 278795.3750\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 117953.9141 - val_loss: 67803.5469\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 99589.2734 - val_loss: 65653.2969\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 106983.1953 - val_loss: 2019425.8750\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 103084.2344 - val_loss: 1657627.6250\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 104256.8906 - val_loss: 1475158.6250\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 106396.8906 - val_loss: 380343.8750\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 101090.9141 - val_loss: 176466.6094\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 91803.2109 - val_loss: 189586.3750\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 87283.8828 - val_loss: 632803.6875\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 93320.6797 - val_loss: 1390296.0000\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 83297.8438 - val_loss: 1330590.1250\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 92620.8906 - val_loss: 2092805.1250\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85553.6875 - val_loss: 156415.8750\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 82124.7188 - val_loss: 269429.8438\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85143.0938 - val_loss: 487273.5000\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 82050.7812 - val_loss: 975832.5625\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 82169.4141 - val_loss: 431133.0000\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 78106.8203 - val_loss: 406913.3125\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69820.2109 - val_loss: 549296.3125\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71069.2031 - val_loss: 1060140.8750\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71595.1406 - val_loss: 322539.6875\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 80142.8828 - val_loss: 1644655.3750\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 97932.4297 - val_loss: 103684.3906\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 83236.6641 - val_loss: 802969.9375\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 77280.4219 - val_loss: 360863.9062\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 74146.0938 - val_loss: 448081.4688\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67680.1484 - val_loss: 941122.7500\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 77830.9922 - val_loss: 182917.1719\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68088.0703 - val_loss: 2648779.0000\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69066.7500 - val_loss: 2993874.2500\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62850.2500 - val_loss: 2475036.2500\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64727.1016 - val_loss: 1985203.6250\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68724.3906 - val_loss: 1648947.3750\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66581.8125 - val_loss: 3617049.0000\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57631.9570 - val_loss: 1823387.1250\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 68582.7969 - val_loss: 2317187.2500\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62989.1484 - val_loss: 2161053.7500\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64445.9531 - val_loss: 2414482.0000\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57914.1289 - val_loss: 1929844.0000\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64541.2031 - val_loss: 4161435.2500\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59710.8086 - val_loss: 1605693.0000\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62074.8594 - val_loss: 1201319.6250\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 72166.6250 - val_loss: 2068051.0000\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68230.1641 - val_loss: 2314819.0000\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 61962.7852 - val_loss: 2197043.7500\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53821.4688 - val_loss: 2435102.0000\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 71604.0625 - val_loss: 2303223.2500\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 66346.1797 - val_loss: 2990427.2500\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 63240.5859 - val_loss: 2371303.0000\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 61049.8008 - val_loss: 3654225.5000\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64703.8516 - val_loss: 4043844.0000\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60631.2891 - val_loss: 4662348.5000\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61341.4023 - val_loss: 9070916.0000\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53605.8633 - val_loss: 7776303.5000\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57856.7969 - val_loss: 9141595.0000\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57817.0664 - val_loss: 7099924.0000\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58975.9727 - val_loss: 6298611.5000\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60919.6484 - val_loss: 6840797.0000\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57601.2695 - val_loss: 7753173.0000\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68627.9375 - val_loss: 1657523.8750\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61257.6992 - val_loss: 7727733.5000\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60526.4844 - val_loss: 7845244.0000\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62622.5586 - val_loss: 5486976.0000\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59587.6250 - val_loss: 5013669.0000\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54623.0586 - val_loss: 5516406.5000\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 73834.6172 - val_loss: 7472227.0000\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62848.2070 - val_loss: 6077473.0000\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55236.6680 - val_loss: 4193090.2500\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63133.1406 - val_loss: 4491351.0000\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60482.5195 - val_loss: 3562546.2500\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54648.4805 - val_loss: 2883945.5000\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52212.8828 - val_loss: 3120588.5000\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54085.6719 - val_loss: 4698217.0000\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55343.1641 - val_loss: 4489409.5000\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57108.3359 - val_loss: 3839969.5000\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 59624.0625 - val_loss: 4299728.5000\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53002.4570 - val_loss: 3680847.7500\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61780.2266 - val_loss: 4648210.0000\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 65383.8828 - val_loss: 3497018.0000\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55621.4922 - val_loss: 2453673.0000\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 55619.2109 - val_loss: 3137092.0000\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57969.2227 - val_loss: 3991703.2500\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54300.4805 - val_loss: 3422010.5000\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61687.3672 - val_loss: 3712002.2500\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54256.0820 - val_loss: 2804844.7500\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52221.8984 - val_loss: 2786370.5000\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 58471.7461 - val_loss: 2593178.5000\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53385.4688 - val_loss: 1657558.8750\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50408.8945 - val_loss: 2246641.5000\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56403.9023 - val_loss: 3303803.2500\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 51682.0703 - val_loss: 2785683.5000\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56373.8906 - val_loss: 2660330.7500\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 53645.5703 - val_loss: 3461522.0000\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55027.2109 - val_loss: 3479146.2500\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53515.0508 - val_loss: 3142469.2500\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59576.2852 - val_loss: 3183873.7500\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60963.6328 - val_loss: 4984686.5000\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57008.1484 - val_loss: 4866279.0000\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54818.8594 - val_loss: 3730427.7500\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55302.5039 - val_loss: 3401716.2500\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51629.3711 - val_loss: 2560924.2500\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52051.1523 - val_loss: 2387674.2500\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55849.6641 - val_loss: 1814722.5000\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55802.0898 - val_loss: 5073629.0000\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51397.0586 - val_loss: 4457501.5000\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51788.1328 - val_loss: 3835436.5000\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56578.7148 - val_loss: 3829220.5000\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52187.4570 - val_loss: 3374848.2500\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50534.9531 - val_loss: 3076973.0000\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54500.4297 - val_loss: 2875412.7500\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50201.4219 - val_loss: 2223629.7500\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51963.4414 - val_loss: 2385627.0000\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51370.1289 - val_loss: 1860909.2500\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52259.7656 - val_loss: 2001366.7500\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55976.0781 - val_loss: 2834376.5000\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57649.6797 - val_loss: 2236431.0000\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45740.2344 - val_loss: 1754769.8750\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47114.8242 - val_loss: 1801600.1250\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49444.2539 - val_loss: 1772430.5000\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48808.6602 - val_loss: 1791038.2500\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46097.8750 - val_loss: 2116580.7500\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50148.2383 - val_loss: 2605622.0000\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52734.8320 - val_loss: 3722104.5000\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48893.1133 - val_loss: 3563472.7500\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52408.8281 - val_loss: 2481256.5000\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51096.4766 - val_loss: 3468163.7500\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44228.6797 - val_loss: 3055560.5000\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49921.7539 - val_loss: 2633005.7500\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 53068.8008 - val_loss: 4114943.0000\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55151.4258 - val_loss: 3534758.7500\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46586.7969 - val_loss: 2460112.0000\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49342.3867 - val_loss: 2717214.7500\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47337.9023 - val_loss: 2924625.0000\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50092.4297 - val_loss: 3076565.2500\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46844.5000 - val_loss: 2570880.5000\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46032.0156 - val_loss: 2094726.6250\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 48943.5508 - val_loss: 2576916.0000\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46554.6484 - val_loss: 3925015.0000\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51801.5508 - val_loss: 4235537.5000\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48031.3203 - val_loss: 4621854.0000\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50083.4648 - val_loss: 5103179.5000\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46142.3984 - val_loss: 3665715.2500\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44168.4688 - val_loss: 3701456.7500\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53506.6953 - val_loss: 3050552.5000\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47440.2227 - val_loss: 3743867.5000\n",
      "Epoch 222/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46462.7734 - val_loss: 2696627.0000\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43205.8008 - val_loss: 2751157.2500\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50156.8906 - val_loss: 3284575.7500\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50326.1719 - val_loss: 3524943.2500\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44884.6875 - val_loss: 3031349.7500\n",
      "Epoch 227/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45660.1484 - val_loss: 4044333.0000\n",
      "Epoch 228/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44203.6523 - val_loss: 2948157.7500\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48652.0547 - val_loss: 2702448.5000\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45099.4883 - val_loss: 2323897.0000\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48857.5234 - val_loss: 3056912.7500\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45898.7695 - val_loss: 3492034.0000\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42503.2969 - val_loss: 4810913.5000\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43351.9727 - val_loss: 3894348.2500\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45265.6836 - val_loss: 3773987.7500\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44412.1719 - val_loss: 3791146.7500\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47442.5898 - val_loss: 3930793.0000\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45551.5508 - val_loss: 3491616.7500\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46556.1680 - val_loss: 3771573.0000\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47162.2773 - val_loss: 3507481.5000\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44355.7930 - val_loss: 4047469.2500\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46165.0859 - val_loss: 4127092.2500\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45030.5508 - val_loss: 2384414.5000\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41986.8320 - val_loss: 2612312.7500\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43909.0820 - val_loss: 2992192.7500\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45245.7930 - val_loss: 2638093.2500\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43576.6992 - val_loss: 2249201.2500\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45460.5078 - val_loss: 2995157.5000\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51212.9375 - val_loss: 2981620.0000\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47210.6523 - val_loss: 2781903.5000\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44575.1992 - val_loss: 2992243.0000\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44340.4297 - val_loss: 3047063.7500\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46524.1875 - val_loss: 3158727.0000\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43341.0625 - val_loss: 4062405.7500\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45892.3945 - val_loss: 3967496.7500\n",
      "Epoch 256/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 44807.7656 - val_loss: 3400666.0000\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46271.4766 - val_loss: 2752419.5000\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45286.2344 - val_loss: 2843159.7500\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45082.0273 - val_loss: 3823692.5000\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 73470.9219 - val_loss: 4317915.0000\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57539.6953 - val_loss: 2983802.7500\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44301.0508 - val_loss: 2476685.2500\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45668.7695 - val_loss: 1879976.6250\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47316.7383 - val_loss: 1698749.7500\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43274.7266 - val_loss: 1735825.3750\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45241.7227 - val_loss: 1435381.0000\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41633.7539 - val_loss: 1576380.6250\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43635.3242 - val_loss: 1532191.6250\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41251.7695 - val_loss: 1246178.1250\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41257.1562 - val_loss: 1465626.0000\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41139.1914 - val_loss: 1616583.5000\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40423.4219 - val_loss: 1420263.2500\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42720.7930 - val_loss: 1467553.1250\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43478.7031 - val_loss: 1232703.3750\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40963.9258 - val_loss: 2130725.7500\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41320.3047 - val_loss: 2168553.2500\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43050.5469 - val_loss: 2326832.2500\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44250.6367 - val_loss: 2740668.7500\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42859.1523 - val_loss: 1816726.5000\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42024.9219 - val_loss: 2422730.0000\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42593.1797 - val_loss: 1864240.2500\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44698.0547 - val_loss: 1629386.8750\n",
      "Epoch 283/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44511.4219 - val_loss: 2412959.7500\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41062.5586 - val_loss: 2459184.5000\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42642.6445 - val_loss: 3035589.0000\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44074.1289 - val_loss: 2119927.5000\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41782.4453 - val_loss: 1454621.5000\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43136.7148 - val_loss: 2938850.7500\n",
      "Epoch 289/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43903.5469 - val_loss: 1560474.3750\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41190.5234 - val_loss: 2359930.0000\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43910.6914 - val_loss: 3874486.0000\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39751.0039 - val_loss: 3551683.2500\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39072.3711 - val_loss: 2663860.7500\n",
      "Epoch 294/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40442.9844 - val_loss: 2527956.7500\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47164.5234 - val_loss: 3728928.0000\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43972.4023 - val_loss: 3391326.2500\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45380.2539 - val_loss: 3571728.0000\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43193.2734 - val_loss: 3452717.0000\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42106.6445 - val_loss: 3328488.7500\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45271.9102 - val_loss: 4600356.0000\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45527.1445 - val_loss: 4112170.2500\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40840.7695 - val_loss: 3846277.5000\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43537.4492 - val_loss: 3809957.5000\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46680.3789 - val_loss: 3243862.7500\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44403.3242 - val_loss: 4646818.0000\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42577.5664 - val_loss: 3474385.5000\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41706.9414 - val_loss: 3879439.7500\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41407.7461 - val_loss: 4132697.2500\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43085.9805 - val_loss: 2742448.5000\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42080.5430 - val_loss: 4077450.2500\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45421.8086 - val_loss: 3528551.0000\n",
      "Epoch 312/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42399.8086 - val_loss: 3705380.0000\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45193.4062 - val_loss: 3072529.7500\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46249.1484 - val_loss: 4244574.5000\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40999.7891 - val_loss: 3122708.0000\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40320.0859 - val_loss: 3814194.0000\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46290.3203 - val_loss: 4721631.0000\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39222.9023 - val_loss: 4140905.5000\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41369.3750 - val_loss: 3660215.5000\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42546.6758 - val_loss: 7171549.5000\n",
      "Epoch 321/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42930.8672 - val_loss: 4875257.0000\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45050.9883 - val_loss: 4546533.5000\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40990.5898 - val_loss: 2938270.2500\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39671.9141 - val_loss: 2664795.7500\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44449.3047 - val_loss: 2511375.2500\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41889.3398 - val_loss: 2990494.7500\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43345.1602 - val_loss: 3871546.0000\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44687.6250 - val_loss: 2743622.5000\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40431.5703 - val_loss: 2763780.5000\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40704.2578 - val_loss: 3838073.0000\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43538.8867 - val_loss: 5513771.0000\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42950.6133 - val_loss: 4251150.0000\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41687.2031 - val_loss: 3875588.5000\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39992.8867 - val_loss: 4479402.0000\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39122.1367 - val_loss: 4143442.5000\n",
      "Epoch 336/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41463.1602 - val_loss: 3338227.2500\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39653.8555 - val_loss: 4463612.0000\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44700.1953 - val_loss: 4373552.5000\n",
      "Epoch 339/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38116.4922 - val_loss: 5593457.5000\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39189.6094 - val_loss: 5459269.0000\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43454.3008 - val_loss: 5765342.0000\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43744.1211 - val_loss: 7504641.0000\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39884.8281 - val_loss: 7622173.0000\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40231.1875 - val_loss: 6350021.0000\n",
      "Epoch 345/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37742.4336 - val_loss: 5668326.0000\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42296.4297 - val_loss: 5298946.5000\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39335.5039 - val_loss: 4765006.5000\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42533.3633 - val_loss: 4714744.0000\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44399.6484 - val_loss: 4710909.0000\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 50285.0664 - val_loss: 6486401.5000\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41713.6250 - val_loss: 5271064.0000\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41212.6055 - val_loss: 4948763.5000\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37710.1484 - val_loss: 4750070.5000\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41663.1211 - val_loss: 5207635.5000\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42155.0078 - val_loss: 6429372.0000\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36962.1016 - val_loss: 4651243.5000\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40634.5273 - val_loss: 3566856.0000\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38581.8828 - val_loss: 5040776.5000\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38641.6445 - val_loss: 3854556.5000\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41336.7852 - val_loss: 5053690.5000\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40730.5039 - val_loss: 6600952.0000\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41244.3555 - val_loss: 4491140.0000\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45702.3555 - val_loss: 8750075.0000\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39349.1914 - val_loss: 5515111.5000\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37591.7109 - val_loss: 5850136.0000\n",
      "Epoch 366/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39850.0820 - val_loss: 6125379.0000\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38186.0195 - val_loss: 4474818.5000\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41579.0898 - val_loss: 3721428.0000\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38159.9609 - val_loss: 3252813.5000\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38608.1367 - val_loss: 3460928.0000\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40938.3828 - val_loss: 4325933.5000\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40512.4102 - val_loss: 5915870.0000\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39772.0195 - val_loss: 5566310.5000\n",
      "Epoch 374/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38451.6172 - val_loss: 4767942.0000\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36196.0703 - val_loss: 4605317.0000\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37273.5508 - val_loss: 6183103.0000\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40415.8711 - val_loss: 6429029.0000\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41253.0508 - val_loss: 6907283.5000\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38381.3008 - val_loss: 6678271.0000\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38414.6719 - val_loss: 5800252.0000\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45567.2656 - val_loss: 7662774.5000\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39345.0586 - val_loss: 6418923.0000\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39526.5156 - val_loss: 5567884.0000\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39518.9844 - val_loss: 5540274.0000\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35726.8008 - val_loss: 5741597.0000\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39633.8164 - val_loss: 5630760.5000\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42005.2383 - val_loss: 5470706.0000\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36319.9922 - val_loss: 5571922.5000\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40224.0742 - val_loss: 4795906.5000\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42114.6016 - val_loss: 5361618.0000\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44053.7812 - val_loss: 6606793.0000\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41474.7344 - val_loss: 6251565.5000\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39896.0391 - val_loss: 6262462.0000\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37889.9883 - val_loss: 5930770.0000\n",
      "Epoch 395/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41387.9180 - val_loss: 6990232.0000\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38340.1172 - val_loss: 4973255.0000\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36244.7461 - val_loss: 7281095.0000\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35587.0977 - val_loss: 6322458.5000\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39369.0352 - val_loss: 5164855.0000\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 40053.1875 - val_loss: 4648089.0000\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38549.5156 - val_loss: 5749893.5000\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36437.2344 - val_loss: 6644018.0000\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36326.0859 - val_loss: 5977281.0000\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36209.7188 - val_loss: 7025062.0000\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42212.3672 - val_loss: 5956575.5000\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39762.8594 - val_loss: 5884649.0000\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38530.5781 - val_loss: 6229532.0000\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38517.7109 - val_loss: 5876523.0000\n",
      "Epoch 409/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37617.2188 - val_loss: 5091584.5000\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51186.8125 - val_loss: 14535915.0000\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39382.0156 - val_loss: 10167954.0000\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59639.1445 - val_loss: 365473.0625\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36822.3398 - val_loss: 2829194.5000\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40240.4219 - val_loss: 6659846.5000\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38078.3633 - val_loss: 7676764.0000\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38250.1328 - val_loss: 7129760.5000\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36849.5586 - val_loss: 7889478.5000\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36498.7734 - val_loss: 7970376.5000\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34687.5039 - val_loss: 6574382.5000\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42387.5000 - val_loss: 10458629.0000\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39404.9883 - val_loss: 7998386.5000\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38752.4688 - val_loss: 7070495.0000\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37153.0391 - val_loss: 5999540.5000\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39372.1328 - val_loss: 5643197.5000\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36568.1641 - val_loss: 5466537.0000\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37986.9141 - val_loss: 6160079.5000\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37666.5117 - val_loss: 4889289.5000\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37653.7812 - val_loss: 5999613.0000\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36721.0820 - val_loss: 5403093.5000\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41059.6875 - val_loss: 5722863.5000\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39907.7500 - val_loss: 5494821.0000\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36877.9492 - val_loss: 6660779.5000\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36239.4961 - val_loss: 5872072.0000\n",
      "Epoch 434/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38976.4961 - val_loss: 5558305.5000\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40824.1641 - val_loss: 5769537.0000\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36387.8477 - val_loss: 4254502.0000\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35215.7188 - val_loss: 4867877.0000\n",
      "Epoch 438/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38969.3203 - val_loss: 3159683.2500\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38207.5156 - val_loss: 4312595.0000\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40110.7227 - val_loss: 4040356.7500\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36208.2461 - val_loss: 4373186.5000\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42595.9648 - val_loss: 5948512.0000\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36588.0430 - val_loss: 5770280.5000\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37372.5312 - val_loss: 4124679.7500\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35286.3633 - val_loss: 3774994.2500\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37830.4062 - val_loss: 4316828.5000\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33662.5000 - val_loss: 3531166.5000\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34257.8398 - val_loss: 3858203.5000\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 36409.4922 - val_loss: 4012697.5000\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37065.5078 - val_loss: 3931188.2500\n",
      "Epoch 451/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37738.3203 - val_loss: 5070660.5000\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34945.1133 - val_loss: 4102150.5000\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36331.8242 - val_loss: 3094695.5000\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39154.5469 - val_loss: 3896825.0000\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39561.3477 - val_loss: 3200652.7500\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35424.1758 - val_loss: 3522890.5000\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39863.5391 - val_loss: 3326807.2500\n",
      "Epoch 458/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 33696.6758 - val_loss: 4051000.0000\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36888.2891 - val_loss: 4296881.5000\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37975.2734 - val_loss: 4885108.0000\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39086.3438 - val_loss: 5659882.5000\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35092.4844 - val_loss: 4830111.0000\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34123.6172 - val_loss: 4808640.0000\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36244.4805 - val_loss: 4987359.0000\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36960.1758 - val_loss: 7800504.0000\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34806.0938 - val_loss: 4428567.0000\n",
      "Epoch 467/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35394.8750 - val_loss: 4151037.2500\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38524.7305 - val_loss: 4150295.7500\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 32276.9648 - val_loss: 4213886.5000\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33191.6445 - val_loss: 3158326.0000\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34117.5195 - val_loss: 3379762.2500\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38056.9141 - val_loss: 3756020.2500\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35129.5117 - val_loss: 3102382.7500\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33758.2930 - val_loss: 2558109.7500\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35849.9219 - val_loss: 3840915.7500\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40124.1328 - val_loss: 4347676.0000\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33535.2773 - val_loss: 4456352.5000\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 37317.5781 - val_loss: 8360354.5000\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35388.8242 - val_loss: 5876341.5000\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37521.3750 - val_loss: 6276957.0000\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35757.1875 - val_loss: 5274040.0000\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34148.5547 - val_loss: 5195343.5000\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35499.5195 - val_loss: 6194303.5000\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37171.2188 - val_loss: 6100943.5000\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32539.1914 - val_loss: 5029150.0000\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36340.0430 - val_loss: 4322056.5000\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36728.9219 - val_loss: 3206821.5000\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34427.2891 - val_loss: 3381126.2500\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33285.0508 - val_loss: 4354202.5000\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35694.5508 - val_loss: 3295447.5000\n",
      "Epoch 491/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37766.1406 - val_loss: 4254981.5000\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34490.2734 - val_loss: 5043170.5000\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33582.8633 - val_loss: 3357745.2500\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31468.1016 - val_loss: 3555591.7500\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34906.4922 - val_loss: 3750739.0000\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33802.8008 - val_loss: 3768906.7500\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33635.9453 - val_loss: 3803550.7500\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37080.0664 - val_loss: 2932623.7500\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34266.9336 - val_loss: 3228605.7500\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37641.5742 - val_loss: 2682698.5000\n",
      "Finished.\n",
      "Training Swish Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "185/185 [==============================] - 3s 8ms/step - loss: 422859.7500 - val_loss: 564721.5000\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 421625.6562 - val_loss: 563491.0000\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 419816.0625 - val_loss: 533641.6875\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 416465.9375 - val_loss: 408000.3750\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 411974.2500 - val_loss: 335648.8125\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 408011.1562 - val_loss: 329566.1562\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 403910.9688 - val_loss: 324917.2188\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 399427.2500 - val_loss: 431270.2500\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 394435.5312 - val_loss: 327712.5312\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 390885.8750 - val_loss: 321229.5625\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 387050.0625 - val_loss: 331444.9375\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 383341.8750 - val_loss: 323156.0000\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 376677.4375 - val_loss: 319700.6875\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 372911.4062 - val_loss: 321288.8125\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 365368.6875 - val_loss: 310964.2188\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 361816.6562 - val_loss: 361602.8750\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 355794.3125 - val_loss: 406996.4062\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 353604.5312 - val_loss: 382304.0938\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 347118.4688 - val_loss: 413790.4375\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 340334.4375 - val_loss: 449826.0312\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 335839.5312 - val_loss: 476268.3438\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 330407.6562 - val_loss: 440479.6562\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 326488.3438 - val_loss: 354503.3438\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 318267.6875 - val_loss: 313344.8125\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 315836.8438 - val_loss: 347072.4688\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 308343.4688 - val_loss: 284728.6875\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 302689.9375 - val_loss: 284826.6562\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 295635.5312 - val_loss: 258979.7812\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 293292.0625 - val_loss: 306058.3125\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 294839.8750 - val_loss: 261412.7344\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 288911.0938 - val_loss: 245878.4688\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 277943.9062 - val_loss: 278476.8438\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 273846.4688 - val_loss: 263194.6562\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 277053.5000 - val_loss: 240510.7812\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 270046.7812 - val_loss: 209388.8125\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 263946.6875 - val_loss: 212383.9844\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 259271.4531 - val_loss: 209107.8906\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 253125.5469 - val_loss: 200028.3906\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 255002.5781 - val_loss: 196941.5000\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 244898.2656 - val_loss: 187440.7500\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 239661.2188 - val_loss: 184230.5312\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 237975.6250 - val_loss: 196174.9375\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 233507.7500 - val_loss: 199175.1250\n",
      "Epoch 44/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 233562.8438 - val_loss: 224172.1875\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 225666.0156 - val_loss: 166824.7656\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 220246.7969 - val_loss: 184934.0156\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 217535.5469 - val_loss: 161143.7344\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 210591.1875 - val_loss: 168983.7812\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 210133.3125 - val_loss: 174148.9531\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 198926.4531 - val_loss: 156176.4844\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 200356.6250 - val_loss: 162037.9062\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 197102.2812 - val_loss: 204265.1562\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 190035.6875 - val_loss: 169669.2969\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 188433.2500 - val_loss: 235332.0312\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 177051.8281 - val_loss: 217367.9688\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 179632.5156 - val_loss: 221459.6250\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 179351.7344 - val_loss: 247738.6406\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 168234.2500 - val_loss: 294877.5625\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 173339.7031 - val_loss: 448161.9062\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 169637.1406 - val_loss: 539151.5625\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 161633.4219 - val_loss: 525429.9375\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 147807.1406 - val_loss: 553581.0625\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 148527.0312 - val_loss: 403255.8438\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 152121.9688 - val_loss: 600231.0000\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 147815.2344 - val_loss: 566364.0625\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 144330.9688 - val_loss: 637059.5000\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 134235.3438 - val_loss: 551333.5625\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 143817.0469 - val_loss: 735932.6875\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 125764.4844 - val_loss: 1150299.1250\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 129916.3594 - val_loss: 697580.4375\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 123371.5703 - val_loss: 1100907.5000\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 123747.9453 - val_loss: 768130.8750\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 117697.3047 - val_loss: 632218.3750\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 116093.6406 - val_loss: 750397.3750\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 108396.6172 - val_loss: 601921.8125\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 106335.4531 - val_loss: 657066.6250\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 101719.7500 - val_loss: 521770.1562\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 104517.1484 - val_loss: 701152.1250\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 101416.8125 - val_loss: 714315.8750\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 92455.8750 - val_loss: 855282.9375\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 92526.8984 - val_loss: 656276.1875\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 91783.0703 - val_loss: 1258340.7500\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 92577.0078 - val_loss: 776711.3750\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 86170.4766 - val_loss: 682416.5000\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88022.9297 - val_loss: 672512.3750\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 83656.7109 - val_loss: 715498.7500\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 84792.0391 - val_loss: 1566671.1250\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 84932.7656 - val_loss: 1433443.6250\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85067.4375 - val_loss: 2173918.2500\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 76606.2812 - val_loss: 1933932.2500\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 78863.0469 - val_loss: 1754177.5000\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 79672.8125 - val_loss: 2090094.7500\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70698.8594 - val_loss: 1869553.5000\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 75382.1797 - val_loss: 1878487.1250\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 75720.7188 - val_loss: 1717037.3750\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 73932.3594 - val_loss: 1703023.2500\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69998.7812 - val_loss: 1714601.3750\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65448.1445 - val_loss: 1275736.2500\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69105.5938 - val_loss: 1365721.1250\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70349.0312 - val_loss: 1508316.3750\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71998.5625 - val_loss: 1362954.8750\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66742.0234 - val_loss: 1322055.5000\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70599.3438 - val_loss: 1162382.2500\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61875.4922 - val_loss: 1189243.7500\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64754.2695 - val_loss: 1066189.0000\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62679.7422 - val_loss: 1216569.3750\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67945.9609 - val_loss: 1269898.6250\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63213.1367 - val_loss: 1439634.1250\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68718.2578 - val_loss: 1350752.8750\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57684.1953 - val_loss: 1381783.2500\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68320.9297 - val_loss: 1632132.2500\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61860.2852 - val_loss: 1392732.1250\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59848.8672 - val_loss: 1465536.6250\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65321.6172 - val_loss: 1655630.3750\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61985.5039 - val_loss: 1601962.7500\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58101.1250 - val_loss: 1489839.8750\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60332.1641 - val_loss: 1614772.7500\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71326.6250 - val_loss: 2127589.7500\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54042.5352 - val_loss: 1672979.6250\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65088.3711 - val_loss: 997216.4375\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55869.3555 - val_loss: 1110197.8750\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54690.8633 - val_loss: 1134679.1250\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50480.4727 - val_loss: 1260941.7500\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59128.5898 - val_loss: 1525356.3750\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60757.7812 - val_loss: 1224497.3750\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63321.8828 - val_loss: 1761472.7500\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55079.0508 - val_loss: 1357710.6250\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54066.6797 - val_loss: 1199253.6250\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56521.6875 - val_loss: 1433487.0000\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58576.7930 - val_loss: 1240386.5000\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52309.2031 - val_loss: 1167673.0000\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60640.2812 - val_loss: 1148265.2500\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59685.8359 - val_loss: 1321178.6250\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55410.3203 - val_loss: 1295249.7500\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55451.2148 - val_loss: 798504.3125\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55883.7891 - val_loss: 924551.2500\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54747.9375 - val_loss: 839811.8750\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53627.2734 - val_loss: 825669.2500\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51672.8281 - val_loss: 700839.3750\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48912.8477 - val_loss: 530029.7500\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52830.4414 - val_loss: 608084.5000\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51764.1133 - val_loss: 788758.5625\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54234.6211 - val_loss: 649918.3125\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49393.3633 - val_loss: 776496.1250\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49589.9766 - val_loss: 905665.4375\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53030.6211 - val_loss: 658741.8125\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51713.8672 - val_loss: 608817.0000\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47584.5430 - val_loss: 707658.8125\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52816.4062 - val_loss: 954970.5000\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50516.4531 - val_loss: 780938.2500\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51980.8594 - val_loss: 799110.3125\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50087.4414 - val_loss: 696842.5625\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49220.5742 - val_loss: 574761.1875\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44705.1797 - val_loss: 778494.5625\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51362.3477 - val_loss: 716740.6250\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46945.9453 - val_loss: 649274.2500\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48997.7031 - val_loss: 488278.0938\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52119.2656 - val_loss: 626146.6875\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48244.5000 - val_loss: 413311.4062\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52131.8672 - val_loss: 363958.6250\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 51895.4922 - val_loss: 576065.1250\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48126.2227 - val_loss: 697470.9375\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49379.3477 - val_loss: 813135.5000\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55662.5234 - val_loss: 499475.4375\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 45218.4375 - val_loss: 618134.9375\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48091.5078 - val_loss: 521312.2188\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45607.4102 - val_loss: 389376.5938\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46324.6602 - val_loss: 416686.6562\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 43934.5859 - val_loss: 507070.2188\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54709.2930 - val_loss: 735953.5625\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49855.9883 - val_loss: 620275.0000\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46183.5039 - val_loss: 641374.2500\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44492.5273 - val_loss: 438298.4062\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47678.8633 - val_loss: 428991.1250\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43614.6758 - val_loss: 322816.0625\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46830.3477 - val_loss: 444514.3125\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42183.0273 - val_loss: 433537.6250\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45176.0742 - val_loss: 475183.2812\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46406.7188 - val_loss: 327604.1250\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50461.6055 - val_loss: 501210.4688\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45134.0430 - val_loss: 473356.3125\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43395.4648 - val_loss: 596584.5625\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 45418.4219 - val_loss: 419768.6875\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46636.8008 - val_loss: 372120.2188\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45665.6094 - val_loss: 512021.7188\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43645.7734 - val_loss: 452670.5000\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44362.0703 - val_loss: 394018.0625\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40621.1953 - val_loss: 344260.0625\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44095.5742 - val_loss: 296539.0625\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 44605.1406 - val_loss: 538912.8125\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41904.6172 - val_loss: 353188.5312\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44230.9805 - val_loss: 345214.1250\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42441.8242 - val_loss: 350756.2188\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49531.0508 - val_loss: 330686.7812\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43209.2188 - val_loss: 220619.6719\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43832.6523 - val_loss: 1180679.5000\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43653.0898 - val_loss: 1197560.7500\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40004.2344 - val_loss: 1150387.3750\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48688.9883 - val_loss: 1352009.2500\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44364.4727 - val_loss: 1065962.1250\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43982.1875 - val_loss: 1055845.1250\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41831.8164 - val_loss: 825149.0000\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41665.8711 - val_loss: 728678.6250\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43362.7461 - val_loss: 652707.6250\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41230.2656 - val_loss: 737957.3125\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41974.2539 - val_loss: 673048.7500\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43123.1211 - val_loss: 811501.5000\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39331.1875 - val_loss: 571262.0625\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41059.8438 - val_loss: 488690.3125\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45390.8320 - val_loss: 512406.7188\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38683.4297 - val_loss: 475021.4062\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42840.5312 - val_loss: 339614.9375\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45805.3867 - val_loss: 544854.1875\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 43983.8320 - val_loss: 675625.3125\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41503.7695 - val_loss: 598093.3125\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42002.2422 - val_loss: 462324.0000\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40691.8281 - val_loss: 455086.9062\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42148.2812 - val_loss: 457838.5625\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39936.6602 - val_loss: 593664.1875\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41705.0859 - val_loss: 563857.0000\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43307.8516 - val_loss: 485291.5938\n",
      "Epoch 222/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40833.1250 - val_loss: 429035.2812\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39237.0977 - val_loss: 494031.6250\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41445.9102 - val_loss: 428964.5312\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40695.9492 - val_loss: 529026.1875\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42609.2461 - val_loss: 657485.7500\n",
      "Epoch 227/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 45187.9023 - val_loss: 588314.7500\n",
      "Epoch 228/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41034.3750 - val_loss: 558497.5000\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43255.9961 - val_loss: 654825.5000\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39325.3984 - val_loss: 648609.8125\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40998.0664 - val_loss: 620283.3750\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39153.1992 - val_loss: 449497.8750\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38197.7891 - val_loss: 449796.4375\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39559.7812 - val_loss: 653734.6250\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41169.6719 - val_loss: 540432.6250\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41013.2383 - val_loss: 499784.0938\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40827.6328 - val_loss: 482779.7188\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40105.5781 - val_loss: 471104.9688\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38164.0977 - val_loss: 411346.1875\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38104.1602 - val_loss: 451450.9375\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40596.7188 - val_loss: 447338.0312\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39307.2539 - val_loss: 402757.3438\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38282.7266 - val_loss: 453099.3125\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40609.0586 - val_loss: 596489.1875\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36372.2852 - val_loss: 546502.1875\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37008.6055 - val_loss: 352032.2188\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35656.7930 - val_loss: 426802.3750\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39663.5000 - val_loss: 503352.3750\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47071.8164 - val_loss: 515123.7500\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37545.7891 - val_loss: 434011.1250\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39527.6094 - val_loss: 396513.0312\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37505.9570 - val_loss: 558410.0625\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40323.4023 - val_loss: 530043.8125\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37845.0547 - val_loss: 489746.7812\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37646.8906 - val_loss: 465656.2188\n",
      "Epoch 256/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42842.9023 - val_loss: 574615.0000\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37536.2500 - val_loss: 427382.7500\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39463.5469 - val_loss: 476628.4688\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42780.7461 - val_loss: 339626.4688\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38780.8633 - val_loss: 288236.6250\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36841.0742 - val_loss: 456080.1875\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36460.6250 - val_loss: 475105.6250\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36317.3984 - val_loss: 295862.3125\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41868.4883 - val_loss: 331254.7812\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36616.1328 - val_loss: 263778.8125\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38421.8242 - val_loss: 286807.6875\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36572.6133 - val_loss: 366655.4062\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36516.6562 - val_loss: 450855.6250\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35753.9414 - val_loss: 379430.3438\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36475.1719 - val_loss: 524455.2500\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38369.5469 - val_loss: 378941.4062\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36890.7500 - val_loss: 444659.7812\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40889.9883 - val_loss: 426581.0938\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36960.0117 - val_loss: 313871.0000\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36862.1836 - val_loss: 443619.9375\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39117.2031 - val_loss: 779383.5625\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38617.2578 - val_loss: 474756.3125\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42828.3047 - val_loss: 587109.1250\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36993.3086 - val_loss: 665293.6250\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37038.8164 - val_loss: 626959.1875\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36600.5078 - val_loss: 514183.4375\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39302.8047 - val_loss: 648158.4375\n",
      "Epoch 283/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36938.7344 - val_loss: 520799.1250\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33933.2930 - val_loss: 456335.0000\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36869.7930 - val_loss: 518252.7812\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37970.0586 - val_loss: 447288.6250\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36610.0742 - val_loss: 364638.6875\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35248.6406 - val_loss: 368972.6875\n",
      "Epoch 289/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39019.6445 - val_loss: 275930.2812\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37808.7891 - val_loss: 392726.2812\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34279.1016 - val_loss: 313922.0000\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38669.8477 - val_loss: 526035.1250\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35105.9570 - val_loss: 546239.7500\n",
      "Epoch 294/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41058.2969 - val_loss: 430724.0625\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34556.5547 - val_loss: 462605.1562\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34929.1211 - val_loss: 326518.3438\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36038.2266 - val_loss: 373406.8750\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34790.9375 - val_loss: 259751.8750\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36325.6445 - val_loss: 387492.6250\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39973.4531 - val_loss: 348531.7812\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35946.0898 - val_loss: 465888.0312\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38838.3203 - val_loss: 411197.5312\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41777.0742 - val_loss: 1494597.2500\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35848.1289 - val_loss: 923105.0625\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34681.4141 - val_loss: 879225.5000\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36829.2812 - val_loss: 821684.3125\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35923.8750 - val_loss: 776490.5625\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33544.9062 - val_loss: 880505.6250\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36494.3203 - val_loss: 480404.6250\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37414.1953 - val_loss: 524020.6250\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37301.6680 - val_loss: 599294.0000\n",
      "Epoch 312/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37433.6055 - val_loss: 700315.0625\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35496.6367 - val_loss: 816026.9375\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33280.7812 - val_loss: 695325.2500\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37056.6133 - val_loss: 854867.1250\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34596.4453 - val_loss: 801496.0625\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34143.4414 - val_loss: 761547.0000\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35102.8438 - val_loss: 724387.5000\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33779.4648 - val_loss: 710870.0000\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42329.9922 - val_loss: 961216.5000\n",
      "Epoch 321/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 35489.8711 - val_loss: 1291104.7500\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35217.4219 - val_loss: 927468.8125\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34440.7969 - val_loss: 1162418.8750\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33686.0703 - val_loss: 850014.9375\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39590.7734 - val_loss: 833927.6875\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36493.3125 - val_loss: 555489.9375\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32207.9629 - val_loss: 633016.4375\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35001.4336 - val_loss: 498730.0625\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34619.4180 - val_loss: 615784.1875\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32301.0820 - val_loss: 658021.3125\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35128.6562 - val_loss: 1182246.8750\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33142.8594 - val_loss: 1315800.7500\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32286.0762 - val_loss: 1088885.2500\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34819.3945 - val_loss: 1160365.0000\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32923.3555 - val_loss: 1004315.8750\n",
      "Epoch 336/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 32276.5234 - val_loss: 1314434.5000\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34300.5039 - val_loss: 1081669.7500\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32258.2656 - val_loss: 980950.1250\n",
      "Epoch 339/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32940.1367 - val_loss: 1104878.7500\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33825.4023 - val_loss: 1263542.5000\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32444.8809 - val_loss: 1359979.5000\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33882.5820 - val_loss: 1232777.2500\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32759.7754 - val_loss: 1000800.4375\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31775.6152 - val_loss: 1118165.6250\n",
      "Epoch 345/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34707.2891 - val_loss: 1198990.6250\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34279.1836 - val_loss: 1209161.0000\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34183.4844 - val_loss: 1066287.1250\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33067.9102 - val_loss: 1169035.0000\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32749.3574 - val_loss: 985837.6250\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32762.0762 - val_loss: 936549.0625\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31406.2715 - val_loss: 1012079.8125\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32016.1270 - val_loss: 1293354.5000\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32601.7305 - val_loss: 1364752.2500\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39915.6758 - val_loss: 1223629.7500\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 37787.0977 - val_loss: 1029710.5625\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32590.1719 - val_loss: 1476065.3750\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30718.1289 - val_loss: 1368748.6250\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31912.5625 - val_loss: 1211994.2500\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34061.6641 - val_loss: 1454515.8750\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35295.4844 - val_loss: 1011445.5000\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32027.2246 - val_loss: 1226935.1250\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31215.4277 - val_loss: 1197389.0000\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30627.4395 - val_loss: 1128563.5000\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33236.2969 - val_loss: 1231196.3750\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31403.1230 - val_loss: 1152741.2500\n",
      "Epoch 366/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31161.4316 - val_loss: 909705.6250\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34072.0898 - val_loss: 1503373.8750\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36049.5039 - val_loss: 937981.8125\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32741.6309 - val_loss: 1083419.0000\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30313.6035 - val_loss: 992974.6875\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32447.1113 - val_loss: 817508.5000\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31693.0176 - val_loss: 652115.7500\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32779.1562 - val_loss: 637896.5625\n",
      "Epoch 374/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31407.9434 - val_loss: 827333.9375\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29031.9004 - val_loss: 1047392.6250\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31572.9297 - val_loss: 870932.2500\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34497.2266 - val_loss: 922053.0625\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31185.4785 - val_loss: 1019230.6250\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33873.4766 - val_loss: 723642.4375\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35126.7109 - val_loss: 1146328.2500\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30934.1074 - val_loss: 1098368.0000\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30302.7090 - val_loss: 840738.6875\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34212.8281 - val_loss: 806778.3125\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 35799.4609 - val_loss: 1195213.0000\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32525.3164 - val_loss: 1237918.0000\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32753.2422 - val_loss: 1184344.7500\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30978.8203 - val_loss: 1394763.8750\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31449.0918 - val_loss: 1062170.1250\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30190.9160 - val_loss: 1085324.0000\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29745.5371 - val_loss: 1261852.0000\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33240.7695 - val_loss: 993057.4375\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30151.3652 - val_loss: 908830.3125\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30562.5156 - val_loss: 787558.7500\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29861.1152 - val_loss: 1186783.0000\n",
      "Epoch 395/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31777.7305 - val_loss: 1136766.7500\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34773.2031 - val_loss: 1510280.2500\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31309.8262 - val_loss: 1213547.7500\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31985.8906 - val_loss: 1329346.0000\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33312.5898 - val_loss: 813576.0625\n",
      "Epoch 400/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31042.6641 - val_loss: 1015099.2500\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30844.4004 - val_loss: 815305.0000\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31681.3320 - val_loss: 688357.2500\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30733.7461 - val_loss: 1083679.3750\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32946.4180 - val_loss: 1151741.2500\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 34809.2617 - val_loss: 1596282.1250\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29465.8613 - val_loss: 1300562.7500\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29937.6758 - val_loss: 1828552.5000\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31385.2500 - val_loss: 1477411.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31956.4785 - val_loss: 1628354.1250\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30362.0293 - val_loss: 1354397.7500\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27550.7344 - val_loss: 1570765.1250\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31385.9258 - val_loss: 1173308.1250\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29018.0625 - val_loss: 1005488.1875\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30953.8125 - val_loss: 1320867.1250\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30886.5762 - val_loss: 1014674.8125\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28432.4180 - val_loss: 985709.9375\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33095.6016 - val_loss: 1177801.2500\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29980.8730 - val_loss: 1079226.2500\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30464.6230 - val_loss: 936531.4375\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29270.5117 - val_loss: 1243280.7500\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29166.7969 - val_loss: 1220633.2500\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31036.9277 - val_loss: 1400677.5000\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30924.9648 - val_loss: 1287024.1250\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30365.7852 - val_loss: 1469593.0000\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 31074.1406 - val_loss: 1345346.0000\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 29135.2148 - val_loss: 1431668.1250\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28754.1602 - val_loss: 1419607.6250\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30353.6133 - val_loss: 1347234.3750\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27803.1621 - val_loss: 1272155.0000\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29251.5508 - val_loss: 1549464.2500\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28296.2207 - val_loss: 1321303.0000\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30287.8535 - val_loss: 1225886.7500\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28108.3145 - val_loss: 1414559.5000\n",
      "Epoch 434/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28051.3594 - val_loss: 1581883.6250\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29370.9102 - val_loss: 1462985.3750\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31578.5039 - val_loss: 1831483.3750\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30189.3984 - val_loss: 1177244.5000\n",
      "Epoch 438/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29460.6582 - val_loss: 1543580.1250\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28655.0195 - val_loss: 1116740.3750\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29326.8691 - val_loss: 1269093.5000\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30578.8086 - val_loss: 1686718.0000\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 36125.3398 - val_loss: 1593851.6250\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32064.9531 - val_loss: 1619752.1250\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31530.2227 - val_loss: 1746312.1250\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29470.0938 - val_loss: 2228827.7500\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30482.8633 - val_loss: 1988018.5000\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29034.3965 - val_loss: 2054639.7500\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30641.0898 - val_loss: 1602325.1250\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30030.5625 - val_loss: 2079465.3750\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29307.3691 - val_loss: 2146157.5000\n",
      "Epoch 451/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27604.5469 - val_loss: 1793147.1250\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28874.5781 - val_loss: 2325689.0000\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31901.0801 - val_loss: 1706085.0000\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28326.4824 - val_loss: 2708504.5000\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 26594.3691 - val_loss: 2339716.2500\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29293.9375 - val_loss: 1504145.2500\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30417.4043 - val_loss: 2185926.5000\n",
      "Epoch 458/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29016.8848 - val_loss: 2190457.0000\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28267.1699 - val_loss: 2270103.2500\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27108.8281 - val_loss: 2290403.5000\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28060.1777 - val_loss: 1531848.7500\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27313.8125 - val_loss: 1579426.0000\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29779.6836 - val_loss: 1269282.2500\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28908.4922 - val_loss: 1294543.1250\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28249.8633 - val_loss: 1911696.0000\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 26921.5918 - val_loss: 2303045.0000\n",
      "Epoch 467/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32476.6797 - val_loss: 2662892.5000\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30001.6270 - val_loss: 3016341.5000\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29308.6367 - val_loss: 2919968.0000\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29800.3984 - val_loss: 2203917.7500\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28464.8848 - val_loss: 1760333.7500\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27239.6230 - val_loss: 1931084.2500\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28829.5625 - val_loss: 2590702.7500\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27465.9688 - val_loss: 2486677.7500\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27770.9746 - val_loss: 1783391.5000\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 25309.0254 - val_loss: 3269092.2500\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 31477.8320 - val_loss: 2645334.7500\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27427.4824 - val_loss: 2433544.0000\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30034.1406 - val_loss: 1558895.0000\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 26321.4199 - val_loss: 1816288.8750\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27338.4395 - val_loss: 1930121.1250\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38103.8203 - val_loss: 1624666.8750\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29653.2207 - val_loss: 1058844.7500\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 30491.1602 - val_loss: 1765813.7500\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27700.1543 - val_loss: 1829329.8750\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27007.0879 - val_loss: 1856169.8750\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 26797.9375 - val_loss: 1756304.6250\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27284.5117 - val_loss: 1575693.7500\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27513.4727 - val_loss: 1261957.1250\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 27289.7031 - val_loss: 1948975.6250\n",
      "Epoch 491/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 30019.9629 - val_loss: 1386222.6250\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 25792.7246 - val_loss: 2301991.0000\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 32932.6289 - val_loss: 2188836.0000\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29243.8984 - val_loss: 2250732.5000\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 33557.3828 - val_loss: 2614283.5000\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29745.8047 - val_loss: 2932027.7500\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 32207.6270 - val_loss: 2252563.2500\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28346.3887 - val_loss: 2436930.2500\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 29380.6445 - val_loss: 2192186.0000\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 28197.0176 - val_loss: 2307486.0000\n",
      "Finished.\n",
      "Training Sequential Activation Neural Network...\n",
      "Epoch 1/500\n",
      "185/185 [==============================] - 3s 8ms/step - loss: 422928.6875 - val_loss: 564588.6875\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 421767.9062 - val_loss: 563664.3125\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 420476.4375 - val_loss: 562692.5000\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 418785.9375 - val_loss: 562737.5625\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 416408.7812 - val_loss: 562410.0000\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 411338.7500 - val_loss: 561371.6250\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 405137.0000 - val_loss: 557947.5000\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 401393.3438 - val_loss: 555687.9375\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 395344.0625 - val_loss: 553194.6250\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 389865.3438 - val_loss: 549394.8125\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 386414.8750 - val_loss: 547892.7500\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 380050.5938 - val_loss: 542337.0625\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 374629.7500 - val_loss: 538639.8750\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 368341.8438 - val_loss: 525698.4375\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 364038.0625 - val_loss: 518422.5000\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 359395.5000 - val_loss: 514695.7188\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 353646.7500 - val_loss: 510516.2812\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 348717.9375 - val_loss: 508991.2812\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 345442.4688 - val_loss: 504659.4688\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 338165.5000 - val_loss: 501486.2188\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 332536.6250 - val_loss: 500454.7812\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 327489.3125 - val_loss: 486563.7500\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 326032.1562 - val_loss: 491218.8125\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 320423.0938 - val_loss: 467451.2500\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 315395.1250 - val_loss: 456632.2188\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 310098.8125 - val_loss: 463580.5000\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 307425.4062 - val_loss: 474824.4688\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 303689.2500 - val_loss: 454000.0312\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 291583.7188 - val_loss: 444812.3125\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 289972.1562 - val_loss: 450703.8750\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 294144.4688 - val_loss: 466515.4688\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 285284.0312 - val_loss: 444676.9688\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 275087.5938 - val_loss: 454811.7500\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 276233.1562 - val_loss: 406082.0938\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 270406.5000 - val_loss: 422729.7812\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 264334.8125 - val_loss: 395011.2500\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 262378.4062 - val_loss: 409627.0625\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 259635.5312 - val_loss: 364580.8438\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 258050.6562 - val_loss: 355137.7188\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 246290.2500 - val_loss: 349616.6562\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 247093.3125 - val_loss: 343049.7500\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 237124.0781 - val_loss: 335791.2500\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 238437.5156 - val_loss: 354018.6562\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 232292.0156 - val_loss: 332268.8125\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 226752.9375 - val_loss: 323818.4375\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 220959.5781 - val_loss: 324869.8750\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 213529.7344 - val_loss: 311337.0312\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 208589.4062 - val_loss: 311868.0000\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 208015.2500 - val_loss: 321063.0000\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 207000.4062 - val_loss: 308019.0000\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 199345.8125 - val_loss: 380422.0938\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 193928.5000 - val_loss: 312902.0000\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 190456.8281 - val_loss: 289637.0000\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 187497.3281 - val_loss: 287891.4688\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 182580.7188 - val_loss: 286760.9375\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 176687.7188 - val_loss: 356329.5625\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 175956.1094 - val_loss: 399420.7188\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 179501.4688 - val_loss: 357242.1875\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 172562.4219 - val_loss: 330049.3125\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 167319.8906 - val_loss: 461832.6875\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 160281.4531 - val_loss: 387103.2500\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 156367.3594 - val_loss: 370207.6250\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 153728.1406 - val_loss: 404138.0000\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 149174.4375 - val_loss: 369842.2500\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 154101.6875 - val_loss: 355944.6562\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 144392.8594 - val_loss: 365951.9688\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 146365.0781 - val_loss: 303139.8750\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 134285.8750 - val_loss: 297991.4375\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 123967.5781 - val_loss: 270357.4062\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 126458.0781 - val_loss: 266544.7812\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 127675.4062 - val_loss: 264487.3750\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 118822.7344 - val_loss: 309427.3750\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 123710.9688 - val_loss: 291090.4062\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 120137.8750 - val_loss: 256003.6875\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 127830.6406 - val_loss: 239877.6719\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 107517.9453 - val_loss: 297668.3438\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 103698.7188 - val_loss: 333453.5625\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 104446.6328 - val_loss: 423789.3438\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 99923.1250 - val_loss: 376484.3438\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 94503.0391 - val_loss: 295151.5625\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 100827.2812 - val_loss: 250465.4688\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 95113.8125 - val_loss: 247544.2500\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 96348.5469 - val_loss: 248261.4375\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 94156.9062 - val_loss: 169393.8438\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88045.3750 - val_loss: 185242.1094\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 81944.6953 - val_loss: 194056.6406\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85508.0391 - val_loss: 291153.8125\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 86210.6094 - val_loss: 225894.0781\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 81903.0469 - val_loss: 226133.7969\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 74758.0547 - val_loss: 223184.5000\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 83094.0469 - val_loss: 417890.6875\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 98868.2891 - val_loss: 398135.9688\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 82028.1172 - val_loss: 368393.1250\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 80789.2422 - val_loss: 303108.9062\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 74882.3438 - val_loss: 291651.0625\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88008.4297 - val_loss: 309576.1875\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 74521.1250 - val_loss: 294665.1875\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 72088.2656 - val_loss: 291310.5625\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70386.9531 - val_loss: 304184.7188\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69387.1328 - val_loss: 301939.5312\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71193.3906 - val_loss: 291263.6250\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 70932.9141 - val_loss: 294006.8438\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 69646.9219 - val_loss: 369296.0938\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66938.7812 - val_loss: 351494.3125\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67660.5312 - val_loss: 317140.7188\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66529.0781 - val_loss: 314844.1250\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64799.5117 - val_loss: 315401.6562\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63438.1367 - val_loss: 295950.8438\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69521.2188 - val_loss: 294390.2812\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63686.5859 - val_loss: 295826.9688\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63624.8828 - val_loss: 292020.2188\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67900.0703 - val_loss: 292141.5312\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65557.0859 - val_loss: 296958.3438\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66614.7500 - val_loss: 318273.0000\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88523.0859 - val_loss: 314213.9375\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71370.4297 - val_loss: 299865.3125\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63052.8477 - val_loss: 300090.4062\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71635.4141 - val_loss: 300378.0938\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59841.3594 - val_loss: 298910.6875\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 80099.9688 - val_loss: 214791.6719\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66014.8359 - val_loss: 154292.2500\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61074.0000 - val_loss: 149093.3438\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58434.3203 - val_loss: 315728.4688\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63534.3633 - val_loss: 298397.7812\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63928.0586 - val_loss: 302091.0000\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70238.6797 - val_loss: 302984.8750\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63715.7656 - val_loss: 299224.2500\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68044.9141 - val_loss: 304012.6562\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63647.0312 - val_loss: 287642.4062\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65361.6914 - val_loss: 278605.7188\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66236.4219 - val_loss: 309247.6875\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64880.2930 - val_loss: 292195.4375\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61611.7773 - val_loss: 270788.0000\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60612.8281 - val_loss: 254778.4531\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65388.3672 - val_loss: 179766.1406\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 70430.7969 - val_loss: 174645.1094\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60752.5039 - val_loss: 237557.0312\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60944.6406 - val_loss: 175356.5625\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63422.5117 - val_loss: 482763.6875\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66902.0938 - val_loss: 481763.2812\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60983.4961 - val_loss: 223314.5156\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59773.8047 - val_loss: 340754.9688\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64816.8438 - val_loss: 281145.0312\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66311.7969 - val_loss: 430481.5000\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62157.7109 - val_loss: 305148.1875\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61196.1445 - val_loss: 308906.1250\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63257.0742 - val_loss: 297503.0312\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71074.5312 - val_loss: 243906.2969\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65136.2656 - val_loss: 303328.9688\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67303.0625 - val_loss: 198487.0938\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61082.5664 - val_loss: 172664.1250\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60109.1055 - val_loss: 183966.5781\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58363.8203 - val_loss: 214733.3594\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 61890.0859 - val_loss: 243354.0781\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63249.8906 - val_loss: 258926.7031\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 65058.4570 - val_loss: 192496.5469\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61138.8047 - val_loss: 283627.4688\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61084.7891 - val_loss: 327617.2188\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64984.1445 - val_loss: 965197.4375\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 76712.5391 - val_loss: 270991.7812\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61846.5742 - val_loss: 244605.2031\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58087.2188 - val_loss: 247971.2812\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66197.2734 - val_loss: 157433.8906\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59566.9297 - val_loss: 145761.6562\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 67518.5938 - val_loss: 314456.5000\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61046.1484 - val_loss: 310196.1562\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62999.9375 - val_loss: 310799.8750\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65783.4219 - val_loss: 305030.7500\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61094.0898 - val_loss: 306211.5625\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58417.2188 - val_loss: 306295.5000\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61583.1758 - val_loss: 308569.0625\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63865.7188 - val_loss: 266794.1562\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62008.5938 - val_loss: 309238.4688\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 67579.2969 - val_loss: 265490.7500\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 58663.5312 - val_loss: 259406.2656\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60778.3047 - val_loss: 336068.2812\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 62443.2617 - val_loss: 330727.2500\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60879.1758 - val_loss: 318016.7812\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 64330.9258 - val_loss: 306260.1875\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 58898.0273 - val_loss: 308542.2812\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 57291.5117 - val_loss: 326286.7812\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60660.8086 - val_loss: 303249.2812\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60232.0312 - val_loss: 306515.4062\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 61748.8242 - val_loss: 319380.6250\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 61909.9766 - val_loss: 303244.1250\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 64887.9922 - val_loss: 346316.0625\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55797.4375 - val_loss: 168275.3750\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62432.4727 - val_loss: 294514.5312\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60987.2422 - val_loss: 246412.6094\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 74215.9141 - val_loss: 221490.7500\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 65105.7500 - val_loss: 179897.6719\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61232.5469 - val_loss: 172284.1719\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 64027.1797 - val_loss: 164169.1094\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61366.6875 - val_loss: 162821.9219\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56034.5469 - val_loss: 167307.0781\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60579.6445 - val_loss: 162364.4219\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 56700.8438 - val_loss: 165900.5000\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 60280.9648 - val_loss: 164389.6406\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 59003.3008 - val_loss: 458657.3125\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 86959.4375 - val_loss: 243775.9688\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 62913.9883 - val_loss: 156150.8438\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64034.0117 - val_loss: 140434.2344\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55797.0469 - val_loss: 139063.9062\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61243.4375 - val_loss: 137604.7344\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64213.0859 - val_loss: 155099.3594\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 62244.1602 - val_loss: 159099.8125\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 64708.5000 - val_loss: 180263.7031\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 55909.9336 - val_loss: 163061.7969\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57972.7305 - val_loss: 139231.2500\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58637.2227 - val_loss: 141897.8906\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62627.0156 - val_loss: 141529.8750\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57382.0977 - val_loss: 140412.3750\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61574.6484 - val_loss: 147780.3594\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61235.9297 - val_loss: 145572.9375\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54911.3359 - val_loss: 146206.4844\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56333.2070 - val_loss: 144332.2812\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58708.5312 - val_loss: 155750.4844\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60741.2422 - val_loss: 192935.1719\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 68234.0000 - val_loss: 156046.5625\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 69142.5156 - val_loss: 189979.8281\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56682.2969 - val_loss: 161116.0781\n",
      "Epoch 222/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66381.0156 - val_loss: 166500.7188\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59587.6328 - val_loss: 322284.3125\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59722.9414 - val_loss: 313069.0938\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58568.9219 - val_loss: 303460.8750\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56597.7656 - val_loss: 302528.7500\n",
      "Epoch 227/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52946.2891 - val_loss: 324848.4688\n",
      "Epoch 228/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58844.7773 - val_loss: 325342.5000\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55554.2773 - val_loss: 328306.0625\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57091.6602 - val_loss: 325016.0625\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53623.0742 - val_loss: 326336.7812\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59932.1055 - val_loss: 163319.9688\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61759.0938 - val_loss: 196343.6094\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55623.0508 - val_loss: 314405.8750\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61380.0977 - val_loss: 306141.2188\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57205.5625 - val_loss: 301224.8125\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57931.5195 - val_loss: 317125.2188\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57095.1289 - val_loss: 317903.4062\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60248.2422 - val_loss: 149686.0156\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60229.6406 - val_loss: 252754.0000\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61488.5234 - val_loss: 277943.0938\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 60955.3594 - val_loss: 297482.6562\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57198.3359 - val_loss: 296579.8438\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58204.2344 - val_loss: 344486.9062\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59481.4258 - val_loss: 356577.6562\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60528.3047 - val_loss: 299577.1562\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59718.4531 - val_loss: 310478.6875\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58175.2773 - val_loss: 319715.4062\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61754.0078 - val_loss: 306072.0000\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59050.6016 - val_loss: 304015.4375\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62652.0430 - val_loss: 325769.3750\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59764.2148 - val_loss: 340191.2188\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59556.5898 - val_loss: 329850.3750\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63072.6953 - val_loss: 348652.7812\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60811.4688 - val_loss: 341892.2188\n",
      "Epoch 256/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 71642.8438 - val_loss: 380327.7812\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59091.2266 - val_loss: 363289.5312\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52646.2227 - val_loss: 377455.4688\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57695.3359 - val_loss: 877973.5625\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58859.7852 - val_loss: 536820.2500\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59747.6445 - val_loss: 819994.5625\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64668.4922 - val_loss: 418450.0938\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57558.3438 - val_loss: 387931.3750\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59348.3789 - val_loss: 368235.5938\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60156.9648 - val_loss: 356480.1875\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66338.8906 - val_loss: 316877.1562\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56207.1562 - val_loss: 320050.0312\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62689.5391 - val_loss: 317056.8750\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56370.6523 - val_loss: 318332.2500\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57102.3086 - val_loss: 321574.4688\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62355.7930 - val_loss: 320668.9062\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56981.2852 - val_loss: 326895.2188\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60666.4805 - val_loss: 393036.3125\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59454.3320 - val_loss: 492652.1562\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61607.0352 - val_loss: 568976.8125\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54226.9180 - val_loss: 457926.1250\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53229.9609 - val_loss: 1237668.3750\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56374.4375 - val_loss: 464768.1875\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57305.3594 - val_loss: 911023.7500\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59764.0000 - val_loss: 1674802.8750\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63042.8242 - val_loss: 551441.9375\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62150.4336 - val_loss: 325049.1562\n",
      "Epoch 283/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63097.1445 - val_loss: 409047.6875\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58282.6445 - val_loss: 424203.5625\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57542.9609 - val_loss: 382859.1875\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59214.4062 - val_loss: 385120.3750\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55217.9062 - val_loss: 420301.6875\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60053.2578 - val_loss: 300226.0000\n",
      "Epoch 289/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59564.5078 - val_loss: 313086.7812\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 64802.3086 - val_loss: 332985.8750\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61654.3359 - val_loss: 351962.5938\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 54995.0898 - val_loss: 315954.9375\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55661.1602 - val_loss: 307428.5312\n",
      "Epoch 294/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60566.7266 - val_loss: 305482.1250\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58383.7656 - val_loss: 307642.1875\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55488.5430 - val_loss: 307530.5312\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56422.7461 - val_loss: 301421.3125\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56386.7617 - val_loss: 323683.5625\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58679.9258 - val_loss: 305009.0625\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58393.2891 - val_loss: 303981.6875\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 63556.7383 - val_loss: 303405.4375\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60245.9961 - val_loss: 306571.0938\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55545.3047 - val_loss: 304553.6875\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 62316.4375 - val_loss: 308770.8438\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57846.6016 - val_loss: 491137.3125\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58859.8438 - val_loss: 303355.1875\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54199.3125 - val_loss: 306225.7500\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53291.6641 - val_loss: 434112.3750\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 72485.1797 - val_loss: 154765.5156\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57699.6094 - val_loss: 164757.7969\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59166.8477 - val_loss: 162672.9688\n",
      "Epoch 312/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53741.9727 - val_loss: 167948.9531\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53052.0234 - val_loss: 195521.5938\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60134.8281 - val_loss: 181185.9375\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57534.8008 - val_loss: 345975.2500\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55787.7148 - val_loss: 485284.6875\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59211.1367 - val_loss: 516330.2812\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60484.7148 - val_loss: 323272.7188\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57299.7266 - val_loss: 319472.7500\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60536.3125 - val_loss: 454424.8438\n",
      "Epoch 321/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56207.1484 - val_loss: 579739.2500\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 66911.4922 - val_loss: 228174.8438\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60890.6523 - val_loss: 219060.3281\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55036.1328 - val_loss: 238710.8750\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59425.0195 - val_loss: 317568.7812\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56214.9531 - val_loss: 371173.5312\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55721.5664 - val_loss: 347936.1250\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57939.7266 - val_loss: 315117.7500\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59794.8320 - val_loss: 328435.9375\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55893.7539 - val_loss: 348147.0625\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60906.2500 - val_loss: 376258.3438\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55681.8398 - val_loss: 345770.6562\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56507.0469 - val_loss: 342800.3125\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60966.1562 - val_loss: 387272.0312\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58435.5625 - val_loss: 679066.7500\n",
      "Epoch 336/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60064.8867 - val_loss: 635606.0000\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55784.1641 - val_loss: 340205.0625\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61750.7109 - val_loss: 2239034.2500\n",
      "Epoch 339/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56047.8594 - val_loss: 703169.6250\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57296.9414 - val_loss: 889452.7500\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59027.1797 - val_loss: 745275.2500\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 61318.9336 - val_loss: 538134.4375\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53319.3672 - val_loss: 585799.6875\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53907.9219 - val_loss: 351581.0312\n",
      "Epoch 345/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 58696.5586 - val_loss: 347976.6875\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53949.8984 - val_loss: 578759.2500\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 58788.3945 - val_loss: 320190.1875\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52932.9062 - val_loss: 311360.1562\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 53691.3203 - val_loss: 317941.0000\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55243.0273 - val_loss: 304639.4062\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51815.5625 - val_loss: 519727.8750\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 59370.4141 - val_loss: 318576.3750\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54436.5430 - val_loss: 343582.3438\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 60238.2383 - val_loss: 385546.6875\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 57869.3477 - val_loss: 397141.0312\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 53939.1406 - val_loss: 508574.3438\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 55665.3672 - val_loss: 323910.3438\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 52259.2227 - val_loss: 316531.6875\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 50108.4648 - val_loss: 608954.3125\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52493.8281 - val_loss: 350794.3125\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 53703.1875 - val_loss: 321745.6875\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 55149.6406 - val_loss: 646132.5000\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 55400.8867 - val_loss: 662942.0000\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49231.2891 - val_loss: 663388.4375\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47944.5938 - val_loss: 874878.2500\n",
      "Epoch 366/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50763.8008 - val_loss: 851499.4375\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54008.0586 - val_loss: 773102.8750\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52747.7500 - val_loss: 355363.2812\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49220.9531 - val_loss: 536044.3125\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 54694.1758 - val_loss: 1101352.0000\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49566.9336 - val_loss: 351239.0938\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 52472.1641 - val_loss: 1154814.2500\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51649.9141 - val_loss: 396047.2500\n",
      "Epoch 374/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57322.6250 - val_loss: 373228.9375\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45640.9258 - val_loss: 372061.4688\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 56640.4727 - val_loss: 944982.6250\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 57024.1523 - val_loss: 596695.6875\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48460.7891 - val_loss: 852175.3125\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 48889.9023 - val_loss: 1205294.7500\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49430.7930 - val_loss: 980277.5000\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50556.5391 - val_loss: 4227563.0000\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50305.8789 - val_loss: 356411.8750\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51167.2461 - val_loss: 273347.1250\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49683.3086 - val_loss: 247678.7344\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51562.5273 - val_loss: 253584.7969\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48440.1641 - val_loss: 332600.0938\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48796.5234 - val_loss: 336890.2500\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48101.5898 - val_loss: 419907.2188\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45350.4805 - val_loss: 333072.0312\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47096.4688 - val_loss: 371197.4375\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49622.0586 - val_loss: 377029.0000\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51413.4648 - val_loss: 444408.9062\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46915.5039 - val_loss: 254526.1406\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50086.3984 - val_loss: 196243.7969\n",
      "Epoch 395/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51477.6875 - val_loss: 257615.3438\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46135.0156 - val_loss: 260866.9062\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47244.0391 - val_loss: 270901.7188\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47123.9023 - val_loss: 255684.0938\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48753.0547 - val_loss: 610625.5000\n",
      "Epoch 400/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47784.3711 - val_loss: 351230.5625\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48739.0586 - val_loss: 311439.0312\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50884.3750 - val_loss: 213274.6406\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44060.4180 - val_loss: 242285.0781\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45737.5391 - val_loss: 473100.9375\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43774.0703 - val_loss: 370536.9375\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48679.7148 - val_loss: 444318.3438\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46240.7930 - val_loss: 410438.9688\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43123.5625 - val_loss: 449379.2188\n",
      "Epoch 409/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46938.6641 - val_loss: 387045.8750\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50223.4688 - val_loss: 368684.9375\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43008.5664 - val_loss: 465835.6875\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48770.4375 - val_loss: 284217.5000\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47050.1719 - val_loss: 362308.4375\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44586.8438 - val_loss: 724747.3125\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 47349.7734 - val_loss: 295219.0938\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44115.4531 - val_loss: 261904.0156\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48716.2461 - val_loss: 298334.8125\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47608.7305 - val_loss: 278612.0625\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45508.9453 - val_loss: 266405.9688\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42942.7461 - val_loss: 269950.5312\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45008.4375 - val_loss: 254318.9219\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 48477.9141 - val_loss: 280860.3125\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44455.8711 - val_loss: 340013.8750\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49685.6602 - val_loss: 330729.4062\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47949.8203 - val_loss: 392463.5000\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49522.5391 - val_loss: 231831.0156\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44410.9531 - val_loss: 237886.5312\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42864.4648 - val_loss: 397444.8438\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44055.8047 - val_loss: 328317.0625\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44756.3203 - val_loss: 312267.4688\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43606.0156 - val_loss: 392152.5312\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45172.1602 - val_loss: 423557.2500\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44176.8516 - val_loss: 288300.2500\n",
      "Epoch 434/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45278.8438 - val_loss: 240838.8281\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51787.8555 - val_loss: 288348.9375\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42979.2188 - val_loss: 308693.6562\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47435.8008 - val_loss: 269077.6562\n",
      "Epoch 438/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47120.0508 - val_loss: 597671.1875\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 51397.5039 - val_loss: 208450.3125\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44337.0938 - val_loss: 245689.8125\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43532.3633 - val_loss: 345188.0938\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 50330.7773 - val_loss: 358485.8438\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42147.7070 - val_loss: 314064.3125\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43142.8125 - val_loss: 296103.8125\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49453.4180 - val_loss: 331182.2500\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43527.2617 - val_loss: 306287.9375\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43228.5352 - val_loss: 276846.5000\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45806.3477 - val_loss: 278455.7812\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47373.7070 - val_loss: 275809.4062\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44697.7266 - val_loss: 273752.2188\n",
      "Epoch 451/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46488.6641 - val_loss: 318808.6875\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43525.4102 - val_loss: 270290.6562\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44480.6953 - val_loss: 463453.0312\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44840.9883 - val_loss: 344737.3438\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44751.8008 - val_loss: 358877.6562\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 49368.4258 - val_loss: 459269.0312\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41990.4961 - val_loss: 377701.5000\n",
      "Epoch 458/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44707.3867 - val_loss: 276562.7500\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38195.5625 - val_loss: 359167.6875\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39969.5039 - val_loss: 1497894.0000\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43338.3047 - val_loss: 334379.8125\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 45311.4453 - val_loss: 332964.4688\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43741.8984 - val_loss: 304620.8438\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42690.0195 - val_loss: 270810.0625\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40710.2500 - val_loss: 1846834.6250\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43073.0352 - val_loss: 498979.7188\n",
      "Epoch 467/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43275.5977 - val_loss: 434560.0938\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 42978.4844 - val_loss: 400535.5000\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40159.8203 - val_loss: 1049314.1250\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41464.3086 - val_loss: 290869.5312\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44927.7969 - val_loss: 294329.0938\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42590.7695 - val_loss: 767424.1250\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 44365.4297 - val_loss: 281348.8125\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44630.9531 - val_loss: 235787.4219\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42946.6758 - val_loss: 2309059.2500\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41610.5430 - val_loss: 330128.3438\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41818.5078 - val_loss: 1046797.9375\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42143.9414 - val_loss: 466863.4688\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 39581.3672 - val_loss: 375085.7188\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 40029.6875 - val_loss: 685081.8750\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 41028.0000 - val_loss: 704607.6250\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44662.8555 - val_loss: 250721.4688\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41455.3867 - val_loss: 205429.4688\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40742.9805 - val_loss: 344258.0000\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40932.7031 - val_loss: 305665.8438\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40094.7930 - val_loss: 385969.0000\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44521.3555 - val_loss: 313296.7188\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42393.7344 - val_loss: 254682.6250\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39911.0273 - val_loss: 736003.6875\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38632.2734 - val_loss: 263374.1875\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 44179.9375 - val_loss: 367107.8125\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43407.2305 - val_loss: 719546.0000\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46690.8477 - val_loss: 267897.4375\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 43071.9062 - val_loss: 377111.4375\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38965.3750 - val_loss: 353244.5938\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 38708.0430 - val_loss: 376106.5000\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 39130.1055 - val_loss: 395517.4062\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38810.8047 - val_loss: 300814.5625\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 38365.6875 - val_loss: 274825.2188\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 40669.2461 - val_loss: 271850.4375\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Create and fit all neural networks for evaluations\n",
    "models, histories = test(X_train.to_numpy(), y_train.to_numpy(), X_test=X_test.to_numpy(), y_test=y_test.to_numpy(), task='regression', epochs=500, batch_size=128, task_name='Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01f347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss over the epochs\n",
    "plt.plot(np.array(range(len(histories['MANN'].history['loss']))), histories['MANN'].history['loss'], label='MANN')\n",
    "plt.plot(np.array(range(len(histories['MANN_dropout'].history['loss']))), histories['MANN_dropout'].history['loss'], label='MANN_dropout')\n",
    "plt.plot(np.array(range(len(histories['Sigmoid'].history['loss']))), histories['Sigmoid'].history['loss'], label='Sigmoid')\n",
    "plt.plot(np.array(range(len(histories['Tanh'].history['loss']))), histories['Tanh'].history['loss'], label='Tanh')\n",
    "plt.plot(np.array(range(len(histories['LeakyReLU'].history['loss']))), histories['LeakyReLU'].history['loss'], label='Leaky ReLU')\n",
    "plt.plot(np.array(range(len(histories['ELU'].history['loss']))), histories['ELU'].history['loss'], label='ELU')\n",
    "plt.plot(np.array(range(len(histories['Swish'].history['loss']))), histories['Swish'].history['loss'], label='Swish')\n",
    "plt.plot(np.array(range(len(histories['Sequential'].history['loss']))), histories['Sequential'].history['loss'], label='Sequential')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c132234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the validation loss over the epochs\n",
    "plt.plot(np.array(range(len(histories['MANN'].history['loss']))), histories['MANN'].history['val_loss'], label='MANN', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['MANN_dropout'].history['loss']))), histories['MANN_dropout'].history['val_loss'], label='MANN_dropout', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['Sigmoid'].history['loss']))), histories['Sigmoid'].history['val_loss'], label='Sigmoid', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['Tanh'].history['loss']))), histories['Tanh'].history['val_loss'], label='Tanh', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['LeakyReLU'].history['loss']))), histories['LeakyReLU'].history['val_loss'], label='Leaky ReLU', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['ELU'].history['loss']))), histories['ELU'].history['val_loss'], label='ELU', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['Swish'].history['loss']))), histories['Swish'].history['val_loss'], label='Swish', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['Sequential'].history['loss']))), histories['Sequential'].history['val_loss'], label='Sequential', linewidth=0.75)\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde53abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "train_hist_df = pd.DataFrame()\n",
    "val_hist_df = pd.DataFrame()\n",
    "for name, callback in histories.items():\n",
    "    train_hist_df = pd.concat((train_hist_df, pd.DataFrame(callback.history['loss'], columns=[name])), axis=1, join='inner', ignore_index=True)\n",
    "    val_hist_df = pd.concat((val_hist_df, pd.DataFrame(callback.history['val_loss'], columns=[name])), axis=1, join='inner', ignore_index=True)\n",
    "    \n",
    "train_hist_df.to_csv('Regression.training_hist.csv')\n",
    "val_hist_df.to_csv('Regression.validation_hist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "87203ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.w\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.b\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.moving_variance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_mean\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-9.moving_variance\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-9.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVR(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVR</label><div class=\"sk-toggleable__content\"><pre>LinearSVR(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVR(max_iter=10000)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best performing weights for each model and fit the traditional ML models\n",
    "for name, model in models.items():\n",
    "    model.load_weights(f'Regression.{name}.tf')\n",
    "\n",
    "# Traditional models as a baseline comparison\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "svm = LinearSVR(max_iter=10000)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7aa5c4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 5ms/step - loss: 65544.9844\n",
      "185/185 [==============================] - 1s 4ms/step - loss: 223829.5625\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 109276.7500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 26422.4316\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 261046.9688\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 65653.3125\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 156176.4844\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 137604.7500\n"
     ]
    }
   ],
   "source": [
    "# Get the testing loss for each model\n",
    "linreg_loss = keras.losses.mean_squared_error(y_test.to_numpy(), linreg.predict(X_test)).numpy()\n",
    "svm_loss = keras.losses.mean_squared_error(y_test.to_numpy(), svm.predict(X_test)).numpy()\n",
    "MANN_loss = models['MANN'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['loss']\n",
    "MANN_dropout_loss = models['MANN_Dropout'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['loss']\n",
    "Sigmoid_loss = models['Sigmoid'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['loss']\n",
    "Tanh_loss = models['Tanh'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['loss']\n",
    "LeakyReLU_loss = models['LeakyReLU'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['loss']\n",
    "ELU_loss = models['ELU'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['loss']\n",
    "Swish_loss = models['Swish'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['loss']\n",
    "Sequential_loss = models['Sequential'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "611db66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tanh NN</th>\n",
       "      <td>26422.431641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANN</th>\n",
       "      <td>65544.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU NN</th>\n",
       "      <td>65653.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sigmoid NN</th>\n",
       "      <td>109276.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sequential NN</th>\n",
       "      <td>137604.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swish NN</th>\n",
       "      <td>156176.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANN w/ Dropout</th>\n",
       "      <td>223829.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leaky ReLU NN</th>\n",
       "      <td>261046.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>326164.614714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>361163.442891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Squared Error\n",
       "Tanh NN                       26422.431641\n",
       "MANN                          65544.984375\n",
       "ELU NN                        65653.312500\n",
       "Sigmoid NN                   109276.750000\n",
       "Sequential NN                137604.750000\n",
       "Swish NN                     156176.484375\n",
       "MANN w/ Dropout              223829.562500\n",
       "Leaky ReLU NN                261046.968750\n",
       "Linear Regression            326164.614714\n",
       "Support Vector Machine       361163.442891"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save testing loss to table and display results\n",
    "results = pd.DataFrame([linreg_loss, svm_loss, MANN_loss, MANN_dropout_loss, Sigmoid_loss, Tanh_loss, LeakyReLU_loss, ELU_loss, Swish_loss, Sequential_loss],\n",
    "                      index=['Linear Regression', 'Support Vector Machine', 'MANN', 'MANN w/ Dropout', 'Sigmoid NN', 'Tanh NN', 'Leaky ReLU NN', 'ELU NN', 'Swish NN', 'Sequential NN'],\n",
    "                      columns=['Mean Squared Error'])\n",
    "results.sort_values('Mean Squared Error', inplace=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d593718",
   "metadata": {},
   "source": [
    "## NLP task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c873f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split into testing and training for processing\n",
    "data = pd.read_csv('./Datasets/NLP/twitter_MBTI.csv', index_col=0)\n",
    "features = data['text']\n",
    "target = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=42, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d711e73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7811</td>\n",
       "      <td>7811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7581</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>I just realize that today is dzi's birthday......</td>\n",
       "      <td>infp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "count                                                7811  7811\n",
       "unique                                               7581    16\n",
       "top     I just realize that today is dzi's birthday......  infp\n",
       "freq                                                    2  1282"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727ced36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Pericles216 @HierBeforeTheAC @Sachinettiyil T...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Hispanthicckk Being you makes you look cute||...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Alshymi Les balles sont réelles et sont tirée...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm like entp but idiotic|||Hey boy, do you wa...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kaeshurr1 Give it to @ZargarShanif ... He has...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Doing my project on isle neumann|||@fuzy_sox I...</td>\n",
       "      <td>entp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>she gets it https://t.co/tK0PlXKO2d|||@nakopoc...</td>\n",
       "      <td>entp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>@WeezingOffline @Max__4__x @raptalksk @Hemant3...</td>\n",
       "      <td>entp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Thanks to @About1816 for inviting me to write ...</td>\n",
       "      <td>entp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nichkhun IG Post 2022.06.19\\nExtra with 2AM Jo...</td>\n",
       "      <td>entp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text label\n",
       "0   @Pericles216 @HierBeforeTheAC @Sachinettiyil T...  intj\n",
       "1   @Hispanthicckk Being you makes you look cute||...  intj\n",
       "2   @Alshymi Les balles sont réelles et sont tirée...  intj\n",
       "3   I'm like entp but idiotic|||Hey boy, do you wa...  intj\n",
       "4   @kaeshurr1 Give it to @ZargarShanif ... He has...  intj\n",
       "..                                                ...   ...\n",
       "95  Doing my project on isle neumann|||@fuzy_sox I...  entp\n",
       "96  she gets it https://t.co/tK0PlXKO2d|||@nakopoc...  entp\n",
       "97  @WeezingOffline @Max__4__x @raptalksk @Hemant3...  entp\n",
       "98  Thanks to @About1816 for inviting me to write ...  entp\n",
       "99  Nichkhun IG Post 2022.06.19\\nExtra with 2AM Jo...  entp\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb79c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "def lemmatize(document):\n",
    "    word_pos_tags = nltk.pos_tag(document)\n",
    "    roots = [lemmatizer.lemmatize(tag[0], wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)]\n",
    "    return roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7283a6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process and normalize the data\n",
    "one_hot = OneHotEncoder(sparse_output=False)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# One-Hot encode target labels\n",
    "y_train = pd.DataFrame(data=one_hot.fit_transform(y_train.to_numpy().reshape(-1,1)), columns=one_hot.categories_)\n",
    "y_test = pd.DataFrame(data=one_hot.transform(y_test.to_numpy().reshape(-1,1)), columns=one_hot.categories_)\n",
    "\n",
    "# Clean and process text\n",
    "X_train = X_train.map(lambda x: x.lower().strip())\n",
    "X_test = X_test.map(lambda x: x.lower().strip())\n",
    "\n",
    "X_train = X_train.map(lambda x: [token for y in x.split('|||') for token in y.split(' ') if 'http' not in token and '@' not in token])\n",
    "X_test = X_test.map(lambda x: [token for y in x.split('|||') for token in y.split(' ') if 'http' not in token and '@' not in token])\n",
    "\n",
    "X_train = X_train.map(lambda x: ' '.join(x))\n",
    "X_test = X_test.map(lambda x: ' '.join(x))\n",
    "\n",
    "X_train = X_train.map(word_tokenize)\n",
    "X_test = X_test.map(word_tokenize)\n",
    "\n",
    "X_train = X_train.map(lambda x: [word for word in x if word not in stop_words and word.isalpha()])\n",
    "X_test = X_test.map(lambda x: [word for word in x if word not in stop_words and word.isalpha()])\n",
    "\n",
    "X_train = X_train.map(lambda x: lemmatize(x))\n",
    "X_test = X_test.map(lambda x: lemmatize(x))\n",
    "\n",
    "X_train = X_train.map(lambda x: ' '.join(x))\n",
    "X_test = X_test.map(lambda x: ' '.join(x))\n",
    "\n",
    "# Create word embeddings with TF-IDF\n",
    "#X_train = vectorizer.fit_transform(X_train)\n",
    "#X_test = vectorizer.transform(X_test)\n",
    "\n",
    "#X_train = np.asarray(X_train.todense())\n",
    "#X_test = np.asarray(X_test.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e08b35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multi Activation Neural Network...\n",
      "Epoch 1/500\n",
      "49/49 [==============================] - 5s 64ms/step - loss: 2.9257 - categorical_accuracy: 0.0482 - val_loss: 5.9992 - val_categorical_accuracy: 0.0128\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 3s 60ms/step - loss: 2.6086 - categorical_accuracy: 0.1271 - val_loss: 4.2651 - val_categorical_accuracy: 0.0128\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 3s 61ms/step - loss: 2.3998 - categorical_accuracy: 0.2510 - val_loss: 3.5062 - val_categorical_accuracy: 0.0128\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 3s 61ms/step - loss: 2.2496 - categorical_accuracy: 0.3244 - val_loss: 2.8920 - val_categorical_accuracy: 0.0819\n",
      "Epoch 5/500\n",
      "49/49 [==============================] - 3s 61ms/step - loss: 2.0678 - categorical_accuracy: 0.3865 - val_loss: 2.8113 - val_categorical_accuracy: 0.1472\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 2.0584 - categorical_accuracy: 0.3694 - val_loss: 3.1251 - val_categorical_accuracy: 0.0710\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.8777 - categorical_accuracy: 0.4253 - val_loss: 3.1624 - val_categorical_accuracy: 0.1113\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.7177 - categorical_accuracy: 0.4816 - val_loss: 3.0369 - val_categorical_accuracy: 0.1331\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5728 - categorical_accuracy: 0.5246 - val_loss: 3.1306 - val_categorical_accuracy: 0.1350\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.4324 - categorical_accuracy: 0.5623 - val_loss: 3.5226 - val_categorical_accuracy: 0.1356\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3319 - categorical_accuracy: 0.5936 - val_loss: 3.5016 - val_categorical_accuracy: 0.1638\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.2275 - categorical_accuracy: 0.6295 - val_loss: 3.5358 - val_categorical_accuracy: 0.1651\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1480 - categorical_accuracy: 0.6524 - val_loss: 3.4352 - val_categorical_accuracy: 0.1631\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0700 - categorical_accuracy: 0.6794 - val_loss: 5.3086 - val_categorical_accuracy: 0.1631\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0051 - categorical_accuracy: 0.6994 - val_loss: 5.4040 - val_categorical_accuracy: 0.1651\n",
      "Epoch 16/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9329 - categorical_accuracy: 0.7284 - val_loss: 4.7166 - val_categorical_accuracy: 0.1561\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0253 - categorical_accuracy: 0.6938 - val_loss: 25.6879 - val_categorical_accuracy: 0.0736\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9551 - categorical_accuracy: 0.7119 - val_loss: 13.3034 - val_categorical_accuracy: 0.0768\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8543 - categorical_accuracy: 0.7436 - val_loss: 7.7338 - val_categorical_accuracy: 0.0800\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.7894 - categorical_accuracy: 0.7638 - val_loss: 6.2847 - val_categorical_accuracy: 0.0985\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.7457 - categorical_accuracy: 0.7788 - val_loss: 4.6093 - val_categorical_accuracy: 0.0800\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.6898 - categorical_accuracy: 0.7916 - val_loss: 4.8728 - val_categorical_accuracy: 0.0883\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.6569 - categorical_accuracy: 0.8009 - val_loss: 4.3446 - val_categorical_accuracy: 0.1222\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.6163 - categorical_accuracy: 0.8102 - val_loss: 5.2265 - val_categorical_accuracy: 0.1152\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.5778 - categorical_accuracy: 0.8230 - val_loss: 4.3900 - val_categorical_accuracy: 0.1516\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.5606 - categorical_accuracy: 0.8265 - val_loss: 4.6652 - val_categorical_accuracy: 0.1427\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.5314 - categorical_accuracy: 0.8433 - val_loss: 15.6357 - val_categorical_accuracy: 0.0435\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.5006 - categorical_accuracy: 0.8529 - val_loss: 7.1612 - val_categorical_accuracy: 0.0659\n",
      "Epoch 29/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.4884 - categorical_accuracy: 0.8585 - val_loss: 5.8071 - val_categorical_accuracy: 0.1408\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.4782 - categorical_accuracy: 0.8641 - val_loss: 5.6664 - val_categorical_accuracy: 0.1567\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.4493 - categorical_accuracy: 0.8779 - val_loss: 6.0809 - val_categorical_accuracy: 0.1344\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.4307 - categorical_accuracy: 0.8806 - val_loss: 5.7808 - val_categorical_accuracy: 0.1350\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.4200 - categorical_accuracy: 0.8896 - val_loss: 6.1460 - val_categorical_accuracy: 0.1088\n",
      "Epoch 34/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.3947 - categorical_accuracy: 0.8953 - val_loss: 5.6762 - val_categorical_accuracy: 0.1248\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.3759 - categorical_accuracy: 0.8972 - val_loss: 5.2999 - val_categorical_accuracy: 0.1024\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.3526 - categorical_accuracy: 0.9065 - val_loss: 5.1212 - val_categorical_accuracy: 0.1177\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.3344 - categorical_accuracy: 0.9096 - val_loss: 4.7780 - val_categorical_accuracy: 0.1516\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.3147 - categorical_accuracy: 0.9179 - val_loss: 5.0091 - val_categorical_accuracy: 0.1587\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.3025 - categorical_accuracy: 0.9200 - val_loss: 5.0930 - val_categorical_accuracy: 0.1459\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.3044 - categorical_accuracy: 0.9217 - val_loss: 5.0216 - val_categorical_accuracy: 0.1376\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2919 - categorical_accuracy: 0.9205 - val_loss: 5.0930 - val_categorical_accuracy: 0.1177\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.2806 - categorical_accuracy: 0.9246 - val_loss: 5.0947 - val_categorical_accuracy: 0.1363\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2668 - categorical_accuracy: 0.9321 - val_loss: 5.2273 - val_categorical_accuracy: 0.1228\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.2581 - categorical_accuracy: 0.9315 - val_loss: 5.2571 - val_categorical_accuracy: 0.1324\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2584 - categorical_accuracy: 0.9333 - val_loss: 5.3794 - val_categorical_accuracy: 0.1465\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2592 - categorical_accuracy: 0.9320 - val_loss: 5.6606 - val_categorical_accuracy: 0.1126\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2410 - categorical_accuracy: 0.9395 - val_loss: 5.4014 - val_categorical_accuracy: 0.0998\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.2359 - categorical_accuracy: 0.9406 - val_loss: 11.0187 - val_categorical_accuracy: 0.1017\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2231 - categorical_accuracy: 0.9408 - val_loss: 9.4620 - val_categorical_accuracy: 0.0998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2094 - categorical_accuracy: 0.9483 - val_loss: 10.4363 - val_categorical_accuracy: 0.0755\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.2087 - categorical_accuracy: 0.9465 - val_loss: 10.2685 - val_categorical_accuracy: 0.0832\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1979 - categorical_accuracy: 0.9518 - val_loss: 10.0954 - val_categorical_accuracy: 0.0774\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.1947 - categorical_accuracy: 0.9485 - val_loss: 8.8520 - val_categorical_accuracy: 0.0787\n",
      "Epoch 54/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1948 - categorical_accuracy: 0.9501 - val_loss: 7.1081 - val_categorical_accuracy: 0.0749\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1901 - categorical_accuracy: 0.9515 - val_loss: 10.1045 - val_categorical_accuracy: 0.0921\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1884 - categorical_accuracy: 0.9539 - val_loss: 9.0098 - val_categorical_accuracy: 0.0781\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1875 - categorical_accuracy: 0.9529 - val_loss: 8.5060 - val_categorical_accuracy: 0.0934\n",
      "Epoch 58/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.1756 - categorical_accuracy: 0.9579 - val_loss: 7.8924 - val_categorical_accuracy: 0.1561\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1828 - categorical_accuracy: 0.9569 - val_loss: 7.9143 - val_categorical_accuracy: 0.1350\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1711 - categorical_accuracy: 0.9569 - val_loss: 6.4340 - val_categorical_accuracy: 0.1132\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1746 - categorical_accuracy: 0.9576 - val_loss: 7.1449 - val_categorical_accuracy: 0.1638\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.1723 - categorical_accuracy: 0.9560 - val_loss: 6.7168 - val_categorical_accuracy: 0.1523\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1673 - categorical_accuracy: 0.9600 - val_loss: 6.0939 - val_categorical_accuracy: 0.1299\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1554 - categorical_accuracy: 0.9653 - val_loss: 6.1376 - val_categorical_accuracy: 0.1331\n",
      "Epoch 65/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1490 - categorical_accuracy: 0.9665 - val_loss: 7.2589 - val_categorical_accuracy: 0.0806\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1619 - categorical_accuracy: 0.9633 - val_loss: 6.8995 - val_categorical_accuracy: 0.1107\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1404 - categorical_accuracy: 0.9662 - val_loss: 6.6552 - val_categorical_accuracy: 0.1164\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1392 - categorical_accuracy: 0.9653 - val_loss: 6.6945 - val_categorical_accuracy: 0.1305\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1383 - categorical_accuracy: 0.9699 - val_loss: 7.3811 - val_categorical_accuracy: 0.1036\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1361 - categorical_accuracy: 0.9688 - val_loss: 6.7272 - val_categorical_accuracy: 0.1267\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1326 - categorical_accuracy: 0.9701 - val_loss: 6.6570 - val_categorical_accuracy: 0.1280\n",
      "Epoch 72/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1319 - categorical_accuracy: 0.9669 - val_loss: 6.6996 - val_categorical_accuracy: 0.1260\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1258 - categorical_accuracy: 0.9677 - val_loss: 6.9502 - val_categorical_accuracy: 0.1260\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1295 - categorical_accuracy: 0.9677 - val_loss: 6.8784 - val_categorical_accuracy: 0.1542\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1240 - categorical_accuracy: 0.9670 - val_loss: 8.1149 - val_categorical_accuracy: 0.1241\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.4954 - categorical_accuracy: 0.8892 - val_loss: 8.7398 - val_categorical_accuracy: 0.0614\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.7214 - categorical_accuracy: 0.8307 - val_loss: 10.7210 - val_categorical_accuracy: 0.1011\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.5294 - categorical_accuracy: 0.8689 - val_loss: 9.7445 - val_categorical_accuracy: 0.0659\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.3606 - categorical_accuracy: 0.9060 - val_loss: 9.5919 - val_categorical_accuracy: 0.0838\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.2838 - categorical_accuracy: 0.9262 - val_loss: 8.1396 - val_categorical_accuracy: 0.0960\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2387 - categorical_accuracy: 0.9417 - val_loss: 8.2664 - val_categorical_accuracy: 0.0966\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1954 - categorical_accuracy: 0.9523 - val_loss: 8.3516 - val_categorical_accuracy: 0.1139\n",
      "Epoch 83/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.1763 - categorical_accuracy: 0.9541 - val_loss: 8.1819 - val_categorical_accuracy: 0.1056\n",
      "Epoch 84/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1548 - categorical_accuracy: 0.9614 - val_loss: 8.9853 - val_categorical_accuracy: 0.1260\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1424 - categorical_accuracy: 0.9638 - val_loss: 8.4412 - val_categorical_accuracy: 0.1273\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1262 - categorical_accuracy: 0.9704 - val_loss: 7.1025 - val_categorical_accuracy: 0.1318\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1247 - categorical_accuracy: 0.9698 - val_loss: 6.4713 - val_categorical_accuracy: 0.1446\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1159 - categorical_accuracy: 0.9734 - val_loss: 7.0927 - val_categorical_accuracy: 0.1248\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1125 - categorical_accuracy: 0.9739 - val_loss: 6.9800 - val_categorical_accuracy: 0.1420\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1076 - categorical_accuracy: 0.9762 - val_loss: 6.5667 - val_categorical_accuracy: 0.1196\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.1002 - categorical_accuracy: 0.9774 - val_loss: 6.6936 - val_categorical_accuracy: 0.1113\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1070 - categorical_accuracy: 0.9712 - val_loss: 11.7410 - val_categorical_accuracy: 0.1062\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.1027 - categorical_accuracy: 0.9771 - val_loss: 13.0431 - val_categorical_accuracy: 0.1081\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0956 - categorical_accuracy: 0.9773 - val_loss: 9.7227 - val_categorical_accuracy: 0.1139\n",
      "Epoch 95/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0911 - categorical_accuracy: 0.9795 - val_loss: 9.3838 - val_categorical_accuracy: 0.1139\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0934 - categorical_accuracy: 0.9792 - val_loss: 8.5142 - val_categorical_accuracy: 0.1190\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0862 - categorical_accuracy: 0.9805 - val_loss: 7.3152 - val_categorical_accuracy: 0.1344\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0879 - categorical_accuracy: 0.9794 - val_loss: 7.2820 - val_categorical_accuracy: 0.1337\n",
      "Epoch 99/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0894 - categorical_accuracy: 0.9810 - val_loss: 7.4763 - val_categorical_accuracy: 0.1324\n",
      "Epoch 100/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0914 - categorical_accuracy: 0.9803 - val_loss: 7.0832 - val_categorical_accuracy: 0.1324\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0923 - categorical_accuracy: 0.9795 - val_loss: 7.5807 - val_categorical_accuracy: 0.1248\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0921 - categorical_accuracy: 0.9787 - val_loss: 7.3197 - val_categorical_accuracy: 0.1235\n",
      "Epoch 103/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0999 - categorical_accuracy: 0.9773 - val_loss: 7.2247 - val_categorical_accuracy: 0.1344\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0814 - categorical_accuracy: 0.9813 - val_loss: 7.7568 - val_categorical_accuracy: 0.1184\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0800 - categorical_accuracy: 0.9816 - val_loss: 7.6139 - val_categorical_accuracy: 0.1254\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0757 - categorical_accuracy: 0.9822 - val_loss: 6.9913 - val_categorical_accuracy: 0.1529\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0850 - categorical_accuracy: 0.9797 - val_loss: 7.1044 - val_categorical_accuracy: 0.1164\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0888 - categorical_accuracy: 0.9813 - val_loss: 7.0531 - val_categorical_accuracy: 0.1222\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0806 - categorical_accuracy: 0.9824 - val_loss: 8.8646 - val_categorical_accuracy: 0.0915\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0768 - categorical_accuracy: 0.9814 - val_loss: 8.1615 - val_categorical_accuracy: 0.1369\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0930 - categorical_accuracy: 0.9782 - val_loss: 11.1332 - val_categorical_accuracy: 0.0966\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0908 - categorical_accuracy: 0.9790 - val_loss: 10.9386 - val_categorical_accuracy: 0.1024\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0831 - categorical_accuracy: 0.9806 - val_loss: 10.6847 - val_categorical_accuracy: 0.0915\n",
      "Epoch 114/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0785 - categorical_accuracy: 0.9830 - val_loss: 9.1519 - val_categorical_accuracy: 0.1446\n",
      "Epoch 115/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0782 - categorical_accuracy: 0.9802 - val_loss: 7.1916 - val_categorical_accuracy: 0.1312\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.1461 - categorical_accuracy: 0.9669 - val_loss: 121.2884 - val_categorical_accuracy: 0.0998\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.4469 - categorical_accuracy: 0.8862 - val_loss: 18.2777 - val_categorical_accuracy: 0.0416\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2656 - categorical_accuracy: 0.9310 - val_loss: 10.5726 - val_categorical_accuracy: 0.0339\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1612 - categorical_accuracy: 0.9579 - val_loss: 12.3597 - val_categorical_accuracy: 0.0499\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.1134 - categorical_accuracy: 0.9725 - val_loss: 9.2541 - val_categorical_accuracy: 0.0589\n",
      "Epoch 121/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0926 - categorical_accuracy: 0.9778 - val_loss: 10.4272 - val_categorical_accuracy: 0.0825\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0855 - categorical_accuracy: 0.9795 - val_loss: 11.5112 - val_categorical_accuracy: 0.0742\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0761 - categorical_accuracy: 0.9826 - val_loss: 8.5018 - val_categorical_accuracy: 0.0947\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0646 - categorical_accuracy: 0.9848 - val_loss: 8.8740 - val_categorical_accuracy: 0.1043\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0608 - categorical_accuracy: 0.9867 - val_loss: 8.8215 - val_categorical_accuracy: 0.1081\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0622 - categorical_accuracy: 0.9856 - val_loss: 8.3106 - val_categorical_accuracy: 0.1184\n",
      "Epoch 127/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0602 - categorical_accuracy: 0.9867 - val_loss: 10.6384 - val_categorical_accuracy: 0.0288\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0551 - categorical_accuracy: 0.9870 - val_loss: 11.0715 - val_categorical_accuracy: 0.0601\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0577 - categorical_accuracy: 0.9870 - val_loss: 12.2788 - val_categorical_accuracy: 0.0595\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0515 - categorical_accuracy: 0.9877 - val_loss: 11.7998 - val_categorical_accuracy: 0.0857\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0524 - categorical_accuracy: 0.9888 - val_loss: 12.8104 - val_categorical_accuracy: 0.1011\n",
      "Epoch 132/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0498 - categorical_accuracy: 0.9904 - val_loss: 9.6180 - val_categorical_accuracy: 0.1100\n",
      "Epoch 133/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0511 - categorical_accuracy: 0.9877 - val_loss: 10.2661 - val_categorical_accuracy: 0.1126\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0474 - categorical_accuracy: 0.9898 - val_loss: 8.8349 - val_categorical_accuracy: 0.1292\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0466 - categorical_accuracy: 0.9899 - val_loss: 9.1429 - val_categorical_accuracy: 0.1248\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0490 - categorical_accuracy: 0.9882 - val_loss: 8.6062 - val_categorical_accuracy: 0.1356\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0556 - categorical_accuracy: 0.9870 - val_loss: 8.7857 - val_categorical_accuracy: 0.1433\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0479 - categorical_accuracy: 0.9883 - val_loss: 7.9683 - val_categorical_accuracy: 0.1567\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0427 - categorical_accuracy: 0.9898 - val_loss: 8.0144 - val_categorical_accuracy: 0.1510\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0441 - categorical_accuracy: 0.9894 - val_loss: 8.7179 - val_categorical_accuracy: 0.1484\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0406 - categorical_accuracy: 0.9907 - val_loss: 8.1989 - val_categorical_accuracy: 0.1433\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0470 - categorical_accuracy: 0.9888 - val_loss: 8.5730 - val_categorical_accuracy: 0.1196\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0494 - categorical_accuracy: 0.9896 - val_loss: 8.7293 - val_categorical_accuracy: 0.1344\n",
      "Epoch 144/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0470 - categorical_accuracy: 0.9896 - val_loss: 8.2926 - val_categorical_accuracy: 0.1408\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0409 - categorical_accuracy: 0.9910 - val_loss: 8.7946 - val_categorical_accuracy: 0.1260\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0495 - categorical_accuracy: 0.9882 - val_loss: 9.1459 - val_categorical_accuracy: 0.1228\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0531 - categorical_accuracy: 0.9878 - val_loss: 8.9004 - val_categorical_accuracy: 0.1292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0539 - categorical_accuracy: 0.9880 - val_loss: 9.8688 - val_categorical_accuracy: 0.1683\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0515 - categorical_accuracy: 0.9888 - val_loss: 13.1794 - val_categorical_accuracy: 0.0461\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0519 - categorical_accuracy: 0.9878 - val_loss: 8.4939 - val_categorical_accuracy: 0.1164\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0503 - categorical_accuracy: 0.9894 - val_loss: 9.1001 - val_categorical_accuracy: 0.1593\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0494 - categorical_accuracy: 0.9883 - val_loss: 10.9079 - val_categorical_accuracy: 0.1753\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0578 - categorical_accuracy: 0.9870 - val_loss: 11.1947 - val_categorical_accuracy: 0.1823\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0614 - categorical_accuracy: 0.9842 - val_loss: 9.1970 - val_categorical_accuracy: 0.1555\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0607 - categorical_accuracy: 0.9866 - val_loss: 8.5883 - val_categorical_accuracy: 0.1561\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0530 - categorical_accuracy: 0.9867 - val_loss: 9.2448 - val_categorical_accuracy: 0.1011\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0565 - categorical_accuracy: 0.9886 - val_loss: 8.1313 - val_categorical_accuracy: 0.1184\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0497 - categorical_accuracy: 0.9901 - val_loss: 9.1162 - val_categorical_accuracy: 0.1113\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0485 - categorical_accuracy: 0.9882 - val_loss: 8.3636 - val_categorical_accuracy: 0.1574\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0412 - categorical_accuracy: 0.9909 - val_loss: 8.1423 - val_categorical_accuracy: 0.1574\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0403 - categorical_accuracy: 0.9910 - val_loss: 8.6544 - val_categorical_accuracy: 0.1369\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0396 - categorical_accuracy: 0.9909 - val_loss: 8.9016 - val_categorical_accuracy: 0.1273\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.0391 - categorical_accuracy: 0.9917 - val_loss: 8.8044 - val_categorical_accuracy: 0.1376\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0406 - categorical_accuracy: 0.9912 - val_loss: 9.2472 - val_categorical_accuracy: 0.1094\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0413 - categorical_accuracy: 0.9909 - val_loss: 8.5002 - val_categorical_accuracy: 0.1280\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0440 - categorical_accuracy: 0.9898 - val_loss: 9.6849 - val_categorical_accuracy: 0.1228\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0380 - categorical_accuracy: 0.9906 - val_loss: 8.6661 - val_categorical_accuracy: 0.1516\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0357 - categorical_accuracy: 0.9920 - val_loss: 9.5043 - val_categorical_accuracy: 0.1049\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.0347 - categorical_accuracy: 0.9914 - val_loss: 9.5619 - val_categorical_accuracy: 0.1267\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0367 - categorical_accuracy: 0.9909 - val_loss: 9.1287 - val_categorical_accuracy: 0.1216\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 0.0444 - categorical_accuracy: 0.9904 - val_loss: 8.6857 - val_categorical_accuracy: 0.1260\n",
      "Epoch 172/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0395 - categorical_accuracy: 0.9904 - val_loss: 8.8576 - val_categorical_accuracy: 0.1356\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0428 - categorical_accuracy: 0.9907 - val_loss: 8.7576 - val_categorical_accuracy: 0.1484\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0427 - categorical_accuracy: 0.9896 - val_loss: 9.8765 - val_categorical_accuracy: 0.1049\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0336 - categorical_accuracy: 0.9912 - val_loss: 9.2468 - val_categorical_accuracy: 0.1222\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0404 - categorical_accuracy: 0.9910 - val_loss: 9.9449 - val_categorical_accuracy: 0.0928\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0373 - categorical_accuracy: 0.9910 - val_loss: 9.2744 - val_categorical_accuracy: 0.1241\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0366 - categorical_accuracy: 0.9909 - val_loss: 8.7189 - val_categorical_accuracy: 0.1254\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0334 - categorical_accuracy: 0.9917 - val_loss: 8.2806 - val_categorical_accuracy: 0.1337\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0391 - categorical_accuracy: 0.9912 - val_loss: 8.7945 - val_categorical_accuracy: 0.1401\n",
      "Epoch 181/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0418 - categorical_accuracy: 0.9898 - val_loss: 8.8673 - val_categorical_accuracy: 0.1267\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0364 - categorical_accuracy: 0.9909 - val_loss: 9.5726 - val_categorical_accuracy: 0.1126\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0399 - categorical_accuracy: 0.9906 - val_loss: 10.5134 - val_categorical_accuracy: 0.0985\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0439 - categorical_accuracy: 0.9885 - val_loss: 8.6131 - val_categorical_accuracy: 0.1260\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0504 - categorical_accuracy: 0.9870 - val_loss: 9.5326 - val_categorical_accuracy: 0.1299\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0425 - categorical_accuracy: 0.9885 - val_loss: 9.5760 - val_categorical_accuracy: 0.1331\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0426 - categorical_accuracy: 0.9912 - val_loss: 9.3166 - val_categorical_accuracy: 0.1440\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0507 - categorical_accuracy: 0.9870 - val_loss: 9.4872 - val_categorical_accuracy: 0.1152\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0604 - categorical_accuracy: 0.9885 - val_loss: 8.8011 - val_categorical_accuracy: 0.1324\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0481 - categorical_accuracy: 0.9893 - val_loss: 8.3685 - val_categorical_accuracy: 0.1305\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0424 - categorical_accuracy: 0.9899 - val_loss: 8.8855 - val_categorical_accuracy: 0.1427\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0412 - categorical_accuracy: 0.9914 - val_loss: 10.0909 - val_categorical_accuracy: 0.1203\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0384 - categorical_accuracy: 0.9909 - val_loss: 10.2162 - val_categorical_accuracy: 0.1184\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0464 - categorical_accuracy: 0.9907 - val_loss: 10.6134 - val_categorical_accuracy: 0.1222\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0430 - categorical_accuracy: 0.9915 - val_loss: 9.9966 - val_categorical_accuracy: 0.1164\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0372 - categorical_accuracy: 0.9917 - val_loss: 9.0279 - val_categorical_accuracy: 0.1177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0387 - categorical_accuracy: 0.9925 - val_loss: 10.1853 - val_categorical_accuracy: 0.1337\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0327 - categorical_accuracy: 0.9923 - val_loss: 8.4827 - val_categorical_accuracy: 0.1452\n",
      "Epoch 199/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0325 - categorical_accuracy: 0.9920 - val_loss: 10.0352 - val_categorical_accuracy: 0.1164\n",
      "Epoch 200/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0338 - categorical_accuracy: 0.9925 - val_loss: 9.4239 - val_categorical_accuracy: 0.1209\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0352 - categorical_accuracy: 0.9930 - val_loss: 9.1895 - val_categorical_accuracy: 0.1350\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0332 - categorical_accuracy: 0.9918 - val_loss: 9.5009 - val_categorical_accuracy: 0.1312\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0329 - categorical_accuracy: 0.9923 - val_loss: 10.0299 - val_categorical_accuracy: 0.1312\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0397 - categorical_accuracy: 0.9912 - val_loss: 9.3572 - val_categorical_accuracy: 0.1395\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0431 - categorical_accuracy: 0.9915 - val_loss: 11.8368 - val_categorical_accuracy: 0.1126\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0406 - categorical_accuracy: 0.9902 - val_loss: 10.7159 - val_categorical_accuracy: 0.0845\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0388 - categorical_accuracy: 0.9912 - val_loss: 9.2397 - val_categorical_accuracy: 0.1267\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0360 - categorical_accuracy: 0.9920 - val_loss: 9.2181 - val_categorical_accuracy: 0.1356\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0385 - categorical_accuracy: 0.9899 - val_loss: 9.8501 - val_categorical_accuracy: 0.1344\n",
      "Epoch 210/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0346 - categorical_accuracy: 0.9920 - val_loss: 10.9296 - val_categorical_accuracy: 0.0960\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0343 - categorical_accuracy: 0.9931 - val_loss: 10.3984 - val_categorical_accuracy: 0.1196\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0321 - categorical_accuracy: 0.9918 - val_loss: 12.1662 - val_categorical_accuracy: 0.0755\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0281 - categorical_accuracy: 0.9934 - val_loss: 12.8519 - val_categorical_accuracy: 0.0845\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0337 - categorical_accuracy: 0.9925 - val_loss: 8.9796 - val_categorical_accuracy: 0.1280\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0310 - categorical_accuracy: 0.9930 - val_loss: 12.1112 - val_categorical_accuracy: 0.0838\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0266 - categorical_accuracy: 0.9931 - val_loss: 9.1714 - val_categorical_accuracy: 0.1388\n",
      "Epoch 217/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0272 - categorical_accuracy: 0.9942 - val_loss: 9.6270 - val_categorical_accuracy: 0.1408\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0284 - categorical_accuracy: 0.9936 - val_loss: 9.7424 - val_categorical_accuracy: 0.1299\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0335 - categorical_accuracy: 0.9928 - val_loss: 9.6689 - val_categorical_accuracy: 0.1280\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0311 - categorical_accuracy: 0.9938 - val_loss: 11.4311 - val_categorical_accuracy: 0.0934\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0308 - categorical_accuracy: 0.9933 - val_loss: 10.4958 - val_categorical_accuracy: 0.0838\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0340 - categorical_accuracy: 0.9920 - val_loss: 9.2609 - val_categorical_accuracy: 0.1043\n",
      "Epoch 223/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0282 - categorical_accuracy: 0.9933 - val_loss: 9.7948 - val_categorical_accuracy: 0.1260\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0264 - categorical_accuracy: 0.9938 - val_loss: 10.4700 - val_categorical_accuracy: 0.1075\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0284 - categorical_accuracy: 0.9915 - val_loss: 9.8980 - val_categorical_accuracy: 0.0813\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0310 - categorical_accuracy: 0.9934 - val_loss: 9.8585 - val_categorical_accuracy: 0.1222\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0277 - categorical_accuracy: 0.9941 - val_loss: 9.7977 - val_categorical_accuracy: 0.1286\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0302 - categorical_accuracy: 0.9925 - val_loss: 10.8821 - val_categorical_accuracy: 0.1241\n",
      "Epoch 229/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0256 - categorical_accuracy: 0.9944 - val_loss: 10.9697 - val_categorical_accuracy: 0.1350\n",
      "Epoch 230/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0299 - categorical_accuracy: 0.9934 - val_loss: 12.4462 - val_categorical_accuracy: 0.0851\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0236 - categorical_accuracy: 0.9952 - val_loss: 9.6932 - val_categorical_accuracy: 0.1305\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0206 - categorical_accuracy: 0.9952 - val_loss: 9.9204 - val_categorical_accuracy: 0.1171\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0219 - categorical_accuracy: 0.9939 - val_loss: 9.8937 - val_categorical_accuracy: 0.1388\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0231 - categorical_accuracy: 0.9942 - val_loss: 9.7579 - val_categorical_accuracy: 0.1318\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0237 - categorical_accuracy: 0.9942 - val_loss: 10.0433 - val_categorical_accuracy: 0.1548\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0257 - categorical_accuracy: 0.9936 - val_loss: 10.4197 - val_categorical_accuracy: 0.1363\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0322 - categorical_accuracy: 0.9944 - val_loss: 10.2893 - val_categorical_accuracy: 0.1286\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0223 - categorical_accuracy: 0.9944 - val_loss: 9.7757 - val_categorical_accuracy: 0.1356\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0210 - categorical_accuracy: 0.9942 - val_loss: 9.9679 - val_categorical_accuracy: 0.1248\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0218 - categorical_accuracy: 0.9949 - val_loss: 10.1917 - val_categorical_accuracy: 0.1401\n",
      "Epoch 241/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0259 - categorical_accuracy: 0.9939 - val_loss: 11.2636 - val_categorical_accuracy: 0.1401\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0304 - categorical_accuracy: 0.9926 - val_loss: 10.9533 - val_categorical_accuracy: 0.1152\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0326 - categorical_accuracy: 0.9923 - val_loss: 10.6292 - val_categorical_accuracy: 0.1433\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0275 - categorical_accuracy: 0.9933 - val_loss: 10.6596 - val_categorical_accuracy: 0.1235\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0291 - categorical_accuracy: 0.9947 - val_loss: 11.3846 - val_categorical_accuracy: 0.1222\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0254 - categorical_accuracy: 0.9949 - val_loss: 9.7516 - val_categorical_accuracy: 0.1280\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0242 - categorical_accuracy: 0.9930 - val_loss: 9.4808 - val_categorical_accuracy: 0.1376\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0268 - categorical_accuracy: 0.9939 - val_loss: 10.2255 - val_categorical_accuracy: 0.1324\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0213 - categorical_accuracy: 0.9947 - val_loss: 14.4061 - val_categorical_accuracy: 0.0576\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0239 - categorical_accuracy: 0.9944 - val_loss: 11.0404 - val_categorical_accuracy: 0.1158\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0234 - categorical_accuracy: 0.9944 - val_loss: 16.0349 - val_categorical_accuracy: 0.0685\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0279 - categorical_accuracy: 0.9934 - val_loss: 9.3329 - val_categorical_accuracy: 0.1452\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0265 - categorical_accuracy: 0.9944 - val_loss: 9.0891 - val_categorical_accuracy: 0.1190\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0333 - categorical_accuracy: 0.9934 - val_loss: 13.1718 - val_categorical_accuracy: 0.0928\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0310 - categorical_accuracy: 0.9931 - val_loss: 12.5801 - val_categorical_accuracy: 0.0819\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0339 - categorical_accuracy: 0.9920 - val_loss: 9.4568 - val_categorical_accuracy: 0.1523\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0227 - categorical_accuracy: 0.9954 - val_loss: 10.5275 - val_categorical_accuracy: 0.0781\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0274 - categorical_accuracy: 0.9930 - val_loss: 11.4646 - val_categorical_accuracy: 0.1337\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0224 - categorical_accuracy: 0.9952 - val_loss: 9.3823 - val_categorical_accuracy: 0.1318\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0231 - categorical_accuracy: 0.9952 - val_loss: 9.8109 - val_categorical_accuracy: 0.1382\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0194 - categorical_accuracy: 0.9962 - val_loss: 12.2204 - val_categorical_accuracy: 0.1043\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0191 - categorical_accuracy: 0.9957 - val_loss: 17.4165 - val_categorical_accuracy: 0.0953\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0195 - categorical_accuracy: 0.9950 - val_loss: 11.5804 - val_categorical_accuracy: 0.1011\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0203 - categorical_accuracy: 0.9952 - val_loss: 10.8343 - val_categorical_accuracy: 0.1401\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0227 - categorical_accuracy: 0.9955 - val_loss: 15.0796 - val_categorical_accuracy: 0.1062\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0254 - categorical_accuracy: 0.9955 - val_loss: 19.5020 - val_categorical_accuracy: 0.0333\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0190 - categorical_accuracy: 0.9960 - val_loss: 11.4464 - val_categorical_accuracy: 0.1075\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0265 - categorical_accuracy: 0.9941 - val_loss: 16.3175 - val_categorical_accuracy: 0.1004\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0211 - categorical_accuracy: 0.9949 - val_loss: 20.5548 - val_categorical_accuracy: 0.1049\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0327 - categorical_accuracy: 0.9944 - val_loss: 12.1398 - val_categorical_accuracy: 0.1363\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0174 - categorical_accuracy: 0.9965 - val_loss: 10.9724 - val_categorical_accuracy: 0.1427\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0174 - categorical_accuracy: 0.9971 - val_loss: 10.7403 - val_categorical_accuracy: 0.1235\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0173 - categorical_accuracy: 0.9970 - val_loss: 10.0733 - val_categorical_accuracy: 0.1433\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0199 - categorical_accuracy: 0.9968 - val_loss: 10.7033 - val_categorical_accuracy: 0.1363\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0234 - categorical_accuracy: 0.9952 - val_loss: 10.6611 - val_categorical_accuracy: 0.1420\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0250 - categorical_accuracy: 0.9957 - val_loss: 10.4692 - val_categorical_accuracy: 0.1312\n",
      "Epoch 277/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0150 - categorical_accuracy: 0.9968 - val_loss: 10.9820 - val_categorical_accuracy: 0.1216\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0149 - categorical_accuracy: 0.9965 - val_loss: 10.1663 - val_categorical_accuracy: 0.1459\n",
      "Epoch 279/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0141 - categorical_accuracy: 0.9971 - val_loss: 10.7366 - val_categorical_accuracy: 0.1171\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0176 - categorical_accuracy: 0.9957 - val_loss: 10.7887 - val_categorical_accuracy: 0.1164\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0197 - categorical_accuracy: 0.9963 - val_loss: 13.3124 - val_categorical_accuracy: 0.1081\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0266 - categorical_accuracy: 0.9958 - val_loss: 14.0464 - val_categorical_accuracy: 0.0915\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0209 - categorical_accuracy: 0.9965 - val_loss: 10.9757 - val_categorical_accuracy: 0.1484\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0198 - categorical_accuracy: 0.9955 - val_loss: 15.9178 - val_categorical_accuracy: 0.0889\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0171 - categorical_accuracy: 0.9973 - val_loss: 11.5303 - val_categorical_accuracy: 0.1171\n",
      "Epoch 286/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0172 - categorical_accuracy: 0.9957 - val_loss: 10.1513 - val_categorical_accuracy: 0.1248\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0164 - categorical_accuracy: 0.9965 - val_loss: 11.0956 - val_categorical_accuracy: 0.1235\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0185 - categorical_accuracy: 0.9965 - val_loss: 10.9795 - val_categorical_accuracy: 0.1286\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0215 - categorical_accuracy: 0.9954 - val_loss: 12.4387 - val_categorical_accuracy: 0.0947\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0250 - categorical_accuracy: 0.9962 - val_loss: 11.7382 - val_categorical_accuracy: 0.1049\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0265 - categorical_accuracy: 0.9944 - val_loss: 11.1186 - val_categorical_accuracy: 0.1184\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0218 - categorical_accuracy: 0.9957 - val_loss: 10.5887 - val_categorical_accuracy: 0.1196\n",
      "Epoch 293/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0232 - categorical_accuracy: 0.9947 - val_loss: 12.2988 - val_categorical_accuracy: 0.1171\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0222 - categorical_accuracy: 0.9950 - val_loss: 12.1733 - val_categorical_accuracy: 0.1254\n",
      "Epoch 295/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0266 - categorical_accuracy: 0.9934 - val_loss: 9.8880 - val_categorical_accuracy: 0.1267\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0227 - categorical_accuracy: 0.9965 - val_loss: 11.6588 - val_categorical_accuracy: 0.1235\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0198 - categorical_accuracy: 0.9955 - val_loss: 10.2167 - val_categorical_accuracy: 0.1107\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0230 - categorical_accuracy: 0.9957 - val_loss: 9.8526 - val_categorical_accuracy: 0.1190\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0282 - categorical_accuracy: 0.9946 - val_loss: 10.7895 - val_categorical_accuracy: 0.1171\n",
      "Epoch 300/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0201 - categorical_accuracy: 0.9958 - val_loss: 10.5590 - val_categorical_accuracy: 0.1497\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0213 - categorical_accuracy: 0.9955 - val_loss: 12.8233 - val_categorical_accuracy: 0.1056\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0194 - categorical_accuracy: 0.9963 - val_loss: 10.4769 - val_categorical_accuracy: 0.1209\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0177 - categorical_accuracy: 0.9954 - val_loss: 10.4209 - val_categorical_accuracy: 0.1299\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0132 - categorical_accuracy: 0.9962 - val_loss: 10.2589 - val_categorical_accuracy: 0.1318\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0211 - categorical_accuracy: 0.9957 - val_loss: 13.4961 - val_categorical_accuracy: 0.1068\n",
      "Epoch 306/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0191 - categorical_accuracy: 0.9957 - val_loss: 12.5377 - val_categorical_accuracy: 0.1177\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0200 - categorical_accuracy: 0.9949 - val_loss: 17.9815 - val_categorical_accuracy: 0.0646\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0167 - categorical_accuracy: 0.9971 - val_loss: 13.0214 - val_categorical_accuracy: 0.1209\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0221 - categorical_accuracy: 0.9952 - val_loss: 13.5659 - val_categorical_accuracy: 0.1126\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0214 - categorical_accuracy: 0.9954 - val_loss: 10.9095 - val_categorical_accuracy: 0.1484\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0189 - categorical_accuracy: 0.9958 - val_loss: 13.0944 - val_categorical_accuracy: 0.1145\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.0161 - categorical_accuracy: 0.9958 - val_loss: 10.8242 - val_categorical_accuracy: 0.1299\n",
      "Epoch 313/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0130 - categorical_accuracy: 0.9968 - val_loss: 10.3335 - val_categorical_accuracy: 0.1337\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0141 - categorical_accuracy: 0.9970 - val_loss: 10.9579 - val_categorical_accuracy: 0.1395\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0152 - categorical_accuracy: 0.9962 - val_loss: 11.3344 - val_categorical_accuracy: 0.1184\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0182 - categorical_accuracy: 0.9958 - val_loss: 10.5500 - val_categorical_accuracy: 0.1177\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0236 - categorical_accuracy: 0.9958 - val_loss: 11.6978 - val_categorical_accuracy: 0.1408\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0177 - categorical_accuracy: 0.9958 - val_loss: 13.6283 - val_categorical_accuracy: 0.0921\n",
      "Epoch 319/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0202 - categorical_accuracy: 0.9954 - val_loss: 10.6519 - val_categorical_accuracy: 0.1292\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0164 - categorical_accuracy: 0.9968 - val_loss: 11.1880 - val_categorical_accuracy: 0.1478\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0135 - categorical_accuracy: 0.9973 - val_loss: 11.5798 - val_categorical_accuracy: 0.1248\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0116 - categorical_accuracy: 0.9970 - val_loss: 10.1970 - val_categorical_accuracy: 0.1388\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0140 - categorical_accuracy: 0.9965 - val_loss: 10.7408 - val_categorical_accuracy: 0.1107\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0134 - categorical_accuracy: 0.9974 - val_loss: 11.4353 - val_categorical_accuracy: 0.1356\n",
      "Epoch 325/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0157 - categorical_accuracy: 0.9971 - val_loss: 11.7937 - val_categorical_accuracy: 0.1292\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0118 - categorical_accuracy: 0.9979 - val_loss: 10.7688 - val_categorical_accuracy: 0.1273\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0099 - categorical_accuracy: 0.9978 - val_loss: 11.5976 - val_categorical_accuracy: 0.1388\n",
      "Epoch 328/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0163 - categorical_accuracy: 0.9963 - val_loss: 12.0143 - val_categorical_accuracy: 0.1337\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0232 - categorical_accuracy: 0.9960 - val_loss: 16.9374 - val_categorical_accuracy: 0.0761\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0135 - categorical_accuracy: 0.9962 - val_loss: 10.9310 - val_categorical_accuracy: 0.1484\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0121 - categorical_accuracy: 0.9978 - val_loss: 10.3188 - val_categorical_accuracy: 0.1286\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0095 - categorical_accuracy: 0.9984 - val_loss: 11.3178 - val_categorical_accuracy: 0.1280\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0134 - categorical_accuracy: 0.9966 - val_loss: 11.3995 - val_categorical_accuracy: 0.1260\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0172 - categorical_accuracy: 0.9970 - val_loss: 11.7511 - val_categorical_accuracy: 0.1542\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0191 - categorical_accuracy: 0.9976 - val_loss: 11.1290 - val_categorical_accuracy: 0.1273\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0150 - categorical_accuracy: 0.9978 - val_loss: 11.4547 - val_categorical_accuracy: 0.1356\n",
      "Epoch 337/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0138 - categorical_accuracy: 0.9970 - val_loss: 12.3750 - val_categorical_accuracy: 0.1177\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0153 - categorical_accuracy: 0.9958 - val_loss: 12.6492 - val_categorical_accuracy: 0.0909\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0103 - categorical_accuracy: 0.9973 - val_loss: 10.8167 - val_categorical_accuracy: 0.1235\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0152 - categorical_accuracy: 0.9952 - val_loss: 14.3389 - val_categorical_accuracy: 0.0953\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0165 - categorical_accuracy: 0.9954 - val_loss: 9.9538 - val_categorical_accuracy: 0.1286\n",
      "Epoch 342/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0139 - categorical_accuracy: 0.9976 - val_loss: 11.5635 - val_categorical_accuracy: 0.1363\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0103 - categorical_accuracy: 0.9974 - val_loss: 11.4697 - val_categorical_accuracy: 0.1465\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0105 - categorical_accuracy: 0.9981 - val_loss: 11.4600 - val_categorical_accuracy: 0.1440\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0095 - categorical_accuracy: 0.9978 - val_loss: 10.9282 - val_categorical_accuracy: 0.1459\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0125 - categorical_accuracy: 0.9968 - val_loss: 13.2484 - val_categorical_accuracy: 0.0896\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0125 - categorical_accuracy: 0.9966 - val_loss: 12.2420 - val_categorical_accuracy: 0.1235\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0260 - categorical_accuracy: 0.9962 - val_loss: 11.8624 - val_categorical_accuracy: 0.1228\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0235 - categorical_accuracy: 0.9955 - val_loss: 12.1042 - val_categorical_accuracy: 0.1228\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0314 - categorical_accuracy: 0.9954 - val_loss: 12.3925 - val_categorical_accuracy: 0.1075\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0114 - categorical_accuracy: 0.9974 - val_loss: 12.4436 - val_categorical_accuracy: 0.1132\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0157 - categorical_accuracy: 0.9960 - val_loss: 12.5110 - val_categorical_accuracy: 0.1235\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0182 - categorical_accuracy: 0.9960 - val_loss: 12.6493 - val_categorical_accuracy: 0.1126\n",
      "Epoch 354/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0283 - categorical_accuracy: 0.9946 - val_loss: 11.1254 - val_categorical_accuracy: 0.1158\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0228 - categorical_accuracy: 0.9936 - val_loss: 18.7917 - val_categorical_accuracy: 0.0627\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0140 - categorical_accuracy: 0.9968 - val_loss: 11.5417 - val_categorical_accuracy: 0.1241\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0142 - categorical_accuracy: 0.9968 - val_loss: 11.2013 - val_categorical_accuracy: 0.1184\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0134 - categorical_accuracy: 0.9966 - val_loss: 11.5811 - val_categorical_accuracy: 0.1158\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0127 - categorical_accuracy: 0.9973 - val_loss: 11.8242 - val_categorical_accuracy: 0.1574\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0120 - categorical_accuracy: 0.9970 - val_loss: 11.8233 - val_categorical_accuracy: 0.1414\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0080 - categorical_accuracy: 0.9986 - val_loss: 13.6894 - val_categorical_accuracy: 0.0972\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0095 - categorical_accuracy: 0.9973 - val_loss: 10.7972 - val_categorical_accuracy: 0.1254\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0126 - categorical_accuracy: 0.9970 - val_loss: 11.7278 - val_categorical_accuracy: 0.1248\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0096 - categorical_accuracy: 0.9979 - val_loss: 11.1293 - val_categorical_accuracy: 0.1286\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0110 - categorical_accuracy: 0.9971 - val_loss: 13.7651 - val_categorical_accuracy: 0.1216\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0162 - categorical_accuracy: 0.9966 - val_loss: 11.6670 - val_categorical_accuracy: 0.1369\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0136 - categorical_accuracy: 0.9978 - val_loss: 12.8523 - val_categorical_accuracy: 0.1100\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0092 - categorical_accuracy: 0.9987 - val_loss: 11.6389 - val_categorical_accuracy: 0.1292\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 0.0126 - categorical_accuracy: 0.9973 - val_loss: 12.3640 - val_categorical_accuracy: 0.1126\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0140 - categorical_accuracy: 0.9962 - val_loss: 12.0871 - val_categorical_accuracy: 0.1209\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0100 - categorical_accuracy: 0.9971 - val_loss: 11.9694 - val_categorical_accuracy: 0.1350\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0162 - categorical_accuracy: 0.9958 - val_loss: 12.8091 - val_categorical_accuracy: 0.1049\n",
      "Epoch 373/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0143 - categorical_accuracy: 0.9963 - val_loss: 11.0264 - val_categorical_accuracy: 0.1523\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0191 - categorical_accuracy: 0.9954 - val_loss: 11.6789 - val_categorical_accuracy: 0.1376\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0201 - categorical_accuracy: 0.9958 - val_loss: 12.5507 - val_categorical_accuracy: 0.1452\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0160 - categorical_accuracy: 0.9965 - val_loss: 12.5977 - val_categorical_accuracy: 0.1286\n",
      "Epoch 377/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0100 - categorical_accuracy: 0.9971 - val_loss: 12.7549 - val_categorical_accuracy: 0.1196\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0155 - categorical_accuracy: 0.9974 - val_loss: 12.3160 - val_categorical_accuracy: 0.1478\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0123 - categorical_accuracy: 0.9973 - val_loss: 11.5220 - val_categorical_accuracy: 0.1312\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0117 - categorical_accuracy: 0.9974 - val_loss: 10.8540 - val_categorical_accuracy: 0.1286\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0161 - categorical_accuracy: 0.9965 - val_loss: 13.6649 - val_categorical_accuracy: 0.0896\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0181 - categorical_accuracy: 0.9970 - val_loss: 12.6498 - val_categorical_accuracy: 0.1094\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0122 - categorical_accuracy: 0.9978 - val_loss: 12.8517 - val_categorical_accuracy: 0.1139\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0103 - categorical_accuracy: 0.9984 - val_loss: 14.5996 - val_categorical_accuracy: 0.1190\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0137 - categorical_accuracy: 0.9976 - val_loss: 12.2738 - val_categorical_accuracy: 0.1248\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0149 - categorical_accuracy: 0.9966 - val_loss: 11.8043 - val_categorical_accuracy: 0.1254\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0117 - categorical_accuracy: 0.9970 - val_loss: 12.7993 - val_categorical_accuracy: 0.1241\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0093 - categorical_accuracy: 0.9982 - val_loss: 12.4577 - val_categorical_accuracy: 0.1190\n",
      "Epoch 389/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0085 - categorical_accuracy: 0.9981 - val_loss: 11.3553 - val_categorical_accuracy: 0.1459\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0063 - categorical_accuracy: 0.9987 - val_loss: 11.2069 - val_categorical_accuracy: 0.1350\n",
      "Epoch 391/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0072 - categorical_accuracy: 0.9981 - val_loss: 15.3620 - val_categorical_accuracy: 0.0870\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0083 - categorical_accuracy: 0.9981 - val_loss: 13.8240 - val_categorical_accuracy: 0.1088\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0085 - categorical_accuracy: 0.9989 - val_loss: 12.1506 - val_categorical_accuracy: 0.0992\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0103 - categorical_accuracy: 0.9976 - val_loss: 11.1678 - val_categorical_accuracy: 0.1248\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0133 - categorical_accuracy: 0.9982 - val_loss: 12.4339 - val_categorical_accuracy: 0.1145\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0062 - categorical_accuracy: 0.9987 - val_loss: 14.1680 - val_categorical_accuracy: 0.1132\n",
      "Epoch 397/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0077 - categorical_accuracy: 0.9986 - val_loss: 11.8196 - val_categorical_accuracy: 0.1312\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0120 - categorical_accuracy: 0.9974 - val_loss: 12.7286 - val_categorical_accuracy: 0.1478\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0136 - categorical_accuracy: 0.9978 - val_loss: 11.0228 - val_categorical_accuracy: 0.1292\n",
      "Epoch 400/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0143 - categorical_accuracy: 0.9976 - val_loss: 12.0216 - val_categorical_accuracy: 0.1324\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0162 - categorical_accuracy: 0.9965 - val_loss: 14.6706 - val_categorical_accuracy: 0.1011\n",
      "Epoch 402/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0147 - categorical_accuracy: 0.9960 - val_loss: 13.7683 - val_categorical_accuracy: 0.0877\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0126 - categorical_accuracy: 0.9973 - val_loss: 13.9988 - val_categorical_accuracy: 0.1216\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0114 - categorical_accuracy: 0.9984 - val_loss: 12.8225 - val_categorical_accuracy: 0.1216\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0075 - categorical_accuracy: 0.9974 - val_loss: 12.5043 - val_categorical_accuracy: 0.1209\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0070 - categorical_accuracy: 0.9984 - val_loss: 11.5458 - val_categorical_accuracy: 0.1030\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0085 - categorical_accuracy: 0.9981 - val_loss: 11.7517 - val_categorical_accuracy: 0.1222\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0085 - categorical_accuracy: 0.9973 - val_loss: 11.8605 - val_categorical_accuracy: 0.1305\n",
      "Epoch 409/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0105 - categorical_accuracy: 0.9979 - val_loss: 24.1499 - val_categorical_accuracy: 0.0845\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0045 - categorical_accuracy: 0.9990 - val_loss: 12.4145 - val_categorical_accuracy: 0.0589\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0117 - categorical_accuracy: 0.9973 - val_loss: 11.6627 - val_categorical_accuracy: 0.0928\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0079 - categorical_accuracy: 0.9981 - val_loss: 11.5312 - val_categorical_accuracy: 0.1299\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0051 - categorical_accuracy: 0.9986 - val_loss: 12.5301 - val_categorical_accuracy: 0.1299\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0102 - categorical_accuracy: 0.9971 - val_loss: 12.5245 - val_categorical_accuracy: 0.1171\n",
      "Epoch 415/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0117 - categorical_accuracy: 0.9962 - val_loss: 11.6623 - val_categorical_accuracy: 0.1305\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0061 - categorical_accuracy: 0.9984 - val_loss: 13.7617 - val_categorical_accuracy: 0.1177\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0066 - categorical_accuracy: 0.9990 - val_loss: 15.5264 - val_categorical_accuracy: 0.0915\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0065 - categorical_accuracy: 0.9986 - val_loss: 11.8761 - val_categorical_accuracy: 0.1388\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0082 - categorical_accuracy: 0.9979 - val_loss: 12.3506 - val_categorical_accuracy: 0.1273\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0080 - categorical_accuracy: 0.9990 - val_loss: 12.1222 - val_categorical_accuracy: 0.1267\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0058 - categorical_accuracy: 0.9989 - val_loss: 12.3189 - val_categorical_accuracy: 0.1222\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0093 - categorical_accuracy: 0.9974 - val_loss: 12.4690 - val_categorical_accuracy: 0.1235\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0059 - categorical_accuracy: 0.9986 - val_loss: 16.4756 - val_categorical_accuracy: 0.0755\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0116 - categorical_accuracy: 0.9974 - val_loss: 45.3458 - val_categorical_accuracy: 0.0934\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0115 - categorical_accuracy: 0.9978 - val_loss: 42.2127 - val_categorical_accuracy: 0.0947\n",
      "Epoch 426/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0089 - categorical_accuracy: 0.9982 - val_loss: 36.6644 - val_categorical_accuracy: 0.0953\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0093 - categorical_accuracy: 0.9978 - val_loss: 13.8942 - val_categorical_accuracy: 0.1152\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0124 - categorical_accuracy: 0.9982 - val_loss: 13.2695 - val_categorical_accuracy: 0.1222\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0111 - categorical_accuracy: 0.9982 - val_loss: 12.2621 - val_categorical_accuracy: 0.1356\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0111 - categorical_accuracy: 0.9976 - val_loss: 15.4571 - val_categorical_accuracy: 0.1292\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0104 - categorical_accuracy: 0.9978 - val_loss: 13.6855 - val_categorical_accuracy: 0.1203\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0092 - categorical_accuracy: 0.9979 - val_loss: 11.8787 - val_categorical_accuracy: 0.0992\n",
      "Epoch 433/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0167 - categorical_accuracy: 0.9978 - val_loss: 12.3968 - val_categorical_accuracy: 0.1145\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0093 - categorical_accuracy: 0.9984 - val_loss: 13.6388 - val_categorical_accuracy: 0.1612\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0084 - categorical_accuracy: 0.9984 - val_loss: 15.3476 - val_categorical_accuracy: 0.1747\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0172 - categorical_accuracy: 0.9970 - val_loss: 12.9339 - val_categorical_accuracy: 0.1580\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0181 - categorical_accuracy: 0.9968 - val_loss: 20.9782 - val_categorical_accuracy: 0.0262\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0161 - categorical_accuracy: 0.9976 - val_loss: 24.1216 - val_categorical_accuracy: 0.0569\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0079 - categorical_accuracy: 0.9981 - val_loss: 15.2968 - val_categorical_accuracy: 0.0781\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0126 - categorical_accuracy: 0.9970 - val_loss: 17.7703 - val_categorical_accuracy: 0.1203\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0137 - categorical_accuracy: 0.9981 - val_loss: 15.8782 - val_categorical_accuracy: 0.1158\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0141 - categorical_accuracy: 0.9978 - val_loss: 13.9378 - val_categorical_accuracy: 0.1203\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0078 - categorical_accuracy: 0.9979 - val_loss: 12.8390 - val_categorical_accuracy: 0.1312\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0066 - categorical_accuracy: 0.9989 - val_loss: 12.2781 - val_categorical_accuracy: 0.1286\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0140 - categorical_accuracy: 0.9976 - val_loss: 15.8776 - val_categorical_accuracy: 0.0921\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0084 - categorical_accuracy: 0.9976 - val_loss: 11.6849 - val_categorical_accuracy: 0.1222\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0108 - categorical_accuracy: 0.9974 - val_loss: 12.3738 - val_categorical_accuracy: 0.1388\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0116 - categorical_accuracy: 0.9981 - val_loss: 11.8741 - val_categorical_accuracy: 0.1235\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0138 - categorical_accuracy: 0.9971 - val_loss: 14.4525 - val_categorical_accuracy: 0.0870\n",
      "Epoch 450/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0158 - categorical_accuracy: 0.9971 - val_loss: 14.5058 - val_categorical_accuracy: 0.1689\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0122 - categorical_accuracy: 0.9978 - val_loss: 20.6430 - val_categorical_accuracy: 0.0717\n",
      "Epoch 452/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0126 - categorical_accuracy: 0.9987 - val_loss: 12.4474 - val_categorical_accuracy: 0.0825\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0087 - categorical_accuracy: 0.9971 - val_loss: 13.8720 - val_categorical_accuracy: 0.1337\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0109 - categorical_accuracy: 0.9976 - val_loss: 12.6786 - val_categorical_accuracy: 0.1657\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0076 - categorical_accuracy: 0.9978 - val_loss: 12.2062 - val_categorical_accuracy: 0.1638\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0090 - categorical_accuracy: 0.9978 - val_loss: 15.6613 - val_categorical_accuracy: 0.1024\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0078 - categorical_accuracy: 0.9982 - val_loss: 12.5664 - val_categorical_accuracy: 0.1536\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0087 - categorical_accuracy: 0.9982 - val_loss: 11.9397 - val_categorical_accuracy: 0.1504\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0115 - categorical_accuracy: 0.9978 - val_loss: 12.3049 - val_categorical_accuracy: 0.1158\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0095 - categorical_accuracy: 0.9974 - val_loss: 11.8763 - val_categorical_accuracy: 0.1286\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.0085 - categorical_accuracy: 0.9984 - val_loss: 13.2748 - val_categorical_accuracy: 0.1312\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0071 - categorical_accuracy: 0.9978 - val_loss: 13.5251 - val_categorical_accuracy: 0.1529\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0064 - categorical_accuracy: 0.9986 - val_loss: 19.6998 - val_categorical_accuracy: 0.1075\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0055 - categorical_accuracy: 0.9984 - val_loss: 12.3078 - val_categorical_accuracy: 0.1433\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0053 - categorical_accuracy: 0.9986 - val_loss: 13.6109 - val_categorical_accuracy: 0.1273\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0052 - categorical_accuracy: 0.9987 - val_loss: 13.8250 - val_categorical_accuracy: 0.1036\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0074 - categorical_accuracy: 0.9984 - val_loss: 13.0044 - val_categorical_accuracy: 0.1472\n",
      "Epoch 468/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0121 - categorical_accuracy: 0.9976 - val_loss: 27.1402 - val_categorical_accuracy: 0.0902\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0121 - categorical_accuracy: 0.9976 - val_loss: 14.2316 - val_categorical_accuracy: 0.1004\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0156 - categorical_accuracy: 0.9965 - val_loss: 11.8079 - val_categorical_accuracy: 0.1043\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0214 - categorical_accuracy: 0.9962 - val_loss: 12.0778 - val_categorical_accuracy: 0.1139\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0146 - categorical_accuracy: 0.9963 - val_loss: 26.8622 - val_categorical_accuracy: 0.0940\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0117 - categorical_accuracy: 0.9981 - val_loss: 11.7856 - val_categorical_accuracy: 0.1056\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0118 - categorical_accuracy: 0.9973 - val_loss: 11.6973 - val_categorical_accuracy: 0.1164\n",
      "Epoch 475/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0152 - categorical_accuracy: 0.9962 - val_loss: 11.0896 - val_categorical_accuracy: 0.1292\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0138 - categorical_accuracy: 0.9979 - val_loss: 16.0729 - val_categorical_accuracy: 0.1081\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0110 - categorical_accuracy: 0.9978 - val_loss: 21.0921 - val_categorical_accuracy: 0.0915\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0141 - categorical_accuracy: 0.9974 - val_loss: 14.1156 - val_categorical_accuracy: 0.1324\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.0193 - categorical_accuracy: 0.9952 - val_loss: 14.1285 - val_categorical_accuracy: 0.1331\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0218 - categorical_accuracy: 0.9966 - val_loss: 14.4951 - val_categorical_accuracy: 0.0864\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0138 - categorical_accuracy: 0.9968 - val_loss: 14.8057 - val_categorical_accuracy: 0.1369\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0176 - categorical_accuracy: 0.9965 - val_loss: 11.0575 - val_categorical_accuracy: 0.1286\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0134 - categorical_accuracy: 0.9976 - val_loss: 12.2257 - val_categorical_accuracy: 0.1292\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0109 - categorical_accuracy: 0.9976 - val_loss: 12.1831 - val_categorical_accuracy: 0.1222\n",
      "Epoch 485/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0078 - categorical_accuracy: 0.9976 - val_loss: 13.4984 - val_categorical_accuracy: 0.1081\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0092 - categorical_accuracy: 0.9981 - val_loss: 12.6728 - val_categorical_accuracy: 0.1356\n",
      "Epoch 487/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0094 - categorical_accuracy: 0.9970 - val_loss: 15.5394 - val_categorical_accuracy: 0.1094\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0097 - categorical_accuracy: 0.9971 - val_loss: 23.6640 - val_categorical_accuracy: 0.1011\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0090 - categorical_accuracy: 0.9979 - val_loss: 15.6920 - val_categorical_accuracy: 0.0896\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0047 - categorical_accuracy: 0.9990 - val_loss: 11.3776 - val_categorical_accuracy: 0.1408\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0097 - categorical_accuracy: 0.9984 - val_loss: 13.5618 - val_categorical_accuracy: 0.1427\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0095 - categorical_accuracy: 0.9982 - val_loss: 11.4569 - val_categorical_accuracy: 0.1363\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0042 - categorical_accuracy: 0.9994 - val_loss: 12.1787 - val_categorical_accuracy: 0.1254\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0055 - categorical_accuracy: 0.9984 - val_loss: 13.1821 - val_categorical_accuracy: 0.1222\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0085 - categorical_accuracy: 0.9981 - val_loss: 11.9247 - val_categorical_accuracy: 0.1241\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0085 - categorical_accuracy: 0.9981 - val_loss: 12.4578 - val_categorical_accuracy: 0.1344\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0047 - categorical_accuracy: 0.9987 - val_loss: 11.4349 - val_categorical_accuracy: 0.1363\n",
      "Epoch 498/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0086 - categorical_accuracy: 0.9973 - val_loss: 12.5525 - val_categorical_accuracy: 0.1177\n",
      "Epoch 499/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0097 - categorical_accuracy: 0.9976 - val_loss: 13.3635 - val_categorical_accuracy: 0.1184\n",
      "Epoch 500/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0044 - categorical_accuracy: 0.9990 - val_loss: 13.1564 - val_categorical_accuracy: 0.1152\n",
      "\n",
      "Training Multi Activation Neural Network w/ Dropout...\n",
      "Epoch 1/500\n",
      "49/49 [==============================] - 5s 65ms/step - loss: 2.9483 - categorical_accuracy: 0.0864 - val_loss: 3.5376 - val_categorical_accuracy: 0.0377\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 3s 71ms/step - loss: 2.8621 - categorical_accuracy: 0.1080 - val_loss: 2.9753 - val_categorical_accuracy: 0.0365\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 2.8009 - categorical_accuracy: 0.1160 - val_loss: 2.9830 - val_categorical_accuracy: 0.1068\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 3s 60ms/step - loss: 2.7300 - categorical_accuracy: 0.1341 - val_loss: 2.6849 - val_categorical_accuracy: 0.1606\n",
      "Epoch 5/500\n",
      "49/49 [==============================] - 3s 67ms/step - loss: 2.6840 - categorical_accuracy: 0.1519 - val_loss: 2.6494 - val_categorical_accuracy: 0.1644\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 3s 62ms/step - loss: 2.6392 - categorical_accuracy: 0.1559 - val_loss: 2.6196 - val_categorical_accuracy: 0.1638\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.6056 - categorical_accuracy: 0.1676 - val_loss: 2.6210 - val_categorical_accuracy: 0.1248\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 3s 67ms/step - loss: 2.5695 - categorical_accuracy: 0.1721 - val_loss: 2.5671 - val_categorical_accuracy: 0.1606\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.5404 - categorical_accuracy: 0.1913 - val_loss: 2.6681 - val_categorical_accuracy: 0.1356\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.4959 - categorical_accuracy: 0.2033 - val_loss: 2.5862 - val_categorical_accuracy: 0.1625\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 2.4695 - categorical_accuracy: 0.2039 - val_loss: 2.6212 - val_categorical_accuracy: 0.1657\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 2.4382 - categorical_accuracy: 0.2105 - val_loss: 2.7202 - val_categorical_accuracy: 0.1043\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 2.3971 - categorical_accuracy: 0.2185 - val_loss: 2.5716 - val_categorical_accuracy: 0.1164\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.3629 - categorical_accuracy: 0.2324 - val_loss: 2.7037 - val_categorical_accuracy: 0.1651\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 2.3433 - categorical_accuracy: 0.2306 - val_loss: 2.6805 - val_categorical_accuracy: 0.1459\n",
      "Epoch 16/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.3178 - categorical_accuracy: 0.2393 - val_loss: 2.7409 - val_categorical_accuracy: 0.1420\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.2703 - categorical_accuracy: 0.2447 - val_loss: 2.6995 - val_categorical_accuracy: 0.1324\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.2293 - categorical_accuracy: 0.2537 - val_loss: 2.7064 - val_categorical_accuracy: 0.1164\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.2179 - categorical_accuracy: 0.2604 - val_loss: 2.9336 - val_categorical_accuracy: 0.1292\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.1859 - categorical_accuracy: 0.2646 - val_loss: 2.6930 - val_categorical_accuracy: 0.1414\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.1527 - categorical_accuracy: 0.2684 - val_loss: 2.7536 - val_categorical_accuracy: 0.1414\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.1460 - categorical_accuracy: 0.2666 - val_loss: 2.8122 - val_categorical_accuracy: 0.1504\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.1254 - categorical_accuracy: 0.2762 - val_loss: 3.2538 - val_categorical_accuracy: 0.1670\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.1022 - categorical_accuracy: 0.2775 - val_loss: 2.7951 - val_categorical_accuracy: 0.1484\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.0867 - categorical_accuracy: 0.2820 - val_loss: 2.7290 - val_categorical_accuracy: 0.1452\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 2.0513 - categorical_accuracy: 0.2870 - val_loss: 2.8416 - val_categorical_accuracy: 0.1689\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 2.0496 - categorical_accuracy: 0.2892 - val_loss: 2.9424 - val_categorical_accuracy: 0.1497\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.0302 - categorical_accuracy: 0.2921 - val_loss: 2.8587 - val_categorical_accuracy: 0.1452\n",
      "Epoch 29/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 2.0228 - categorical_accuracy: 0.2940 - val_loss: 2.7028 - val_categorical_accuracy: 0.1497\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 2.0131 - categorical_accuracy: 0.3009 - val_loss: 2.8468 - val_categorical_accuracy: 0.1523\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 2.0018 - categorical_accuracy: 0.3041 - val_loss: 3.0847 - val_categorical_accuracy: 0.1331\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.9825 - categorical_accuracy: 0.3103 - val_loss: 3.0336 - val_categorical_accuracy: 0.1350\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.9738 - categorical_accuracy: 0.3155 - val_loss: 2.8576 - val_categorical_accuracy: 0.1478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.9729 - categorical_accuracy: 0.3110 - val_loss: 2.9096 - val_categorical_accuracy: 0.1484\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.9455 - categorical_accuracy: 0.3283 - val_loss: 2.9084 - val_categorical_accuracy: 0.1510\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.9375 - categorical_accuracy: 0.3279 - val_loss: 2.9231 - val_categorical_accuracy: 0.1536\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.9230 - categorical_accuracy: 0.3334 - val_loss: 2.7554 - val_categorical_accuracy: 0.1536\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.9035 - categorical_accuracy: 0.3339 - val_loss: 2.9309 - val_categorical_accuracy: 0.1510\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.8941 - categorical_accuracy: 0.3411 - val_loss: 2.8770 - val_categorical_accuracy: 0.1504\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.8945 - categorical_accuracy: 0.3399 - val_loss: 2.9971 - val_categorical_accuracy: 0.1446\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.8914 - categorical_accuracy: 0.3441 - val_loss: 3.1566 - val_categorical_accuracy: 0.1427\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.8616 - categorical_accuracy: 0.3484 - val_loss: 2.9348 - val_categorical_accuracy: 0.1574\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.8462 - categorical_accuracy: 0.3492 - val_loss: 2.8996 - val_categorical_accuracy: 0.1523\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.8313 - categorical_accuracy: 0.3547 - val_loss: 3.0241 - val_categorical_accuracy: 0.1567\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.8189 - categorical_accuracy: 0.3619 - val_loss: 2.9706 - val_categorical_accuracy: 0.1472\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.8030 - categorical_accuracy: 0.3622 - val_loss: 3.0367 - val_categorical_accuracy: 0.1567\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.7894 - categorical_accuracy: 0.3649 - val_loss: 3.1510 - val_categorical_accuracy: 0.1452\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.7972 - categorical_accuracy: 0.3638 - val_loss: 3.0854 - val_categorical_accuracy: 0.1593\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.7763 - categorical_accuracy: 0.3688 - val_loss: 3.1907 - val_categorical_accuracy: 0.1548\n",
      "Epoch 50/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.7702 - categorical_accuracy: 0.3724 - val_loss: 3.1506 - val_categorical_accuracy: 0.1446\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.7503 - categorical_accuracy: 0.3779 - val_loss: 3.1796 - val_categorical_accuracy: 0.1536\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.7574 - categorical_accuracy: 0.3694 - val_loss: 3.2580 - val_categorical_accuracy: 0.1497\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.7434 - categorical_accuracy: 0.3779 - val_loss: 3.3434 - val_categorical_accuracy: 0.1452\n",
      "Epoch 54/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.8061 - categorical_accuracy: 0.3660 - val_loss: 3.1050 - val_categorical_accuracy: 0.1657\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.7581 - categorical_accuracy: 0.3766 - val_loss: 3.1803 - val_categorical_accuracy: 0.1561\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.7525 - categorical_accuracy: 0.3745 - val_loss: 3.1960 - val_categorical_accuracy: 0.1516\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.7411 - categorical_accuracy: 0.3747 - val_loss: 3.2409 - val_categorical_accuracy: 0.1542\n",
      "Epoch 58/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.7045 - categorical_accuracy: 0.3883 - val_loss: 3.2478 - val_categorical_accuracy: 0.1542\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.6834 - categorical_accuracy: 0.3892 - val_loss: 3.5493 - val_categorical_accuracy: 0.1465\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6708 - categorical_accuracy: 0.3907 - val_loss: 3.2119 - val_categorical_accuracy: 0.1599\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6950 - categorical_accuracy: 0.3899 - val_loss: 3.2600 - val_categorical_accuracy: 0.1548\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.6721 - categorical_accuracy: 0.3966 - val_loss: 3.3231 - val_categorical_accuracy: 0.1523\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6554 - categorical_accuracy: 0.3987 - val_loss: 3.4188 - val_categorical_accuracy: 0.1548\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6627 - categorical_accuracy: 0.3960 - val_loss: 3.8145 - val_categorical_accuracy: 0.1587\n",
      "Epoch 65/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6588 - categorical_accuracy: 0.3953 - val_loss: 3.3299 - val_categorical_accuracy: 0.1644\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6731 - categorical_accuracy: 0.4014 - val_loss: 3.6573 - val_categorical_accuracy: 0.1657\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.6641 - categorical_accuracy: 0.4027 - val_loss: 3.4679 - val_categorical_accuracy: 0.1536\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.6419 - categorical_accuracy: 0.4032 - val_loss: 3.4543 - val_categorical_accuracy: 0.1587\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.6298 - categorical_accuracy: 0.4165 - val_loss: 3.5658 - val_categorical_accuracy: 0.1459\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.6389 - categorical_accuracy: 0.4131 - val_loss: 3.5232 - val_categorical_accuracy: 0.1599\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.6044 - categorical_accuracy: 0.4224 - val_loss: 3.6486 - val_categorical_accuracy: 0.1484\n",
      "Epoch 72/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.5975 - categorical_accuracy: 0.4195 - val_loss: 3.5591 - val_categorical_accuracy: 0.1459\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.6112 - categorical_accuracy: 0.4173 - val_loss: 3.4399 - val_categorical_accuracy: 0.1555\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.5816 - categorical_accuracy: 0.4232 - val_loss: 3.6281 - val_categorical_accuracy: 0.1548\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.5876 - categorical_accuracy: 0.4259 - val_loss: 3.4960 - val_categorical_accuracy: 0.1536\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.5895 - categorical_accuracy: 0.4286 - val_loss: 3.5154 - val_categorical_accuracy: 0.1510\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.5641 - categorical_accuracy: 0.4323 - val_loss: 3.5832 - val_categorical_accuracy: 0.1587\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.5668 - categorical_accuracy: 0.4302 - val_loss: 3.7736 - val_categorical_accuracy: 0.1523\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5490 - categorical_accuracy: 0.4390 - val_loss: 3.7406 - val_categorical_accuracy: 0.1612\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5679 - categorical_accuracy: 0.4385 - val_loss: 3.8221 - val_categorical_accuracy: 0.1542\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.5362 - categorical_accuracy: 0.4446 - val_loss: 3.5621 - val_categorical_accuracy: 0.1548\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5543 - categorical_accuracy: 0.4350 - val_loss: 4.5044 - val_categorical_accuracy: 0.1727\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 49ms/step - loss: 1.7542 - categorical_accuracy: 0.3916 - val_loss: 4.6103 - val_categorical_accuracy: 0.1132\n",
      "Epoch 84/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6712 - categorical_accuracy: 0.4088 - val_loss: 3.8417 - val_categorical_accuracy: 0.1452\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6473 - categorical_accuracy: 0.4179 - val_loss: 3.9446 - val_categorical_accuracy: 0.1459\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6134 - categorical_accuracy: 0.4262 - val_loss: 3.5918 - val_categorical_accuracy: 0.1484\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6428 - categorical_accuracy: 0.4161 - val_loss: 4.2427 - val_categorical_accuracy: 0.1721\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.6265 - categorical_accuracy: 0.4211 - val_loss: 3.6634 - val_categorical_accuracy: 0.1536\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.5709 - categorical_accuracy: 0.4344 - val_loss: 3.6057 - val_categorical_accuracy: 0.1363\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5666 - categorical_accuracy: 0.4344 - val_loss: 3.6244 - val_categorical_accuracy: 0.1497\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5520 - categorical_accuracy: 0.4342 - val_loss: 3.5664 - val_categorical_accuracy: 0.1657\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.5578 - categorical_accuracy: 0.4302 - val_loss: 3.4004 - val_categorical_accuracy: 0.1631\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5364 - categorical_accuracy: 0.4441 - val_loss: 4.8324 - val_categorical_accuracy: 0.1708\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5348 - categorical_accuracy: 0.4416 - val_loss: 3.6293 - val_categorical_accuracy: 0.1593\n",
      "Epoch 95/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5150 - categorical_accuracy: 0.4464 - val_loss: 3.5484 - val_categorical_accuracy: 0.1536\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5187 - categorical_accuracy: 0.4509 - val_loss: 4.0081 - val_categorical_accuracy: 0.1721\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.4967 - categorical_accuracy: 0.4485 - val_loss: 3.7475 - val_categorical_accuracy: 0.1510\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5046 - categorical_accuracy: 0.4459 - val_loss: 3.7751 - val_categorical_accuracy: 0.1497\n",
      "Epoch 99/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5030 - categorical_accuracy: 0.4526 - val_loss: 3.6669 - val_categorical_accuracy: 0.1670\n",
      "Epoch 100/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.5015 - categorical_accuracy: 0.4488 - val_loss: 3.5750 - val_categorical_accuracy: 0.1529\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.4824 - categorical_accuracy: 0.4509 - val_loss: 4.2057 - val_categorical_accuracy: 0.1734\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.5078 - categorical_accuracy: 0.4481 - val_loss: 3.5729 - val_categorical_accuracy: 0.1695\n",
      "Epoch 103/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.4602 - categorical_accuracy: 0.4565 - val_loss: 3.6144 - val_categorical_accuracy: 0.1536\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 1.4581 - categorical_accuracy: 0.4635 - val_loss: 3.7547 - val_categorical_accuracy: 0.1408\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.4556 - categorical_accuracy: 0.4609 - val_loss: 3.6573 - val_categorical_accuracy: 0.1529\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 1.4467 - categorical_accuracy: 0.4665 - val_loss: 3.7566 - val_categorical_accuracy: 0.1574\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 1.4354 - categorical_accuracy: 0.4662 - val_loss: 3.7854 - val_categorical_accuracy: 0.1580\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.4571 - categorical_accuracy: 0.4603 - val_loss: 3.7397 - val_categorical_accuracy: 0.1529\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.4270 - categorical_accuracy: 0.4637 - val_loss: 3.8130 - val_categorical_accuracy: 0.1414\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 1.4177 - categorical_accuracy: 0.4667 - val_loss: 3.7164 - val_categorical_accuracy: 0.1676\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 1.4197 - categorical_accuracy: 0.4765 - val_loss: 3.7933 - val_categorical_accuracy: 0.1452\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 1.4347 - categorical_accuracy: 0.4606 - val_loss: 3.7765 - val_categorical_accuracy: 0.1478\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 1.4136 - categorical_accuracy: 0.4728 - val_loss: 3.6842 - val_categorical_accuracy: 0.1484\n",
      "Epoch 114/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.4187 - categorical_accuracy: 0.4739 - val_loss: 3.7792 - val_categorical_accuracy: 0.1440\n",
      "Epoch 115/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.4229 - categorical_accuracy: 0.4640 - val_loss: 3.7670 - val_categorical_accuracy: 0.1670\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.4167 - categorical_accuracy: 0.4680 - val_loss: 3.9038 - val_categorical_accuracy: 0.1625\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.4109 - categorical_accuracy: 0.4710 - val_loss: 3.9712 - val_categorical_accuracy: 0.1555\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.4290 - categorical_accuracy: 0.4701 - val_loss: 3.6549 - val_categorical_accuracy: 0.1567\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.4070 - categorical_accuracy: 0.4790 - val_loss: 3.8986 - val_categorical_accuracy: 0.1446\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.3950 - categorical_accuracy: 0.4722 - val_loss: 3.8134 - val_categorical_accuracy: 0.1625\n",
      "Epoch 121/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.3857 - categorical_accuracy: 0.4770 - val_loss: 3.8352 - val_categorical_accuracy: 0.1593\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3834 - categorical_accuracy: 0.4787 - val_loss: 3.8663 - val_categorical_accuracy: 0.1612\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3758 - categorical_accuracy: 0.4795 - val_loss: 3.8948 - val_categorical_accuracy: 0.1619\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.3904 - categorical_accuracy: 0.4813 - val_loss: 3.8261 - val_categorical_accuracy: 0.1599\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.3837 - categorical_accuracy: 0.4848 - val_loss: 4.0983 - val_categorical_accuracy: 0.1625\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.3833 - categorical_accuracy: 0.4843 - val_loss: 3.9114 - val_categorical_accuracy: 0.1484\n",
      "Epoch 127/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.3968 - categorical_accuracy: 0.4816 - val_loss: 3.8873 - val_categorical_accuracy: 0.1472\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.3919 - categorical_accuracy: 0.4765 - val_loss: 3.7874 - val_categorical_accuracy: 0.1542\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3760 - categorical_accuracy: 0.4861 - val_loss: 3.8145 - val_categorical_accuracy: 0.1529\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.3716 - categorical_accuracy: 0.4872 - val_loss: 3.8460 - val_categorical_accuracy: 0.1676\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3819 - categorical_accuracy: 0.4827 - val_loss: 3.9297 - val_categorical_accuracy: 0.1657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.3677 - categorical_accuracy: 0.4890 - val_loss: 3.9472 - val_categorical_accuracy: 0.1587\n",
      "Epoch 133/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.3608 - categorical_accuracy: 0.4930 - val_loss: 3.8922 - val_categorical_accuracy: 0.1536\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3452 - categorical_accuracy: 0.4962 - val_loss: 4.1952 - val_categorical_accuracy: 0.1536\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3463 - categorical_accuracy: 0.4949 - val_loss: 4.0662 - val_categorical_accuracy: 0.1504\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3456 - categorical_accuracy: 0.4973 - val_loss: 4.0443 - val_categorical_accuracy: 0.1644\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3535 - categorical_accuracy: 0.4958 - val_loss: 3.9997 - val_categorical_accuracy: 0.1587\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3356 - categorical_accuracy: 0.5026 - val_loss: 4.0450 - val_categorical_accuracy: 0.1574\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3522 - categorical_accuracy: 0.4994 - val_loss: 4.1365 - val_categorical_accuracy: 0.1683\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3219 - categorical_accuracy: 0.5008 - val_loss: 4.1420 - val_categorical_accuracy: 0.1510\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3347 - categorical_accuracy: 0.5027 - val_loss: 4.0671 - val_categorical_accuracy: 0.1574\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3276 - categorical_accuracy: 0.5062 - val_loss: 4.2097 - val_categorical_accuracy: 0.1587\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3168 - categorical_accuracy: 0.5061 - val_loss: 4.0454 - val_categorical_accuracy: 0.1593\n",
      "Epoch 144/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3128 - categorical_accuracy: 0.5053 - val_loss: 4.1503 - val_categorical_accuracy: 0.1663\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.3242 - categorical_accuracy: 0.5058 - val_loss: 4.2942 - val_categorical_accuracy: 0.1484\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3165 - categorical_accuracy: 0.5126 - val_loss: 3.9856 - val_categorical_accuracy: 0.1536\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3228 - categorical_accuracy: 0.5083 - val_loss: 4.0789 - val_categorical_accuracy: 0.1580\n",
      "Epoch 148/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3077 - categorical_accuracy: 0.5066 - val_loss: 4.0769 - val_categorical_accuracy: 0.1625\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3168 - categorical_accuracy: 0.5066 - val_loss: 4.1865 - val_categorical_accuracy: 0.1580\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3007 - categorical_accuracy: 0.5106 - val_loss: 4.2004 - val_categorical_accuracy: 0.1491\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3105 - categorical_accuracy: 0.5157 - val_loss: 4.1463 - val_categorical_accuracy: 0.1631\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.2956 - categorical_accuracy: 0.5155 - val_loss: 4.2021 - val_categorical_accuracy: 0.1523\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.3063 - categorical_accuracy: 0.5170 - val_loss: 4.1896 - val_categorical_accuracy: 0.1414\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2889 - categorical_accuracy: 0.5168 - val_loss: 4.0833 - val_categorical_accuracy: 0.1523\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.3148 - categorical_accuracy: 0.5085 - val_loss: 4.0284 - val_categorical_accuracy: 0.1555\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2910 - categorical_accuracy: 0.5195 - val_loss: 4.0648 - val_categorical_accuracy: 0.1593\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2825 - categorical_accuracy: 0.5198 - val_loss: 4.1109 - val_categorical_accuracy: 0.1382\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.3084 - categorical_accuracy: 0.5125 - val_loss: 4.3242 - val_categorical_accuracy: 0.1465\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2868 - categorical_accuracy: 0.5222 - val_loss: 4.0515 - val_categorical_accuracy: 0.1599\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2790 - categorical_accuracy: 0.5189 - val_loss: 4.2363 - val_categorical_accuracy: 0.1420\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 1.2703 - categorical_accuracy: 0.5240 - val_loss: 4.2782 - val_categorical_accuracy: 0.1574\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 1.2763 - categorical_accuracy: 0.5224 - val_loss: 4.1064 - val_categorical_accuracy: 0.1408\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2456 - categorical_accuracy: 0.5275 - val_loss: 4.3183 - val_categorical_accuracy: 0.1593\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 1.2614 - categorical_accuracy: 0.5296 - val_loss: 4.0942 - val_categorical_accuracy: 0.1561\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 1.2558 - categorical_accuracy: 0.5285 - val_loss: 4.2884 - val_categorical_accuracy: 0.1631\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2562 - categorical_accuracy: 0.5294 - val_loss: 4.1295 - val_categorical_accuracy: 0.1510\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2622 - categorical_accuracy: 0.5275 - val_loss: 4.3595 - val_categorical_accuracy: 0.1529\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.2600 - categorical_accuracy: 0.5320 - val_loss: 4.5496 - val_categorical_accuracy: 0.1414\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2488 - categorical_accuracy: 0.5351 - val_loss: 4.4792 - val_categorical_accuracy: 0.1376\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2439 - categorical_accuracy: 0.5335 - val_loss: 4.4810 - val_categorical_accuracy: 0.1791\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2235 - categorical_accuracy: 0.5359 - val_loss: 4.1917 - val_categorical_accuracy: 0.1440\n",
      "Epoch 172/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.2251 - categorical_accuracy: 0.5344 - val_loss: 4.3403 - val_categorical_accuracy: 0.1593\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2504 - categorical_accuracy: 0.5359 - val_loss: 4.1985 - val_categorical_accuracy: 0.1446\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2212 - categorical_accuracy: 0.5357 - val_loss: 3.9793 - val_categorical_accuracy: 0.1523\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2326 - categorical_accuracy: 0.5381 - val_loss: 4.3335 - val_categorical_accuracy: 0.1497\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.2360 - categorical_accuracy: 0.5352 - val_loss: 4.1934 - val_categorical_accuracy: 0.1715\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.2314 - categorical_accuracy: 0.5373 - val_loss: 4.3797 - val_categorical_accuracy: 0.1420\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.2244 - categorical_accuracy: 0.5384 - val_loss: 4.1800 - val_categorical_accuracy: 0.1523\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.2242 - categorical_accuracy: 0.5384 - val_loss: 4.0682 - val_categorical_accuracy: 0.1446\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1934 - categorical_accuracy: 0.5448 - val_loss: 4.1638 - val_categorical_accuracy: 0.1542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.2101 - categorical_accuracy: 0.5448 - val_loss: 4.1183 - val_categorical_accuracy: 0.1478\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.2168 - categorical_accuracy: 0.5424 - val_loss: 4.3741 - val_categorical_accuracy: 0.1638\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1867 - categorical_accuracy: 0.5480 - val_loss: 4.3725 - val_categorical_accuracy: 0.1465\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1882 - categorical_accuracy: 0.5488 - val_loss: 4.3259 - val_categorical_accuracy: 0.1484\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1946 - categorical_accuracy: 0.5405 - val_loss: 4.5241 - val_categorical_accuracy: 0.1337\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.2114 - categorical_accuracy: 0.5459 - val_loss: 4.2194 - val_categorical_accuracy: 0.1510\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1916 - categorical_accuracy: 0.5472 - val_loss: 4.6968 - val_categorical_accuracy: 0.1401\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1919 - categorical_accuracy: 0.5450 - val_loss: 4.2921 - val_categorical_accuracy: 0.1427\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1925 - categorical_accuracy: 0.5474 - val_loss: 4.3367 - val_categorical_accuracy: 0.1555\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1781 - categorical_accuracy: 0.5495 - val_loss: 4.2042 - val_categorical_accuracy: 0.1516\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1836 - categorical_accuracy: 0.5488 - val_loss: 4.4526 - val_categorical_accuracy: 0.1567\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1966 - categorical_accuracy: 0.5523 - val_loss: 4.1402 - val_categorical_accuracy: 0.1587\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1823 - categorical_accuracy: 0.5543 - val_loss: 3.9929 - val_categorical_accuracy: 0.1452\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1725 - categorical_accuracy: 0.5499 - val_loss: 4.4138 - val_categorical_accuracy: 0.1587\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1821 - categorical_accuracy: 0.5523 - val_loss: 4.1382 - val_categorical_accuracy: 0.1536\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1922 - categorical_accuracy: 0.5517 - val_loss: 4.4546 - val_categorical_accuracy: 0.1484\n",
      "Epoch 197/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1855 - categorical_accuracy: 0.5547 - val_loss: 4.1606 - val_categorical_accuracy: 0.1504\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1788 - categorical_accuracy: 0.5543 - val_loss: 4.0434 - val_categorical_accuracy: 0.1580\n",
      "Epoch 199/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1659 - categorical_accuracy: 0.5551 - val_loss: 4.6156 - val_categorical_accuracy: 0.1606\n",
      "Epoch 200/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1750 - categorical_accuracy: 0.5525 - val_loss: 4.2640 - val_categorical_accuracy: 0.1516\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1584 - categorical_accuracy: 0.5608 - val_loss: 4.1123 - val_categorical_accuracy: 0.1542\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1535 - categorical_accuracy: 0.5591 - val_loss: 4.2741 - val_categorical_accuracy: 0.1459\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1360 - categorical_accuracy: 0.5647 - val_loss: 4.1576 - val_categorical_accuracy: 0.1580\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1671 - categorical_accuracy: 0.5651 - val_loss: 4.2670 - val_categorical_accuracy: 0.1504\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1645 - categorical_accuracy: 0.5591 - val_loss: 4.5122 - val_categorical_accuracy: 0.1472\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1507 - categorical_accuracy: 0.5616 - val_loss: 4.4122 - val_categorical_accuracy: 0.1414\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1457 - categorical_accuracy: 0.5664 - val_loss: 4.7612 - val_categorical_accuracy: 0.1446\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.1406 - categorical_accuracy: 0.5663 - val_loss: 4.1140 - val_categorical_accuracy: 0.1580\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1530 - categorical_accuracy: 0.5655 - val_loss: 4.0386 - val_categorical_accuracy: 0.1599\n",
      "Epoch 210/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1402 - categorical_accuracy: 0.5688 - val_loss: 4.2134 - val_categorical_accuracy: 0.1567\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1380 - categorical_accuracy: 0.5723 - val_loss: 4.3996 - val_categorical_accuracy: 0.1695\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1642 - categorical_accuracy: 0.5695 - val_loss: 4.2751 - val_categorical_accuracy: 0.1440\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1614 - categorical_accuracy: 0.5613 - val_loss: 3.8956 - val_categorical_accuracy: 0.1478\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1285 - categorical_accuracy: 0.5704 - val_loss: 4.5964 - val_categorical_accuracy: 0.1356\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1289 - categorical_accuracy: 0.5720 - val_loss: 4.1484 - val_categorical_accuracy: 0.1523\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1277 - categorical_accuracy: 0.5712 - val_loss: 4.1070 - val_categorical_accuracy: 0.1452\n",
      "Epoch 217/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1415 - categorical_accuracy: 0.5696 - val_loss: 4.1696 - val_categorical_accuracy: 0.1542\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.1201 - categorical_accuracy: 0.5824 - val_loss: 5.4076 - val_categorical_accuracy: 0.1177\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1309 - categorical_accuracy: 0.5765 - val_loss: 4.1621 - val_categorical_accuracy: 0.1555\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1365 - categorical_accuracy: 0.5704 - val_loss: 4.0792 - val_categorical_accuracy: 0.1536\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.1189 - categorical_accuracy: 0.5735 - val_loss: 3.9410 - val_categorical_accuracy: 0.1567\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1335 - categorical_accuracy: 0.5714 - val_loss: 4.1486 - val_categorical_accuracy: 0.1414\n",
      "Epoch 223/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1106 - categorical_accuracy: 0.5845 - val_loss: 4.2267 - val_categorical_accuracy: 0.1491\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1148 - categorical_accuracy: 0.5823 - val_loss: 4.6226 - val_categorical_accuracy: 0.1408\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1022 - categorical_accuracy: 0.5845 - val_loss: 4.2325 - val_categorical_accuracy: 0.1657\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1033 - categorical_accuracy: 0.5888 - val_loss: 4.5059 - val_categorical_accuracy: 0.1369\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1257 - categorical_accuracy: 0.5813 - val_loss: 3.9129 - val_categorical_accuracy: 0.1529\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1043 - categorical_accuracy: 0.5834 - val_loss: 4.3130 - val_categorical_accuracy: 0.1484\n",
      "Epoch 229/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1035 - categorical_accuracy: 0.5882 - val_loss: 4.4717 - val_categorical_accuracy: 0.1542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.1127 - categorical_accuracy: 0.5869 - val_loss: 4.2203 - val_categorical_accuracy: 0.1478\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0944 - categorical_accuracy: 0.5877 - val_loss: 4.1595 - val_categorical_accuracy: 0.1606\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0881 - categorical_accuracy: 0.5925 - val_loss: 4.6077 - val_categorical_accuracy: 0.1337\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1081 - categorical_accuracy: 0.5914 - val_loss: 4.1119 - val_categorical_accuracy: 0.1388\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1031 - categorical_accuracy: 0.5875 - val_loss: 4.2238 - val_categorical_accuracy: 0.1555\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1016 - categorical_accuracy: 0.5919 - val_loss: 4.0666 - val_categorical_accuracy: 0.1388\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1056 - categorical_accuracy: 0.5877 - val_loss: 4.2569 - val_categorical_accuracy: 0.1542\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0767 - categorical_accuracy: 0.5970 - val_loss: 4.1884 - val_categorical_accuracy: 0.1408\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0879 - categorical_accuracy: 0.5956 - val_loss: 4.1026 - val_categorical_accuracy: 0.1440\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0770 - categorical_accuracy: 0.5964 - val_loss: 4.3256 - val_categorical_accuracy: 0.1523\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0781 - categorical_accuracy: 0.5981 - val_loss: 4.2060 - val_categorical_accuracy: 0.1356\n",
      "Epoch 241/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0900 - categorical_accuracy: 0.5991 - val_loss: 4.1652 - val_categorical_accuracy: 0.1433\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0822 - categorical_accuracy: 0.5922 - val_loss: 4.1847 - val_categorical_accuracy: 0.1420\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0613 - categorical_accuracy: 0.5957 - val_loss: 4.1406 - val_categorical_accuracy: 0.1497\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0973 - categorical_accuracy: 0.5949 - val_loss: 4.1700 - val_categorical_accuracy: 0.1452\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0922 - categorical_accuracy: 0.5938 - val_loss: 4.2511 - val_categorical_accuracy: 0.1363\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0821 - categorical_accuracy: 0.5965 - val_loss: 4.3033 - val_categorical_accuracy: 0.1574\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0518 - categorical_accuracy: 0.6116 - val_loss: 4.0714 - val_categorical_accuracy: 0.1369\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0777 - categorical_accuracy: 0.5933 - val_loss: 4.4589 - val_categorical_accuracy: 0.1369\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0698 - categorical_accuracy: 0.6007 - val_loss: 4.3750 - val_categorical_accuracy: 0.1427\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0592 - categorical_accuracy: 0.6036 - val_loss: 3.9952 - val_categorical_accuracy: 0.1497\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0620 - categorical_accuracy: 0.5988 - val_loss: 4.1783 - val_categorical_accuracy: 0.1382\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0699 - categorical_accuracy: 0.5973 - val_loss: 4.1042 - val_categorical_accuracy: 0.1433\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0736 - categorical_accuracy: 0.6047 - val_loss: 4.2161 - val_categorical_accuracy: 0.1369\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 1.0779 - categorical_accuracy: 0.5989 - val_loss: 4.2710 - val_categorical_accuracy: 0.1388\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.0817 - categorical_accuracy: 0.6026 - val_loss: 4.1284 - val_categorical_accuracy: 0.1388\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0545 - categorical_accuracy: 0.6072 - val_loss: 4.0056 - val_categorical_accuracy: 0.1382\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0599 - categorical_accuracy: 0.6055 - val_loss: 4.2486 - val_categorical_accuracy: 0.1536\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0729 - categorical_accuracy: 0.6069 - val_loss: 5.2619 - val_categorical_accuracy: 0.1382\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0599 - categorical_accuracy: 0.6037 - val_loss: 4.0950 - val_categorical_accuracy: 0.1484\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0554 - categorical_accuracy: 0.6061 - val_loss: 4.2191 - val_categorical_accuracy: 0.1504\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.0656 - categorical_accuracy: 0.6071 - val_loss: 4.2989 - val_categorical_accuracy: 0.1484\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0683 - categorical_accuracy: 0.6032 - val_loss: 3.9282 - val_categorical_accuracy: 0.1440\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.0487 - categorical_accuracy: 0.6080 - val_loss: 4.3480 - val_categorical_accuracy: 0.1408\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0511 - categorical_accuracy: 0.6071 - val_loss: 4.1456 - val_categorical_accuracy: 0.1292\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0275 - categorical_accuracy: 0.6149 - val_loss: 4.1060 - val_categorical_accuracy: 0.1433\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0418 - categorical_accuracy: 0.6151 - val_loss: 4.1448 - val_categorical_accuracy: 0.1331\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0545 - categorical_accuracy: 0.6058 - val_loss: 4.4637 - val_categorical_accuracy: 0.1388\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0466 - categorical_accuracy: 0.6106 - val_loss: 4.0288 - val_categorical_accuracy: 0.1395\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0536 - categorical_accuracy: 0.6108 - val_loss: 4.2937 - val_categorical_accuracy: 0.1497\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0241 - categorical_accuracy: 0.6188 - val_loss: 3.8953 - val_categorical_accuracy: 0.1369\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0408 - categorical_accuracy: 0.6101 - val_loss: 4.5487 - val_categorical_accuracy: 0.1318\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0497 - categorical_accuracy: 0.6048 - val_loss: 4.0952 - val_categorical_accuracy: 0.1497\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0285 - categorical_accuracy: 0.6168 - val_loss: 4.1879 - val_categorical_accuracy: 0.1459\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0328 - categorical_accuracy: 0.6117 - val_loss: 4.3526 - val_categorical_accuracy: 0.1606\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0436 - categorical_accuracy: 0.6101 - val_loss: 4.1289 - val_categorical_accuracy: 0.1561\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0491 - categorical_accuracy: 0.6068 - val_loss: 3.9400 - val_categorical_accuracy: 0.1478\n",
      "Epoch 277/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0486 - categorical_accuracy: 0.6100 - val_loss: 4.2822 - val_categorical_accuracy: 0.1491\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0480 - categorical_accuracy: 0.6082 - val_loss: 4.3056 - val_categorical_accuracy: 0.1497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0233 - categorical_accuracy: 0.6164 - val_loss: 4.0532 - val_categorical_accuracy: 0.1433\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0207 - categorical_accuracy: 0.6149 - val_loss: 3.9786 - val_categorical_accuracy: 0.1516\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.0340 - categorical_accuracy: 0.6165 - val_loss: 4.1771 - val_categorical_accuracy: 0.1491\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0355 - categorical_accuracy: 0.6128 - val_loss: 4.3027 - val_categorical_accuracy: 0.1280\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0265 - categorical_accuracy: 0.6168 - val_loss: 4.1695 - val_categorical_accuracy: 0.1356\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0294 - categorical_accuracy: 0.6152 - val_loss: 4.2567 - val_categorical_accuracy: 0.1440\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0413 - categorical_accuracy: 0.6154 - val_loss: 4.0183 - val_categorical_accuracy: 0.1529\n",
      "Epoch 286/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0174 - categorical_accuracy: 0.6180 - val_loss: 4.0251 - val_categorical_accuracy: 0.1376\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0028 - categorical_accuracy: 0.6240 - val_loss: 4.0540 - val_categorical_accuracy: 0.1312\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0340 - categorical_accuracy: 0.6112 - val_loss: 4.2217 - val_categorical_accuracy: 0.1523\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0180 - categorical_accuracy: 0.6176 - val_loss: 3.8544 - val_categorical_accuracy: 0.1465\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0413 - categorical_accuracy: 0.6116 - val_loss: 4.2429 - val_categorical_accuracy: 0.1484\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0146 - categorical_accuracy: 0.6168 - val_loss: 4.0392 - val_categorical_accuracy: 0.1433\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0119 - categorical_accuracy: 0.6181 - val_loss: 3.9480 - val_categorical_accuracy: 0.1587\n",
      "Epoch 293/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0178 - categorical_accuracy: 0.6156 - val_loss: 3.7773 - val_categorical_accuracy: 0.1465\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0221 - categorical_accuracy: 0.6204 - val_loss: 4.2598 - val_categorical_accuracy: 0.1440\n",
      "Epoch 295/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9988 - categorical_accuracy: 0.6271 - val_loss: 4.2839 - val_categorical_accuracy: 0.1510\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0253 - categorical_accuracy: 0.6152 - val_loss: 4.0499 - val_categorical_accuracy: 0.1369\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0065 - categorical_accuracy: 0.6173 - val_loss: 4.0376 - val_categorical_accuracy: 0.1408\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0112 - categorical_accuracy: 0.6204 - val_loss: 3.8448 - val_categorical_accuracy: 0.1382\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0220 - categorical_accuracy: 0.6181 - val_loss: 3.9511 - val_categorical_accuracy: 0.1350\n",
      "Epoch 300/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0010 - categorical_accuracy: 0.6245 - val_loss: 4.0624 - val_categorical_accuracy: 0.1440\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0159 - categorical_accuracy: 0.6173 - val_loss: 4.2053 - val_categorical_accuracy: 0.1388\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9906 - categorical_accuracy: 0.6232 - val_loss: 3.7495 - val_categorical_accuracy: 0.1318\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0032 - categorical_accuracy: 0.6197 - val_loss: 4.0957 - val_categorical_accuracy: 0.1350\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9916 - categorical_accuracy: 0.6280 - val_loss: 4.3286 - val_categorical_accuracy: 0.1299\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9929 - categorical_accuracy: 0.6296 - val_loss: 4.2900 - val_categorical_accuracy: 0.1542\n",
      "Epoch 306/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0087 - categorical_accuracy: 0.6191 - val_loss: 4.6258 - val_categorical_accuracy: 0.1324\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0218 - categorical_accuracy: 0.6175 - val_loss: 4.0217 - val_categorical_accuracy: 0.1491\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0138 - categorical_accuracy: 0.6197 - val_loss: 4.0082 - val_categorical_accuracy: 0.1465\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0171 - categorical_accuracy: 0.6252 - val_loss: 4.0983 - val_categorical_accuracy: 0.1484\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9909 - categorical_accuracy: 0.6242 - val_loss: 4.0400 - val_categorical_accuracy: 0.1401\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0088 - categorical_accuracy: 0.6263 - val_loss: 4.0262 - val_categorical_accuracy: 0.1369\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9990 - categorical_accuracy: 0.6272 - val_loss: 4.2130 - val_categorical_accuracy: 0.1497\n",
      "Epoch 313/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9930 - categorical_accuracy: 0.6287 - val_loss: 3.9310 - val_categorical_accuracy: 0.1420\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9766 - categorical_accuracy: 0.6279 - val_loss: 3.9137 - val_categorical_accuracy: 0.1408\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9937 - categorical_accuracy: 0.6204 - val_loss: 4.2469 - val_categorical_accuracy: 0.1350\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 3s 53ms/step - loss: 0.9837 - categorical_accuracy: 0.6258 - val_loss: 4.2190 - val_categorical_accuracy: 0.1267\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9794 - categorical_accuracy: 0.6303 - val_loss: 3.9451 - val_categorical_accuracy: 0.1273\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9984 - categorical_accuracy: 0.6240 - val_loss: 4.0512 - val_categorical_accuracy: 0.1273\n",
      "Epoch 319/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9799 - categorical_accuracy: 0.6279 - val_loss: 4.0601 - val_categorical_accuracy: 0.1164\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9800 - categorical_accuracy: 0.6255 - val_loss: 4.2505 - val_categorical_accuracy: 0.1222\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9787 - categorical_accuracy: 0.6263 - val_loss: 3.8437 - val_categorical_accuracy: 0.1222\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9840 - categorical_accuracy: 0.6306 - val_loss: 3.8183 - val_categorical_accuracy: 0.1260\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9905 - categorical_accuracy: 0.6208 - val_loss: 3.8825 - val_categorical_accuracy: 0.1228\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9943 - categorical_accuracy: 0.6269 - val_loss: 4.1115 - val_categorical_accuracy: 0.1190\n",
      "Epoch 325/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9963 - categorical_accuracy: 0.6250 - val_loss: 3.9079 - val_categorical_accuracy: 0.1049\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9624 - categorical_accuracy: 0.6324 - val_loss: 4.1869 - val_categorical_accuracy: 0.1081\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9782 - categorical_accuracy: 0.6280 - val_loss: 4.0285 - val_categorical_accuracy: 0.1171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9845 - categorical_accuracy: 0.6232 - val_loss: 4.0786 - val_categorical_accuracy: 0.1100\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9787 - categorical_accuracy: 0.6280 - val_loss: 3.9208 - val_categorical_accuracy: 0.1152\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0055 - categorical_accuracy: 0.6266 - val_loss: 3.6945 - val_categorical_accuracy: 0.1113\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9787 - categorical_accuracy: 0.6311 - val_loss: 4.1901 - val_categorical_accuracy: 0.1062\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9740 - categorical_accuracy: 0.6276 - val_loss: 4.1147 - val_categorical_accuracy: 0.1088\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9878 - categorical_accuracy: 0.6295 - val_loss: 3.8196 - val_categorical_accuracy: 0.1120\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9743 - categorical_accuracy: 0.6303 - val_loss: 3.9530 - val_categorical_accuracy: 0.1062\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9913 - categorical_accuracy: 0.6263 - val_loss: 4.1418 - val_categorical_accuracy: 0.1075\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9732 - categorical_accuracy: 0.6293 - val_loss: 3.8986 - val_categorical_accuracy: 0.1062\n",
      "Epoch 337/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9811 - categorical_accuracy: 0.6309 - val_loss: 4.0653 - val_categorical_accuracy: 0.1056\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9458 - categorical_accuracy: 0.6389 - val_loss: 3.9634 - val_categorical_accuracy: 0.1062\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9453 - categorical_accuracy: 0.6420 - val_loss: 4.0769 - val_categorical_accuracy: 0.1120\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9977 - categorical_accuracy: 0.6304 - val_loss: 3.9129 - val_categorical_accuracy: 0.1049\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9667 - categorical_accuracy: 0.6346 - val_loss: 5.7841 - val_categorical_accuracy: 0.1036\n",
      "Epoch 342/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9848 - categorical_accuracy: 0.6312 - val_loss: 3.9663 - val_categorical_accuracy: 0.1113\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9500 - categorical_accuracy: 0.6440 - val_loss: 3.7776 - val_categorical_accuracy: 0.1043\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9828 - categorical_accuracy: 0.6314 - val_loss: 4.1526 - val_categorical_accuracy: 0.1043\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9684 - categorical_accuracy: 0.6364 - val_loss: 3.9216 - val_categorical_accuracy: 0.1030\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9599 - categorical_accuracy: 0.6391 - val_loss: 4.2586 - val_categorical_accuracy: 0.1062\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 0.9543 - categorical_accuracy: 0.6436 - val_loss: 3.9509 - val_categorical_accuracy: 0.1075\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9481 - categorical_accuracy: 0.6367 - val_loss: 3.8303 - val_categorical_accuracy: 0.1004\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9608 - categorical_accuracy: 0.6488 - val_loss: 4.0627 - val_categorical_accuracy: 0.1075\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9466 - categorical_accuracy: 0.6466 - val_loss: 3.8208 - val_categorical_accuracy: 0.1062\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9323 - categorical_accuracy: 0.6471 - val_loss: 4.0932 - val_categorical_accuracy: 0.1056\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9126 - categorical_accuracy: 0.6485 - val_loss: 4.2070 - val_categorical_accuracy: 0.0998\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9610 - categorical_accuracy: 0.6354 - val_loss: 3.9607 - val_categorical_accuracy: 0.1030\n",
      "Epoch 354/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.9341 - categorical_accuracy: 0.6426 - val_loss: 4.0424 - val_categorical_accuracy: 0.1024\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9440 - categorical_accuracy: 0.6431 - val_loss: 4.1402 - val_categorical_accuracy: 0.1043\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.9196 - categorical_accuracy: 0.6559 - val_loss: 5.6954 - val_categorical_accuracy: 0.1126\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9630 - categorical_accuracy: 0.6381 - val_loss: 3.9838 - val_categorical_accuracy: 0.1043\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9458 - categorical_accuracy: 0.6455 - val_loss: 4.4599 - val_categorical_accuracy: 0.1030\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.9376 - categorical_accuracy: 0.6445 - val_loss: 4.4845 - val_categorical_accuracy: 0.0960\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9291 - categorical_accuracy: 0.6442 - val_loss: 4.1434 - val_categorical_accuracy: 0.0998\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9417 - categorical_accuracy: 0.6476 - val_loss: 4.1205 - val_categorical_accuracy: 0.0928\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9399 - categorical_accuracy: 0.6463 - val_loss: 5.2787 - val_categorical_accuracy: 0.1043\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9374 - categorical_accuracy: 0.6472 - val_loss: 4.1416 - val_categorical_accuracy: 0.1049\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9440 - categorical_accuracy: 0.6447 - val_loss: 4.2766 - val_categorical_accuracy: 0.0985\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9229 - categorical_accuracy: 0.6503 - val_loss: 4.1117 - val_categorical_accuracy: 0.0972\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9236 - categorical_accuracy: 0.6508 - val_loss: 4.2539 - val_categorical_accuracy: 0.1113\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9151 - categorical_accuracy: 0.6581 - val_loss: 4.2799 - val_categorical_accuracy: 0.1011\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9019 - categorical_accuracy: 0.6580 - val_loss: 4.1896 - val_categorical_accuracy: 0.1030\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8883 - categorical_accuracy: 0.6573 - val_loss: 4.3466 - val_categorical_accuracy: 0.1024\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9139 - categorical_accuracy: 0.6552 - val_loss: 4.7826 - val_categorical_accuracy: 0.1075\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9454 - categorical_accuracy: 0.6484 - val_loss: 4.4615 - val_categorical_accuracy: 0.1056\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9224 - categorical_accuracy: 0.6472 - val_loss: 4.1975 - val_categorical_accuracy: 0.1088\n",
      "Epoch 373/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9212 - categorical_accuracy: 0.6508 - val_loss: 4.1518 - val_categorical_accuracy: 0.1126\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.9402 - categorical_accuracy: 0.6498 - val_loss: 4.9104 - val_categorical_accuracy: 0.1030\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9270 - categorical_accuracy: 0.6479 - val_loss: 4.1860 - val_categorical_accuracy: 0.0960\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8987 - categorical_accuracy: 0.6577 - val_loss: 4.3209 - val_categorical_accuracy: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9084 - categorical_accuracy: 0.6528 - val_loss: 4.1932 - val_categorical_accuracy: 0.1068\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9154 - categorical_accuracy: 0.6528 - val_loss: 4.0119 - val_categorical_accuracy: 0.0972\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9024 - categorical_accuracy: 0.6508 - val_loss: 4.1997 - val_categorical_accuracy: 0.0921\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.9212 - categorical_accuracy: 0.6520 - val_loss: 4.1540 - val_categorical_accuracy: 0.0966\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8990 - categorical_accuracy: 0.6597 - val_loss: 4.2035 - val_categorical_accuracy: 0.1017\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9008 - categorical_accuracy: 0.6554 - val_loss: 4.2744 - val_categorical_accuracy: 0.1068\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9252 - categorical_accuracy: 0.6496 - val_loss: 4.4253 - val_categorical_accuracy: 0.1004\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9123 - categorical_accuracy: 0.6567 - val_loss: 4.1477 - val_categorical_accuracy: 0.1030\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9300 - categorical_accuracy: 0.6538 - val_loss: 4.3104 - val_categorical_accuracy: 0.0966\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9067 - categorical_accuracy: 0.6589 - val_loss: 4.3606 - val_categorical_accuracy: 0.0966\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9009 - categorical_accuracy: 0.6577 - val_loss: 4.3225 - val_categorical_accuracy: 0.1011\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8814 - categorical_accuracy: 0.6610 - val_loss: 4.5313 - val_categorical_accuracy: 0.1036\n",
      "Epoch 389/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.8977 - categorical_accuracy: 0.6552 - val_loss: 4.2992 - val_categorical_accuracy: 0.1043\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8743 - categorical_accuracy: 0.6644 - val_loss: 4.3438 - val_categorical_accuracy: 0.1056\n",
      "Epoch 391/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8961 - categorical_accuracy: 0.6657 - val_loss: 4.1885 - val_categorical_accuracy: 0.1081\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8889 - categorical_accuracy: 0.6612 - val_loss: 4.3838 - val_categorical_accuracy: 0.0972\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9087 - categorical_accuracy: 0.6528 - val_loss: 4.2817 - val_categorical_accuracy: 0.0966\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8934 - categorical_accuracy: 0.6599 - val_loss: 4.5068 - val_categorical_accuracy: 0.1062\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8935 - categorical_accuracy: 0.6596 - val_loss: 4.2909 - val_categorical_accuracy: 0.1043\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9047 - categorical_accuracy: 0.6544 - val_loss: 4.4208 - val_categorical_accuracy: 0.0985\n",
      "Epoch 397/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8861 - categorical_accuracy: 0.6613 - val_loss: 4.2282 - val_categorical_accuracy: 0.0998\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8946 - categorical_accuracy: 0.6628 - val_loss: 4.2153 - val_categorical_accuracy: 0.0883\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9138 - categorical_accuracy: 0.6530 - val_loss: 4.3169 - val_categorical_accuracy: 0.1017\n",
      "Epoch 400/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.9051 - categorical_accuracy: 0.6538 - val_loss: 4.3822 - val_categorical_accuracy: 0.1043\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 0.8907 - categorical_accuracy: 0.6580 - val_loss: 4.2056 - val_categorical_accuracy: 0.0966\n",
      "Epoch 402/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.9209 - categorical_accuracy: 0.6556 - val_loss: 4.5345 - val_categorical_accuracy: 0.0940\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8916 - categorical_accuracy: 0.6583 - val_loss: 4.5028 - val_categorical_accuracy: 0.0985\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8759 - categorical_accuracy: 0.6666 - val_loss: 4.5609 - val_categorical_accuracy: 0.1024\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8803 - categorical_accuracy: 0.6641 - val_loss: 4.5242 - val_categorical_accuracy: 0.0998\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8756 - categorical_accuracy: 0.6625 - val_loss: 4.3069 - val_categorical_accuracy: 0.0921\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.8885 - categorical_accuracy: 0.6610 - val_loss: 4.2616 - val_categorical_accuracy: 0.0928\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9046 - categorical_accuracy: 0.6586 - val_loss: 4.7185 - val_categorical_accuracy: 0.0998\n",
      "Epoch 409/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8869 - categorical_accuracy: 0.6572 - val_loss: 4.6029 - val_categorical_accuracy: 0.1056\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8976 - categorical_accuracy: 0.6532 - val_loss: 4.6792 - val_categorical_accuracy: 0.0998\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9060 - categorical_accuracy: 0.6549 - val_loss: 4.3598 - val_categorical_accuracy: 0.0960\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8988 - categorical_accuracy: 0.6556 - val_loss: 4.2812 - val_categorical_accuracy: 0.0985\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8774 - categorical_accuracy: 0.6605 - val_loss: 4.4911 - val_categorical_accuracy: 0.1017\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8561 - categorical_accuracy: 0.6701 - val_loss: 4.4058 - val_categorical_accuracy: 0.1024\n",
      "Epoch 415/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8671 - categorical_accuracy: 0.6687 - val_loss: 4.8397 - val_categorical_accuracy: 0.1004\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8737 - categorical_accuracy: 0.6597 - val_loss: 4.5050 - val_categorical_accuracy: 0.1017\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8687 - categorical_accuracy: 0.6668 - val_loss: 4.4057 - val_categorical_accuracy: 0.1011\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8811 - categorical_accuracy: 0.6650 - val_loss: 4.6038 - val_categorical_accuracy: 0.0966\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8737 - categorical_accuracy: 0.6652 - val_loss: 4.7735 - val_categorical_accuracy: 0.0966\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8840 - categorical_accuracy: 0.6655 - val_loss: 4.7668 - val_categorical_accuracy: 0.0966\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8644 - categorical_accuracy: 0.6665 - val_loss: 4.3495 - val_categorical_accuracy: 0.0921\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8994 - categorical_accuracy: 0.6618 - val_loss: 4.2843 - val_categorical_accuracy: 0.0998\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8839 - categorical_accuracy: 0.6617 - val_loss: 4.4400 - val_categorical_accuracy: 0.0947\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8792 - categorical_accuracy: 0.6613 - val_loss: 4.5124 - val_categorical_accuracy: 0.1017\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.8775 - categorical_accuracy: 0.6653 - val_loss: 4.5740 - val_categorical_accuracy: 0.1017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8761 - categorical_accuracy: 0.6634 - val_loss: 4.7473 - val_categorical_accuracy: 0.0972\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8840 - categorical_accuracy: 0.6647 - val_loss: 4.4707 - val_categorical_accuracy: 0.1017\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8853 - categorical_accuracy: 0.6623 - val_loss: 4.2130 - val_categorical_accuracy: 0.1011\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8843 - categorical_accuracy: 0.6588 - val_loss: 4.8617 - val_categorical_accuracy: 0.0998\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8776 - categorical_accuracy: 0.6623 - val_loss: 4.5142 - val_categorical_accuracy: 0.1049\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8752 - categorical_accuracy: 0.6668 - val_loss: 4.7460 - val_categorical_accuracy: 0.1011\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8766 - categorical_accuracy: 0.6605 - val_loss: 4.4023 - val_categorical_accuracy: 0.0979\n",
      "Epoch 433/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8622 - categorical_accuracy: 0.6669 - val_loss: 4.6888 - val_categorical_accuracy: 0.0960\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8464 - categorical_accuracy: 0.6701 - val_loss: 4.3454 - val_categorical_accuracy: 0.1024\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8469 - categorical_accuracy: 0.6716 - val_loss: 5.2656 - val_categorical_accuracy: 0.1075\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8643 - categorical_accuracy: 0.6631 - val_loss: 4.8838 - val_categorical_accuracy: 0.0992\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8769 - categorical_accuracy: 0.6629 - val_loss: 4.5936 - val_categorical_accuracy: 0.0985\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8481 - categorical_accuracy: 0.6693 - val_loss: 4.9062 - val_categorical_accuracy: 0.0966\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8522 - categorical_accuracy: 0.6681 - val_loss: 4.9494 - val_categorical_accuracy: 0.0998\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8925 - categorical_accuracy: 0.6631 - val_loss: 4.6815 - val_categorical_accuracy: 0.1036\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8477 - categorical_accuracy: 0.6724 - val_loss: 4.6867 - val_categorical_accuracy: 0.1017\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8496 - categorical_accuracy: 0.6705 - val_loss: 4.7720 - val_categorical_accuracy: 0.0992\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8753 - categorical_accuracy: 0.6641 - val_loss: 5.1774 - val_categorical_accuracy: 0.1004\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8624 - categorical_accuracy: 0.6697 - val_loss: 4.7432 - val_categorical_accuracy: 0.0934\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8618 - categorical_accuracy: 0.6665 - val_loss: 4.5651 - val_categorical_accuracy: 0.0992\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8675 - categorical_accuracy: 0.6639 - val_loss: 4.9951 - val_categorical_accuracy: 0.0992\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8762 - categorical_accuracy: 0.6660 - val_loss: 4.8021 - val_categorical_accuracy: 0.1011\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8379 - categorical_accuracy: 0.6730 - val_loss: 4.5967 - val_categorical_accuracy: 0.1017\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8516 - categorical_accuracy: 0.6706 - val_loss: 5.1534 - val_categorical_accuracy: 0.1017\n",
      "Epoch 450/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8515 - categorical_accuracy: 0.6645 - val_loss: 4.9343 - val_categorical_accuracy: 0.1011\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8556 - categorical_accuracy: 0.6681 - val_loss: 5.5886 - val_categorical_accuracy: 0.1062\n",
      "Epoch 452/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8547 - categorical_accuracy: 0.6700 - val_loss: 4.8736 - val_categorical_accuracy: 0.0953\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8548 - categorical_accuracy: 0.6705 - val_loss: 4.8805 - val_categorical_accuracy: 0.1030\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8667 - categorical_accuracy: 0.6620 - val_loss: 5.6527 - val_categorical_accuracy: 0.1043\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8513 - categorical_accuracy: 0.6732 - val_loss: 4.8292 - val_categorical_accuracy: 0.1081\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8409 - categorical_accuracy: 0.6687 - val_loss: 4.3600 - val_categorical_accuracy: 0.1036\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8825 - categorical_accuracy: 0.6663 - val_loss: 4.7813 - val_categorical_accuracy: 0.1017\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8591 - categorical_accuracy: 0.6676 - val_loss: 4.6573 - val_categorical_accuracy: 0.0979\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8462 - categorical_accuracy: 0.6679 - val_loss: 4.7225 - val_categorical_accuracy: 0.1081\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8573 - categorical_accuracy: 0.6701 - val_loss: 5.7283 - val_categorical_accuracy: 0.1062\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8503 - categorical_accuracy: 0.6709 - val_loss: 5.3481 - val_categorical_accuracy: 0.1024\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8593 - categorical_accuracy: 0.6709 - val_loss: 4.6776 - val_categorical_accuracy: 0.1017\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8532 - categorical_accuracy: 0.6722 - val_loss: 4.5934 - val_categorical_accuracy: 0.1024\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8488 - categorical_accuracy: 0.6701 - val_loss: 5.3576 - val_categorical_accuracy: 0.1030\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8587 - categorical_accuracy: 0.6748 - val_loss: 5.1121 - val_categorical_accuracy: 0.0953\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8689 - categorical_accuracy: 0.6673 - val_loss: 4.9155 - val_categorical_accuracy: 0.1004\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8716 - categorical_accuracy: 0.6660 - val_loss: 4.9454 - val_categorical_accuracy: 0.1043\n",
      "Epoch 468/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8315 - categorical_accuracy: 0.6762 - val_loss: 4.4939 - val_categorical_accuracy: 0.1056\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8607 - categorical_accuracy: 0.6709 - val_loss: 5.0088 - val_categorical_accuracy: 0.0992\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8890 - categorical_accuracy: 0.6631 - val_loss: 4.7162 - val_categorical_accuracy: 0.0998\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8435 - categorical_accuracy: 0.6729 - val_loss: 4.5286 - val_categorical_accuracy: 0.0940\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8646 - categorical_accuracy: 0.6617 - val_loss: 4.8116 - val_categorical_accuracy: 0.0966\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8467 - categorical_accuracy: 0.6708 - val_loss: 4.4884 - val_categorical_accuracy: 0.1024\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8362 - categorical_accuracy: 0.6676 - val_loss: 4.6142 - val_categorical_accuracy: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8436 - categorical_accuracy: 0.6748 - val_loss: 4.9889 - val_categorical_accuracy: 0.0985\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8443 - categorical_accuracy: 0.6661 - val_loss: 5.1880 - val_categorical_accuracy: 0.1036\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8411 - categorical_accuracy: 0.6759 - val_loss: 4.8966 - val_categorical_accuracy: 0.1081\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8373 - categorical_accuracy: 0.6743 - val_loss: 5.8751 - val_categorical_accuracy: 0.1068\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8525 - categorical_accuracy: 0.6730 - val_loss: 4.6039 - val_categorical_accuracy: 0.0985\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8532 - categorical_accuracy: 0.6738 - val_loss: 5.2000 - val_categorical_accuracy: 0.1004\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8744 - categorical_accuracy: 0.6615 - val_loss: 4.9057 - val_categorical_accuracy: 0.0979\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8740 - categorical_accuracy: 0.6663 - val_loss: 4.7632 - val_categorical_accuracy: 0.0934\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8491 - categorical_accuracy: 0.6657 - val_loss: 4.7561 - val_categorical_accuracy: 0.0947\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8615 - categorical_accuracy: 0.6687 - val_loss: 4.7616 - val_categorical_accuracy: 0.1036\n",
      "Epoch 485/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8331 - categorical_accuracy: 0.6789 - val_loss: 5.4561 - val_categorical_accuracy: 0.1024\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8459 - categorical_accuracy: 0.6748 - val_loss: 4.7632 - val_categorical_accuracy: 0.0979\n",
      "Epoch 487/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8682 - categorical_accuracy: 0.6700 - val_loss: 4.7702 - val_categorical_accuracy: 0.1036\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8605 - categorical_accuracy: 0.6716 - val_loss: 4.6374 - val_categorical_accuracy: 0.0972\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8415 - categorical_accuracy: 0.6741 - val_loss: 5.3487 - val_categorical_accuracy: 0.1056\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8264 - categorical_accuracy: 0.6729 - val_loss: 5.1212 - val_categorical_accuracy: 0.0985\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8353 - categorical_accuracy: 0.6781 - val_loss: 5.4331 - val_categorical_accuracy: 0.1011\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8712 - categorical_accuracy: 0.6658 - val_loss: 5.1039 - val_categorical_accuracy: 0.1011\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8310 - categorical_accuracy: 0.6722 - val_loss: 4.8958 - val_categorical_accuracy: 0.0985\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.8160 - categorical_accuracy: 0.6770 - val_loss: 5.0179 - val_categorical_accuracy: 0.0979\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8223 - categorical_accuracy: 0.6789 - val_loss: 4.9448 - val_categorical_accuracy: 0.1011\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8371 - categorical_accuracy: 0.6745 - val_loss: 4.8741 - val_categorical_accuracy: 0.0947\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.8215 - categorical_accuracy: 0.6789 - val_loss: 5.2512 - val_categorical_accuracy: 0.1030\n",
      "Epoch 498/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8259 - categorical_accuracy: 0.6796 - val_loss: 5.3415 - val_categorical_accuracy: 0.1004\n",
      "Epoch 499/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8224 - categorical_accuracy: 0.6698 - val_loss: 5.2849 - val_categorical_accuracy: 0.0972\n",
      "Epoch 500/500\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8575 - categorical_accuracy: 0.6719 - val_loss: 5.1985 - val_categorical_accuracy: 0.1017\n",
      "Finished.\n",
      "Training Sigmoid Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "49/49 [==============================] - 4s 62ms/step - loss: 2.7743 - categorical_accuracy: 0.1090 - val_loss: 2.7706 - val_categorical_accuracy: 0.0934\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 4s 74ms/step - loss: 2.7334 - categorical_accuracy: 0.0933 - val_loss: 2.7272 - val_categorical_accuracy: 0.0934\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 3s 60ms/step - loss: 2.7045 - categorical_accuracy: 0.1216 - val_loss: 2.6844 - val_categorical_accuracy: 0.0934\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 2.6716 - categorical_accuracy: 0.1352 - val_loss: 2.6415 - val_categorical_accuracy: 0.0934\n",
      "Epoch 5/500\n",
      "49/49 [==============================] - 3s 58ms/step - loss: 2.6356 - categorical_accuracy: 0.1352 - val_loss: 2.6034 - val_categorical_accuracy: 0.0934\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 2.6010 - categorical_accuracy: 0.1423 - val_loss: 2.5883 - val_categorical_accuracy: 0.1036\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5732 - categorical_accuracy: 0.1641 - val_loss: 2.6470 - val_categorical_accuracy: 0.1036\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5542 - categorical_accuracy: 0.1641 - val_loss: 2.9071 - val_categorical_accuracy: 0.1036\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5426 - categorical_accuracy: 0.1641 - val_loss: 3.3194 - val_categorical_accuracy: 0.1036\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5358 - categorical_accuracy: 0.1641 - val_loss: 4.8946 - val_categorical_accuracy: 0.0934\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5319 - categorical_accuracy: 0.1641 - val_loss: 7.6580 - val_categorical_accuracy: 0.0934\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5293 - categorical_accuracy: 0.1641 - val_loss: 7.3271 - val_categorical_accuracy: 0.1036\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5277 - categorical_accuracy: 0.1641 - val_loss: 12.1446 - val_categorical_accuracy: 0.1036\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5266 - categorical_accuracy: 0.1641 - val_loss: 17.7181 - val_categorical_accuracy: 0.1036\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5258 - categorical_accuracy: 0.1641 - val_loss: 15.0896 - val_categorical_accuracy: 0.1036\n",
      "Epoch 16/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5252 - categorical_accuracy: 0.1641 - val_loss: 19.4642 - val_categorical_accuracy: 0.1036\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5249 - categorical_accuracy: 0.1641 - val_loss: 19.8435 - val_categorical_accuracy: 0.1036\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5246 - categorical_accuracy: 0.1641 - val_loss: 17.6478 - val_categorical_accuracy: 0.1036\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5245 - categorical_accuracy: 0.1641 - val_loss: 18.9003 - val_categorical_accuracy: 0.0934\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5244 - categorical_accuracy: 0.1641 - val_loss: 21.3633 - val_categorical_accuracy: 0.0934\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5243 - categorical_accuracy: 0.1641 - val_loss: 22.1594 - val_categorical_accuracy: 0.0934\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5243 - categorical_accuracy: 0.1641 - val_loss: 15.4133 - val_categorical_accuracy: 0.1644\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.5043 - val_categorical_accuracy: 0.1036\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5243 - categorical_accuracy: 0.1641 - val_loss: 19.6907 - val_categorical_accuracy: 0.1036\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 24.8678 - val_categorical_accuracy: 0.1036\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 18.4662 - val_categorical_accuracy: 0.1036\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.4373 - val_categorical_accuracy: 0.0134\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 41.2584 - val_categorical_accuracy: 0.0134\n",
      "Epoch 29/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.4455 - val_categorical_accuracy: 0.0998\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 12.7800 - val_categorical_accuracy: 0.1356\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 33.2750 - val_categorical_accuracy: 0.0134\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 48.0440 - val_categorical_accuracy: 0.0102\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 25.5377 - val_categorical_accuracy: 0.1356\n",
      "Epoch 34/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 24.5398 - val_categorical_accuracy: 0.0102\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 25.6663 - val_categorical_accuracy: 0.1356\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.8365 - val_categorical_accuracy: 0.1036\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 25.9028 - val_categorical_accuracy: 0.1036\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.5073 - val_categorical_accuracy: 0.0134\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 34.2365 - val_categorical_accuracy: 0.0134\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 48.7025 - val_categorical_accuracy: 0.0102\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.7064 - val_categorical_accuracy: 0.0102\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.8476 - val_categorical_accuracy: 0.0128\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 13.3813 - val_categorical_accuracy: 0.1644\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 10.7539 - val_categorical_accuracy: 0.1644\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 12.8285 - val_categorical_accuracy: 0.1356\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 25.6149 - val_categorical_accuracy: 0.0134\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.2594 - val_categorical_accuracy: 0.0134\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.6593 - val_categorical_accuracy: 0.0134\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 24.0236 - val_categorical_accuracy: 0.0934\n",
      "Epoch 50/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 48.3754 - val_categorical_accuracy: 0.0102\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 44.9983 - val_categorical_accuracy: 0.0102\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 21.7199 - val_categorical_accuracy: 0.0934\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.4024 - val_categorical_accuracy: 0.1036\n",
      "Epoch 54/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.3969 - val_categorical_accuracy: 0.1644\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 21.3234 - val_categorical_accuracy: 0.0467\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 26.8873 - val_categorical_accuracy: 0.0934\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.6022 - val_categorical_accuracy: 0.1036\n",
      "Epoch 58/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.7701 - val_categorical_accuracy: 0.0134\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 24.5150 - val_categorical_accuracy: 0.0102\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.0159 - val_categorical_accuracy: 0.0467\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.5043 - val_categorical_accuracy: 0.0998\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.1652 - val_categorical_accuracy: 0.0467\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.8644 - val_categorical_accuracy: 0.1356\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.6342 - val_categorical_accuracy: 0.0467\n",
      "Epoch 65/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.7211 - val_categorical_accuracy: 0.0102\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 14.2512 - val_categorical_accuracy: 0.0998\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 14.5907 - val_categorical_accuracy: 0.1644\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.0949 - val_categorical_accuracy: 0.0998\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.4477 - val_categorical_accuracy: 0.0467\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.4577 - val_categorical_accuracy: 0.1036\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.7626 - val_categorical_accuracy: 0.1036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 20.9639 - val_categorical_accuracy: 0.1036\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5243 - categorical_accuracy: 0.1641 - val_loss: 14.9237 - val_categorical_accuracy: 0.1644\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 12.1058 - val_categorical_accuracy: 0.1644\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 8.2979 - val_categorical_accuracy: 0.1644\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.3054 - val_categorical_accuracy: 0.0934\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 25.4459 - val_categorical_accuracy: 0.0102\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 21.3796 - val_categorical_accuracy: 0.1356\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 26.6790 - val_categorical_accuracy: 0.0102\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 33.2740 - val_categorical_accuracy: 0.0102\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.1178 - val_categorical_accuracy: 0.1036\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.6760 - val_categorical_accuracy: 0.0467\n",
      "Epoch 83/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.3359 - val_categorical_accuracy: 0.1644\n",
      "Epoch 84/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.0896 - val_categorical_accuracy: 0.0998\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 48.5145 - val_categorical_accuracy: 0.0102\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.0080 - val_categorical_accuracy: 0.0128\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.1182 - val_categorical_accuracy: 0.0998\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.2021 - val_categorical_accuracy: 0.0128\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 35.3955 - val_categorical_accuracy: 0.0102\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 11.6163 - val_categorical_accuracy: 0.1644\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 14.5139 - val_categorical_accuracy: 0.1644\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.5688 - val_categorical_accuracy: 0.0102\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 18.7227 - val_categorical_accuracy: 0.0934\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.6844 - val_categorical_accuracy: 0.1036\n",
      "Epoch 95/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.4249 - val_categorical_accuracy: 0.1036\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 12.9289 - val_categorical_accuracy: 0.1036\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 12.9935 - val_categorical_accuracy: 0.0998\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.2031 - val_categorical_accuracy: 0.1644\n",
      "Epoch 99/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.7454 - val_categorical_accuracy: 0.1036\n",
      "Epoch 100/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 13.4803 - val_categorical_accuracy: 0.1644\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.2125 - val_categorical_accuracy: 0.1036\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 21.9149 - val_categorical_accuracy: 0.0934\n",
      "Epoch 103/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 12.5062 - val_categorical_accuracy: 0.0333\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 9.9862 - val_categorical_accuracy: 0.0998\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.1079 - val_categorical_accuracy: 0.0134\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 48.2157 - val_categorical_accuracy: 0.0102\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 13.4317 - val_categorical_accuracy: 0.1644\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.6840 - val_categorical_accuracy: 0.1036\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 18.9667 - val_categorical_accuracy: 0.0102\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.5390 - val_categorical_accuracy: 0.0224\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 18.7673 - val_categorical_accuracy: 0.0224\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 38.3854 - val_categorical_accuracy: 0.0134\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 23.7929 - val_categorical_accuracy: 0.0128\n",
      "Epoch 114/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 51.1170 - val_categorical_accuracy: 0.0102\n",
      "Epoch 115/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.3004 - val_categorical_accuracy: 0.0934\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 39.6226 - val_categorical_accuracy: 0.0134\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1384 - val_categorical_accuracy: 0.0998\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 43.6328 - val_categorical_accuracy: 0.0102\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.1451 - val_categorical_accuracy: 0.0102\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.3420 - val_categorical_accuracy: 0.1356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.1030 - val_categorical_accuracy: 0.0934\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 10.1441 - val_categorical_accuracy: 0.1644\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.0429 - val_categorical_accuracy: 0.0102\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 47.4337 - val_categorical_accuracy: 0.0102\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.1792 - val_categorical_accuracy: 0.0102\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.6749 - val_categorical_accuracy: 0.0467\n",
      "Epoch 127/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 48.8543 - val_categorical_accuracy: 0.0102\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 25.8121 - val_categorical_accuracy: 0.0102\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.6100 - val_categorical_accuracy: 0.0934\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.0927 - val_categorical_accuracy: 0.0998\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.8149 - val_categorical_accuracy: 0.0998\n",
      "Epoch 132/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.0522 - val_categorical_accuracy: 0.0998\n",
      "Epoch 133/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.0582 - val_categorical_accuracy: 0.0998\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.6245 - val_categorical_accuracy: 0.0467\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 48.1403 - val_categorical_accuracy: 0.0102\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 48.0177 - val_categorical_accuracy: 0.0102\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.8625 - val_categorical_accuracy: 0.0467\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.4806 - val_categorical_accuracy: 0.1036\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.0774 - val_categorical_accuracy: 0.1644\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.6285 - val_categorical_accuracy: 0.1036\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.5526 - val_categorical_accuracy: 0.1036\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.2067 - val_categorical_accuracy: 0.0416\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 18.0807 - val_categorical_accuracy: 0.1644\n",
      "Epoch 144/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.7917 - val_categorical_accuracy: 0.1644\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.7907 - val_categorical_accuracy: 0.1036\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.6997 - val_categorical_accuracy: 0.0134\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2670 - val_categorical_accuracy: 0.0934\n",
      "Epoch 148/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2838 - val_categorical_accuracy: 0.0934\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 31.2153 - val_categorical_accuracy: 0.0134\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 28.8365 - val_categorical_accuracy: 0.0934\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 29.0137 - val_categorical_accuracy: 0.0934\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.3391 - val_categorical_accuracy: 0.1036\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 18.9009 - val_categorical_accuracy: 0.1644\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.5753 - val_categorical_accuracy: 0.0736\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.5515 - val_categorical_accuracy: 0.1036\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 13.5305 - val_categorical_accuracy: 0.1036\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.6359 - val_categorical_accuracy: 0.1036\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.8093 - val_categorical_accuracy: 0.1644\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.8054 - val_categorical_accuracy: 0.1644\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.0873 - val_categorical_accuracy: 0.1644\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.9826 - val_categorical_accuracy: 0.0998\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 14.8563 - val_categorical_accuracy: 0.0998\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.5736 - val_categorical_accuracy: 0.1036\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.4201 - val_categorical_accuracy: 0.1036\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.5186 - val_categorical_accuracy: 0.1036\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 40.2716 - val_categorical_accuracy: 0.0134\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 11.5496 - val_categorical_accuracy: 0.0998\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.3202 - val_categorical_accuracy: 0.0467\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.3739 - val_categorical_accuracy: 0.0102\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.4576 - val_categorical_accuracy: 0.0102\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.1717 - val_categorical_accuracy: 0.0102\n",
      "Epoch 172/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.2569 - val_categorical_accuracy: 0.0102\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 28.2952 - val_categorical_accuracy: 0.0102\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.1148 - val_categorical_accuracy: 0.0998\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.1236 - val_categorical_accuracy: 0.0998\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1166 - val_categorical_accuracy: 0.0998\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 52.1584 - val_categorical_accuracy: 0.0102\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.4271 - val_categorical_accuracy: 0.0102\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.3714 - val_categorical_accuracy: 0.0102\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 37.0747 - val_categorical_accuracy: 0.0134\n",
      "Epoch 181/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 25.6685 - val_categorical_accuracy: 0.1356\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 48.5068 - val_categorical_accuracy: 0.0102\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.2794 - val_categorical_accuracy: 0.0467\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5243 - categorical_accuracy: 0.1641 - val_loss: 16.9948 - val_categorical_accuracy: 0.0467\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.2290 - val_categorical_accuracy: 0.0467\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.1061 - val_categorical_accuracy: 0.0998\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.4200 - val_categorical_accuracy: 0.0102\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.3969 - val_categorical_accuracy: 0.0102\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.9457 - val_categorical_accuracy: 0.0102\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1333 - val_categorical_accuracy: 0.0998\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.1286 - val_categorical_accuracy: 0.0998\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1089 - val_categorical_accuracy: 0.0998\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 21.9122 - val_categorical_accuracy: 0.0128\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.4899 - val_categorical_accuracy: 0.0998\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 14.8984 - val_categorical_accuracy: 0.0998\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.9980 - val_categorical_accuracy: 0.0224\n",
      "Epoch 197/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 10.2707 - val_categorical_accuracy: 0.0934\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.2216 - val_categorical_accuracy: 0.0134\n",
      "Epoch 199/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.3636 - val_categorical_accuracy: 0.1036\n",
      "Epoch 200/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 21.8843 - val_categorical_accuracy: 0.1036\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.0595 - val_categorical_accuracy: 0.0934\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 28.9561 - val_categorical_accuracy: 0.0934\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.6389 - val_categorical_accuracy: 0.1036\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 23.4428 - val_categorical_accuracy: 0.1036\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.1733 - val_categorical_accuracy: 0.1036\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.0552 - val_categorical_accuracy: 0.0934\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.2190 - val_categorical_accuracy: 0.0934\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.2032 - val_categorical_accuracy: 0.0934\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.1819 - val_categorical_accuracy: 0.0934\n",
      "Epoch 210/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 23.6339 - val_categorical_accuracy: 0.0134\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 41.6476 - val_categorical_accuracy: 0.0134\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 43.0361 - val_categorical_accuracy: 0.0134\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 43.0491 - val_categorical_accuracy: 0.0134\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 43.1665 - val_categorical_accuracy: 0.0134\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1044 - val_categorical_accuracy: 0.0934\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 41.6195 - val_categorical_accuracy: 0.0134\n",
      "Epoch 217/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.9133 - val_categorical_accuracy: 0.1356\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.6937 - val_categorical_accuracy: 0.0467\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1238 - val_categorical_accuracy: 0.0998\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 23.2343 - val_categorical_accuracy: 0.0128\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.6085 - val_categorical_accuracy: 0.0128\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.9485 - val_categorical_accuracy: 0.0998\n",
      "Epoch 223/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 24.0632 - val_categorical_accuracy: 0.1356\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.4343 - val_categorical_accuracy: 0.0998\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 40.7152 - val_categorical_accuracy: 0.0134\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.6207 - val_categorical_accuracy: 0.0102\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.0671 - val_categorical_accuracy: 0.0934\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 38.5448 - val_categorical_accuracy: 0.0134\n",
      "Epoch 229/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.1973 - val_categorical_accuracy: 0.1644\n",
      "Epoch 230/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 17.1529 - val_categorical_accuracy: 0.0998\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1484 - val_categorical_accuracy: 0.0998\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.9431 - val_categorical_accuracy: 0.0998\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.3659 - val_categorical_accuracy: 0.0467\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.9006 - val_categorical_accuracy: 0.0934\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.1875 - val_categorical_accuracy: 0.0934\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.0529 - val_categorical_accuracy: 0.0934\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 12.5193 - val_categorical_accuracy: 0.0224\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 12.8417 - val_categorical_accuracy: 0.0224\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 14.8337 - val_categorical_accuracy: 0.1644\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 13.2790 - val_categorical_accuracy: 0.1036\n",
      "Epoch 241/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 26.1757 - val_categorical_accuracy: 0.0134\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 25.8494 - val_categorical_accuracy: 0.0102\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1709 - val_categorical_accuracy: 0.0128\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 20.4957 - val_categorical_accuracy: 0.0467\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.9806 - val_categorical_accuracy: 0.0467\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 14.4018 - val_categorical_accuracy: 0.0998\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.2192 - val_categorical_accuracy: 0.0998\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.2307 - val_categorical_accuracy: 0.0998\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.2658 - val_categorical_accuracy: 0.0102\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 31.2100 - val_categorical_accuracy: 0.0102\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.2543 - val_categorical_accuracy: 0.0934\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.3426 - val_categorical_accuracy: 0.0128\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.5516 - val_categorical_accuracy: 0.0467\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.7123 - val_categorical_accuracy: 0.0998\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.2578 - val_categorical_accuracy: 0.0998\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.0358 - val_categorical_accuracy: 0.1644\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.2377 - val_categorical_accuracy: 0.0998\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.2951 - val_categorical_accuracy: 0.1644\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 20.3102 - val_categorical_accuracy: 0.1644\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.0552 - val_categorical_accuracy: 0.0998\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.2384 - val_categorical_accuracy: 0.0998\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.9062 - val_categorical_accuracy: 0.1644\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.0460 - val_categorical_accuracy: 0.1036\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.4781 - val_categorical_accuracy: 0.1036\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 20.2769 - val_categorical_accuracy: 0.1644\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1880 - val_categorical_accuracy: 0.0998\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 18.4251 - val_categorical_accuracy: 0.1036\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.3451 - val_categorical_accuracy: 0.1036\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.1352 - val_categorical_accuracy: 0.1036\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 21.3847 - val_categorical_accuracy: 0.1036\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.6663 - val_categorical_accuracy: 0.0102\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.7692 - val_categorical_accuracy: 0.0102\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.0072 - val_categorical_accuracy: 0.0934\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 43.2055 - val_categorical_accuracy: 0.0134\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.9095 - val_categorical_accuracy: 0.0102\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 41.7652 - val_categorical_accuracy: 0.0134\n",
      "Epoch 277/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1085 - val_categorical_accuracy: 0.0934\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.0996 - val_categorical_accuracy: 0.0102\n",
      "Epoch 279/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.0712 - val_categorical_accuracy: 0.0934\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 48.8792 - val_categorical_accuracy: 0.0102\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.1241 - val_categorical_accuracy: 0.0102\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.2126 - val_categorical_accuracy: 0.0102\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.2232 - val_categorical_accuracy: 0.0467\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.8132 - val_categorical_accuracy: 0.0467\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 42.9867 - val_categorical_accuracy: 0.0134\n",
      "Epoch 286/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.0286 - val_categorical_accuracy: 0.0134\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.0844 - val_categorical_accuracy: 0.0934\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2909 - val_categorical_accuracy: 0.0934\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.3063 - val_categorical_accuracy: 0.0934\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.3490 - val_categorical_accuracy: 0.0934\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 26.4890 - val_categorical_accuracy: 0.0934\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.3605 - val_categorical_accuracy: 0.0934\n",
      "Epoch 293/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 21.4521 - val_categorical_accuracy: 0.0934\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.1490 - val_categorical_accuracy: 0.0134\n",
      "Epoch 295/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.0352 - val_categorical_accuracy: 0.1356\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.6269 - val_categorical_accuracy: 0.0467\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.6092 - val_categorical_accuracy: 0.0134\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 12.0940 - val_categorical_accuracy: 0.1036\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.3467 - val_categorical_accuracy: 0.0934\n",
      "Epoch 300/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.3570 - val_categorical_accuracy: 0.0934\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.4335 - val_categorical_accuracy: 0.0934\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.0491 - val_categorical_accuracy: 0.1036\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.0789 - val_categorical_accuracy: 0.0998\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.0515 - val_categorical_accuracy: 0.0998\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 42.8265 - val_categorical_accuracy: 0.0102\n",
      "Epoch 306/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.7312 - val_categorical_accuracy: 0.0467\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1270 - val_categorical_accuracy: 0.0998\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.3001 - val_categorical_accuracy: 0.0934\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2581 - val_categorical_accuracy: 0.0934\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2462 - val_categorical_accuracy: 0.0934\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2350 - val_categorical_accuracy: 0.0934\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1921 - val_categorical_accuracy: 0.0934\n",
      "Epoch 313/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 33.1797 - val_categorical_accuracy: 0.0102\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 22.0769 - val_categorical_accuracy: 0.0934\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.6966 - val_categorical_accuracy: 0.0102\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 23.3163 - val_categorical_accuracy: 0.0128\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 23.6710 - val_categorical_accuracy: 0.0128\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.5122 - val_categorical_accuracy: 0.0134\n",
      "Epoch 319/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 22.1274 - val_categorical_accuracy: 0.0934\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1428 - val_categorical_accuracy: 0.0934\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1318 - val_categorical_accuracy: 0.0934\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1034 - val_categorical_accuracy: 0.0934\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 24.6555 - val_categorical_accuracy: 0.1036\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.1208 - val_categorical_accuracy: 0.1644\n",
      "Epoch 325/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 12.7636 - val_categorical_accuracy: 0.1644\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 13.1376 - val_categorical_accuracy: 0.1036\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 21.5056 - val_categorical_accuracy: 0.0934\n",
      "Epoch 328/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 21.1175 - val_categorical_accuracy: 0.0128\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 42.9401 - val_categorical_accuracy: 0.0102\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 41.7569 - val_categorical_accuracy: 0.0134\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 28.4573 - val_categorical_accuracy: 0.0134\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.0607 - val_categorical_accuracy: 0.0934\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 19.9248 - val_categorical_accuracy: 0.0934\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.0950 - val_categorical_accuracy: 0.0934\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 23.8700 - val_categorical_accuracy: 0.1036\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.6095 - val_categorical_accuracy: 0.0934\n",
      "Epoch 337/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.2153 - val_categorical_accuracy: 0.1036\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.2467 - val_categorical_accuracy: 0.1036\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 13.8252 - val_categorical_accuracy: 0.0102\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 18.1518 - val_categorical_accuracy: 0.1644\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 20.0901 - val_categorical_accuracy: 0.1644\n",
      "Epoch 342/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 13.7279 - val_categorical_accuracy: 0.0416\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.6452 - val_categorical_accuracy: 0.1644\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.1970 - val_categorical_accuracy: 0.1644\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.2879 - val_categorical_accuracy: 0.1644\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.0497 - val_categorical_accuracy: 0.0998\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.3665 - val_categorical_accuracy: 0.0998\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 43.4277 - val_categorical_accuracy: 0.0134\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 22.3113 - val_categorical_accuracy: 0.0934\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.3890 - val_categorical_accuracy: 0.0134\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2914 - val_categorical_accuracy: 0.0934\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.3604 - val_categorical_accuracy: 0.0934\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 33.3952 - val_categorical_accuracy: 0.0134\n",
      "Epoch 354/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 32.8798 - val_categorical_accuracy: 0.0102\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 13.6706 - val_categorical_accuracy: 0.1036\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.9602 - val_categorical_accuracy: 0.1644\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.2226 - val_categorical_accuracy: 0.1644\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.3009 - val_categorical_accuracy: 0.1036\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 12.1517 - val_categorical_accuracy: 0.1644\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.2501 - val_categorical_accuracy: 0.1644\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 20.2594 - val_categorical_accuracy: 0.1644\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 13.0111 - val_categorical_accuracy: 0.1036\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 18.0179 - val_categorical_accuracy: 0.1644\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 26.6427 - val_categorical_accuracy: 0.1036\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 13.5356 - val_categorical_accuracy: 0.1644\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 21.5827 - val_categorical_accuracy: 0.1036\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 18.8801 - val_categorical_accuracy: 0.1644\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.3535 - val_categorical_accuracy: 0.0934\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 42.4946 - val_categorical_accuracy: 0.0134\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 42.5018 - val_categorical_accuracy: 0.0134\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 22.2940 - val_categorical_accuracy: 0.0934\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.8193 - val_categorical_accuracy: 0.1036\n",
      "Epoch 373/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.2175 - val_categorical_accuracy: 0.0934\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2014 - val_categorical_accuracy: 0.0934\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 28.4280 - val_categorical_accuracy: 0.0934\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 24.0869 - val_categorical_accuracy: 0.0934\n",
      "Epoch 377/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.0009 - val_categorical_accuracy: 0.0998\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.4445 - val_categorical_accuracy: 0.0998\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.4097 - val_categorical_accuracy: 0.0998\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2092 - val_categorical_accuracy: 0.0934\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.7132 - val_categorical_accuracy: 0.1036\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2188 - val_categorical_accuracy: 0.0934\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 26.1092 - val_categorical_accuracy: 0.0134\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.5860 - val_categorical_accuracy: 0.0467\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 23.8938 - val_categorical_accuracy: 0.0134\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 42.8723 - val_categorical_accuracy: 0.0134\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 18.0334 - val_categorical_accuracy: 0.1356\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 47.6850 - val_categorical_accuracy: 0.0102\n",
      "Epoch 389/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 36.1121 - val_categorical_accuracy: 0.0134\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1497 - val_categorical_accuracy: 0.0934\n",
      "Epoch 391/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 29.0375 - val_categorical_accuracy: 0.0102\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.9010 - val_categorical_accuracy: 0.0102\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2103 - val_categorical_accuracy: 0.0934\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2133 - val_categorical_accuracy: 0.0934\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2870 - val_categorical_accuracy: 0.0934\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 39.5900 - val_categorical_accuracy: 0.0134\n",
      "Epoch 397/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 24.2188 - val_categorical_accuracy: 0.0934\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.3756 - val_categorical_accuracy: 0.0934\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.1082 - val_categorical_accuracy: 0.1036\n",
      "Epoch 400/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 15.5131 - val_categorical_accuracy: 0.0416\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 18.4089 - val_categorical_accuracy: 0.1036\n",
      "Epoch 402/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.2225 - val_categorical_accuracy: 0.1644\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 16.7380 - val_categorical_accuracy: 0.0998\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 11.7499 - val_categorical_accuracy: 0.0416\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 24.5183 - val_categorical_accuracy: 0.1036\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 28.6873 - val_categorical_accuracy: 0.0934\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.8674 - val_categorical_accuracy: 0.0934\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 24.8426 - val_categorical_accuracy: 0.1036\n",
      "Epoch 409/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.7448 - val_categorical_accuracy: 0.0416\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.0362 - val_categorical_accuracy: 0.1036\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 25.2778 - val_categorical_accuracy: 0.1036\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 21.7864 - val_categorical_accuracy: 0.1036\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.9252 - val_categorical_accuracy: 0.1036\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 16.5634 - val_categorical_accuracy: 0.0998\n",
      "Epoch 415/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 21.0797 - val_categorical_accuracy: 0.0128\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.8321 - val_categorical_accuracy: 0.0467\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 21.2070 - val_categorical_accuracy: 0.0128\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.7953 - val_categorical_accuracy: 0.1036\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.3484 - val_categorical_accuracy: 0.0998\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.3667 - val_categorical_accuracy: 0.0998\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 33.7012 - val_categorical_accuracy: 0.0134\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.9838 - val_categorical_accuracy: 0.1036\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 15.8428 - val_categorical_accuracy: 0.1644\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2685 - val_categorical_accuracy: 0.0934\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 22.2195 - val_categorical_accuracy: 0.0934\n",
      "Epoch 426/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1706 - val_categorical_accuracy: 0.0934\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2569 - val_categorical_accuracy: 0.0934\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1879 - val_categorical_accuracy: 0.0934\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1777 - val_categorical_accuracy: 0.0934\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1856 - val_categorical_accuracy: 0.0934\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.6256 - val_categorical_accuracy: 0.0934\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 22.1885 - val_categorical_accuracy: 0.0934\n",
      "Epoch 433/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 35.9709 - val_categorical_accuracy: 0.0134\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.5133 - val_categorical_accuracy: 0.0998\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 23.8992 - val_categorical_accuracy: 0.0934\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.0468 - val_categorical_accuracy: 0.1036\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.0912 - val_categorical_accuracy: 0.1036\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.9926 - val_categorical_accuracy: 0.1036\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1713 - val_categorical_accuracy: 0.0934\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1800 - val_categorical_accuracy: 0.0934\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1264 - val_categorical_accuracy: 0.0934\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.6424 - val_categorical_accuracy: 0.0134\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.5051 - val_categorical_accuracy: 0.0736\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.3819 - val_categorical_accuracy: 0.0998\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.5277 - val_categorical_accuracy: 0.0102\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.6463 - val_categorical_accuracy: 0.0102\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 48.6186 - val_categorical_accuracy: 0.0102\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.7321 - val_categorical_accuracy: 0.0934\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.3119 - val_categorical_accuracy: 0.0934\n",
      "Epoch 450/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 17.6456 - val_categorical_accuracy: 0.0998\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 23.0161 - val_categorical_accuracy: 0.0128\n",
      "Epoch 452/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.0828 - val_categorical_accuracy: 0.0467\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.7307 - val_categorical_accuracy: 0.1644\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 20.0220 - val_categorical_accuracy: 0.1644\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.9040 - val_categorical_accuracy: 0.0102\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 25.1112 - val_categorical_accuracy: 0.1356\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.5263 - val_categorical_accuracy: 0.0998\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.6431 - val_categorical_accuracy: 0.0998\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.6327 - val_categorical_accuracy: 0.0998\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 18.9324 - val_categorical_accuracy: 0.0998\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.5588 - val_categorical_accuracy: 0.0998\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 43.4384 - val_categorical_accuracy: 0.0134\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 38.8224 - val_categorical_accuracy: 0.0134\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 41.3960 - val_categorical_accuracy: 0.0134\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 32.3844 - val_categorical_accuracy: 0.0134\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 24.3983 - val_categorical_accuracy: 0.1036\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.9116 - val_categorical_accuracy: 0.1036\n",
      "Epoch 468/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.7252 - val_categorical_accuracy: 0.0998\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.1287 - val_categorical_accuracy: 0.0934\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 12.4661 - val_categorical_accuracy: 0.0934\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 13.4055 - val_categorical_accuracy: 0.0934\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.5766 - val_categorical_accuracy: 0.0998\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 11.2543 - val_categorical_accuracy: 0.0467\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 24.5391 - val_categorical_accuracy: 0.0934\n",
      "Epoch 475/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.1057 - val_categorical_accuracy: 0.0934\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 41.2554 - val_categorical_accuracy: 0.0134\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2991 - val_categorical_accuracy: 0.0934\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 22.3141 - val_categorical_accuracy: 0.0934\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.3133 - val_categorical_accuracy: 0.0934\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2815 - val_categorical_accuracy: 0.0934\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.5302 - val_categorical_accuracy: 0.0134\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 22.2963 - val_categorical_accuracy: 0.0934\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.3331 - val_categorical_accuracy: 0.1644\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 21.2625 - val_categorical_accuracy: 0.1036\n",
      "Epoch 485/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 26.2109 - val_categorical_accuracy: 0.0102\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.5979 - val_categorical_accuracy: 0.0102\n",
      "Epoch 487/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.6514 - val_categorical_accuracy: 0.1644\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.8103 - val_categorical_accuracy: 0.1644\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.7355 - val_categorical_accuracy: 0.1644\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 20.1043 - val_categorical_accuracy: 0.1644\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.6859 - val_categorical_accuracy: 0.0998\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.6397 - val_categorical_accuracy: 0.0998\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.6590 - val_categorical_accuracy: 0.0998\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.7074 - val_categorical_accuracy: 0.0998\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.2737 - val_categorical_accuracy: 0.1644\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.8485 - val_categorical_accuracy: 0.1644\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.3353 - val_categorical_accuracy: 0.1036\n",
      "Epoch 498/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 10.4329 - val_categorical_accuracy: 0.1644\n",
      "Epoch 499/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 19.0818 - val_categorical_accuracy: 0.1036\n",
      "Epoch 500/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 24.5902 - val_categorical_accuracy: 0.0134\n",
      "Finished.\n",
      "Training Tanh Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "49/49 [==============================] - 4s 63ms/step - loss: 2.7635 - categorical_accuracy: 0.1290 - val_loss: 2.7371 - val_categorical_accuracy: 0.0736\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 3s 71ms/step - loss: 2.7265 - categorical_accuracy: 0.1352 - val_loss: 2.7150 - val_categorical_accuracy: 0.0736\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 3s 58ms/step - loss: 2.6869 - categorical_accuracy: 0.1352 - val_loss: 2.7050 - val_categorical_accuracy: 0.0736\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.6408 - categorical_accuracy: 0.1352 - val_loss: 2.7914 - val_categorical_accuracy: 0.0998\n",
      "Epoch 5/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5972 - categorical_accuracy: 0.1352 - val_loss: 3.0165 - val_categorical_accuracy: 0.0998\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5652 - categorical_accuracy: 0.1474 - val_loss: 3.3687 - val_categorical_accuracy: 0.0998\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5462 - categorical_accuracy: 0.1641 - val_loss: 3.8432 - val_categorical_accuracy: 0.0998\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5363 - categorical_accuracy: 0.1641 - val_loss: 4.4501 - val_categorical_accuracy: 0.0998\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5313 - categorical_accuracy: 0.1641 - val_loss: 5.2468 - val_categorical_accuracy: 0.0998\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5287 - categorical_accuracy: 0.1641 - val_loss: 6.2404 - val_categorical_accuracy: 0.0998\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5272 - categorical_accuracy: 0.1641 - val_loss: 7.4163 - val_categorical_accuracy: 0.0934\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5263 - categorical_accuracy: 0.1641 - val_loss: 8.7447 - val_categorical_accuracy: 0.0934\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5257 - categorical_accuracy: 0.1641 - val_loss: 31.5944 - val_categorical_accuracy: 0.0102\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5252 - categorical_accuracy: 0.1641 - val_loss: 21.2708 - val_categorical_accuracy: 0.0467\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5249 - categorical_accuracy: 0.1641 - val_loss: 27.5526 - val_categorical_accuracy: 0.0467\n",
      "Epoch 16/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5247 - categorical_accuracy: 0.1641 - val_loss: 39.8124 - val_categorical_accuracy: 0.0128\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5245 - categorical_accuracy: 0.1641 - val_loss: 44.4730 - val_categorical_accuracy: 0.0128\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5245 - categorical_accuracy: 0.1641 - val_loss: 15.0338 - val_categorical_accuracy: 0.0934\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5244 - categorical_accuracy: 0.1641 - val_loss: 15.4134 - val_categorical_accuracy: 0.0934\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5243 - categorical_accuracy: 0.1641 - val_loss: 77.5385 - val_categorical_accuracy: 0.0128\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5243 - categorical_accuracy: 0.1641 - val_loss: 78.3780 - val_categorical_accuracy: 0.0128\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 44.4848 - val_categorical_accuracy: 0.1036\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 74.4410 - val_categorical_accuracy: 0.0102\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 74.7561 - val_categorical_accuracy: 0.0102\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5243 - categorical_accuracy: 0.1641 - val_loss: 30.4348 - val_categorical_accuracy: 0.0665\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 95.7721 - val_categorical_accuracy: 0.0102\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 18.7296 - val_categorical_accuracy: 0.0102\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.9490 - val_categorical_accuracy: 0.1036\n",
      "Epoch 29/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.3315 - val_categorical_accuracy: 0.0998\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 45.7099 - val_categorical_accuracy: 0.1644\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 75.7494 - val_categorical_accuracy: 0.0102\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 57.6479 - val_categorical_accuracy: 0.0102\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.9796 - val_categorical_accuracy: 0.0934\n",
      "Epoch 34/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 96.7823 - val_categorical_accuracy: 0.0128\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 55.6583 - val_categorical_accuracy: 0.0134\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.1028 - val_categorical_accuracy: 0.1036\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 53.5700 - val_categorical_accuracy: 0.0134\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 36.1034 - val_categorical_accuracy: 0.0467\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 36.0658 - val_categorical_accuracy: 0.0467\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 36.0796 - val_categorical_accuracy: 0.1644\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.0263 - val_categorical_accuracy: 0.0934\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 16.0112 - val_categorical_accuracy: 0.0934\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 57.8813 - val_categorical_accuracy: 0.0102\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.8749 - val_categorical_accuracy: 0.0102\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 91.5965 - val_categorical_accuracy: 0.0102\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 75.9906 - val_categorical_accuracy: 0.0102\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 57.9768 - val_categorical_accuracy: 0.0102\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.9955 - val_categorical_accuracy: 0.0102\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 126.6618 - val_categorical_accuracy: 0.0128\n",
      "Epoch 50/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 41.0451 - val_categorical_accuracy: 0.0736\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 44.2889 - val_categorical_accuracy: 0.0128\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 76.2008 - val_categorical_accuracy: 0.0102\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 36.0640 - val_categorical_accuracy: 0.0998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.2854 - val_categorical_accuracy: 0.0128\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.8484 - val_categorical_accuracy: 0.1036\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 44.8695 - val_categorical_accuracy: 0.1036\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.8569 - val_categorical_accuracy: 0.1036\n",
      "Epoch 58/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.8244 - val_categorical_accuracy: 0.1036\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 88.8367 - val_categorical_accuracy: 0.0102\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 95.2429 - val_categorical_accuracy: 0.0102\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 60.8174 - val_categorical_accuracy: 0.0134\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.7672 - val_categorical_accuracy: 0.0134\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.0651 - val_categorical_accuracy: 0.1036\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 39.3483 - val_categorical_accuracy: 0.0358\n",
      "Epoch 65/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 58.0426 - val_categorical_accuracy: 0.0102\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.9900 - val_categorical_accuracy: 0.0934\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 35.9848 - val_categorical_accuracy: 0.0998\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 23.8966 - val_categorical_accuracy: 0.0998\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 57.3602 - val_categorical_accuracy: 0.0102\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.4767 - val_categorical_accuracy: 0.0665\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 56.0953 - val_categorical_accuracy: 0.0134\n",
      "Epoch 72/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 53.3479 - val_categorical_accuracy: 0.1644\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 56.1654 - val_categorical_accuracy: 0.0134\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 32.3760 - val_categorical_accuracy: 0.1036\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.4386 - val_categorical_accuracy: 0.0665\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 76.2011 - val_categorical_accuracy: 0.0102\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 98.4642 - val_categorical_accuracy: 0.0102\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 46.4876 - val_categorical_accuracy: 0.1036\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.6231 - val_categorical_accuracy: 0.0665\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.6540 - val_categorical_accuracy: 0.0665\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 61.4566 - val_categorical_accuracy: 0.0134\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 120.5051 - val_categorical_accuracy: 0.0134\n",
      "Epoch 83/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.8037 - val_categorical_accuracy: 0.0128\n",
      "Epoch 84/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 43.9709 - val_categorical_accuracy: 0.0102\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 47.8303 - val_categorical_accuracy: 0.0128\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.8673 - val_categorical_accuracy: 0.0934\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.8551 - val_categorical_accuracy: 0.0934\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.8114 - val_categorical_accuracy: 0.0934\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 76.1660 - val_categorical_accuracy: 0.0102\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 90.8381 - val_categorical_accuracy: 0.0102\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 76.1803 - val_categorical_accuracy: 0.0102\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.9497 - val_categorical_accuracy: 0.0102\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 35.7346 - val_categorical_accuracy: 0.1356\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 42.0449 - val_categorical_accuracy: 0.0102\n",
      "Epoch 95/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 63.8823 - val_categorical_accuracy: 0.0134\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 35.9076 - val_categorical_accuracy: 0.0467\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 35.7260 - val_categorical_accuracy: 0.1356\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.8733 - val_categorical_accuracy: 0.1036\n",
      "Epoch 99/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 44.8173 - val_categorical_accuracy: 0.1036\n",
      "Epoch 100/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.7925 - val_categorical_accuracy: 0.1036\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.5298 - val_categorical_accuracy: 0.1036\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 61.2522 - val_categorical_accuracy: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 120.3805 - val_categorical_accuracy: 0.0134\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 127.4785 - val_categorical_accuracy: 0.0128\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.1916 - val_categorical_accuracy: 0.0134\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.4706 - val_categorical_accuracy: 0.0665\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.4138 - val_categorical_accuracy: 0.1036\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 81.8713 - val_categorical_accuracy: 0.0102\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 81.8483 - val_categorical_accuracy: 0.0102\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.0800 - val_categorical_accuracy: 0.0134\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.2005 - val_categorical_accuracy: 0.0134\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.1176 - val_categorical_accuracy: 0.0134\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 17.1421 - val_categorical_accuracy: 0.0134\n",
      "Epoch 114/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.1120 - val_categorical_accuracy: 0.0134\n",
      "Epoch 115/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 32.2893 - val_categorical_accuracy: 0.0467\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 35.8569 - val_categorical_accuracy: 0.0467\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 56.2647 - val_categorical_accuracy: 0.0134\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 99.9737 - val_categorical_accuracy: 0.0134\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 61.2278 - val_categorical_accuracy: 0.0134\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 61.2070 - val_categorical_accuracy: 0.0134\n",
      "Epoch 121/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 61.2087 - val_categorical_accuracy: 0.0134\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 52.9054 - val_categorical_accuracy: 0.1644\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 45.1768 - val_categorical_accuracy: 0.0128\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 35.8942 - val_categorical_accuracy: 0.0467\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 26.3849 - val_categorical_accuracy: 0.1644\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 35.8884 - val_categorical_accuracy: 0.0467\n",
      "Epoch 127/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 34.8450 - val_categorical_accuracy: 0.0467\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.9809 - val_categorical_accuracy: 0.0934\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 120.6244 - val_categorical_accuracy: 0.0134\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.4650 - val_categorical_accuracy: 0.0665\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 35.5200 - val_categorical_accuracy: 0.0998\n",
      "Epoch 132/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.9060 - val_categorical_accuracy: 0.0934\n",
      "Epoch 133/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.9476 - val_categorical_accuracy: 0.0934\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 33.9968 - val_categorical_accuracy: 0.0998\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 13.9704 - val_categorical_accuracy: 0.0934\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.6071 - val_categorical_accuracy: 0.1644\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 46.3536 - val_categorical_accuracy: 0.1644\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.5690 - val_categorical_accuracy: 0.0998\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 35.8578 - val_categorical_accuracy: 0.0467\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.4322 - val_categorical_accuracy: 0.1036\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.4224 - val_categorical_accuracy: 0.1644\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 47.3467 - val_categorical_accuracy: 0.1644\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.6695 - val_categorical_accuracy: 0.1644\n",
      "Epoch 144/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.6865 - val_categorical_accuracy: 0.0102\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.5164 - val_categorical_accuracy: 0.0665\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.6716 - val_categorical_accuracy: 0.1644\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.5795 - val_categorical_accuracy: 0.0665\n",
      "Epoch 148/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 35.6872 - val_categorical_accuracy: 0.0467\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.3005 - val_categorical_accuracy: 0.0128\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.2320 - val_categorical_accuracy: 0.0128\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 57.3455 - val_categorical_accuracy: 0.0102\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 91.7817 - val_categorical_accuracy: 0.0102\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 91.7261 - val_categorical_accuracy: 0.0102\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 75.3524 - val_categorical_accuracy: 0.0102\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.7260 - val_categorical_accuracy: 0.1036\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.8764 - val_categorical_accuracy: 0.0665\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 28.1515 - val_categorical_accuracy: 0.0665\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.8671 - val_categorical_accuracy: 0.0134\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.0972 - val_categorical_accuracy: 0.1036\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.7057 - val_categorical_accuracy: 0.0934\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.1438 - val_categorical_accuracy: 0.1036\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.7030 - val_categorical_accuracy: 0.0934\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 40.4972 - val_categorical_accuracy: 0.0102\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 56.7916 - val_categorical_accuracy: 0.0102\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.7092 - val_categorical_accuracy: 0.0665\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 98.8013 - val_categorical_accuracy: 0.0102\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.6652 - val_categorical_accuracy: 0.0102\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.1601 - val_categorical_accuracy: 0.0134\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.6977 - val_categorical_accuracy: 0.0934\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 96.3362 - val_categorical_accuracy: 0.0128\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 80.6096 - val_categorical_accuracy: 0.0102\n",
      "Epoch 172/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 74.7420 - val_categorical_accuracy: 0.0102\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 74.7334 - val_categorical_accuracy: 0.0102\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 42.3561 - val_categorical_accuracy: 0.1036\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.4082 - val_categorical_accuracy: 0.1036\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 39.9256 - val_categorical_accuracy: 0.0102\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 79.8464 - val_categorical_accuracy: 0.0102\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 54.3602 - val_categorical_accuracy: 0.1644\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 35.4785 - val_categorical_accuracy: 0.0467\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 44.5791 - val_categorical_accuracy: 0.1644\n",
      "Epoch 181/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 52.4988 - val_categorical_accuracy: 0.1644\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 35.2355 - val_categorical_accuracy: 0.0467\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.3886 - val_categorical_accuracy: 0.1644\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.1262 - val_categorical_accuracy: 0.1036\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 15.8300 - val_categorical_accuracy: 0.0934\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 48.0034 - val_categorical_accuracy: 0.0128\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.1168 - val_categorical_accuracy: 0.1036\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 42.3784 - val_categorical_accuracy: 0.0128\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.6679 - val_categorical_accuracy: 0.1036\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 39.1563 - val_categorical_accuracy: 0.0102\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 74.0950 - val_categorical_accuracy: 0.0102\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.4251 - val_categorical_accuracy: 0.0134\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 42.5201 - val_categorical_accuracy: 0.0128\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 96.1376 - val_categorical_accuracy: 0.0128\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 88.0629 - val_categorical_accuracy: 0.0134\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.8706 - val_categorical_accuracy: 0.1644\n",
      "Epoch 197/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 98.4498 - val_categorical_accuracy: 0.0102\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.7617 - val_categorical_accuracy: 0.0134\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.6652 - val_categorical_accuracy: 0.0665\n",
      "Epoch 200/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 36.9038 - val_categorical_accuracy: 0.0128\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.8596 - val_categorical_accuracy: 0.0134\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.9530 - val_categorical_accuracy: 0.0134\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 43.8320 - val_categorical_accuracy: 0.0128\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.6413 - val_categorical_accuracy: 0.0665\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.6265 - val_categorical_accuracy: 0.0665\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 30.5774 - val_categorical_accuracy: 0.0665\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 46.5740 - val_categorical_accuracy: 0.1036\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.6039 - val_categorical_accuracy: 0.1036\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 74.7924 - val_categorical_accuracy: 0.0102\n",
      "Epoch 210/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.6858 - val_categorical_accuracy: 0.1036\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.7104 - val_categorical_accuracy: 0.0665\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.1886 - val_categorical_accuracy: 0.0134\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 15.7632 - val_categorical_accuracy: 0.0934\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.7638 - val_categorical_accuracy: 0.0128\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 35.0983 - val_categorical_accuracy: 0.0998\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 129.1001 - val_categorical_accuracy: 0.0128\n",
      "Epoch 217/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 100.5012 - val_categorical_accuracy: 0.0102\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.5094 - val_categorical_accuracy: 0.0998\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.6478 - val_categorical_accuracy: 0.1036\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 102.0227 - val_categorical_accuracy: 0.0134\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 56.7712 - val_categorical_accuracy: 0.0134\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.8055 - val_categorical_accuracy: 0.0134\n",
      "Epoch 223/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 61.6500 - val_categorical_accuracy: 0.0134\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 56.5834 - val_categorical_accuracy: 0.0134\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 49.1991 - val_categorical_accuracy: 0.0128\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.2286 - val_categorical_accuracy: 0.0128\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 56.2973 - val_categorical_accuracy: 0.0134\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.3839 - val_categorical_accuracy: 0.0134\n",
      "Epoch 229/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.4670 - val_categorical_accuracy: 0.0998\n",
      "Epoch 230/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.3371 - val_categorical_accuracy: 0.0128\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 81.8477 - val_categorical_accuracy: 0.0102\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.3464 - val_categorical_accuracy: 0.0665\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.2789 - val_categorical_accuracy: 0.0665\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 99.2106 - val_categorical_accuracy: 0.0102\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 56.3820 - val_categorical_accuracy: 0.0134\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.1887 - val_categorical_accuracy: 0.0665\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.1905 - val_categorical_accuracy: 0.0665\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 51.1128 - val_categorical_accuracy: 0.1644\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.6913 - val_categorical_accuracy: 0.1036\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.2789 - val_categorical_accuracy: 0.0665\n",
      "Epoch 241/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 46.9450 - val_categorical_accuracy: 0.1036\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.4928 - val_categorical_accuracy: 0.0998\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 34.0446 - val_categorical_accuracy: 0.0467\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 51.2977 - val_categorical_accuracy: 0.0128\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 51.5515 - val_categorical_accuracy: 0.0128\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 51.7505 - val_categorical_accuracy: 0.0128\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.1412 - val_categorical_accuracy: 0.0934\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 52.0108 - val_categorical_accuracy: 0.0128\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 52.0667 - val_categorical_accuracy: 0.0128\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.2188 - val_categorical_accuracy: 0.0998\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.2300 - val_categorical_accuracy: 0.0934\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.2867 - val_categorical_accuracy: 0.0998\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 16.4150 - val_categorical_accuracy: 0.0998\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 46.9945 - val_categorical_accuracy: 0.0128\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 47.0868 - val_categorical_accuracy: 0.0128\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.1531 - val_categorical_accuracy: 0.1036\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.6670 - val_categorical_accuracy: 0.1036\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.6744 - val_categorical_accuracy: 0.1644\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.8907 - val_categorical_accuracy: 0.1036\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 85.0913 - val_categorical_accuracy: 0.0102\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 44.2644 - val_categorical_accuracy: 0.1036\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.5342 - val_categorical_accuracy: 0.1036\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.4217 - val_categorical_accuracy: 0.1036\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 28.1779 - val_categorical_accuracy: 0.0998\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 99.3655 - val_categorical_accuracy: 0.0102\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 62.9725 - val_categorical_accuracy: 0.0134\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 46.6917 - val_categorical_accuracy: 0.0128\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.2971 - val_categorical_accuracy: 0.0128\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.2541 - val_categorical_accuracy: 0.0128\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 85.6736 - val_categorical_accuracy: 0.0102\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.3210 - val_categorical_accuracy: 0.0128\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 36.2740 - val_categorical_accuracy: 0.0467\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.7142 - val_categorical_accuracy: 0.0128\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 54.0085 - val_categorical_accuracy: 0.0128\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 53.8838 - val_categorical_accuracy: 0.0128\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 54.4849 - val_categorical_accuracy: 0.0128\n",
      "Epoch 277/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 36.5785 - val_categorical_accuracy: 0.0998\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.3196 - val_categorical_accuracy: 0.1036\n",
      "Epoch 279/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.5978 - val_categorical_accuracy: 0.0665\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 46.7346 - val_categorical_accuracy: 0.1036\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.6416 - val_categorical_accuracy: 0.1036\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 85.7704 - val_categorical_accuracy: 0.0102\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 48.6409 - val_categorical_accuracy: 0.1644\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 48.1594 - val_categorical_accuracy: 0.1644\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 47.3760 - val_categorical_accuracy: 0.1644\n",
      "Epoch 286/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 29.0149 - val_categorical_accuracy: 0.0665\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 117.2878 - val_categorical_accuracy: 0.0134\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 28.9644 - val_categorical_accuracy: 0.0665\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.1208 - val_categorical_accuracy: 0.0102\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.4733 - val_categorical_accuracy: 0.0128\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.5702 - val_categorical_accuracy: 0.0128\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 47.1541 - val_categorical_accuracy: 0.1036\n",
      "Epoch 293/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 49.0068 - val_categorical_accuracy: 0.0128\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 44.9146 - val_categorical_accuracy: 0.1036\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.0016 - val_categorical_accuracy: 0.0665\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.4159 - val_categorical_accuracy: 0.0134\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 54.1671 - val_categorical_accuracy: 0.0128\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.5439 - val_categorical_accuracy: 0.0128\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 36.9070 - val_categorical_accuracy: 0.0467\n",
      "Epoch 300/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.1431 - val_categorical_accuracy: 0.0128\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 94.2634 - val_categorical_accuracy: 0.0102\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 84.7091 - val_categorical_accuracy: 0.0128\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 18.2292 - val_categorical_accuracy: 0.0998\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.3901 - val_categorical_accuracy: 0.0102\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.0186 - val_categorical_accuracy: 0.0102\n",
      "Epoch 306/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 47.5109 - val_categorical_accuracy: 0.1644\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 51.6902 - val_categorical_accuracy: 0.0134\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.3970 - val_categorical_accuracy: 0.1036\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.9229 - val_categorical_accuracy: 0.0998\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 52.3308 - val_categorical_accuracy: 0.0128\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.8033 - val_categorical_accuracy: 0.0998\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 47.5749 - val_categorical_accuracy: 0.0128\n",
      "Epoch 313/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.0472 - val_categorical_accuracy: 0.0665\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 77.8818 - val_categorical_accuracy: 0.0102\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 55.3691 - val_categorical_accuracy: 0.0128\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.0538 - val_categorical_accuracy: 0.0128\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 55.6046 - val_categorical_accuracy: 0.0128\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 105.5588 - val_categorical_accuracy: 0.0128\n",
      "Epoch 319/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.8660 - val_categorical_accuracy: 0.0998\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.1603 - val_categorical_accuracy: 0.0128\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 88.4197 - val_categorical_accuracy: 0.0128\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 47.2820 - val_categorical_accuracy: 0.1644\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 74.4568 - val_categorical_accuracy: 0.0128\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 87.7406 - val_categorical_accuracy: 0.0128\n",
      "Epoch 325/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.2994 - val_categorical_accuracy: 0.0128\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.4823 - val_categorical_accuracy: 0.0128\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 37.5142 - val_categorical_accuracy: 0.0467\n",
      "Epoch 328/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.0517 - val_categorical_accuracy: 0.0134\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.1283 - val_categorical_accuracy: 0.0102\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 47.2589 - val_categorical_accuracy: 0.1036\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 38.8661 - val_categorical_accuracy: 0.0998\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.3851 - val_categorical_accuracy: 0.0665\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.4100 - val_categorical_accuracy: 0.0665\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.6267 - val_categorical_accuracy: 0.0665\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 60.6273 - val_categorical_accuracy: 0.0102\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.5328 - val_categorical_accuracy: 0.1644\n",
      "Epoch 337/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.9937 - val_categorical_accuracy: 0.0134\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.0404 - val_categorical_accuracy: 0.0134\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.8025 - val_categorical_accuracy: 0.1644\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.8242 - val_categorical_accuracy: 0.0224\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 96.7972 - val_categorical_accuracy: 0.0102\n",
      "Epoch 342/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.1946 - val_categorical_accuracy: 0.0128\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.7653 - val_categorical_accuracy: 0.0128\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 61.4759 - val_categorical_accuracy: 0.0102\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 29.6528 - val_categorical_accuracy: 0.1036\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 38.8710 - val_categorical_accuracy: 0.0998\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.2191 - val_categorical_accuracy: 0.0128\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.2954 - val_categorical_accuracy: 0.0128\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 18.9213 - val_categorical_accuracy: 0.0998\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.4122 - val_categorical_accuracy: 0.0102\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.4284 - val_categorical_accuracy: 0.0102\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 18.8351 - val_categorical_accuracy: 0.0998\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.2822 - val_categorical_accuracy: 0.0128\n",
      "Epoch 354/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 58.4921 - val_categorical_accuracy: 0.0128\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.5013 - val_categorical_accuracy: 0.0128\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.6448 - val_categorical_accuracy: 0.0128\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 61.1445 - val_categorical_accuracy: 0.0102\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.1032 - val_categorical_accuracy: 0.0128\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 59.4369 - val_categorical_accuracy: 0.0128\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.2710 - val_categorical_accuracy: 0.0128\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.8952 - val_categorical_accuracy: 0.0128\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.8514 - val_categorical_accuracy: 0.0128\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.5136 - val_categorical_accuracy: 0.0128\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 103.1341 - val_categorical_accuracy: 0.0102\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 64.0078 - val_categorical_accuracy: 0.0134\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 63.8567 - val_categorical_accuracy: 0.0134\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 64.0959 - val_categorical_accuracy: 0.0134\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 64.2352 - val_categorical_accuracy: 0.0134\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 64.3547 - val_categorical_accuracy: 0.0134\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.2639 - val_categorical_accuracy: 0.1036\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 88.3296 - val_categorical_accuracy: 0.0128\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 28.5815 - val_categorical_accuracy: 0.1036\n",
      "Epoch 373/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 28.3547 - val_categorical_accuracy: 0.1036\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 42.2315 - val_categorical_accuracy: 0.0128\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 64.4095 - val_categorical_accuracy: 0.0134\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 87.3477 - val_categorical_accuracy: 0.0128\n",
      "Epoch 377/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 64.7342 - val_categorical_accuracy: 0.0134\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 101.9605 - val_categorical_accuracy: 0.0102\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 64.7894 - val_categorical_accuracy: 0.0134\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.5543 - val_categorical_accuracy: 0.0134\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 59.6122 - val_categorical_accuracy: 0.0134\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 102.6335 - val_categorical_accuracy: 0.0102\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 102.3718 - val_categorical_accuracy: 0.0102\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 64.0631 - val_categorical_accuracy: 0.0134\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 64.1658 - val_categorical_accuracy: 0.0134\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 24.5654 - val_categorical_accuracy: 0.0665\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.8696 - val_categorical_accuracy: 0.1036\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.8528 - val_categorical_accuracy: 0.1036\n",
      "Epoch 389/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 31.1845 - val_categorical_accuracy: 0.0998\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 31.4240 - val_categorical_accuracy: 0.0998\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.7911 - val_categorical_accuracy: 0.0665\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 42.4341 - val_categorical_accuracy: 0.1036\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.2463 - val_categorical_accuracy: 0.0128\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 40.0185 - val_categorical_accuracy: 0.0467\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.9694 - val_categorical_accuracy: 0.1036\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 40.5441 - val_categorical_accuracy: 0.0467\n",
      "Epoch 397/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 54.9244 - val_categorical_accuracy: 0.0128\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 54.5284 - val_categorical_accuracy: 0.0128\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 54.3973 - val_categorical_accuracy: 0.0128\n",
      "Epoch 400/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 65.2603 - val_categorical_accuracy: 0.0134\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 41.7549 - val_categorical_accuracy: 0.1036\n",
      "Epoch 402/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.0256 - val_categorical_accuracy: 0.0102\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 61.5011 - val_categorical_accuracy: 0.0128\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 61.9225 - val_categorical_accuracy: 0.0128\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 79.3375 - val_categorical_accuracy: 0.0102\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.8939 - val_categorical_accuracy: 0.0665\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.9207 - val_categorical_accuracy: 0.0665\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 42.7831 - val_categorical_accuracy: 0.1644\n",
      "Epoch 409/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.5265 - val_categorical_accuracy: 0.0665\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.3901 - val_categorical_accuracy: 0.0665\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 66.3128 - val_categorical_accuracy: 0.0134\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 46.1782 - val_categorical_accuracy: 0.0224\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 63.1077 - val_categorical_accuracy: 0.0134\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 68.5745 - val_categorical_accuracy: 0.0134\n",
      "Epoch 415/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.9783 - val_categorical_accuracy: 0.1036\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 26.5968 - val_categorical_accuracy: 0.1036\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 62.2763 - val_categorical_accuracy: 0.0128\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 143.2696 - val_categorical_accuracy: 0.0128\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 43.7951 - val_categorical_accuracy: 0.0134\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 137.8856 - val_categorical_accuracy: 0.0128\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.6670 - val_categorical_accuracy: 0.0665\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 68.7366 - val_categorical_accuracy: 0.0134\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 69.0415 - val_categorical_accuracy: 0.0134\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 69.1700 - val_categorical_accuracy: 0.0134\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 28.1056 - val_categorical_accuracy: 0.0665\n",
      "Epoch 426/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 21.4221 - val_categorical_accuracy: 0.0134\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 109.5927 - val_categorical_accuracy: 0.0128\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 76.1996 - val_categorical_accuracy: 0.0102\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 92.4680 - val_categorical_accuracy: 0.0128\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 92.6830 - val_categorical_accuracy: 0.0128\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 57.2874 - val_categorical_accuracy: 0.0102\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 64.5228 - val_categorical_accuracy: 0.0134\n",
      "Epoch 433/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 28.7297 - val_categorical_accuracy: 0.0665\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 28.7304 - val_categorical_accuracy: 0.0665\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 64.3381 - val_categorical_accuracy: 0.0134\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 28.9253 - val_categorical_accuracy: 0.0665\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 69.5167 - val_categorical_accuracy: 0.0134\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 94.8812 - val_categorical_accuracy: 0.0102\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 91.1019 - val_categorical_accuracy: 0.0128\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 91.0060 - val_categorical_accuracy: 0.0128\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 58.5464 - val_categorical_accuracy: 0.0128\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 58.6807 - val_categorical_accuracy: 0.0128\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.0578 - val_categorical_accuracy: 0.0128\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.2849 - val_categorical_accuracy: 0.0128\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.7192 - val_categorical_accuracy: 0.1036\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.8102 - val_categorical_accuracy: 0.0665\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.7273 - val_categorical_accuracy: 0.0665\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 30.8280 - val_categorical_accuracy: 0.0224\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 71.4882 - val_categorical_accuracy: 0.0134\n",
      "Epoch 450/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 71.4128 - val_categorical_accuracy: 0.0134\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 71.3485 - val_categorical_accuracy: 0.0134\n",
      "Epoch 452/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 17.1841 - val_categorical_accuracy: 0.0998\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 93.3168 - val_categorical_accuracy: 0.0128\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 46.5632 - val_categorical_accuracy: 0.1644\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 27.0719 - val_categorical_accuracy: 0.0102\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 92.3523 - val_categorical_accuracy: 0.0128\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 91.9638 - val_categorical_accuracy: 0.0128\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 92.0270 - val_categorical_accuracy: 0.0128\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.7607 - val_categorical_accuracy: 0.0128\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 60.8621 - val_categorical_accuracy: 0.0134\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 29.9319 - val_categorical_accuracy: 0.0665\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 69.6854 - val_categorical_accuracy: 0.0134\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 98.3154 - val_categorical_accuracy: 0.0102\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 92.1005 - val_categorical_accuracy: 0.0128\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 91.5391 - val_categorical_accuracy: 0.0128\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 40.8946 - val_categorical_accuracy: 0.0134\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.2492 - val_categorical_accuracy: 0.0665\n",
      "Epoch 468/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 48.4620 - val_categorical_accuracy: 0.1036\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 47.9344 - val_categorical_accuracy: 0.1644\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.1821 - val_categorical_accuracy: 0.1036\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 103.1273 - val_categorical_accuracy: 0.0102\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 48.1032 - val_categorical_accuracy: 0.1036\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.5116 - val_categorical_accuracy: 0.0665\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.6065 - val_categorical_accuracy: 0.0665\n",
      "Epoch 475/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 85.6409 - val_categorical_accuracy: 0.0128\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 85.7360 - val_categorical_accuracy: 0.0128\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.6293 - val_categorical_accuracy: 0.0665\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 66.7274 - val_categorical_accuracy: 0.0134\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 28.2753 - val_categorical_accuracy: 0.1036\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.6055 - val_categorical_accuracy: 0.0128\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.6901 - val_categorical_accuracy: 0.0128\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 53.9725 - val_categorical_accuracy: 0.0128\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 87.1614 - val_categorical_accuracy: 0.0128\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 60.8490 - val_categorical_accuracy: 0.0102\n",
      "Epoch 485/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.3708 - val_categorical_accuracy: 0.0665\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.1076 - val_categorical_accuracy: 0.0665\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 29.7913 - val_categorical_accuracy: 0.0665\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 125.8533 - val_categorical_accuracy: 0.0134\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.5610 - val_categorical_accuracy: 0.0102\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 59.3708 - val_categorical_accuracy: 0.0102\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 59.8313 - val_categorical_accuracy: 0.0102\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 50.1134 - val_categorical_accuracy: 0.1644\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 56.8085 - val_categorical_accuracy: 0.0128\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 27.7737 - val_categorical_accuracy: 0.1036\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5240 - categorical_accuracy: 0.1641 - val_loss: 70.9361 - val_categorical_accuracy: 0.0134\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5242 - categorical_accuracy: 0.1641 - val_loss: 86.0797 - val_categorical_accuracy: 0.0102\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 88.2489 - val_categorical_accuracy: 0.0102\n",
      "Epoch 498/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 30.0711 - val_categorical_accuracy: 0.0665\n",
      "Epoch 499/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 55.8454 - val_categorical_accuracy: 0.0128\n",
      "Epoch 500/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5241 - categorical_accuracy: 0.1641 - val_loss: 55.0624 - val_categorical_accuracy: 0.0128\n",
      "Finished.\n",
      "Training Leaky ReLU Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "49/49 [==============================] - 5s 73ms/step - loss: 2.8985 - categorical_accuracy: 0.0786 - val_loss: 9.0904 - val_categorical_accuracy: 0.0358\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 2.4530 - categorical_accuracy: 0.2081 - val_loss: 6.7440 - val_categorical_accuracy: 0.0998\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 3s 67ms/step - loss: 2.1030 - categorical_accuracy: 0.3427 - val_loss: 4.9354 - val_categorical_accuracy: 0.1011\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.7575 - categorical_accuracy: 0.4709 - val_loss: 9.3290 - val_categorical_accuracy: 0.1663\n",
      "Epoch 5/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.4709 - categorical_accuracy: 0.5783 - val_loss: 8.8502 - val_categorical_accuracy: 0.1644\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.2233 - categorical_accuracy: 0.6961 - val_loss: 7.0310 - val_categorical_accuracy: 0.1663\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0244 - categorical_accuracy: 0.7414 - val_loss: 6.2523 - val_categorical_accuracy: 0.0358\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.8692 - categorical_accuracy: 0.7578 - val_loss: 4.5081 - val_categorical_accuracy: 0.1542\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.7517 - categorical_accuracy: 0.8036 - val_loss: 8.0433 - val_categorical_accuracy: 0.0377\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 3s 65ms/step - loss: 0.6583 - categorical_accuracy: 0.8446 - val_loss: 3.9152 - val_categorical_accuracy: 0.1433\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.5739 - categorical_accuracy: 0.8955 - val_loss: 3.0901 - val_categorical_accuracy: 0.1305\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.4999 - categorical_accuracy: 0.9219 - val_loss: 5.6184 - val_categorical_accuracy: 0.1759\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.4293 - categorical_accuracy: 0.9389 - val_loss: 4.1187 - val_categorical_accuracy: 0.1222\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.3595 - categorical_accuracy: 0.9518 - val_loss: 9.5733 - val_categorical_accuracy: 0.0339\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.3061 - categorical_accuracy: 0.9627 - val_loss: 6.1225 - val_categorical_accuracy: 0.0409\n",
      "Epoch 16/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2654 - categorical_accuracy: 0.9693 - val_loss: 4.9497 - val_categorical_accuracy: 0.1542\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2317 - categorical_accuracy: 0.9739 - val_loss: 11.5526 - val_categorical_accuracy: 0.0294\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2070 - categorical_accuracy: 0.9768 - val_loss: 4.5292 - val_categorical_accuracy: 0.1369\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1824 - categorical_accuracy: 0.9800 - val_loss: 19.6787 - val_categorical_accuracy: 0.0313\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1587 - categorical_accuracy: 0.9818 - val_loss: 4.6177 - val_categorical_accuracy: 0.1075\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1453 - categorical_accuracy: 0.9842 - val_loss: 11.0839 - val_categorical_accuracy: 0.0345\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.1311 - categorical_accuracy: 0.9856 - val_loss: 6.3143 - val_categorical_accuracy: 0.0441\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1189 - categorical_accuracy: 0.9864 - val_loss: 4.3650 - val_categorical_accuracy: 0.1344\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1067 - categorical_accuracy: 0.9875 - val_loss: 4.9208 - val_categorical_accuracy: 0.1164\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0976 - categorical_accuracy: 0.9882 - val_loss: 4.1990 - val_categorical_accuracy: 0.0467\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0878 - categorical_accuracy: 0.9885 - val_loss: 3.9600 - val_categorical_accuracy: 0.0710\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0807 - categorical_accuracy: 0.9890 - val_loss: 3.8802 - val_categorical_accuracy: 0.1433\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0741 - categorical_accuracy: 0.9890 - val_loss: 4.0570 - val_categorical_accuracy: 0.1107\n",
      "Epoch 29/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0703 - categorical_accuracy: 0.9886 - val_loss: 4.0632 - val_categorical_accuracy: 0.0768\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0641 - categorical_accuracy: 0.9890 - val_loss: 4.0064 - val_categorical_accuracy: 0.0665\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0600 - categorical_accuracy: 0.9886 - val_loss: 13.0489 - val_categorical_accuracy: 0.0345\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0572 - categorical_accuracy: 0.9891 - val_loss: 5.5013 - val_categorical_accuracy: 0.0889\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0525 - categorical_accuracy: 0.9890 - val_loss: 4.5714 - val_categorical_accuracy: 0.0499\n",
      "Epoch 34/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0494 - categorical_accuracy: 0.9894 - val_loss: 4.1578 - val_categorical_accuracy: 0.0870\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0452 - categorical_accuracy: 0.9898 - val_loss: 4.2314 - val_categorical_accuracy: 0.0665\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0419 - categorical_accuracy: 0.9918 - val_loss: 20.5998 - val_categorical_accuracy: 0.0333\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0393 - categorical_accuracy: 0.9918 - val_loss: 4.2216 - val_categorical_accuracy: 0.1209\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0368 - categorical_accuracy: 0.9939 - val_loss: 4.6055 - val_categorical_accuracy: 0.0288\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0350 - categorical_accuracy: 0.9954 - val_loss: 4.5735 - val_categorical_accuracy: 0.0569\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0301 - categorical_accuracy: 0.9966 - val_loss: 6.3639 - val_categorical_accuracy: 0.0819\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0317 - categorical_accuracy: 0.9968 - val_loss: 145.8336 - val_categorical_accuracy: 0.0339\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0380 - categorical_accuracy: 0.9958 - val_loss: 29.4532 - val_categorical_accuracy: 0.0441\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0378 - categorical_accuracy: 0.9950 - val_loss: 22.7988 - val_categorical_accuracy: 0.0441\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0332 - categorical_accuracy: 0.9968 - val_loss: 31.6114 - val_categorical_accuracy: 0.0339\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0287 - categorical_accuracy: 0.9974 - val_loss: 6.2274 - val_categorical_accuracy: 0.0928\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0262 - categorical_accuracy: 0.9986 - val_loss: 5.0525 - val_categorical_accuracy: 0.0832\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0248 - categorical_accuracy: 0.9984 - val_loss: 12.4707 - val_categorical_accuracy: 0.0339\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0209 - categorical_accuracy: 0.9986 - val_loss: 5.0119 - val_categorical_accuracy: 0.1427\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0191 - categorical_accuracy: 0.9990 - val_loss: 9.4424 - val_categorical_accuracy: 0.1587\n",
      "Epoch 50/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0189 - categorical_accuracy: 0.9992 - val_loss: 7.1029 - val_categorical_accuracy: 0.0377\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0148 - categorical_accuracy: 0.9997 - val_loss: 8.3408 - val_categorical_accuracy: 0.0448\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0129 - categorical_accuracy: 0.9997 - val_loss: 9.2217 - val_categorical_accuracy: 0.1196\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0114 - categorical_accuracy: 0.9997 - val_loss: 6.4079 - val_categorical_accuracy: 0.0896\n",
      "Epoch 54/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0111 - categorical_accuracy: 0.9997 - val_loss: 10.4537 - val_categorical_accuracy: 0.0473\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0095 - categorical_accuracy: 0.9998 - val_loss: 7.1186 - val_categorical_accuracy: 0.0761\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0090 - categorical_accuracy: 0.9997 - val_loss: 5.1046 - val_categorical_accuracy: 0.1062\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0082 - categorical_accuracy: 0.9998 - val_loss: 5.1057 - val_categorical_accuracy: 0.1337\n",
      "Epoch 58/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0085 - categorical_accuracy: 0.9997 - val_loss: 6.1366 - val_categorical_accuracy: 0.1504\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0078 - categorical_accuracy: 0.9997 - val_loss: 11.4773 - val_categorical_accuracy: 0.1088\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0076 - categorical_accuracy: 0.9995 - val_loss: 7.3623 - val_categorical_accuracy: 0.1216\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0082 - categorical_accuracy: 0.9995 - val_loss: 5.6787 - val_categorical_accuracy: 0.1318\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0070 - categorical_accuracy: 0.9997 - val_loss: 5.6308 - val_categorical_accuracy: 0.0928\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0064 - categorical_accuracy: 0.9995 - val_loss: 25.9752 - val_categorical_accuracy: 0.0736\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0086 - categorical_accuracy: 0.9998 - val_loss: 17.0434 - val_categorical_accuracy: 0.0729\n",
      "Epoch 65/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0140 - categorical_accuracy: 0.9979 - val_loss: 23.3536 - val_categorical_accuracy: 0.0333\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0203 - categorical_accuracy: 0.9970 - val_loss: 59.7982 - val_categorical_accuracy: 0.0333\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0514 - categorical_accuracy: 0.9907 - val_loss: 27.9912 - val_categorical_accuracy: 0.0333\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1027 - categorical_accuracy: 0.9752 - val_loss: 13.1469 - val_categorical_accuracy: 0.1644\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.2081 - categorical_accuracy: 0.9425 - val_loss: 89.6662 - val_categorical_accuracy: 0.0998\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2112 - categorical_accuracy: 0.9406 - val_loss: 261.5963 - val_categorical_accuracy: 0.0998\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1062 - categorical_accuracy: 0.9726 - val_loss: 169.0034 - val_categorical_accuracy: 0.1644\n",
      "Epoch 72/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0412 - categorical_accuracy: 0.9941 - val_loss: 87.7033 - val_categorical_accuracy: 0.1644\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0241 - categorical_accuracy: 0.9981 - val_loss: 46.7094 - val_categorical_accuracy: 0.1644\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0162 - categorical_accuracy: 0.9994 - val_loss: 37.2553 - val_categorical_accuracy: 0.1670\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0128 - categorical_accuracy: 0.9997 - val_loss: 23.3588 - val_categorical_accuracy: 0.1734\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0107 - categorical_accuracy: 0.9998 - val_loss: 18.8489 - val_categorical_accuracy: 0.1708\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0095 - categorical_accuracy: 0.9997 - val_loss: 10.9749 - val_categorical_accuracy: 0.1472\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0087 - categorical_accuracy: 0.9997 - val_loss: 12.1272 - val_categorical_accuracy: 0.1772\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0081 - categorical_accuracy: 0.9998 - val_loss: 8.5770 - val_categorical_accuracy: 0.1561\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0072 - categorical_accuracy: 0.9997 - val_loss: 10.9516 - val_categorical_accuracy: 0.1695\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0064 - categorical_accuracy: 1.0000 - val_loss: 10.3151 - val_categorical_accuracy: 0.1625\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 8.5328 - val_categorical_accuracy: 0.1420\n",
      "Epoch 83/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0056 - categorical_accuracy: 0.9995 - val_loss: 4.7792 - val_categorical_accuracy: 0.1433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0049 - categorical_accuracy: 0.9998 - val_loss: 5.4876 - val_categorical_accuracy: 0.1280\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0050 - categorical_accuracy: 0.9997 - val_loss: 4.9793 - val_categorical_accuracy: 0.1305\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0047 - categorical_accuracy: 0.9997 - val_loss: 4.9753 - val_categorical_accuracy: 0.1299\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0045 - categorical_accuracy: 0.9997 - val_loss: 5.8832 - val_categorical_accuracy: 0.1235\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0043 - categorical_accuracy: 0.9997 - val_loss: 6.2569 - val_categorical_accuracy: 0.1516\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0038 - categorical_accuracy: 0.9998 - val_loss: 8.5408 - val_categorical_accuracy: 0.0448\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0041 - categorical_accuracy: 0.9997 - val_loss: 7.4226 - val_categorical_accuracy: 0.0685\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0037 - categorical_accuracy: 0.9997 - val_loss: 4.6023 - val_categorical_accuracy: 0.1651\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0037 - categorical_accuracy: 0.9997 - val_loss: 6.7954 - val_categorical_accuracy: 0.0857\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0035 - categorical_accuracy: 0.9997 - val_loss: 4.8418 - val_categorical_accuracy: 0.1248\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 7.7308 - val_categorical_accuracy: 0.0729\n",
      "Epoch 95/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0031 - categorical_accuracy: 0.9998 - val_loss: 4.6867 - val_categorical_accuracy: 0.1574\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0030 - categorical_accuracy: 0.9997 - val_loss: 5.2941 - val_categorical_accuracy: 0.1216\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0028 - categorical_accuracy: 0.9997 - val_loss: 4.8542 - val_categorical_accuracy: 0.1536\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0029 - categorical_accuracy: 0.9998 - val_loss: 5.4187 - val_categorical_accuracy: 0.1196\n",
      "Epoch 99/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 4.6729 - val_categorical_accuracy: 0.1593\n",
      "Epoch 100/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 5.4664 - val_categorical_accuracy: 0.1158\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0024 - categorical_accuracy: 0.9998 - val_loss: 5.4548 - val_categorical_accuracy: 0.1235\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0025 - categorical_accuracy: 0.9998 - val_loss: 6.6393 - val_categorical_accuracy: 0.1363\n",
      "Epoch 103/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 4.8018 - val_categorical_accuracy: 0.1350\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0023 - categorical_accuracy: 0.9998 - val_loss: 6.2592 - val_categorical_accuracy: 0.1190\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0024 - categorical_accuracy: 0.9997 - val_loss: 6.7062 - val_categorical_accuracy: 0.0921\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 4.7999 - val_categorical_accuracy: 0.1472\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 4.6915 - val_categorical_accuracy: 0.1420\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 4.8190 - val_categorical_accuracy: 0.1408\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 5.6577 - val_categorical_accuracy: 0.1126\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 8.5352 - val_categorical_accuracy: 0.0601\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 8.7580 - val_categorical_accuracy: 0.0614\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 5.8622 - val_categorical_accuracy: 0.1171\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9998 - val_loss: 6.4114 - val_categorical_accuracy: 0.0966\n",
      "Epoch 114/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 6.8067 - val_categorical_accuracy: 0.1068\n",
      "Epoch 115/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 8.3704 - val_categorical_accuracy: 0.0678\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 7.5824 - val_categorical_accuracy: 0.1094\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 8.2478 - val_categorical_accuracy: 0.0889\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 6.7011 - val_categorical_accuracy: 0.1075\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 6.9179 - val_categorical_accuracy: 0.1132\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 5.2102 - val_categorical_accuracy: 0.1363\n",
      "Epoch 121/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 7.4975 - val_categorical_accuracy: 0.1465\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9995 - val_loss: 10.5244 - val_categorical_accuracy: 0.0569\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 10.2303 - val_categorical_accuracy: 0.0685\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 9.4590 - val_categorical_accuracy: 0.0781\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0010 - categorical_accuracy: 1.0000 - val_loss: 8.6568 - val_categorical_accuracy: 0.0672\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 7.4990 - val_categorical_accuracy: 0.0877\n",
      "Epoch 127/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0010 - categorical_accuracy: 1.0000 - val_loss: 7.4720 - val_categorical_accuracy: 0.0787\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 9.0669 - val_categorical_accuracy: 0.0928\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 9.1680e-04 - categorical_accuracy: 1.0000 - val_loss: 6.0901 - val_categorical_accuracy: 0.1132\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 5.0482 - val_categorical_accuracy: 0.1427\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 9.9166 - val_categorical_accuracy: 0.0608\n",
      "Epoch 132/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.4123e-04 - categorical_accuracy: 1.0000 - val_loss: 7.8802 - val_categorical_accuracy: 0.0940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.2358e-04 - categorical_accuracy: 1.0000 - val_loss: 6.6787 - val_categorical_accuracy: 0.1158\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.8835e-04 - categorical_accuracy: 1.0000 - val_loss: 7.0073 - val_categorical_accuracy: 0.1004\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 6.5337 - val_categorical_accuracy: 0.1388\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 9.5003 - val_categorical_accuracy: 0.1216\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.3198e-04 - categorical_accuracy: 1.0000 - val_loss: 5.2946 - val_categorical_accuracy: 0.1446\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.7150e-04 - categorical_accuracy: 1.0000 - val_loss: 7.7482 - val_categorical_accuracy: 0.0883\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.5389e-04 - categorical_accuracy: 1.0000 - val_loss: 8.5387 - val_categorical_accuracy: 0.1011\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.0905e-04 - categorical_accuracy: 0.9998 - val_loss: 8.3298 - val_categorical_accuracy: 0.1107\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 6.0257 - val_categorical_accuracy: 0.1254\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.6998e-04 - categorical_accuracy: 1.0000 - val_loss: 5.7686 - val_categorical_accuracy: 0.1203\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.1440e-04 - categorical_accuracy: 0.9998 - val_loss: 7.7000 - val_categorical_accuracy: 0.0851\n",
      "Epoch 144/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.8117e-04 - categorical_accuracy: 0.9997 - val_loss: 7.6113 - val_categorical_accuracy: 0.1004\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.4622e-04 - categorical_accuracy: 1.0000 - val_loss: 6.2527 - val_categorical_accuracy: 0.1145\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.8376e-04 - categorical_accuracy: 1.0000 - val_loss: 9.0574 - val_categorical_accuracy: 0.0691\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.3518e-04 - categorical_accuracy: 0.9998 - val_loss: 10.1093 - val_categorical_accuracy: 0.0864\n",
      "Epoch 148/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.0525e-04 - categorical_accuracy: 0.9997 - val_loss: 9.2448 - val_categorical_accuracy: 0.0640\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.3657e-04 - categorical_accuracy: 0.9998 - val_loss: 7.5323 - val_categorical_accuracy: 0.1120\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.3449e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4380 - val_categorical_accuracy: 0.1420\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.4355e-04 - categorical_accuracy: 0.9998 - val_loss: 6.5845 - val_categorical_accuracy: 0.1017\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.9759e-04 - categorical_accuracy: 1.0000 - val_loss: 6.4206 - val_categorical_accuracy: 0.1260\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.2667e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7838 - val_categorical_accuracy: 0.1030\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.3967e-04 - categorical_accuracy: 1.0000 - val_loss: 6.2740 - val_categorical_accuracy: 0.1619\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 18.2807 - val_categorical_accuracy: 0.1459\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 9.5324 - val_categorical_accuracy: 0.0653\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.8302e-04 - categorical_accuracy: 1.0000 - val_loss: 7.8532 - val_categorical_accuracy: 0.1062\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 13.5909 - val_categorical_accuracy: 0.0531\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 14.2836 - val_categorical_accuracy: 0.1235\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0020 - categorical_accuracy: 0.9997 - val_loss: 8.7540 - val_categorical_accuracy: 0.1062\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0034 - categorical_accuracy: 0.9998 - val_loss: 20.8916 - val_categorical_accuracy: 0.0915\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0043 - categorical_accuracy: 0.9997 - val_loss: 15.3849 - val_categorical_accuracy: 0.0940\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0048 - categorical_accuracy: 0.9990 - val_loss: 14.8549 - val_categorical_accuracy: 0.1081\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0179 - categorical_accuracy: 0.9962 - val_loss: 23.1988 - val_categorical_accuracy: 0.0563\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1276 - categorical_accuracy: 0.9706 - val_loss: 30.0565 - val_categorical_accuracy: 0.0473\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.3180 - categorical_accuracy: 0.9211 - val_loss: 26.4183 - val_categorical_accuracy: 0.1651\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1425 - categorical_accuracy: 0.9565 - val_loss: 40.7681 - val_categorical_accuracy: 0.1651\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0370 - categorical_accuracy: 0.9917 - val_loss: 29.1323 - val_categorical_accuracy: 0.1651\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0162 - categorical_accuracy: 0.9978 - val_loss: 25.9476 - val_categorical_accuracy: 0.1651\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0114 - categorical_accuracy: 0.9984 - val_loss: 8.9355 - val_categorical_accuracy: 0.1523\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0067 - categorical_accuracy: 0.9997 - val_loss: 10.7090 - val_categorical_accuracy: 0.1836\n",
      "Epoch 172/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0059 - categorical_accuracy: 0.9997 - val_loss: 9.5663 - val_categorical_accuracy: 0.1907\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0056 - categorical_accuracy: 0.9995 - val_loss: 6.9128 - val_categorical_accuracy: 0.1619\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0053 - categorical_accuracy: 0.9995 - val_loss: 7.5017 - val_categorical_accuracy: 0.0979\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0047 - categorical_accuracy: 0.9992 - val_loss: 8.4222 - val_categorical_accuracy: 0.0781\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0037 - categorical_accuracy: 0.9998 - val_loss: 9.3991 - val_categorical_accuracy: 0.1113\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0036 - categorical_accuracy: 0.9997 - val_loss: 6.7631 - val_categorical_accuracy: 0.1126\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0031 - categorical_accuracy: 0.9997 - val_loss: 21.0463 - val_categorical_accuracy: 0.1657\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0032 - categorical_accuracy: 0.9997 - val_loss: 12.6399 - val_categorical_accuracy: 0.1779\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 13.2292 - val_categorical_accuracy: 0.1811\n",
      "Epoch 181/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0038 - categorical_accuracy: 0.9997 - val_loss: 9.6468 - val_categorical_accuracy: 0.1926\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0024 - categorical_accuracy: 0.9998 - val_loss: 8.6999 - val_categorical_accuracy: 0.1075\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0022 - categorical_accuracy: 0.9998 - val_loss: 8.5466 - val_categorical_accuracy: 0.0979\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9998 - val_loss: 6.5422 - val_categorical_accuracy: 0.1593\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 7.1848 - val_categorical_accuracy: 0.1184\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9998 - val_loss: 12.3881 - val_categorical_accuracy: 0.1024\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0022 - categorical_accuracy: 0.9997 - val_loss: 9.0323 - val_categorical_accuracy: 0.1203\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 0.9997 - val_loss: 10.4577 - val_categorical_accuracy: 0.1184\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0025 - categorical_accuracy: 0.9997 - val_loss: 9.6044 - val_categorical_accuracy: 0.1222\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0022 - categorical_accuracy: 0.9997 - val_loss: 13.0731 - val_categorical_accuracy: 0.1024\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 8.7467 - val_categorical_accuracy: 0.1830\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 9.5360 - val_categorical_accuracy: 0.1068\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 6.0528 - val_categorical_accuracy: 0.1324\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 10.3082 - val_categorical_accuracy: 0.0678\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 12.7867 - val_categorical_accuracy: 0.1081\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 9.4037 - val_categorical_accuracy: 0.1094\n",
      "Epoch 197/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 6.9627 - val_categorical_accuracy: 0.1299\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0022 - categorical_accuracy: 0.9997 - val_loss: 10.5395 - val_categorical_accuracy: 0.0953\n",
      "Epoch 199/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 11.9270 - val_categorical_accuracy: 0.1830\n",
      "Epoch 200/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 7.2949 - val_categorical_accuracy: 0.1267\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 9.7230 - val_categorical_accuracy: 0.1798\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.2511e-04 - categorical_accuracy: 1.0000 - val_loss: 7.7945 - val_categorical_accuracy: 0.1811\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.5285e-04 - categorical_accuracy: 1.0000 - val_loss: 6.5490 - val_categorical_accuracy: 0.1267\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 10.9374 - val_categorical_accuracy: 0.1887\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 14.0182 - val_categorical_accuracy: 0.1017\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 14.4595 - val_categorical_accuracy: 0.0992\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 13.6936 - val_categorical_accuracy: 0.0998\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 14.3664 - val_categorical_accuracy: 0.0998\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.2040e-04 - categorical_accuracy: 1.0000 - val_loss: 12.4668 - val_categorical_accuracy: 0.1075\n",
      "Epoch 210/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.7020e-04 - categorical_accuracy: 1.0000 - val_loss: 10.8273 - val_categorical_accuracy: 0.1177\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.5655e-04 - categorical_accuracy: 1.0000 - val_loss: 6.0678 - val_categorical_accuracy: 0.1356\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.7515e-04 - categorical_accuracy: 1.0000 - val_loss: 7.1665 - val_categorical_accuracy: 0.1164\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.5028e-04 - categorical_accuracy: 1.0000 - val_loss: 6.9079 - val_categorical_accuracy: 0.1107\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.9982e-04 - categorical_accuracy: 1.0000 - val_loss: 5.8571 - val_categorical_accuracy: 0.1504\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 6.0240e-04 - categorical_accuracy: 1.0000 - val_loss: 9.9143 - val_categorical_accuracy: 0.1209\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.0031e-04 - categorical_accuracy: 1.0000 - val_loss: 9.6303 - val_categorical_accuracy: 0.1817\n",
      "Epoch 217/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 13.0776 - val_categorical_accuracy: 0.0992\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.8978e-04 - categorical_accuracy: 1.0000 - val_loss: 9.9303 - val_categorical_accuracy: 0.1113\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.8850e-04 - categorical_accuracy: 0.9998 - val_loss: 6.4231 - val_categorical_accuracy: 0.1280\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.9169e-04 - categorical_accuracy: 0.9998 - val_loss: 6.5305 - val_categorical_accuracy: 0.1440\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 11.8821 - val_categorical_accuracy: 0.1631\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.7695e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7445 - val_categorical_accuracy: 0.1299\n",
      "Epoch 223/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.9485e-04 - categorical_accuracy: 0.9998 - val_loss: 6.6946 - val_categorical_accuracy: 0.1260\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.8058e-04 - categorical_accuracy: 0.9998 - val_loss: 5.8152 - val_categorical_accuracy: 0.1356\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.3460e-04 - categorical_accuracy: 1.0000 - val_loss: 6.0861 - val_categorical_accuracy: 0.1318\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.9539e-04 - categorical_accuracy: 0.9997 - val_loss: 7.2367 - val_categorical_accuracy: 0.1049\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.7527e-04 - categorical_accuracy: 1.0000 - val_loss: 12.2915 - val_categorical_accuracy: 0.1158\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 5.7050e-04 - categorical_accuracy: 0.9998 - val_loss: 12.0065 - val_categorical_accuracy: 0.1126\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 47ms/step - loss: 6.3842e-04 - categorical_accuracy: 0.9998 - val_loss: 7.3754 - val_categorical_accuracy: 0.1222\n",
      "Epoch 230/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 6.3059e-04 - categorical_accuracy: 0.9998 - val_loss: 8.8359 - val_categorical_accuracy: 0.1465\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 9.3605 - val_categorical_accuracy: 0.1152\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 6.3367e-04 - categorical_accuracy: 0.9998 - val_loss: 8.6738 - val_categorical_accuracy: 0.1158\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 5.1847e-04 - categorical_accuracy: 1.0000 - val_loss: 9.0192 - val_categorical_accuracy: 0.1299\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.3812e-04 - categorical_accuracy: 1.0000 - val_loss: 7.3860 - val_categorical_accuracy: 0.1286\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.6384e-04 - categorical_accuracy: 1.0000 - val_loss: 9.8575 - val_categorical_accuracy: 0.1241\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0024 - categorical_accuracy: 0.9997 - val_loss: 25.3236 - val_categorical_accuracy: 0.1721\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 11.0783 - val_categorical_accuracy: 0.1254\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 17.6356 - val_categorical_accuracy: 0.0972\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 4.9315e-04 - categorical_accuracy: 1.0000 - val_loss: 15.7383 - val_categorical_accuracy: 0.0998\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 14.7095 - val_categorical_accuracy: 0.1043\n",
      "Epoch 241/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.2313e-04 - categorical_accuracy: 0.9998 - val_loss: 6.8306 - val_categorical_accuracy: 0.1414\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.0813e-04 - categorical_accuracy: 1.0000 - val_loss: 8.0475 - val_categorical_accuracy: 0.1702\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.9415e-04 - categorical_accuracy: 1.0000 - val_loss: 7.8780 - val_categorical_accuracy: 0.1260\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.8127e-04 - categorical_accuracy: 0.9997 - val_loss: 19.1711 - val_categorical_accuracy: 0.1740\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.8686e-04 - categorical_accuracy: 1.0000 - val_loss: 11.2193 - val_categorical_accuracy: 0.1062\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.4676e-04 - categorical_accuracy: 1.0000 - val_loss: 12.7645 - val_categorical_accuracy: 0.1126\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 6.1136 - val_categorical_accuracy: 0.1452\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.9239e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7427 - val_categorical_accuracy: 0.1241\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.9510e-04 - categorical_accuracy: 1.0000 - val_loss: 13.2139 - val_categorical_accuracy: 0.1088\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.7007e-04 - categorical_accuracy: 1.0000 - val_loss: 8.0847 - val_categorical_accuracy: 0.1017\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.0765e-04 - categorical_accuracy: 1.0000 - val_loss: 12.8815 - val_categorical_accuracy: 0.1120\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.4565e-04 - categorical_accuracy: 1.0000 - val_loss: 13.1008 - val_categorical_accuracy: 0.1139\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.9782e-04 - categorical_accuracy: 1.0000 - val_loss: 13.5018 - val_categorical_accuracy: 0.1126\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.8129e-04 - categorical_accuracy: 1.0000 - val_loss: 11.3715 - val_categorical_accuracy: 0.1113\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.1996e-04 - categorical_accuracy: 1.0000 - val_loss: 11.1436 - val_categorical_accuracy: 0.1248\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.1527e-04 - categorical_accuracy: 1.0000 - val_loss: 9.4192 - val_categorical_accuracy: 0.1081\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.3613e-04 - categorical_accuracy: 1.0000 - val_loss: 8.8266 - val_categorical_accuracy: 0.1887\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.4900e-04 - categorical_accuracy: 0.9998 - val_loss: 14.9266 - val_categorical_accuracy: 0.1798\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.7751e-04 - categorical_accuracy: 0.9998 - val_loss: 12.3208 - val_categorical_accuracy: 0.0921\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.6669e-04 - categorical_accuracy: 0.9997 - val_loss: 10.5837 - val_categorical_accuracy: 0.1235\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 9.1179e-04 - categorical_accuracy: 0.9997 - val_loss: 18.9444 - val_categorical_accuracy: 0.0966\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 18.4311 - val_categorical_accuracy: 0.0966\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.0921e-04 - categorical_accuracy: 0.9997 - val_loss: 44.0648 - val_categorical_accuracy: 0.1651\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0058 - categorical_accuracy: 0.9994 - val_loss: 49.0286 - val_categorical_accuracy: 0.1702\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0226 - categorical_accuracy: 0.9960 - val_loss: 31.8198 - val_categorical_accuracy: 0.0128\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0532 - categorical_accuracy: 0.9853 - val_loss: 38.1313 - val_categorical_accuracy: 0.0947\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0929 - categorical_accuracy: 0.9741 - val_loss: 41.7560 - val_categorical_accuracy: 0.1030\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0618 - categorical_accuracy: 0.9832 - val_loss: 35.8959 - val_categorical_accuracy: 0.1657\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0325 - categorical_accuracy: 0.9899 - val_loss: 46.5521 - val_categorical_accuracy: 0.1663\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0131 - categorical_accuracy: 0.9970 - val_loss: 32.2761 - val_categorical_accuracy: 0.1670\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0050 - categorical_accuracy: 0.9992 - val_loss: 11.1609 - val_categorical_accuracy: 0.1446\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0046 - categorical_accuracy: 0.9990 - val_loss: 18.7218 - val_categorical_accuracy: 0.0979\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0027 - categorical_accuracy: 0.9998 - val_loss: 14.3740 - val_categorical_accuracy: 0.1363\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0023 - categorical_accuracy: 0.9998 - val_loss: 9.4090 - val_categorical_accuracy: 0.1209\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0018 - categorical_accuracy: 0.9998 - val_loss: 6.8835 - val_categorical_accuracy: 0.1344\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0023 - categorical_accuracy: 0.9995 - val_loss: 11.0997 - val_categorical_accuracy: 0.1190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 10.8292 - val_categorical_accuracy: 0.1715\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 11.5395 - val_categorical_accuracy: 0.1817\n",
      "Epoch 279/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 8.7375 - val_categorical_accuracy: 0.1830\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 12.3609 - val_categorical_accuracy: 0.1536\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 10.0661 - val_categorical_accuracy: 0.1145\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 9.7857 - val_categorical_accuracy: 0.1260\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 6.6732 - val_categorical_accuracy: 0.1292\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 13.9903 - val_categorical_accuracy: 0.1132\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.9820e-04 - categorical_accuracy: 1.0000 - val_loss: 10.6588 - val_categorical_accuracy: 0.1139\n",
      "Epoch 286/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.7956e-04 - categorical_accuracy: 0.9998 - val_loss: 6.6738 - val_categorical_accuracy: 0.1376\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.6523e-04 - categorical_accuracy: 0.9998 - val_loss: 6.2309 - val_categorical_accuracy: 0.1363\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 8.5324 - val_categorical_accuracy: 0.1062\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.6829e-04 - categorical_accuracy: 0.9998 - val_loss: 16.7773 - val_categorical_accuracy: 0.1088\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9995 - val_loss: 13.8715 - val_categorical_accuracy: 0.1382\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0010 - categorical_accuracy: 0.9997 - val_loss: 13.6606 - val_categorical_accuracy: 0.1567\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.3049e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2866 - val_categorical_accuracy: 0.1203\n",
      "Epoch 293/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0010 - categorical_accuracy: 0.9997 - val_loss: 8.0147 - val_categorical_accuracy: 0.1177\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.4125e-04 - categorical_accuracy: 0.9997 - val_loss: 7.8591 - val_categorical_accuracy: 0.1708\n",
      "Epoch 295/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.8663e-04 - categorical_accuracy: 0.9998 - val_loss: 7.4517 - val_categorical_accuracy: 0.1683\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.1963e-04 - categorical_accuracy: 1.0000 - val_loss: 7.0491 - val_categorical_accuracy: 0.1491\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.0980e-04 - categorical_accuracy: 1.0000 - val_loss: 7.7182 - val_categorical_accuracy: 0.1567\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 10.6298 - val_categorical_accuracy: 0.0793\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.4596e-04 - categorical_accuracy: 0.9998 - val_loss: 8.7553 - val_categorical_accuracy: 0.1196\n",
      "Epoch 300/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.2676e-04 - categorical_accuracy: 1.0000 - val_loss: 8.8635 - val_categorical_accuracy: 0.1126\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.3926e-04 - categorical_accuracy: 0.9998 - val_loss: 12.9808 - val_categorical_accuracy: 0.1004\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.8234e-04 - categorical_accuracy: 1.0000 - val_loss: 12.6762 - val_categorical_accuracy: 0.1049\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.1965e-04 - categorical_accuracy: 1.0000 - val_loss: 12.0896 - val_categorical_accuracy: 0.1049\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.9387e-04 - categorical_accuracy: 1.0000 - val_loss: 9.8443 - val_categorical_accuracy: 0.1152\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.3852e-04 - categorical_accuracy: 1.0000 - val_loss: 6.4851 - val_categorical_accuracy: 0.1292\n",
      "Epoch 306/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.1642e-04 - categorical_accuracy: 1.0000 - val_loss: 8.6568 - val_categorical_accuracy: 0.1395\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.2207e-04 - categorical_accuracy: 0.9997 - val_loss: 12.1898 - val_categorical_accuracy: 0.1171\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.4165e-04 - categorical_accuracy: 1.0000 - val_loss: 11.2299 - val_categorical_accuracy: 0.1145\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.7106e-04 - categorical_accuracy: 1.0000 - val_loss: 8.2887 - val_categorical_accuracy: 0.1676\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.3803e-04 - categorical_accuracy: 0.9998 - val_loss: 10.3879 - val_categorical_accuracy: 0.1152\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.2279e-04 - categorical_accuracy: 1.0000 - val_loss: 7.0401 - val_categorical_accuracy: 0.1280\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.3007e-04 - categorical_accuracy: 1.0000 - val_loss: 7.1057 - val_categorical_accuracy: 0.1299\n",
      "Epoch 313/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.8329e-04 - categorical_accuracy: 0.9997 - val_loss: 8.6517 - val_categorical_accuracy: 0.1542\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.5640e-04 - categorical_accuracy: 1.0000 - val_loss: 6.5749 - val_categorical_accuracy: 0.1440\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.9675e-04 - categorical_accuracy: 1.0000 - val_loss: 12.4010 - val_categorical_accuracy: 0.1548\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.7895e-04 - categorical_accuracy: 0.9998 - val_loss: 10.3576 - val_categorical_accuracy: 0.1612\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.4092e-04 - categorical_accuracy: 0.9998 - val_loss: 10.2593 - val_categorical_accuracy: 0.1216\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.6115e-04 - categorical_accuracy: 1.0000 - val_loss: 11.3825 - val_categorical_accuracy: 0.1196\n",
      "Epoch 319/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.1590e-04 - categorical_accuracy: 1.0000 - val_loss: 8.2014 - val_categorical_accuracy: 0.1177\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.3775e-04 - categorical_accuracy: 1.0000 - val_loss: 14.9406 - val_categorical_accuracy: 0.1100\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.9256e-04 - categorical_accuracy: 0.9997 - val_loss: 7.4789 - val_categorical_accuracy: 0.1433\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.4509e-04 - categorical_accuracy: 0.9998 - val_loss: 12.0091 - val_categorical_accuracy: 0.1145\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.7070e-04 - categorical_accuracy: 0.9998 - val_loss: 13.0864 - val_categorical_accuracy: 0.1452\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.8588e-04 - categorical_accuracy: 1.0000 - val_loss: 13.2712 - val_categorical_accuracy: 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.4176e-04 - categorical_accuracy: 1.0000 - val_loss: 7.0168 - val_categorical_accuracy: 0.1599\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.0814e-04 - categorical_accuracy: 1.0000 - val_loss: 6.6904 - val_categorical_accuracy: 0.1331\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.7158e-04 - categorical_accuracy: 1.0000 - val_loss: 14.1704 - val_categorical_accuracy: 0.1158\n",
      "Epoch 328/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.2938e-04 - categorical_accuracy: 1.0000 - val_loss: 23.5866 - val_categorical_accuracy: 0.0940\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 6.4573e-04 - categorical_accuracy: 0.9998 - val_loss: 20.3262 - val_categorical_accuracy: 0.0979\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 2.7790e-04 - categorical_accuracy: 1.0000 - val_loss: 16.4185 - val_categorical_accuracy: 0.1068\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 9.2586e-04 - categorical_accuracy: 0.9997 - val_loss: 8.0925 - val_categorical_accuracy: 0.1209\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 3.0919e-04 - categorical_accuracy: 1.0000 - val_loss: 7.3453 - val_categorical_accuracy: 0.1299\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 3.9456e-04 - categorical_accuracy: 0.9998 - val_loss: 10.3453 - val_categorical_accuracy: 0.1267\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.5267e-04 - categorical_accuracy: 0.9997 - val_loss: 8.3337 - val_categorical_accuracy: 0.1145\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.0911e-04 - categorical_accuracy: 1.0000 - val_loss: 8.8417 - val_categorical_accuracy: 0.1331\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.3791e-04 - categorical_accuracy: 0.9998 - val_loss: 23.5529 - val_categorical_accuracy: 0.1791\n",
      "Epoch 337/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.9688e-04 - categorical_accuracy: 1.0000 - val_loss: 12.1095 - val_categorical_accuracy: 0.1529\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.5378e-04 - categorical_accuracy: 1.0000 - val_loss: 19.1807 - val_categorical_accuracy: 0.0979\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.7800e-04 - categorical_accuracy: 0.9998 - val_loss: 16.5886 - val_categorical_accuracy: 0.1056\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.7528e-04 - categorical_accuracy: 1.0000 - val_loss: 8.5927 - val_categorical_accuracy: 0.1619\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.1657e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4961 - val_categorical_accuracy: 0.1222\n",
      "Epoch 342/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.8951e-04 - categorical_accuracy: 1.0000 - val_loss: 8.9428 - val_categorical_accuracy: 0.1222\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.0828e-04 - categorical_accuracy: 0.9997 - val_loss: 10.0988 - val_categorical_accuracy: 0.0985\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.0458e-04 - categorical_accuracy: 0.9997 - val_loss: 10.4700 - val_categorical_accuracy: 0.0838\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.5232e-04 - categorical_accuracy: 0.9997 - val_loss: 7.5439 - val_categorical_accuracy: 0.1312\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.4094e-04 - categorical_accuracy: 1.0000 - val_loss: 9.3114 - val_categorical_accuracy: 0.1273\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5848e-04 - categorical_accuracy: 1.0000 - val_loss: 8.4281 - val_categorical_accuracy: 0.1235\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.5160e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5329 - val_categorical_accuracy: 0.1395\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.7105e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4033 - val_categorical_accuracy: 0.1459\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.2583e-04 - categorical_accuracy: 0.9998 - val_loss: 13.1878 - val_categorical_accuracy: 0.1286\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.5646e-04 - categorical_accuracy: 0.9998 - val_loss: 24.6925 - val_categorical_accuracy: 0.1734\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.2120e-04 - categorical_accuracy: 1.0000 - val_loss: 16.1500 - val_categorical_accuracy: 0.1798\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.4481e-04 - categorical_accuracy: 1.0000 - val_loss: 23.7326 - val_categorical_accuracy: 0.0940\n",
      "Epoch 354/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.6189e-04 - categorical_accuracy: 1.0000 - val_loss: 19.7646 - val_categorical_accuracy: 0.0985\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5262e-04 - categorical_accuracy: 1.0000 - val_loss: 18.3609 - val_categorical_accuracy: 0.1011\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.3347e-04 - categorical_accuracy: 0.9998 - val_loss: 17.5102 - val_categorical_accuracy: 0.1331\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.7619e-04 - categorical_accuracy: 1.0000 - val_loss: 14.3159 - val_categorical_accuracy: 0.1209\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.7968e-04 - categorical_accuracy: 1.0000 - val_loss: 12.5635 - val_categorical_accuracy: 0.1056\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9995 - val_loss: 31.2897 - val_categorical_accuracy: 0.1683\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0063 - categorical_accuracy: 0.9986 - val_loss: 21.5426 - val_categorical_accuracy: 0.1676\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0286 - categorical_accuracy: 0.9928 - val_loss: 19.6753 - val_categorical_accuracy: 0.0128\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0572 - categorical_accuracy: 0.9878 - val_loss: 24.2546 - val_categorical_accuracy: 0.1043\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0656 - categorical_accuracy: 0.9843 - val_loss: 21.6984 - val_categorical_accuracy: 0.0960\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0391 - categorical_accuracy: 0.9886 - val_loss: 13.8121 - val_categorical_accuracy: 0.1177\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0272 - categorical_accuracy: 0.9926 - val_loss: 17.7403 - val_categorical_accuracy: 0.0960\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0084 - categorical_accuracy: 0.9976 - val_loss: 15.5502 - val_categorical_accuracy: 0.1177\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0042 - categorical_accuracy: 0.9989 - val_loss: 11.6918 - val_categorical_accuracy: 0.1068\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0022 - categorical_accuracy: 0.9997 - val_loss: 11.5474 - val_categorical_accuracy: 0.1209\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0026 - categorical_accuracy: 0.9997 - val_loss: 11.1301 - val_categorical_accuracy: 0.1062\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9997 - val_loss: 11.2424 - val_categorical_accuracy: 0.1222\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0016 - categorical_accuracy: 0.9998 - val_loss: 8.8275 - val_categorical_accuracy: 0.1164\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 12.2351 - val_categorical_accuracy: 0.1593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 8.5684 - val_categorical_accuracy: 0.1683\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.5203e-04 - categorical_accuracy: 0.9998 - val_loss: 7.3056 - val_categorical_accuracy: 0.1388\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 0.9995 - val_loss: 9.7805 - val_categorical_accuracy: 0.1516\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 11.8635 - val_categorical_accuracy: 0.1235\n",
      "Epoch 377/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.1669e-04 - categorical_accuracy: 0.9998 - val_loss: 14.4546 - val_categorical_accuracy: 0.1164\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 0.9995 - val_loss: 14.4100 - val_categorical_accuracy: 0.1855\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.2419e-04 - categorical_accuracy: 1.0000 - val_loss: 14.4631 - val_categorical_accuracy: 0.1862\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 9.8508 - val_categorical_accuracy: 0.1427\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.3639e-04 - categorical_accuracy: 0.9998 - val_loss: 13.4064 - val_categorical_accuracy: 0.0838\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 8.7741 - val_categorical_accuracy: 0.1196\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.3458e-04 - categorical_accuracy: 1.0000 - val_loss: 17.5647 - val_categorical_accuracy: 0.1075\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 8.1522e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2280 - val_categorical_accuracy: 0.1452\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 9.7560e-04 - categorical_accuracy: 0.9997 - val_loss: 16.5594 - val_categorical_accuracy: 0.1625\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 4.0696e-04 - categorical_accuracy: 1.0000 - val_loss: 13.9089 - val_categorical_accuracy: 0.1062\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.7659e-04 - categorical_accuracy: 1.0000 - val_loss: 8.6344 - val_categorical_accuracy: 0.1139\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 12.6756 - val_categorical_accuracy: 0.0972\n",
      "Epoch 389/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.7731e-04 - categorical_accuracy: 0.9998 - val_loss: 7.5095 - val_categorical_accuracy: 0.1388\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.1460e-04 - categorical_accuracy: 0.9998 - val_loss: 14.9012 - val_categorical_accuracy: 0.1190\n",
      "Epoch 391/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.7082e-04 - categorical_accuracy: 1.0000 - val_loss: 19.2923 - val_categorical_accuracy: 0.1011\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 3.7576e-04 - categorical_accuracy: 1.0000 - val_loss: 16.1776 - val_categorical_accuracy: 0.1120\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.1468e-04 - categorical_accuracy: 1.0000 - val_loss: 17.4537 - val_categorical_accuracy: 0.1056\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.6735e-04 - categorical_accuracy: 0.9997 - val_loss: 14.1153 - val_categorical_accuracy: 0.1196\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 5.6336e-04 - categorical_accuracy: 0.9998 - val_loss: 8.1559 - val_categorical_accuracy: 0.1382\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.1298e-04 - categorical_accuracy: 0.9998 - val_loss: 7.0690 - val_categorical_accuracy: 0.1465\n",
      "Epoch 397/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 8.3713e-04 - categorical_accuracy: 0.9997 - val_loss: 14.1840 - val_categorical_accuracy: 0.1702\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.6243e-04 - categorical_accuracy: 0.9998 - val_loss: 14.4134 - val_categorical_accuracy: 0.1817\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.6017e-04 - categorical_accuracy: 0.9997 - val_loss: 13.1463 - val_categorical_accuracy: 0.1625\n",
      "Epoch 400/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.6062e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2514 - val_categorical_accuracy: 0.1388\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.2928e-04 - categorical_accuracy: 0.9997 - val_loss: 15.3557 - val_categorical_accuracy: 0.1120\n",
      "Epoch 402/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.2263e-04 - categorical_accuracy: 1.0000 - val_loss: 7.9850 - val_categorical_accuracy: 0.1292\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.6898e-04 - categorical_accuracy: 1.0000 - val_loss: 11.5424 - val_categorical_accuracy: 0.1395\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.1086e-04 - categorical_accuracy: 1.0000 - val_loss: 10.8980 - val_categorical_accuracy: 0.1408\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.0168e-04 - categorical_accuracy: 0.9998 - val_loss: 13.0803 - val_categorical_accuracy: 0.1670\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.9326e-04 - categorical_accuracy: 1.0000 - val_loss: 13.0204 - val_categorical_accuracy: 0.1120\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.1494e-04 - categorical_accuracy: 1.0000 - val_loss: 10.7627 - val_categorical_accuracy: 0.1152\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.1981e-04 - categorical_accuracy: 1.0000 - val_loss: 8.3963 - val_categorical_accuracy: 0.1267\n",
      "Epoch 409/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.2662e-04 - categorical_accuracy: 0.9998 - val_loss: 8.1872 - val_categorical_accuracy: 0.1350\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.6618e-04 - categorical_accuracy: 1.0000 - val_loss: 19.3749 - val_categorical_accuracy: 0.0953\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.1520e-04 - categorical_accuracy: 1.0000 - val_loss: 19.2806 - val_categorical_accuracy: 0.1024\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.7065e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5613 - val_categorical_accuracy: 0.1318\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.4197e-04 - categorical_accuracy: 1.0000 - val_loss: 7.6466 - val_categorical_accuracy: 0.1356\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.6751e-04 - categorical_accuracy: 0.9998 - val_loss: 22.0091 - val_categorical_accuracy: 0.1759\n",
      "Epoch 415/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.7271e-04 - categorical_accuracy: 0.9998 - val_loss: 13.8831 - val_categorical_accuracy: 0.1241\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.2889e-04 - categorical_accuracy: 0.9997 - val_loss: 9.4141 - val_categorical_accuracy: 0.1593\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.2671e-04 - categorical_accuracy: 0.9998 - val_loss: 13.8973 - val_categorical_accuracy: 0.1862\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.3508e-04 - categorical_accuracy: 1.0000 - val_loss: 11.9998 - val_categorical_accuracy: 0.1791\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.2125e-04 - categorical_accuracy: 0.9998 - val_loss: 13.7456 - val_categorical_accuracy: 0.1823\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.9410e-04 - categorical_accuracy: 1.0000 - val_loss: 7.3784 - val_categorical_accuracy: 0.1401\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.9788e-04 - categorical_accuracy: 1.0000 - val_loss: 15.3058 - val_categorical_accuracy: 0.1164\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.1414e-04 - categorical_accuracy: 1.0000 - val_loss: 13.5041 - val_categorical_accuracy: 0.1158\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.0417e-04 - categorical_accuracy: 1.0000 - val_loss: 7.6132 - val_categorical_accuracy: 0.1318\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.6124e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5247 - val_categorical_accuracy: 0.1356\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.5765e-04 - categorical_accuracy: 1.0000 - val_loss: 7.3585 - val_categorical_accuracy: 0.1331\n",
      "Epoch 426/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.4799e-04 - categorical_accuracy: 1.0000 - val_loss: 9.3867 - val_categorical_accuracy: 0.1446\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.6326e-04 - categorical_accuracy: 1.0000 - val_loss: 7.7527 - val_categorical_accuracy: 0.1408\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.0429e-04 - categorical_accuracy: 1.0000 - val_loss: 15.1791 - val_categorical_accuracy: 0.1126\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.9482e-04 - categorical_accuracy: 1.0000 - val_loss: 11.2678 - val_categorical_accuracy: 0.1126\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.0258e-04 - categorical_accuracy: 1.0000 - val_loss: 8.0529 - val_categorical_accuracy: 0.1139\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.7598e-04 - categorical_accuracy: 1.0000 - val_loss: 15.4171 - val_categorical_accuracy: 0.1158\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.8049e-04 - categorical_accuracy: 0.9998 - val_loss: 8.0399 - val_categorical_accuracy: 0.1241\n",
      "Epoch 433/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 4.5365e-04 - categorical_accuracy: 0.9998 - val_loss: 14.9151 - val_categorical_accuracy: 0.1171\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.6229e-04 - categorical_accuracy: 1.0000 - val_loss: 8.8584 - val_categorical_accuracy: 0.1260\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.6427e-04 - categorical_accuracy: 1.0000 - val_loss: 12.7456 - val_categorical_accuracy: 0.1222\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.1661e-04 - categorical_accuracy: 1.0000 - val_loss: 10.1355 - val_categorical_accuracy: 0.1164\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.4894e-04 - categorical_accuracy: 1.0000 - val_loss: 18.0387 - val_categorical_accuracy: 0.1043\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.3267e-04 - categorical_accuracy: 1.0000 - val_loss: 15.9761 - val_categorical_accuracy: 0.1100\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.6904e-04 - categorical_accuracy: 0.9998 - val_loss: 9.9752 - val_categorical_accuracy: 0.1401\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.0358e-04 - categorical_accuracy: 0.9998 - val_loss: 11.9940 - val_categorical_accuracy: 0.1804\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.4145e-04 - categorical_accuracy: 1.0000 - val_loss: 10.3868 - val_categorical_accuracy: 0.1753\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.5290e-04 - categorical_accuracy: 1.0000 - val_loss: 8.2151 - val_categorical_accuracy: 0.1510\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.7758e-04 - categorical_accuracy: 0.9997 - val_loss: 11.4822 - val_categorical_accuracy: 0.1683\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.6015e-05 - categorical_accuracy: 1.0000 - val_loss: 7.9308 - val_categorical_accuracy: 0.1491\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.3635e-04 - categorical_accuracy: 1.0000 - val_loss: 12.2738 - val_categorical_accuracy: 0.1472\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.4671e-04 - categorical_accuracy: 1.0000 - val_loss: 10.6269 - val_categorical_accuracy: 0.1132\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.3115e-04 - categorical_accuracy: 0.9998 - val_loss: 14.9338 - val_categorical_accuracy: 0.0966\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0064 - categorical_accuracy: 0.9986 - val_loss: 24.1277 - val_categorical_accuracy: 0.1631\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0443 - categorical_accuracy: 0.9918 - val_loss: 26.4672 - val_categorical_accuracy: 0.1727\n",
      "Epoch 450/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0419 - categorical_accuracy: 0.9885 - val_loss: 25.2093 - val_categorical_accuracy: 0.0960\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0475 - categorical_accuracy: 0.9901 - val_loss: 31.7347 - val_categorical_accuracy: 0.1068\n",
      "Epoch 452/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0180 - categorical_accuracy: 0.9955 - val_loss: 8.7173 - val_categorical_accuracy: 0.1299\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0080 - categorical_accuracy: 0.9971 - val_loss: 52.7898 - val_categorical_accuracy: 0.1011\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0034 - categorical_accuracy: 0.9989 - val_loss: 37.7848 - val_categorical_accuracy: 0.1017\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0023 - categorical_accuracy: 0.9994 - val_loss: 26.1214 - val_categorical_accuracy: 0.1056\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0027 - categorical_accuracy: 0.9995 - val_loss: 21.6227 - val_categorical_accuracy: 0.1100\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 0.9995 - val_loss: 13.8402 - val_categorical_accuracy: 0.1203\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 0.9994 - val_loss: 14.0670 - val_categorical_accuracy: 0.1075\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 18.5076 - val_categorical_accuracy: 0.1024\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 10.6081 - val_categorical_accuracy: 0.1203\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0010 - categorical_accuracy: 0.9997 - val_loss: 11.7599 - val_categorical_accuracy: 0.1388\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.8999e-04 - categorical_accuracy: 0.9998 - val_loss: 14.1752 - val_categorical_accuracy: 0.1785\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.7740e-04 - categorical_accuracy: 0.9998 - val_loss: 11.5813 - val_categorical_accuracy: 0.1964\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.3124e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5886 - val_categorical_accuracy: 0.1209\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.9032e-04 - categorical_accuracy: 0.9998 - val_loss: 7.3264 - val_categorical_accuracy: 0.1292\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.3138e-04 - categorical_accuracy: 0.9998 - val_loss: 7.6135 - val_categorical_accuracy: 0.1420\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.6383e-04 - categorical_accuracy: 1.0000 - val_loss: 7.3461 - val_categorical_accuracy: 0.1465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.8464e-04 - categorical_accuracy: 1.0000 - val_loss: 7.6103 - val_categorical_accuracy: 0.1324\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.7015e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4009 - val_categorical_accuracy: 0.1344\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.2524e-04 - categorical_accuracy: 0.9998 - val_loss: 7.3755 - val_categorical_accuracy: 0.1452\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.6902e-04 - categorical_accuracy: 0.9998 - val_loss: 7.5466 - val_categorical_accuracy: 0.1420\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.9435e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2793 - val_categorical_accuracy: 0.1382\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.2153e-04 - categorical_accuracy: 0.9998 - val_loss: 9.5408 - val_categorical_accuracy: 0.1100\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.6487e-04 - categorical_accuracy: 1.0000 - val_loss: 8.7580 - val_categorical_accuracy: 0.1216\n",
      "Epoch 475/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.9648e-04 - categorical_accuracy: 1.0000 - val_loss: 9.3302 - val_categorical_accuracy: 0.1388\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.1139e-04 - categorical_accuracy: 1.0000 - val_loss: 9.1874 - val_categorical_accuracy: 0.1318\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.6009e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2966 - val_categorical_accuracy: 0.1446\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.4389e-04 - categorical_accuracy: 1.0000 - val_loss: 8.0173 - val_categorical_accuracy: 0.1292\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.9846e-04 - categorical_accuracy: 1.0000 - val_loss: 8.0474 - val_categorical_accuracy: 0.1536\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.4921e-04 - categorical_accuracy: 1.0000 - val_loss: 8.4621 - val_categorical_accuracy: 0.1292\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.4204e-04 - categorical_accuracy: 0.9998 - val_loss: 15.3573 - val_categorical_accuracy: 0.1049\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.6091e-04 - categorical_accuracy: 0.9997 - val_loss: 7.7376 - val_categorical_accuracy: 0.1318\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.8137e-04 - categorical_accuracy: 1.0000 - val_loss: 10.2738 - val_categorical_accuracy: 0.1011\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.2624e-04 - categorical_accuracy: 0.9998 - val_loss: 7.5047 - val_categorical_accuracy: 0.1369\n",
      "Epoch 485/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.8577e-04 - categorical_accuracy: 1.0000 - val_loss: 9.5673 - val_categorical_accuracy: 0.1273\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.4708e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4424 - val_categorical_accuracy: 0.1388\n",
      "Epoch 487/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.2907e-04 - categorical_accuracy: 0.9998 - val_loss: 7.9252 - val_categorical_accuracy: 0.1305\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.8813e-04 - categorical_accuracy: 0.9998 - val_loss: 10.5642 - val_categorical_accuracy: 0.1305\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.8332e-04 - categorical_accuracy: 1.0000 - val_loss: 12.5100 - val_categorical_accuracy: 0.1152\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.0390e-04 - categorical_accuracy: 1.0000 - val_loss: 8.0780 - val_categorical_accuracy: 0.1273\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 3.1041e-04 - categorical_accuracy: 1.0000 - val_loss: 7.8739 - val_categorical_accuracy: 0.1529\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 11.2964 - val_categorical_accuracy: 0.1875\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 3.8223e-04 - categorical_accuracy: 0.9998 - val_loss: 11.7186 - val_categorical_accuracy: 0.1184\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 7.7087e-04 - categorical_accuracy: 0.9998 - val_loss: 7.5450 - val_categorical_accuracy: 0.1356\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 3.3380e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4468 - val_categorical_accuracy: 0.1414\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.8137e-04 - categorical_accuracy: 1.0000 - val_loss: 12.2128 - val_categorical_accuracy: 0.1100\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.4996e-04 - categorical_accuracy: 1.0000 - val_loss: 7.6753 - val_categorical_accuracy: 0.1312\n",
      "Epoch 498/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.3564e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4371 - val_categorical_accuracy: 0.1433\n",
      "Epoch 499/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 4.8694e-04 - categorical_accuracy: 0.9997 - val_loss: 7.2100 - val_categorical_accuracy: 0.1388\n",
      "Epoch 500/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.7678e-04 - categorical_accuracy: 0.9997 - val_loss: 7.2720 - val_categorical_accuracy: 0.1350\n",
      "Finished.\n",
      "Training ELU Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "49/49 [==============================] - 4s 67ms/step - loss: 2.8663 - categorical_accuracy: 0.0539 - val_loss: 5.7980 - val_categorical_accuracy: 0.0665\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 3s 72ms/step - loss: 2.2676 - categorical_accuracy: 0.3187 - val_loss: 2.7982 - val_categorical_accuracy: 0.0435\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.8522 - categorical_accuracy: 0.5282 - val_loss: 2.9413 - val_categorical_accuracy: 0.0992\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.4276 - categorical_accuracy: 0.7085 - val_loss: 3.1722 - val_categorical_accuracy: 0.0384\n",
      "Epoch 5/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.1766 - categorical_accuracy: 0.7975 - val_loss: 25.7223 - val_categorical_accuracy: 0.0998\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.9876 - categorical_accuracy: 0.8528 - val_loss: 4.3257 - val_categorical_accuracy: 0.0665\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8211 - categorical_accuracy: 0.8910 - val_loss: 3.5374 - val_categorical_accuracy: 0.0665\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.6691 - categorical_accuracy: 0.9213 - val_loss: 3.4915 - val_categorical_accuracy: 0.0608\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.5433 - categorical_accuracy: 0.9384 - val_loss: 4.2296 - val_categorical_accuracy: 0.0998\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.4490 - categorical_accuracy: 0.9470 - val_loss: 3.5479 - val_categorical_accuracy: 0.1683\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.3719 - categorical_accuracy: 0.9555 - val_loss: 5.4867 - val_categorical_accuracy: 0.1126\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.3143 - categorical_accuracy: 0.9661 - val_loss: 6.3922 - val_categorical_accuracy: 0.1139\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2645 - categorical_accuracy: 0.9715 - val_loss: 5.2963 - val_categorical_accuracy: 0.1120\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.2271 - categorical_accuracy: 0.9749 - val_loss: 3.4124 - val_categorical_accuracy: 0.1004\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1951 - categorical_accuracy: 0.9771 - val_loss: 5.9839 - val_categorical_accuracy: 0.1158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1672 - categorical_accuracy: 0.9786 - val_loss: 3.7711 - val_categorical_accuracy: 0.1727\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1482 - categorical_accuracy: 0.9834 - val_loss: 3.5393 - val_categorical_accuracy: 0.1382\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1323 - categorical_accuracy: 0.9874 - val_loss: 4.8610 - val_categorical_accuracy: 0.1196\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1181 - categorical_accuracy: 0.9918 - val_loss: 3.7198 - val_categorical_accuracy: 0.1248\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1029 - categorical_accuracy: 0.9941 - val_loss: 4.8956 - val_categorical_accuracy: 0.1855\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0908 - categorical_accuracy: 0.9973 - val_loss: 6.4470 - val_categorical_accuracy: 0.0819\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0821 - categorical_accuracy: 0.9979 - val_loss: 4.7516 - val_categorical_accuracy: 0.0979\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0740 - categorical_accuracy: 0.9984 - val_loss: 10.1124 - val_categorical_accuracy: 0.1043\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0660 - categorical_accuracy: 0.9990 - val_loss: 9.1147 - val_categorical_accuracy: 0.0685\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0574 - categorical_accuracy: 0.9992 - val_loss: 7.4764 - val_categorical_accuracy: 0.0665\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0523 - categorical_accuracy: 0.9994 - val_loss: 11.3270 - val_categorical_accuracy: 0.0870\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0476 - categorical_accuracy: 0.9997 - val_loss: 8.6275 - val_categorical_accuracy: 0.0371\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0446 - categorical_accuracy: 0.9989 - val_loss: 7.9707 - val_categorical_accuracy: 0.0819\n",
      "Epoch 29/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0394 - categorical_accuracy: 0.9994 - val_loss: 8.1705 - val_categorical_accuracy: 0.0211\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0352 - categorical_accuracy: 0.9997 - val_loss: 7.6907 - val_categorical_accuracy: 0.0211\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0324 - categorical_accuracy: 0.9997 - val_loss: 6.2907 - val_categorical_accuracy: 0.0352\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0309 - categorical_accuracy: 0.9997 - val_loss: 7.4985 - val_categorical_accuracy: 0.0288\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0279 - categorical_accuracy: 0.9995 - val_loss: 8.6075 - val_categorical_accuracy: 0.0461\n",
      "Epoch 34/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0265 - categorical_accuracy: 0.9995 - val_loss: 5.5531 - val_categorical_accuracy: 0.1971\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0251 - categorical_accuracy: 0.9995 - val_loss: 10.1853 - val_categorical_accuracy: 0.0205\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0226 - categorical_accuracy: 0.9995 - val_loss: 9.8949 - val_categorical_accuracy: 0.0288\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0216 - categorical_accuracy: 0.9994 - val_loss: 5.0695 - val_categorical_accuracy: 0.1875\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0218 - categorical_accuracy: 0.9995 - val_loss: 5.4648 - val_categorical_accuracy: 0.0857\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0193 - categorical_accuracy: 0.9994 - val_loss: 8.4169 - val_categorical_accuracy: 0.0301\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0191 - categorical_accuracy: 0.9994 - val_loss: 5.7776 - val_categorical_accuracy: 0.1804\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0235 - categorical_accuracy: 0.9992 - val_loss: 33.5081 - val_categorical_accuracy: 0.0998\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0350 - categorical_accuracy: 0.9970 - val_loss: 109.3026 - val_categorical_accuracy: 0.0998\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0592 - categorical_accuracy: 0.9910 - val_loss: 58.4989 - val_categorical_accuracy: 0.1644\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1965 - categorical_accuracy: 0.9493 - val_loss: 36.7594 - val_categorical_accuracy: 0.0665\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.5116 - categorical_accuracy: 0.8601 - val_loss: 12.8474 - val_categorical_accuracy: 0.0486\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2454 - categorical_accuracy: 0.9390 - val_loss: 13.8655 - val_categorical_accuracy: 0.0467\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0817 - categorical_accuracy: 0.9898 - val_loss: 13.8485 - val_categorical_accuracy: 0.0473\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0479 - categorical_accuracy: 0.9970 - val_loss: 13.3266 - val_categorical_accuracy: 0.0480\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0339 - categorical_accuracy: 0.9987 - val_loss: 12.0698 - val_categorical_accuracy: 0.0493\n",
      "Epoch 50/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0269 - categorical_accuracy: 0.9992 - val_loss: 11.6898 - val_categorical_accuracy: 0.0480\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0237 - categorical_accuracy: 0.9994 - val_loss: 11.7322 - val_categorical_accuracy: 0.0499\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0213 - categorical_accuracy: 0.9997 - val_loss: 11.3133 - val_categorical_accuracy: 0.0499\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0178 - categorical_accuracy: 0.9995 - val_loss: 11.0680 - val_categorical_accuracy: 0.0403\n",
      "Epoch 54/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0155 - categorical_accuracy: 0.9998 - val_loss: 10.3732 - val_categorical_accuracy: 0.0493\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0145 - categorical_accuracy: 0.9992 - val_loss: 9.9161 - val_categorical_accuracy: 0.0525\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0128 - categorical_accuracy: 0.9998 - val_loss: 7.0113 - val_categorical_accuracy: 0.0781\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0122 - categorical_accuracy: 0.9995 - val_loss: 5.2988 - val_categorical_accuracy: 0.1120\n",
      "Epoch 58/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0114 - categorical_accuracy: 0.9995 - val_loss: 4.7197 - val_categorical_accuracy: 0.1324\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0106 - categorical_accuracy: 1.0000 - val_loss: 4.1394 - val_categorical_accuracy: 0.1504\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0101 - categorical_accuracy: 0.9995 - val_loss: 3.8531 - val_categorical_accuracy: 0.1593\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0088 - categorical_accuracy: 0.9998 - val_loss: 5.2893 - val_categorical_accuracy: 0.1075\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0092 - categorical_accuracy: 0.9998 - val_loss: 3.8357 - val_categorical_accuracy: 0.1536\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0083 - categorical_accuracy: 0.9997 - val_loss: 4.3063 - val_categorical_accuracy: 0.1567\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0078 - categorical_accuracy: 0.9998 - val_loss: 4.0311 - val_categorical_accuracy: 0.1228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0076 - categorical_accuracy: 0.9997 - val_loss: 3.8020 - val_categorical_accuracy: 0.1593\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0068 - categorical_accuracy: 0.9998 - val_loss: 5.0020 - val_categorical_accuracy: 0.1446\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0076 - categorical_accuracy: 0.9995 - val_loss: 4.9322 - val_categorical_accuracy: 0.1337\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0068 - categorical_accuracy: 0.9994 - val_loss: 4.0791 - val_categorical_accuracy: 0.1529\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0065 - categorical_accuracy: 0.9995 - val_loss: 4.8186 - val_categorical_accuracy: 0.1312\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0072 - categorical_accuracy: 0.9995 - val_loss: 4.9304 - val_categorical_accuracy: 0.1184\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0064 - categorical_accuracy: 0.9995 - val_loss: 3.8072 - val_categorical_accuracy: 0.1350\n",
      "Epoch 72/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0054 - categorical_accuracy: 0.9998 - val_loss: 3.9016 - val_categorical_accuracy: 0.1491\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0049 - categorical_accuracy: 1.0000 - val_loss: 3.9029 - val_categorical_accuracy: 0.1459\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0050 - categorical_accuracy: 0.9997 - val_loss: 3.9184 - val_categorical_accuracy: 0.1651\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0049 - categorical_accuracy: 0.9998 - val_loss: 4.3276 - val_categorical_accuracy: 0.1619\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0042 - categorical_accuracy: 0.9998 - val_loss: 3.9229 - val_categorical_accuracy: 0.1612\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0047 - categorical_accuracy: 0.9998 - val_loss: 4.8610 - val_categorical_accuracy: 0.1427\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0050 - categorical_accuracy: 0.9997 - val_loss: 3.9718 - val_categorical_accuracy: 0.1599\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0046 - categorical_accuracy: 0.9998 - val_loss: 4.8503 - val_categorical_accuracy: 0.1446\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0039 - categorical_accuracy: 0.9998 - val_loss: 4.2479 - val_categorical_accuracy: 0.1299\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0042 - categorical_accuracy: 0.9997 - val_loss: 3.9320 - val_categorical_accuracy: 0.1567\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0041 - categorical_accuracy: 0.9997 - val_loss: 4.1045 - val_categorical_accuracy: 0.1376\n",
      "Epoch 83/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0044 - categorical_accuracy: 0.9997 - val_loss: 4.2916 - val_categorical_accuracy: 0.1107\n",
      "Epoch 84/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0032 - categorical_accuracy: 0.9998 - val_loss: 5.4578 - val_categorical_accuracy: 0.1440\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0032 - categorical_accuracy: 0.9998 - val_loss: 6.7304 - val_categorical_accuracy: 0.1209\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0031 - categorical_accuracy: 0.9998 - val_loss: 4.7612 - val_categorical_accuracy: 0.1388\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0030 - categorical_accuracy: 1.0000 - val_loss: 5.0574 - val_categorical_accuracy: 0.1472\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0035 - categorical_accuracy: 0.9997 - val_loss: 4.6479 - val_categorical_accuracy: 0.1164\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0032 - categorical_accuracy: 0.9997 - val_loss: 4.5900 - val_categorical_accuracy: 0.1452\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0028 - categorical_accuracy: 0.9998 - val_loss: 4.4770 - val_categorical_accuracy: 0.1171\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0026 - categorical_accuracy: 0.9998 - val_loss: 3.9926 - val_categorical_accuracy: 0.1599\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0028 - categorical_accuracy: 0.9997 - val_loss: 4.0227 - val_categorical_accuracy: 0.1529\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 5.8706 - val_categorical_accuracy: 0.1395\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0028 - categorical_accuracy: 0.9997 - val_loss: 6.0897 - val_categorical_accuracy: 0.1408\n",
      "Epoch 95/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0024 - categorical_accuracy: 0.9998 - val_loss: 5.1797 - val_categorical_accuracy: 0.1555\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0021 - categorical_accuracy: 1.0000 - val_loss: 4.2054 - val_categorical_accuracy: 0.1484\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0022 - categorical_accuracy: 0.9998 - val_loss: 5.1936 - val_categorical_accuracy: 0.1049\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 6.1032 - val_categorical_accuracy: 0.0979\n",
      "Epoch 99/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0025 - categorical_accuracy: 0.9997 - val_loss: 4.4282 - val_categorical_accuracy: 0.1440\n",
      "Epoch 100/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0022 - categorical_accuracy: 0.9998 - val_loss: 4.1406 - val_categorical_accuracy: 0.1561\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0023 - categorical_accuracy: 0.9997 - val_loss: 6.8330 - val_categorical_accuracy: 0.1235\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0031 - categorical_accuracy: 0.9997 - val_loss: 4.7241 - val_categorical_accuracy: 0.1395\n",
      "Epoch 103/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0027 - categorical_accuracy: 0.9997 - val_loss: 6.8267 - val_categorical_accuracy: 0.0909\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0025 - categorical_accuracy: 0.9997 - val_loss: 5.6271 - val_categorical_accuracy: 0.1036\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 4.1280 - val_categorical_accuracy: 0.1337\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0024 - categorical_accuracy: 0.9997 - val_loss: 5.3397 - val_categorical_accuracy: 0.1145\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 3.9366 - val_categorical_accuracy: 0.1324\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 4.8748 - val_categorical_accuracy: 0.1459\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 4.4914 - val_categorical_accuracy: 0.1504\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 5.3618 - val_categorical_accuracy: 0.1427\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 5.3187 - val_categorical_accuracy: 0.1369\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0019 - categorical_accuracy: 0.9997 - val_loss: 4.4426 - val_categorical_accuracy: 0.1587\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 5.4757 - val_categorical_accuracy: 0.1036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 4.4578 - val_categorical_accuracy: 0.1171\n",
      "Epoch 115/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 4.5188 - val_categorical_accuracy: 0.1452\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0038 - categorical_accuracy: 0.9997 - val_loss: 11.7122 - val_categorical_accuracy: 0.0832\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0028 - categorical_accuracy: 0.9995 - val_loss: 9.6135 - val_categorical_accuracy: 0.0979\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0033 - categorical_accuracy: 0.9994 - val_loss: 12.8384 - val_categorical_accuracy: 0.0793\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0026 - categorical_accuracy: 0.9994 - val_loss: 5.5674 - val_categorical_accuracy: 0.1510\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0045 - categorical_accuracy: 0.9994 - val_loss: 10.7335 - val_categorical_accuracy: 0.1100\n",
      "Epoch 121/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0052 - categorical_accuracy: 0.9986 - val_loss: 10.2150 - val_categorical_accuracy: 0.1184\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0089 - categorical_accuracy: 0.9984 - val_loss: 16.5219 - val_categorical_accuracy: 0.0473\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0105 - categorical_accuracy: 0.9982 - val_loss: 14.7474 - val_categorical_accuracy: 0.0493\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0120 - categorical_accuracy: 0.9976 - val_loss: 17.0941 - val_categorical_accuracy: 0.1356\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0266 - categorical_accuracy: 0.9939 - val_loss: 18.6798 - val_categorical_accuracy: 0.1036\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0969 - categorical_accuracy: 0.9768 - val_loss: 34.1085 - val_categorical_accuracy: 0.0934\n",
      "Epoch 127/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1610 - categorical_accuracy: 0.9597 - val_loss: 23.5536 - val_categorical_accuracy: 0.1043\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1017 - categorical_accuracy: 0.9714 - val_loss: 13.5393 - val_categorical_accuracy: 0.1062\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0409 - categorical_accuracy: 0.9917 - val_loss: 14.4966 - val_categorical_accuracy: 0.0601\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0167 - categorical_accuracy: 0.9971 - val_loss: 18.4578 - val_categorical_accuracy: 0.0940\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0120 - categorical_accuracy: 0.9987 - val_loss: 16.5322 - val_categorical_accuracy: 0.0940\n",
      "Epoch 132/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0092 - categorical_accuracy: 0.9986 - val_loss: 17.3153 - val_categorical_accuracy: 0.0947\n",
      "Epoch 133/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0061 - categorical_accuracy: 0.9994 - val_loss: 16.2777 - val_categorical_accuracy: 0.0953\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0060 - categorical_accuracy: 0.9994 - val_loss: 16.5684 - val_categorical_accuracy: 0.0966\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0050 - categorical_accuracy: 0.9995 - val_loss: 11.1535 - val_categorical_accuracy: 0.1113\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0047 - categorical_accuracy: 0.9997 - val_loss: 11.3521 - val_categorical_accuracy: 0.1158\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0043 - categorical_accuracy: 0.9997 - val_loss: 8.9634 - val_categorical_accuracy: 0.1318\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0032 - categorical_accuracy: 0.9997 - val_loss: 7.9420 - val_categorical_accuracy: 0.1344\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0031 - categorical_accuracy: 0.9997 - val_loss: 6.7014 - val_categorical_accuracy: 0.1241\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0037 - categorical_accuracy: 0.9998 - val_loss: 11.7084 - val_categorical_accuracy: 0.0416\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0028 - categorical_accuracy: 0.9998 - val_loss: 11.6050 - val_categorical_accuracy: 0.0473\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0028 - categorical_accuracy: 0.9997 - val_loss: 12.9633 - val_categorical_accuracy: 0.0224\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0025 - categorical_accuracy: 0.9997 - val_loss: 8.4083 - val_categorical_accuracy: 0.0749\n",
      "Epoch 144/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0033 - categorical_accuracy: 0.9997 - val_loss: 9.3975 - val_categorical_accuracy: 0.1235\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0018 - categorical_accuracy: 0.9998 - val_loss: 10.2788 - val_categorical_accuracy: 0.1209\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0023 - categorical_accuracy: 0.9997 - val_loss: 8.4297 - val_categorical_accuracy: 0.1299\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0037 - categorical_accuracy: 0.9997 - val_loss: 8.4499 - val_categorical_accuracy: 0.1299\n",
      "Epoch 148/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0027 - categorical_accuracy: 0.9997 - val_loss: 5.1580 - val_categorical_accuracy: 0.1203\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0030 - categorical_accuracy: 0.9995 - val_loss: 13.3923 - val_categorical_accuracy: 0.1043\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 8.1801 - val_categorical_accuracy: 0.1638\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 6.9609 - val_categorical_accuracy: 0.1158\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 12.9462 - val_categorical_accuracy: 0.1088\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 10.4949 - val_categorical_accuracy: 0.1222\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 7.0173 - val_categorical_accuracy: 0.1734\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 12.9630 - val_categorical_accuracy: 0.0269\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 6.9251 - val_categorical_accuracy: 0.0889\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 12.8483 - val_categorical_accuracy: 0.0250\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 5.6433 - val_categorical_accuracy: 0.1478\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 7.9496 - val_categorical_accuracy: 0.1356\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 7.0114 - val_categorical_accuracy: 0.1337\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0019 - categorical_accuracy: 0.9997 - val_loss: 8.2953 - val_categorical_accuracy: 0.1350\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.1020e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3710 - val_categorical_accuracy: 0.1484\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 12.9204 - val_categorical_accuracy: 0.0237\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 8.9572e-04 - categorical_accuracy: 1.0000 - val_loss: 12.3809 - val_categorical_accuracy: 0.0301\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 14.0324 - val_categorical_accuracy: 0.1100\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 6.0920 - val_categorical_accuracy: 0.1299\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 6.7854 - val_categorical_accuracy: 0.1414\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.9934e-04 - categorical_accuracy: 0.9998 - val_loss: 5.9333 - val_categorical_accuracy: 0.1580\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.8564e-04 - categorical_accuracy: 1.0000 - val_loss: 5.0762 - val_categorical_accuracy: 0.1427\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 9.0648 - val_categorical_accuracy: 0.1248\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 9.9535 - val_categorical_accuracy: 0.1248\n",
      "Epoch 172/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.7934e-04 - categorical_accuracy: 0.9998 - val_loss: 15.7407 - val_categorical_accuracy: 0.1075\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0018 - categorical_accuracy: 0.9998 - val_loss: 15.5869 - val_categorical_accuracy: 0.1062\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 12.4349 - val_categorical_accuracy: 0.1062\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 7.2528 - val_categorical_accuracy: 0.1574\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.1714e-04 - categorical_accuracy: 1.0000 - val_loss: 14.6486 - val_categorical_accuracy: 0.0230\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 13.6245 - val_categorical_accuracy: 0.0262\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 5.2971 - val_categorical_accuracy: 0.1427\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.8320e-04 - categorical_accuracy: 1.0000 - val_loss: 8.9454 - val_categorical_accuracy: 0.0704\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0010 - categorical_accuracy: 0.9997 - val_loss: 14.0245 - val_categorical_accuracy: 0.0243\n",
      "Epoch 181/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.6014e-04 - categorical_accuracy: 0.9998 - val_loss: 16.0678 - val_categorical_accuracy: 0.0166\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.6235e-04 - categorical_accuracy: 0.9998 - val_loss: 16.2533 - val_categorical_accuracy: 0.0154\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.2073e-04 - categorical_accuracy: 1.0000 - val_loss: 13.1255 - val_categorical_accuracy: 0.0256\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.9915e-04 - categorical_accuracy: 1.0000 - val_loss: 14.0172 - val_categorical_accuracy: 0.0211\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.3996e-04 - categorical_accuracy: 1.0000 - val_loss: 14.5989 - val_categorical_accuracy: 0.1152\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.1268e-04 - categorical_accuracy: 1.0000 - val_loss: 7.7665 - val_categorical_accuracy: 0.1395\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.7611e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4837 - val_categorical_accuracy: 0.1011\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.1363e-04 - categorical_accuracy: 1.0000 - val_loss: 6.0267 - val_categorical_accuracy: 0.1440\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 15.3348 - val_categorical_accuracy: 0.1081\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.8395e-04 - categorical_accuracy: 1.0000 - val_loss: 5.6623 - val_categorical_accuracy: 0.1484\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.4626e-04 - categorical_accuracy: 0.9998 - val_loss: 7.0261 - val_categorical_accuracy: 0.1363\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.2598e-04 - categorical_accuracy: 1.0000 - val_loss: 9.7329 - val_categorical_accuracy: 0.1184\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.7936e-04 - categorical_accuracy: 1.0000 - val_loss: 6.3406 - val_categorical_accuracy: 0.1088\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.1764e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5738 - val_categorical_accuracy: 0.1305\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.2920e-04 - categorical_accuracy: 0.9998 - val_loss: 12.3406 - val_categorical_accuracy: 0.0409\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 5.4509 - val_categorical_accuracy: 0.1260\n",
      "Epoch 197/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.5034e-04 - categorical_accuracy: 0.9998 - val_loss: 11.7203 - val_categorical_accuracy: 0.1132\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0033 - categorical_accuracy: 0.9995 - val_loss: 18.9834 - val_categorical_accuracy: 0.0940\n",
      "Epoch 199/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0062 - categorical_accuracy: 0.9994 - val_loss: 20.0846 - val_categorical_accuracy: 0.0934\n",
      "Epoch 200/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0057 - categorical_accuracy: 0.9995 - val_loss: 10.2229 - val_categorical_accuracy: 0.0608\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0026 - categorical_accuracy: 0.9994 - val_loss: 14.4468 - val_categorical_accuracy: 0.0154\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0069 - categorical_accuracy: 0.9984 - val_loss: 16.4028 - val_categorical_accuracy: 0.0160\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0141 - categorical_accuracy: 0.9978 - val_loss: 12.9327 - val_categorical_accuracy: 0.0141\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0203 - categorical_accuracy: 0.9962 - val_loss: 8.7851 - val_categorical_accuracy: 0.1376\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0408 - categorical_accuracy: 0.9894 - val_loss: 16.5939 - val_categorical_accuracy: 0.0134\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0344 - categorical_accuracy: 0.9906 - val_loss: 7.5623 - val_categorical_accuracy: 0.0633\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0294 - categorical_accuracy: 0.9915 - val_loss: 17.3042 - val_categorical_accuracy: 0.0134\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0201 - categorical_accuracy: 0.9933 - val_loss: 17.6905 - val_categorical_accuracy: 0.0467\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0116 - categorical_accuracy: 0.9974 - val_loss: 12.4785 - val_categorical_accuracy: 0.0486\n",
      "Epoch 210/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0056 - categorical_accuracy: 0.9992 - val_loss: 16.9990 - val_categorical_accuracy: 0.0972\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0043 - categorical_accuracy: 0.9989 - val_loss: 16.8906 - val_categorical_accuracy: 0.0947\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0032 - categorical_accuracy: 0.9992 - val_loss: 16.8351 - val_categorical_accuracy: 0.1030\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0023 - categorical_accuracy: 0.9998 - val_loss: 17.0106 - val_categorical_accuracy: 0.1049\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0027 - categorical_accuracy: 0.9998 - val_loss: 17.4189 - val_categorical_accuracy: 0.1043\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 12.4224 - val_categorical_accuracy: 0.0909\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 8.8091 - val_categorical_accuracy: 0.0902\n",
      "Epoch 217/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 11.1808 - val_categorical_accuracy: 0.0512\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 7.0015 - val_categorical_accuracy: 0.1312\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 12.2632 - val_categorical_accuracy: 0.0934\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 14.7938 - val_categorical_accuracy: 0.0416\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 7.9595 - val_categorical_accuracy: 0.1235\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 9.1496 - val_categorical_accuracy: 0.1190\n",
      "Epoch 223/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 7.2277 - val_categorical_accuracy: 0.1260\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.2854e-04 - categorical_accuracy: 1.0000 - val_loss: 12.5232 - val_categorical_accuracy: 0.0480\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.2014e-04 - categorical_accuracy: 1.0000 - val_loss: 10.3877 - val_categorical_accuracy: 0.0653\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 9.1470 - val_categorical_accuracy: 0.1030\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.7251e-04 - categorical_accuracy: 1.0000 - val_loss: 11.4984 - val_categorical_accuracy: 0.1145\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.8710e-04 - categorical_accuracy: 1.0000 - val_loss: 6.6816 - val_categorical_accuracy: 0.1344\n",
      "Epoch 229/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0020 - categorical_accuracy: 0.9997 - val_loss: 8.9528 - val_categorical_accuracy: 0.1280\n",
      "Epoch 230/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 16.0165 - val_categorical_accuracy: 0.0250\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.0793e-04 - categorical_accuracy: 1.0000 - val_loss: 13.0929 - val_categorical_accuracy: 0.0422\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 6.3393 - val_categorical_accuracy: 0.1561\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.1562e-04 - categorical_accuracy: 0.9998 - val_loss: 15.9207 - val_categorical_accuracy: 0.0243\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.6544e-04 - categorical_accuracy: 0.9998 - val_loss: 7.7913 - val_categorical_accuracy: 0.1292\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.6157e-04 - categorical_accuracy: 1.0000 - val_loss: 7.6806 - val_categorical_accuracy: 0.1504\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.0165e-04 - categorical_accuracy: 1.0000 - val_loss: 7.8770 - val_categorical_accuracy: 0.1004\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.4259e-04 - categorical_accuracy: 0.9998 - val_loss: 19.0841 - val_categorical_accuracy: 0.1062\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.8108e-04 - categorical_accuracy: 1.0000 - val_loss: 14.5724 - val_categorical_accuracy: 0.1235\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.2653e-04 - categorical_accuracy: 1.0000 - val_loss: 7.9718 - val_categorical_accuracy: 0.1260\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.1980e-04 - categorical_accuracy: 1.0000 - val_loss: 6.0604 - val_categorical_accuracy: 0.1433\n",
      "Epoch 241/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 13.6194 - val_categorical_accuracy: 0.1100\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 7.3334 - val_categorical_accuracy: 0.1024\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.4144e-04 - categorical_accuracy: 1.0000 - val_loss: 14.0281 - val_categorical_accuracy: 0.0333\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.3004e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5483 - val_categorical_accuracy: 0.1196\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.9571e-04 - categorical_accuracy: 1.0000 - val_loss: 7.1741 - val_categorical_accuracy: 0.1305\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.8129e-04 - categorical_accuracy: 1.0000 - val_loss: 9.3224 - val_categorical_accuracy: 0.0832\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.3341e-04 - categorical_accuracy: 0.9998 - val_loss: 19.1761 - val_categorical_accuracy: 0.1004\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0020 - categorical_accuracy: 0.9998 - val_loss: 14.4126 - val_categorical_accuracy: 0.0358\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.1223e-04 - categorical_accuracy: 1.0000 - val_loss: 18.8416 - val_categorical_accuracy: 0.0186\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.7157e-04 - categorical_accuracy: 1.0000 - val_loss: 16.7861 - val_categorical_accuracy: 0.0224\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.2316e-04 - categorical_accuracy: 1.0000 - val_loss: 6.4049 - val_categorical_accuracy: 0.1574\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.8640e-04 - categorical_accuracy: 1.0000 - val_loss: 7.1668 - val_categorical_accuracy: 0.1478\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0023 - categorical_accuracy: 0.9997 - val_loss: 8.8637 - val_categorical_accuracy: 0.1164\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 11.3597 - val_categorical_accuracy: 0.0627\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.7978e-04 - categorical_accuracy: 1.0000 - val_loss: 8.2038 - val_categorical_accuracy: 0.1190\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.8910e-04 - categorical_accuracy: 1.0000 - val_loss: 7.7173 - val_categorical_accuracy: 0.1299\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.5664e-04 - categorical_accuracy: 1.0000 - val_loss: 16.3575 - val_categorical_accuracy: 0.0211\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.8609e-04 - categorical_accuracy: 1.0000 - val_loss: 14.4471 - val_categorical_accuracy: 0.0333\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.8447e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2778 - val_categorical_accuracy: 0.1145\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.2453e-04 - categorical_accuracy: 1.0000 - val_loss: 13.9334 - val_categorical_accuracy: 0.1203\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.4775e-04 - categorical_accuracy: 1.0000 - val_loss: 8.6383 - val_categorical_accuracy: 0.0972\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5449e-04 - categorical_accuracy: 1.0000 - val_loss: 7.9639 - val_categorical_accuracy: 0.1299\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.3332e-04 - categorical_accuracy: 1.0000 - val_loss: 10.6095 - val_categorical_accuracy: 0.1203\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.9493e-04 - categorical_accuracy: 1.0000 - val_loss: 6.6556 - val_categorical_accuracy: 0.1427\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.9542e-04 - categorical_accuracy: 1.0000 - val_loss: 8.2893 - val_categorical_accuracy: 0.1350\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.3849e-04 - categorical_accuracy: 1.0000 - val_loss: 13.0662 - val_categorical_accuracy: 0.0557\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0030 - categorical_accuracy: 0.9995 - val_loss: 17.4465 - val_categorical_accuracy: 0.1011\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9994 - val_loss: 17.7542 - val_categorical_accuracy: 0.0128\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0047 - categorical_accuracy: 0.9989 - val_loss: 16.2940 - val_categorical_accuracy: 0.0166\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0119 - categorical_accuracy: 0.9973 - val_loss: 16.8581 - val_categorical_accuracy: 0.0128\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0244 - categorical_accuracy: 0.9934 - val_loss: 23.6908 - val_categorical_accuracy: 0.0128\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0532 - categorical_accuracy: 0.9875 - val_loss: 20.0111 - val_categorical_accuracy: 0.0128\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0485 - categorical_accuracy: 0.9872 - val_loss: 21.4545 - val_categorical_accuracy: 0.0128\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0285 - categorical_accuracy: 0.9920 - val_loss: 24.4977 - val_categorical_accuracy: 0.0467\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0168 - categorical_accuracy: 0.9963 - val_loss: 11.1438 - val_categorical_accuracy: 0.0218\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0055 - categorical_accuracy: 0.9992 - val_loss: 16.4643 - val_categorical_accuracy: 0.0141\n",
      "Epoch 277/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0049 - categorical_accuracy: 0.9986 - val_loss: 16.4001 - val_categorical_accuracy: 0.0134\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0033 - categorical_accuracy: 0.9992 - val_loss: 20.4480 - val_categorical_accuracy: 0.0128\n",
      "Epoch 279/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0032 - categorical_accuracy: 0.9998 - val_loss: 17.4736 - val_categorical_accuracy: 0.0672\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0023 - categorical_accuracy: 0.9998 - val_loss: 15.5916 - val_categorical_accuracy: 0.0672\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0019 - categorical_accuracy: 0.9997 - val_loss: 14.2387 - val_categorical_accuracy: 0.0902\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 13.0516 - val_categorical_accuracy: 0.0896\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 14.1026 - val_categorical_accuracy: 0.0819\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0017 - categorical_accuracy: 0.9995 - val_loss: 19.2108 - val_categorical_accuracy: 0.0966\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 14.7130 - val_categorical_accuracy: 0.1056\n",
      "Epoch 286/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.5412e-04 - categorical_accuracy: 1.0000 - val_loss: 9.5943 - val_categorical_accuracy: 0.1088\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 11.4550 - val_categorical_accuracy: 0.1043\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.7230e-04 - categorical_accuracy: 0.9998 - val_loss: 15.8410 - val_categorical_accuracy: 0.1068\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.2907e-04 - categorical_accuracy: 1.0000 - val_loss: 12.8934 - val_categorical_accuracy: 0.1120\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 23.8435 - val_categorical_accuracy: 0.0960\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.5083e-04 - categorical_accuracy: 0.9998 - val_loss: 14.9712 - val_categorical_accuracy: 0.1113\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.3053e-04 - categorical_accuracy: 0.9998 - val_loss: 11.0457 - val_categorical_accuracy: 0.1171\n",
      "Epoch 293/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.6707e-04 - categorical_accuracy: 1.0000 - val_loss: 6.8763 - val_categorical_accuracy: 0.1721\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.7492e-04 - categorical_accuracy: 0.9997 - val_loss: 11.3773 - val_categorical_accuracy: 0.0589\n",
      "Epoch 295/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.0318e-04 - categorical_accuracy: 1.0000 - val_loss: 8.5882 - val_categorical_accuracy: 0.1254\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.8888e-04 - categorical_accuracy: 0.9997 - val_loss: 14.2930 - val_categorical_accuracy: 0.0377\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.2198e-04 - categorical_accuracy: 1.0000 - val_loss: 20.6928 - val_categorical_accuracy: 0.1043\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 15.4545 - val_categorical_accuracy: 0.1164\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.6730e-04 - categorical_accuracy: 0.9998 - val_loss: 17.4753 - val_categorical_accuracy: 0.0256\n",
      "Epoch 300/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.7316e-04 - categorical_accuracy: 1.0000 - val_loss: 21.8598 - val_categorical_accuracy: 0.0966\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 11.4432 - val_categorical_accuracy: 0.1228\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.9398e-04 - categorical_accuracy: 1.0000 - val_loss: 11.1070 - val_categorical_accuracy: 0.0736\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.1985e-04 - categorical_accuracy: 1.0000 - val_loss: 8.2674 - val_categorical_accuracy: 0.1273\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.4534e-04 - categorical_accuracy: 1.0000 - val_loss: 16.4947 - val_categorical_accuracy: 0.1113\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.9724e-04 - categorical_accuracy: 1.0000 - val_loss: 8.9198 - val_categorical_accuracy: 0.1337\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 2.7562e-04 - categorical_accuracy: 1.0000 - val_loss: 9.4475 - val_categorical_accuracy: 0.1190\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.8249e-04 - categorical_accuracy: 1.0000 - val_loss: 9.4176 - val_categorical_accuracy: 0.1216\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.5127e-04 - categorical_accuracy: 1.0000 - val_loss: 6.9248 - val_categorical_accuracy: 0.1644\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.7485e-04 - categorical_accuracy: 1.0000 - val_loss: 8.5489 - val_categorical_accuracy: 0.1414\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 8.4535e-04 - categorical_accuracy: 0.9997 - val_loss: 23.5913 - val_categorical_accuracy: 0.0909\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 16.9000 - val_categorical_accuracy: 0.0627\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 18.7096 - val_categorical_accuracy: 0.0218\n",
      "Epoch 313/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.8415e-04 - categorical_accuracy: 1.0000 - val_loss: 16.8731 - val_categorical_accuracy: 0.0294\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.0570e-04 - categorical_accuracy: 1.0000 - val_loss: 17.3494 - val_categorical_accuracy: 0.0269\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 3.3634e-04 - categorical_accuracy: 1.0000 - val_loss: 6.9841 - val_categorical_accuracy: 0.1567\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.0700e-04 - categorical_accuracy: 1.0000 - val_loss: 11.2091 - val_categorical_accuracy: 0.1248\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 6.9259e-04 - categorical_accuracy: 0.9998 - val_loss: 25.8953 - val_categorical_accuracy: 0.0940\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0016 - categorical_accuracy: 0.9998 - val_loss: 14.0287 - val_categorical_accuracy: 0.0397\n",
      "Epoch 319/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.4044e-04 - categorical_accuracy: 1.0000 - val_loss: 15.1623 - val_categorical_accuracy: 0.0345\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9998 - val_loss: 12.3224 - val_categorical_accuracy: 0.1043\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.1127e-04 - categorical_accuracy: 0.9998 - val_loss: 9.6589 - val_categorical_accuracy: 0.1107\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.2129e-04 - categorical_accuracy: 0.9998 - val_loss: 16.7905 - val_categorical_accuracy: 0.0256\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.2492e-04 - categorical_accuracy: 1.0000 - val_loss: 9.1319 - val_categorical_accuracy: 0.1120\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.3232e-04 - categorical_accuracy: 1.0000 - val_loss: 7.1402 - val_categorical_accuracy: 0.1382\n",
      "Epoch 325/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.5944e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7582 - val_categorical_accuracy: 0.1542\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.9276e-04 - categorical_accuracy: 1.0000 - val_loss: 8.3151 - val_categorical_accuracy: 0.1427\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.8159e-04 - categorical_accuracy: 1.0000 - val_loss: 10.0631 - val_categorical_accuracy: 0.1171\n",
      "Epoch 328/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.9458e-04 - categorical_accuracy: 1.0000 - val_loss: 11.7201 - val_categorical_accuracy: 0.0601\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.1719e-04 - categorical_accuracy: 1.0000 - val_loss: 19.8079 - val_categorical_accuracy: 0.1004\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.7345e-04 - categorical_accuracy: 0.9998 - val_loss: 15.1597 - val_categorical_accuracy: 0.1036\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 13.4123 - val_categorical_accuracy: 0.0154\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0018 - categorical_accuracy: 0.9995 - val_loss: 15.7403 - val_categorical_accuracy: 0.0147\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0029 - categorical_accuracy: 0.9995 - val_loss: 15.7943 - val_categorical_accuracy: 0.0909\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.7301e-04 - categorical_accuracy: 1.0000 - val_loss: 10.8593 - val_categorical_accuracy: 0.1062\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.0656e-04 - categorical_accuracy: 0.9998 - val_loss: 12.3629 - val_categorical_accuracy: 0.1062\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.2950e-04 - categorical_accuracy: 1.0000 - val_loss: 16.9818 - val_categorical_accuracy: 0.0390\n",
      "Epoch 337/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.9675e-04 - categorical_accuracy: 1.0000 - val_loss: 14.5063 - val_categorical_accuracy: 0.0505\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.2346e-04 - categorical_accuracy: 1.0000 - val_loss: 10.7416 - val_categorical_accuracy: 0.1068\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.1189e-04 - categorical_accuracy: 1.0000 - val_loss: 16.6501 - val_categorical_accuracy: 0.0940\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.7272e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4456 - val_categorical_accuracy: 0.1440\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.3869e-04 - categorical_accuracy: 0.9998 - val_loss: 17.0115 - val_categorical_accuracy: 0.0774\n",
      "Epoch 342/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.2097e-04 - categorical_accuracy: 1.0000 - val_loss: 16.9260 - val_categorical_accuracy: 0.0269\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.0544e-04 - categorical_accuracy: 1.0000 - val_loss: 9.0780 - val_categorical_accuracy: 0.1305\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.8617e-04 - categorical_accuracy: 0.9998 - val_loss: 18.8359 - val_categorical_accuracy: 0.0985\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0010 - categorical_accuracy: 0.9997 - val_loss: 25.5575 - val_categorical_accuracy: 0.0940\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.8964e-04 - categorical_accuracy: 0.9998 - val_loss: 23.9198 - val_categorical_accuracy: 0.0972\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 19.8721 - val_categorical_accuracy: 0.1036\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.3576e-04 - categorical_accuracy: 1.0000 - val_loss: 19.5494 - val_categorical_accuracy: 0.1113\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.1182e-04 - categorical_accuracy: 0.9998 - val_loss: 18.3088 - val_categorical_accuracy: 0.0192\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0017 - categorical_accuracy: 0.9995 - val_loss: 15.6745 - val_categorical_accuracy: 0.0141\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 27.2941 - val_categorical_accuracy: 0.0940\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0049 - categorical_accuracy: 0.9987 - val_loss: 15.7197 - val_categorical_accuracy: 0.1376\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0416 - categorical_accuracy: 0.9906 - val_loss: 25.7511 - val_categorical_accuracy: 0.0467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0564 - categorical_accuracy: 0.9901 - val_loss: 26.1998 - val_categorical_accuracy: 0.0467\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0290 - categorical_accuracy: 0.9938 - val_loss: 19.5053 - val_categorical_accuracy: 0.0486\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0137 - categorical_accuracy: 0.9962 - val_loss: 18.6178 - val_categorical_accuracy: 0.0480\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0052 - categorical_accuracy: 0.9990 - val_loss: 16.8726 - val_categorical_accuracy: 0.0928\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0042 - categorical_accuracy: 0.9989 - val_loss: 19.9527 - val_categorical_accuracy: 0.0972\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 18.0234 - val_categorical_accuracy: 0.1056\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 12.1768 - val_categorical_accuracy: 0.0998\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.0625e-04 - categorical_accuracy: 1.0000 - val_loss: 10.3651 - val_categorical_accuracy: 0.1062\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.2268e-04 - categorical_accuracy: 1.0000 - val_loss: 17.2125 - val_categorical_accuracy: 0.0877\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 9.4459e-04 - categorical_accuracy: 1.0000 - val_loss: 14.0985 - val_categorical_accuracy: 0.0870\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.1262e-04 - categorical_accuracy: 1.0000 - val_loss: 10.9606 - val_categorical_accuracy: 0.1081\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 7.7618 - val_categorical_accuracy: 0.1593\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.2775e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2062 - val_categorical_accuracy: 0.1683\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.0634e-04 - categorical_accuracy: 1.0000 - val_loss: 6.9305 - val_categorical_accuracy: 0.1740\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 7.0323 - val_categorical_accuracy: 0.1791\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.8784e-04 - categorical_accuracy: 0.9998 - val_loss: 7.2515 - val_categorical_accuracy: 0.1715\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 7.1276 - val_categorical_accuracy: 0.1663\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.2213e-04 - categorical_accuracy: 1.0000 - val_loss: 6.8099 - val_categorical_accuracy: 0.1670\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 8.7953e-04 - categorical_accuracy: 0.9998 - val_loss: 6.7486 - val_categorical_accuracy: 0.1683\n",
      "Epoch 373/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 7.1188 - val_categorical_accuracy: 0.1670\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 4.1958e-04 - categorical_accuracy: 1.0000 - val_loss: 6.8001 - val_categorical_accuracy: 0.1651\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.8682e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7560 - val_categorical_accuracy: 0.1651\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.7978e-04 - categorical_accuracy: 0.9998 - val_loss: 6.7325 - val_categorical_accuracy: 0.1715\n",
      "Epoch 377/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.7066e-04 - categorical_accuracy: 0.9998 - val_loss: 6.8393 - val_categorical_accuracy: 0.1631\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.6461e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7100 - val_categorical_accuracy: 0.1740\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.9400e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7706 - val_categorical_accuracy: 0.1727\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9995 - val_loss: 6.6984 - val_categorical_accuracy: 0.1689\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 7.5128 - val_categorical_accuracy: 0.1401\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.5317e-04 - categorical_accuracy: 1.0000 - val_loss: 6.8742 - val_categorical_accuracy: 0.1663\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.4579e-04 - categorical_accuracy: 1.0000 - val_loss: 6.8065 - val_categorical_accuracy: 0.1599\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.6182e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7021 - val_categorical_accuracy: 0.1663\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.4604e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7554 - val_categorical_accuracy: 0.1683\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.9897e-04 - categorical_accuracy: 0.9998 - val_loss: 6.7759 - val_categorical_accuracy: 0.1689\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.3526e-04 - categorical_accuracy: 0.9997 - val_loss: 6.7326 - val_categorical_accuracy: 0.1695\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.9818e-04 - categorical_accuracy: 1.0000 - val_loss: 6.9367 - val_categorical_accuracy: 0.1740\n",
      "Epoch 389/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 3.0924e-04 - categorical_accuracy: 1.0000 - val_loss: 6.7094 - val_categorical_accuracy: 0.1619\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 7.1692 - val_categorical_accuracy: 0.1702\n",
      "Epoch 391/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.2923e-04 - categorical_accuracy: 1.0000 - val_loss: 7.0650 - val_categorical_accuracy: 0.1708\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.4129e-04 - categorical_accuracy: 1.0000 - val_loss: 6.8882 - val_categorical_accuracy: 0.1721\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.6648e-04 - categorical_accuracy: 0.9997 - val_loss: 6.9204 - val_categorical_accuracy: 0.1708\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.1922e-04 - categorical_accuracy: 1.0000 - val_loss: 6.9141 - val_categorical_accuracy: 0.1695\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.3966e-04 - categorical_accuracy: 1.0000 - val_loss: 7.0240 - val_categorical_accuracy: 0.1625\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.1146e-04 - categorical_accuracy: 0.9998 - val_loss: 7.2893 - val_categorical_accuracy: 0.1663\n",
      "Epoch 397/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.3470e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2387 - val_categorical_accuracy: 0.1676\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.5926e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2401 - val_categorical_accuracy: 0.1734\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.7257e-04 - categorical_accuracy: 1.0000 - val_loss: 6.9181 - val_categorical_accuracy: 0.1766\n",
      "Epoch 400/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 7.2120 - val_categorical_accuracy: 0.1798\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.6444e-04 - categorical_accuracy: 0.9997 - val_loss: 7.2396 - val_categorical_accuracy: 0.1721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.2751e-04 - categorical_accuracy: 0.9998 - val_loss: 9.8779 - val_categorical_accuracy: 0.1190\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 7.6898 - val_categorical_accuracy: 0.1420\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.4809e-04 - categorical_accuracy: 0.9998 - val_loss: 8.6186 - val_categorical_accuracy: 0.1228\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.4208e-04 - categorical_accuracy: 0.9998 - val_loss: 9.6487 - val_categorical_accuracy: 0.1164\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 10.1474 - val_categorical_accuracy: 0.1120\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.1931e-04 - categorical_accuracy: 0.9998 - val_loss: 8.7999 - val_categorical_accuracy: 0.1203\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 9.5227 - val_categorical_accuracy: 0.0960\n",
      "Epoch 409/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0033 - categorical_accuracy: 0.9997 - val_loss: 9.7975 - val_categorical_accuracy: 0.1254\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0028 - categorical_accuracy: 0.9995 - val_loss: 10.7823 - val_categorical_accuracy: 0.1363\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 0.9995 - val_loss: 9.8863 - val_categorical_accuracy: 0.1286\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 8.3464e-04 - categorical_accuracy: 0.9997 - val_loss: 8.5069 - val_categorical_accuracy: 0.1209\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.2895e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5093 - val_categorical_accuracy: 0.1625\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.5476e-04 - categorical_accuracy: 1.0000 - val_loss: 7.7084 - val_categorical_accuracy: 0.1670\n",
      "Epoch 415/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.4823e-04 - categorical_accuracy: 1.0000 - val_loss: 8.5333 - val_categorical_accuracy: 0.1510\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.1832e-04 - categorical_accuracy: 1.0000 - val_loss: 8.0578 - val_categorical_accuracy: 0.1587\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.2614e-04 - categorical_accuracy: 1.0000 - val_loss: 8.2587 - val_categorical_accuracy: 0.1599\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.3683e-04 - categorical_accuracy: 0.9998 - val_loss: 8.1158 - val_categorical_accuracy: 0.1670\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.3951e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5808 - val_categorical_accuracy: 0.1561\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.7728e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4487 - val_categorical_accuracy: 0.1702\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.8054e-04 - categorical_accuracy: 1.0000 - val_loss: 7.1246 - val_categorical_accuracy: 0.1536\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.2774e-04 - categorical_accuracy: 1.0000 - val_loss: 7.2298 - val_categorical_accuracy: 0.1593\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.5315e-04 - categorical_accuracy: 0.9998 - val_loss: 7.7678 - val_categorical_accuracy: 0.1548\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.1822e-04 - categorical_accuracy: 1.0000 - val_loss: 7.1750 - val_categorical_accuracy: 0.1606\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.1921e-04 - categorical_accuracy: 0.9998 - val_loss: 7.4934 - val_categorical_accuracy: 0.1401\n",
      "Epoch 426/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.2522e-04 - categorical_accuracy: 0.9998 - val_loss: 7.5693 - val_categorical_accuracy: 0.1478\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 7.8170 - val_categorical_accuracy: 0.1619\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.1083e-04 - categorical_accuracy: 0.9998 - val_loss: 9.7737 - val_categorical_accuracy: 0.1164\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.0465e-04 - categorical_accuracy: 0.9998 - val_loss: 7.9327 - val_categorical_accuracy: 0.1254\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.9391e-04 - categorical_accuracy: 1.0000 - val_loss: 10.5699 - val_categorical_accuracy: 0.1689\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.9864e-04 - categorical_accuracy: 1.0000 - val_loss: 8.8455 - val_categorical_accuracy: 0.1727\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.8050e-04 - categorical_accuracy: 1.0000 - val_loss: 8.0959 - val_categorical_accuracy: 0.1638\n",
      "Epoch 433/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.8301e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4769 - val_categorical_accuracy: 0.1599\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 12.1895 - val_categorical_accuracy: 0.0710\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0043 - categorical_accuracy: 0.9989 - val_loss: 14.8136 - val_categorical_accuracy: 0.0473\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0078 - categorical_accuracy: 0.9982 - val_loss: 16.7853 - val_categorical_accuracy: 0.0333\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0097 - categorical_accuracy: 0.9976 - val_loss: 21.0609 - val_categorical_accuracy: 0.0256\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0092 - categorical_accuracy: 0.9982 - val_loss: 17.8108 - val_categorical_accuracy: 0.0301\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0121 - categorical_accuracy: 0.9970 - val_loss: 17.3314 - val_categorical_accuracy: 0.0313\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0075 - categorical_accuracy: 0.9982 - val_loss: 20.8963 - val_categorical_accuracy: 0.0205\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0101 - categorical_accuracy: 0.9982 - val_loss: 18.3786 - val_categorical_accuracy: 0.0186\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0047 - categorical_accuracy: 0.9987 - val_loss: 17.1073 - val_categorical_accuracy: 0.0358\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0070 - categorical_accuracy: 0.9981 - val_loss: 14.9238 - val_categorical_accuracy: 0.0768\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0037 - categorical_accuracy: 0.9990 - val_loss: 15.2521 - val_categorical_accuracy: 0.0352\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0029 - categorical_accuracy: 0.9990 - val_loss: 15.4821 - val_categorical_accuracy: 0.0569\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0025 - categorical_accuracy: 0.9994 - val_loss: 15.0255 - val_categorical_accuracy: 0.0435\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.2220e-04 - categorical_accuracy: 1.0000 - val_loss: 12.9581 - val_categorical_accuracy: 0.0493\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 10.1586 - val_categorical_accuracy: 0.1120\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.3011e-04 - categorical_accuracy: 1.0000 - val_loss: 10.3102 - val_categorical_accuracy: 0.1574\n",
      "Epoch 450/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 6.9555e-04 - categorical_accuracy: 1.0000 - val_loss: 9.2566 - val_categorical_accuracy: 0.1516\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.7348e-04 - categorical_accuracy: 0.9998 - val_loss: 8.6611 - val_categorical_accuracy: 0.1529\n",
      "Epoch 452/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.5918e-04 - categorical_accuracy: 1.0000 - val_loss: 8.6631 - val_categorical_accuracy: 0.1446\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.8839e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5795 - val_categorical_accuracy: 0.1587\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.4920e-04 - categorical_accuracy: 1.0000 - val_loss: 7.3607 - val_categorical_accuracy: 0.1625\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.4742e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5036 - val_categorical_accuracy: 0.1555\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.7426e-04 - categorical_accuracy: 1.0000 - val_loss: 7.3493 - val_categorical_accuracy: 0.1561\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.9951e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4223 - val_categorical_accuracy: 0.1593\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.7372e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4444 - val_categorical_accuracy: 0.1612\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5627e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4633 - val_categorical_accuracy: 0.1612\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.2283e-04 - categorical_accuracy: 0.9998 - val_loss: 8.2007 - val_categorical_accuracy: 0.1548\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 7.4611 - val_categorical_accuracy: 0.1657\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.5989e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5798 - val_categorical_accuracy: 0.1542\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.8207e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5484 - val_categorical_accuracy: 0.1548\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.4729e-04 - categorical_accuracy: 1.0000 - val_loss: 7.6524 - val_categorical_accuracy: 0.1555\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.2654e-04 - categorical_accuracy: 1.0000 - val_loss: 9.1762 - val_categorical_accuracy: 0.1440\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.4048e-04 - categorical_accuracy: 1.0000 - val_loss: 7.6548 - val_categorical_accuracy: 0.1676\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.5014e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5442 - val_categorical_accuracy: 0.1606\n",
      "Epoch 468/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.8957e-04 - categorical_accuracy: 1.0000 - val_loss: 7.8482 - val_categorical_accuracy: 0.1548\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.3497e-04 - categorical_accuracy: 1.0000 - val_loss: 7.8091 - val_categorical_accuracy: 0.1574\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.3155e-04 - categorical_accuracy: 0.9997 - val_loss: 7.4076 - val_categorical_accuracy: 0.1670\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.6445e-04 - categorical_accuracy: 1.0000 - val_loss: 11.8258 - val_categorical_accuracy: 0.0781\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 15.6479 - val_categorical_accuracy: 0.0365\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 5.3943e-04 - categorical_accuracy: 0.9998 - val_loss: 17.1503 - val_categorical_accuracy: 0.0333\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.3880e-04 - categorical_accuracy: 0.9997 - val_loss: 17.8030 - val_categorical_accuracy: 0.0282\n",
      "Epoch 475/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0020 - categorical_accuracy: 0.9997 - val_loss: 11.6008 - val_categorical_accuracy: 0.0787\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 4.8806e-04 - categorical_accuracy: 0.9998 - val_loss: 10.3624 - val_categorical_accuracy: 0.1478\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 2.9012e-04 - categorical_accuracy: 1.0000 - val_loss: 8.7300 - val_categorical_accuracy: 0.1254\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.9034e-04 - categorical_accuracy: 1.0000 - val_loss: 7.7627 - val_categorical_accuracy: 0.1446\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.7243e-04 - categorical_accuracy: 1.0000 - val_loss: 7.8322 - val_categorical_accuracy: 0.1510\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 3.1594e-04 - categorical_accuracy: 1.0000 - val_loss: 18.3315 - val_categorical_accuracy: 0.0557\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.0701e-04 - categorical_accuracy: 1.0000 - val_loss: 17.8781 - val_categorical_accuracy: 0.0307\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.2927e-04 - categorical_accuracy: 1.0000 - val_loss: 16.4154 - val_categorical_accuracy: 0.0518\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 14.3788 - val_categorical_accuracy: 0.1164\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 14.6331 - val_categorical_accuracy: 0.0576\n",
      "Epoch 485/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.0367e-04 - categorical_accuracy: 1.0000 - val_loss: 12.9860 - val_categorical_accuracy: 0.0697\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 3.4498e-04 - categorical_accuracy: 1.0000 - val_loss: 13.3733 - val_categorical_accuracy: 0.0595\n",
      "Epoch 487/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.1392e-04 - categorical_accuracy: 1.0000 - val_loss: 10.3418 - val_categorical_accuracy: 0.0934\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.5996e-04 - categorical_accuracy: 1.0000 - val_loss: 8.8045 - val_categorical_accuracy: 0.1216\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.0139e-04 - categorical_accuracy: 0.9998 - val_loss: 8.3549 - val_categorical_accuracy: 0.1555\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.6439e-04 - categorical_accuracy: 1.0000 - val_loss: 8.8951 - val_categorical_accuracy: 0.1574\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.6983e-04 - categorical_accuracy: 1.0000 - val_loss: 7.8521 - val_categorical_accuracy: 0.1561\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.3646e-04 - categorical_accuracy: 1.0000 - val_loss: 8.8304 - val_categorical_accuracy: 0.1523\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.6319e-04 - categorical_accuracy: 1.0000 - val_loss: 9.1114 - val_categorical_accuracy: 0.1510\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 6.1636e-04 - categorical_accuracy: 0.9998 - val_loss: 13.3792 - val_categorical_accuracy: 0.1241\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 10.5378 - val_categorical_accuracy: 0.1331\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.6520e-04 - categorical_accuracy: 1.0000 - val_loss: 9.8128 - val_categorical_accuracy: 0.1401\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9995 - val_loss: 8.3894 - val_categorical_accuracy: 0.1427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 8.3677 - val_categorical_accuracy: 0.1433\n",
      "Epoch 499/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.3703e-04 - categorical_accuracy: 0.9998 - val_loss: 13.6412 - val_categorical_accuracy: 0.0979\n",
      "Epoch 500/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.8757e-04 - categorical_accuracy: 0.9997 - val_loss: 18.7018 - val_categorical_accuracy: 0.0218\n",
      "Finished.\n",
      "Training Swish Uniform Activation Neural Network...\n",
      "Epoch 1/500\n",
      "49/49 [==============================] - 4s 68ms/step - loss: 2.8697 - categorical_accuracy: 0.0899 - val_loss: 7.0834 - val_categorical_accuracy: 0.0128\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 4s 77ms/step - loss: 2.4725 - categorical_accuracy: 0.2287 - val_loss: 2.7351 - val_categorical_accuracy: 0.0979\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.1775 - categorical_accuracy: 0.3465 - val_loss: 5.5737 - val_categorical_accuracy: 0.1644\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.8972 - categorical_accuracy: 0.4403 - val_loss: 2.9044 - val_categorical_accuracy: 0.1088\n",
      "Epoch 5/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.6832 - categorical_accuracy: 0.5202 - val_loss: 6.9061 - val_categorical_accuracy: 0.1651\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.5021 - categorical_accuracy: 0.5845 - val_loss: 19.6364 - val_categorical_accuracy: 0.1644\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.3507 - categorical_accuracy: 0.6496 - val_loss: 6.3587 - val_categorical_accuracy: 0.1638\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.1971 - categorical_accuracy: 0.7069 - val_loss: 4.5170 - val_categorical_accuracy: 0.1657\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0524 - categorical_accuracy: 0.7514 - val_loss: 13.9979 - val_categorical_accuracy: 0.1644\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9198 - categorical_accuracy: 0.7835 - val_loss: 5.7881 - val_categorical_accuracy: 0.1056\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.8168 - categorical_accuracy: 0.8067 - val_loss: 3.3530 - val_categorical_accuracy: 0.1030\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.7180 - categorical_accuracy: 0.8363 - val_loss: 3.6693 - val_categorical_accuracy: 0.0992\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.6423 - categorical_accuracy: 0.8556 - val_loss: 3.8339 - val_categorical_accuracy: 0.0960\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.5650 - categorical_accuracy: 0.8691 - val_loss: 4.0113 - val_categorical_accuracy: 0.0960\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.5158 - categorical_accuracy: 0.8832 - val_loss: 3.8566 - val_categorical_accuracy: 0.0659\n",
      "Epoch 16/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.4625 - categorical_accuracy: 0.8936 - val_loss: 5.2664 - val_categorical_accuracy: 0.1030\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.4189 - categorical_accuracy: 0.9072 - val_loss: 7.1118 - val_categorical_accuracy: 0.1203\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.3827 - categorical_accuracy: 0.9201 - val_loss: 7.3434 - val_categorical_accuracy: 0.1017\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.3508 - categorical_accuracy: 0.9241 - val_loss: 5.0005 - val_categorical_accuracy: 0.1152\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.3216 - categorical_accuracy: 0.9337 - val_loss: 7.0498 - val_categorical_accuracy: 0.1280\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.2813 - categorical_accuracy: 0.9461 - val_loss: 6.4177 - val_categorical_accuracy: 0.0729\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2503 - categorical_accuracy: 0.9566 - val_loss: 6.9942 - val_categorical_accuracy: 0.1158\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.2273 - categorical_accuracy: 0.9625 - val_loss: 9.1953 - val_categorical_accuracy: 0.1599\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2056 - categorical_accuracy: 0.9649 - val_loss: 5.0908 - val_categorical_accuracy: 0.0729\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.1802 - categorical_accuracy: 0.9728 - val_loss: 5.5148 - val_categorical_accuracy: 0.1036\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.1654 - categorical_accuracy: 0.9770 - val_loss: 4.5176 - val_categorical_accuracy: 0.1132\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1545 - categorical_accuracy: 0.9810 - val_loss: 8.8874 - val_categorical_accuracy: 0.0717\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1520 - categorical_accuracy: 0.9798 - val_loss: 8.3230 - val_categorical_accuracy: 0.1574\n",
      "Epoch 29/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.1453 - categorical_accuracy: 0.9779 - val_loss: 11.3821 - val_categorical_accuracy: 0.0710\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1405 - categorical_accuracy: 0.9806 - val_loss: 5.4415 - val_categorical_accuracy: 0.1216\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.1363 - categorical_accuracy: 0.9802 - val_loss: 14.6632 - val_categorical_accuracy: 0.1555\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.1200 - categorical_accuracy: 0.9832 - val_loss: 6.0568 - val_categorical_accuracy: 0.1504\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0993 - categorical_accuracy: 0.9886 - val_loss: 20.7421 - val_categorical_accuracy: 0.1574\n",
      "Epoch 34/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0904 - categorical_accuracy: 0.9872 - val_loss: 26.9275 - val_categorical_accuracy: 0.1651\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0866 - categorical_accuracy: 0.9894 - val_loss: 6.6181 - val_categorical_accuracy: 0.0717\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0871 - categorical_accuracy: 0.9883 - val_loss: 5.5533 - val_categorical_accuracy: 0.1120\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0748 - categorical_accuracy: 0.9901 - val_loss: 7.2159 - val_categorical_accuracy: 0.1049\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0686 - categorical_accuracy: 0.9914 - val_loss: 4.4526 - val_categorical_accuracy: 0.1158\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0681 - categorical_accuracy: 0.9917 - val_loss: 5.7009 - val_categorical_accuracy: 0.1472\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0667 - categorical_accuracy: 0.9906 - val_loss: 11.1509 - val_categorical_accuracy: 0.1516\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0602 - categorical_accuracy: 0.9926 - val_loss: 6.0671 - val_categorical_accuracy: 0.1452\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0550 - categorical_accuracy: 0.9939 - val_loss: 7.3559 - val_categorical_accuracy: 0.1292\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0537 - categorical_accuracy: 0.9933 - val_loss: 8.5684 - val_categorical_accuracy: 0.1369\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0533 - categorical_accuracy: 0.9930 - val_loss: 5.3881 - val_categorical_accuracy: 0.1152\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0511 - categorical_accuracy: 0.9931 - val_loss: 5.5264 - val_categorical_accuracy: 0.0979\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0496 - categorical_accuracy: 0.9925 - val_loss: 5.8156 - val_categorical_accuracy: 0.1235\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0525 - categorical_accuracy: 0.9923 - val_loss: 6.1990 - val_categorical_accuracy: 0.0934\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0528 - categorical_accuracy: 0.9922 - val_loss: 7.4580 - val_categorical_accuracy: 0.0742\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0546 - categorical_accuracy: 0.9926 - val_loss: 6.0430 - val_categorical_accuracy: 0.1177\n",
      "Epoch 50/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0619 - categorical_accuracy: 0.9891 - val_loss: 6.4032 - val_categorical_accuracy: 0.0883\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0551 - categorical_accuracy: 0.9917 - val_loss: 6.7057 - val_categorical_accuracy: 0.0915\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0620 - categorical_accuracy: 0.9912 - val_loss: 6.3194 - val_categorical_accuracy: 0.1075\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0590 - categorical_accuracy: 0.9906 - val_loss: 5.8458 - val_categorical_accuracy: 0.1318\n",
      "Epoch 54/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0545 - categorical_accuracy: 0.9909 - val_loss: 24.5499 - val_categorical_accuracy: 0.1516\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0719 - categorical_accuracy: 0.9861 - val_loss: 8.0102 - val_categorical_accuracy: 0.0237\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0972 - categorical_accuracy: 0.9827 - val_loss: 11.3616 - val_categorical_accuracy: 0.0390\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1132 - categorical_accuracy: 0.9800 - val_loss: 6.9351 - val_categorical_accuracy: 0.0729\n",
      "Epoch 58/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0989 - categorical_accuracy: 0.9805 - val_loss: 7.0645 - val_categorical_accuracy: 0.0691\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0821 - categorical_accuracy: 0.9832 - val_loss: 11.3205 - val_categorical_accuracy: 0.0672\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0808 - categorical_accuracy: 0.9848 - val_loss: 9.2507 - val_categorical_accuracy: 0.0531\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0747 - categorical_accuracy: 0.9861 - val_loss: 11.1274 - val_categorical_accuracy: 0.0755\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0645 - categorical_accuracy: 0.9874 - val_loss: 9.7700 - val_categorical_accuracy: 0.0857\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0614 - categorical_accuracy: 0.9883 - val_loss: 8.9554 - val_categorical_accuracy: 0.0774\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0518 - categorical_accuracy: 0.9909 - val_loss: 7.4115 - val_categorical_accuracy: 0.0877\n",
      "Epoch 65/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0500 - categorical_accuracy: 0.9912 - val_loss: 7.5889 - val_categorical_accuracy: 0.0838\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0428 - categorical_accuracy: 0.9922 - val_loss: 7.7684 - val_categorical_accuracy: 0.0646\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0406 - categorical_accuracy: 0.9925 - val_loss: 7.5759 - val_categorical_accuracy: 0.1369\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0393 - categorical_accuracy: 0.9934 - val_loss: 7.9714 - val_categorical_accuracy: 0.0787\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0343 - categorical_accuracy: 0.9941 - val_loss: 13.9376 - val_categorical_accuracy: 0.0742\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0331 - categorical_accuracy: 0.9934 - val_loss: 15.9805 - val_categorical_accuracy: 0.0569\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0312 - categorical_accuracy: 0.9952 - val_loss: 13.9059 - val_categorical_accuracy: 0.1292\n",
      "Epoch 72/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0405 - categorical_accuracy: 0.9954 - val_loss: 16.2468 - val_categorical_accuracy: 0.1606\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0217 - categorical_accuracy: 0.9962 - val_loss: 6.3033 - val_categorical_accuracy: 0.1235\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0214 - categorical_accuracy: 0.9963 - val_loss: 13.5325 - val_categorical_accuracy: 0.1356\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0205 - categorical_accuracy: 0.9971 - val_loss: 12.9247 - val_categorical_accuracy: 0.1657\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0177 - categorical_accuracy: 0.9973 - val_loss: 7.3095 - val_categorical_accuracy: 0.1440\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0162 - categorical_accuracy: 0.9978 - val_loss: 9.7880 - val_categorical_accuracy: 0.1164\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0169 - categorical_accuracy: 0.9973 - val_loss: 7.0777 - val_categorical_accuracy: 0.1196\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0186 - categorical_accuracy: 0.9973 - val_loss: 10.1100 - val_categorical_accuracy: 0.1286\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0184 - categorical_accuracy: 0.9970 - val_loss: 6.9535 - val_categorical_accuracy: 0.0915\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0209 - categorical_accuracy: 0.9970 - val_loss: 7.4235 - val_categorical_accuracy: 0.0851\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0188 - categorical_accuracy: 0.9976 - val_loss: 7.3201 - val_categorical_accuracy: 0.1286\n",
      "Epoch 83/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0193 - categorical_accuracy: 0.9974 - val_loss: 5.6473 - val_categorical_accuracy: 0.1228\n",
      "Epoch 84/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0178 - categorical_accuracy: 0.9979 - val_loss: 8.8351 - val_categorical_accuracy: 0.0793\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0209 - categorical_accuracy: 0.9971 - val_loss: 10.7845 - val_categorical_accuracy: 0.0781\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0191 - categorical_accuracy: 0.9971 - val_loss: 7.2490 - val_categorical_accuracy: 0.0819\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0169 - categorical_accuracy: 0.9973 - val_loss: 10.4407 - val_categorical_accuracy: 0.0717\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0205 - categorical_accuracy: 0.9970 - val_loss: 11.2055 - val_categorical_accuracy: 0.0659\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0198 - categorical_accuracy: 0.9970 - val_loss: 14.3935 - val_categorical_accuracy: 0.0864\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0243 - categorical_accuracy: 0.9968 - val_loss: 8.3521 - val_categorical_accuracy: 0.1120\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0223 - categorical_accuracy: 0.9958 - val_loss: 8.4049 - val_categorical_accuracy: 0.1145\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0256 - categorical_accuracy: 0.9958 - val_loss: 39.4362 - val_categorical_accuracy: 0.0467\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0281 - categorical_accuracy: 0.9950 - val_loss: 40.3098 - val_categorical_accuracy: 0.0467\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0356 - categorical_accuracy: 0.9938 - val_loss: 16.8615 - val_categorical_accuracy: 0.0307\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0374 - categorical_accuracy: 0.9917 - val_loss: 8.1222 - val_categorical_accuracy: 0.0435\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0469 - categorical_accuracy: 0.9898 - val_loss: 8.4977 - val_categorical_accuracy: 0.1465\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0475 - categorical_accuracy: 0.9915 - val_loss: 10.8754 - val_categorical_accuracy: 0.0537\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0475 - categorical_accuracy: 0.9904 - val_loss: 7.2871 - val_categorical_accuracy: 0.1190\n",
      "Epoch 99/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0477 - categorical_accuracy: 0.9926 - val_loss: 20.7387 - val_categorical_accuracy: 0.0768\n",
      "Epoch 100/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0436 - categorical_accuracy: 0.9923 - val_loss: 14.2973 - val_categorical_accuracy: 0.1004\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0351 - categorical_accuracy: 0.9941 - val_loss: 6.7428 - val_categorical_accuracy: 0.1344\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0312 - categorical_accuracy: 0.9949 - val_loss: 8.8381 - val_categorical_accuracy: 0.1049\n",
      "Epoch 103/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0436 - categorical_accuracy: 0.9914 - val_loss: 11.0569 - val_categorical_accuracy: 0.0749\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.5164 - categorical_accuracy: 0.8776 - val_loss: 6.9637 - val_categorical_accuracy: 0.0627\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.6371 - categorical_accuracy: 0.8708 - val_loss: 17.7601 - val_categorical_accuracy: 0.0467\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2980 - categorical_accuracy: 0.9337 - val_loss: 6.1165 - val_categorical_accuracy: 0.1004\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2583 - categorical_accuracy: 0.9384 - val_loss: 69.9779 - val_categorical_accuracy: 0.0102\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8397 - categorical_accuracy: 0.7943 - val_loss: 18.3576 - val_categorical_accuracy: 0.0473\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.4499 - categorical_accuracy: 0.8772 - val_loss: 18.6957 - val_categorical_accuracy: 0.0505\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2172 - categorical_accuracy: 0.9483 - val_loss: 19.2958 - val_categorical_accuracy: 0.0429\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1440 - categorical_accuracy: 0.9675 - val_loss: 45.5491 - val_categorical_accuracy: 0.0102\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1161 - categorical_accuracy: 0.9755 - val_loss: 56.2211 - val_categorical_accuracy: 0.0102\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0924 - categorical_accuracy: 0.9814 - val_loss: 53.3231 - val_categorical_accuracy: 0.0102\n",
      "Epoch 114/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0733 - categorical_accuracy: 0.9882 - val_loss: 47.8519 - val_categorical_accuracy: 0.0109\n",
      "Epoch 115/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0645 - categorical_accuracy: 0.9893 - val_loss: 38.0310 - val_categorical_accuracy: 0.0122\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0618 - categorical_accuracy: 0.9907 - val_loss: 34.8797 - val_categorical_accuracy: 0.0134\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0530 - categorical_accuracy: 0.9931 - val_loss: 26.7406 - val_categorical_accuracy: 0.0608\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.4639 - categorical_accuracy: 0.8748 - val_loss: 36.8116 - val_categorical_accuracy: 0.1644\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.2932 - categorical_accuracy: 0.9305 - val_loss: 50.9084 - val_categorical_accuracy: 0.1631\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1639 - categorical_accuracy: 0.9632 - val_loss: 53.3789 - val_categorical_accuracy: 0.0569\n",
      "Epoch 121/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1166 - categorical_accuracy: 0.9755 - val_loss: 50.3933 - val_categorical_accuracy: 0.0467\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0932 - categorical_accuracy: 0.9842 - val_loss: 44.0753 - val_categorical_accuracy: 0.0640\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0830 - categorical_accuracy: 0.9846 - val_loss: 25.8565 - val_categorical_accuracy: 0.0972\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0684 - categorical_accuracy: 0.9866 - val_loss: 16.9239 - val_categorical_accuracy: 0.1644\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0569 - categorical_accuracy: 0.9899 - val_loss: 8.0779 - val_categorical_accuracy: 0.1049\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0493 - categorical_accuracy: 0.9910 - val_loss: 7.3003 - val_categorical_accuracy: 0.1075\n",
      "Epoch 127/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0504 - categorical_accuracy: 0.9918 - val_loss: 9.1265 - val_categorical_accuracy: 0.1619\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0473 - categorical_accuracy: 0.9934 - val_loss: 7.0689 - val_categorical_accuracy: 0.1484\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0380 - categorical_accuracy: 0.9938 - val_loss: 10.7281 - val_categorical_accuracy: 0.0819\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0390 - categorical_accuracy: 0.9946 - val_loss: 9.5649 - val_categorical_accuracy: 0.1024\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0394 - categorical_accuracy: 0.9938 - val_loss: 12.2236 - val_categorical_accuracy: 0.0781\n",
      "Epoch 132/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0388 - categorical_accuracy: 0.9933 - val_loss: 10.3119 - val_categorical_accuracy: 0.1139\n",
      "Epoch 133/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0359 - categorical_accuracy: 0.9947 - val_loss: 8.5880 - val_categorical_accuracy: 0.1292\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0269 - categorical_accuracy: 0.9962 - val_loss: 9.9155 - val_categorical_accuracy: 0.1567\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0269 - categorical_accuracy: 0.9963 - val_loss: 9.7587 - val_categorical_accuracy: 0.0928\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0307 - categorical_accuracy: 0.9960 - val_loss: 11.9646 - val_categorical_accuracy: 0.1497\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0370 - categorical_accuracy: 0.9936 - val_loss: 8.6393 - val_categorical_accuracy: 0.1280\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0380 - categorical_accuracy: 0.9934 - val_loss: 7.7709 - val_categorical_accuracy: 0.1139\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0375 - categorical_accuracy: 0.9936 - val_loss: 8.3174 - val_categorical_accuracy: 0.1177\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0378 - categorical_accuracy: 0.9944 - val_loss: 7.7470 - val_categorical_accuracy: 0.1536\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0295 - categorical_accuracy: 0.9954 - val_loss: 5.6754 - val_categorical_accuracy: 0.1356\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0350 - categorical_accuracy: 0.9941 - val_loss: 11.1763 - val_categorical_accuracy: 0.0998\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0373 - categorical_accuracy: 0.9939 - val_loss: 133.9752 - val_categorical_accuracy: 0.0128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0388 - categorical_accuracy: 0.9952 - val_loss: 50.3384 - val_categorical_accuracy: 0.1587\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0347 - categorical_accuracy: 0.9947 - val_loss: 27.0614 - val_categorical_accuracy: 0.1356\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0285 - categorical_accuracy: 0.9957 - val_loss: 10.5411 - val_categorical_accuracy: 0.0940\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0263 - categorical_accuracy: 0.9966 - val_loss: 7.7633 - val_categorical_accuracy: 0.0819\n",
      "Epoch 148/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0205 - categorical_accuracy: 0.9971 - val_loss: 7.1360 - val_categorical_accuracy: 0.0896\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0232 - categorical_accuracy: 0.9957 - val_loss: 8.7648 - val_categorical_accuracy: 0.1209\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0263 - categorical_accuracy: 0.9962 - val_loss: 13.9653 - val_categorical_accuracy: 0.0992\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0238 - categorical_accuracy: 0.9954 - val_loss: 11.6492 - val_categorical_accuracy: 0.1318\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0329 - categorical_accuracy: 0.9944 - val_loss: 17.8491 - val_categorical_accuracy: 0.0531\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0308 - categorical_accuracy: 0.9941 - val_loss: 12.3444 - val_categorical_accuracy: 0.0851\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0328 - categorical_accuracy: 0.9949 - val_loss: 11.5502 - val_categorical_accuracy: 0.1542\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0292 - categorical_accuracy: 0.9952 - val_loss: 13.3835 - val_categorical_accuracy: 0.1100\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0296 - categorical_accuracy: 0.9934 - val_loss: 8.2287 - val_categorical_accuracy: 0.1587\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0319 - categorical_accuracy: 0.9931 - val_loss: 12.8971 - val_categorical_accuracy: 0.0934\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0451 - categorical_accuracy: 0.9920 - val_loss: 9.0122 - val_categorical_accuracy: 0.1145\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0417 - categorical_accuracy: 0.9922 - val_loss: 12.0046 - val_categorical_accuracy: 0.1056\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0391 - categorical_accuracy: 0.9930 - val_loss: 7.4715 - val_categorical_accuracy: 0.0736\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0409 - categorical_accuracy: 0.9922 - val_loss: 12.1463 - val_categorical_accuracy: 0.1273\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0476 - categorical_accuracy: 0.9918 - val_loss: 12.7891 - val_categorical_accuracy: 0.1171\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0371 - categorical_accuracy: 0.9931 - val_loss: 16.3691 - val_categorical_accuracy: 0.1350\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0311 - categorical_accuracy: 0.9922 - val_loss: 13.9462 - val_categorical_accuracy: 0.0966\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0230 - categorical_accuracy: 0.9952 - val_loss: 7.3672 - val_categorical_accuracy: 0.1011\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0250 - categorical_accuracy: 0.9947 - val_loss: 11.4691 - val_categorical_accuracy: 0.1171\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0312 - categorical_accuracy: 0.9942 - val_loss: 8.3305 - val_categorical_accuracy: 0.1683\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0331 - categorical_accuracy: 0.9938 - val_loss: 13.1567 - val_categorical_accuracy: 0.1024\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0402 - categorical_accuracy: 0.9941 - val_loss: 8.9734 - val_categorical_accuracy: 0.1049\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0390 - categorical_accuracy: 0.9928 - val_loss: 8.9935 - val_categorical_accuracy: 0.1036\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0347 - categorical_accuracy: 0.9933 - val_loss: 9.6062 - val_categorical_accuracy: 0.1222\n",
      "Epoch 172/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0387 - categorical_accuracy: 0.9920 - val_loss: 12.7922 - val_categorical_accuracy: 0.1030\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0377 - categorical_accuracy: 0.9920 - val_loss: 16.0587 - val_categorical_accuracy: 0.1120\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0388 - categorical_accuracy: 0.9931 - val_loss: 8.4241 - val_categorical_accuracy: 0.0953\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0430 - categorical_accuracy: 0.9918 - val_loss: 7.4451 - val_categorical_accuracy: 0.1574\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0416 - categorical_accuracy: 0.9926 - val_loss: 12.2500 - val_categorical_accuracy: 0.0921\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0371 - categorical_accuracy: 0.9926 - val_loss: 6.8145 - val_categorical_accuracy: 0.0710\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0330 - categorical_accuracy: 0.9930 - val_loss: 6.3956 - val_categorical_accuracy: 0.1286\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0300 - categorical_accuracy: 0.9936 - val_loss: 9.2588 - val_categorical_accuracy: 0.1312\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0285 - categorical_accuracy: 0.9944 - val_loss: 6.8081 - val_categorical_accuracy: 0.0787\n",
      "Epoch 181/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0307 - categorical_accuracy: 0.9942 - val_loss: 12.7233 - val_categorical_accuracy: 0.0953\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0284 - categorical_accuracy: 0.9944 - val_loss: 11.6862 - val_categorical_accuracy: 0.1657\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0281 - categorical_accuracy: 0.9944 - val_loss: 11.1502 - val_categorical_accuracy: 0.1184\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0259 - categorical_accuracy: 0.9950 - val_loss: 12.9741 - val_categorical_accuracy: 0.1427\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0301 - categorical_accuracy: 0.9949 - val_loss: 10.5813 - val_categorical_accuracy: 0.1177\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0277 - categorical_accuracy: 0.9942 - val_loss: 12.2099 - val_categorical_accuracy: 0.0934\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0271 - categorical_accuracy: 0.9938 - val_loss: 12.2065 - val_categorical_accuracy: 0.1267\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0301 - categorical_accuracy: 0.9941 - val_loss: 7.3718 - val_categorical_accuracy: 0.1510\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0300 - categorical_accuracy: 0.9925 - val_loss: 6.7164 - val_categorical_accuracy: 0.1344\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0283 - categorical_accuracy: 0.9947 - val_loss: 10.0789 - val_categorical_accuracy: 0.1459\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0295 - categorical_accuracy: 0.9941 - val_loss: 7.1951 - val_categorical_accuracy: 0.0806\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0347 - categorical_accuracy: 0.9936 - val_loss: 14.0134 - val_categorical_accuracy: 0.0953\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0388 - categorical_accuracy: 0.9926 - val_loss: 11.5332 - val_categorical_accuracy: 0.1356\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0394 - categorical_accuracy: 0.9923 - val_loss: 13.9183 - val_categorical_accuracy: 0.1401\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0370 - categorical_accuracy: 0.9914 - val_loss: 11.6557 - val_categorical_accuracy: 0.1043\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0398 - categorical_accuracy: 0.9918 - val_loss: 6.5900 - val_categorical_accuracy: 0.1382\n",
      "Epoch 197/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0432 - categorical_accuracy: 0.9933 - val_loss: 7.4127 - val_categorical_accuracy: 0.0729\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0385 - categorical_accuracy: 0.9933 - val_loss: 11.7372 - val_categorical_accuracy: 0.1177\n",
      "Epoch 199/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0284 - categorical_accuracy: 0.9936 - val_loss: 9.1772 - val_categorical_accuracy: 0.1228\n",
      "Epoch 200/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0282 - categorical_accuracy: 0.9938 - val_loss: 10.5402 - val_categorical_accuracy: 0.1171\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0284 - categorical_accuracy: 0.9941 - val_loss: 8.2585 - val_categorical_accuracy: 0.1273\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0259 - categorical_accuracy: 0.9946 - val_loss: 12.3945 - val_categorical_accuracy: 0.0883\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0296 - categorical_accuracy: 0.9947 - val_loss: 13.8291 - val_categorical_accuracy: 0.0915\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0361 - categorical_accuracy: 0.9939 - val_loss: 11.3817 - val_categorical_accuracy: 0.0633\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0357 - categorical_accuracy: 0.9931 - val_loss: 17.3935 - val_categorical_accuracy: 0.0672\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0349 - categorical_accuracy: 0.9936 - val_loss: 21.9917 - val_categorical_accuracy: 0.0633\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0231 - categorical_accuracy: 0.9955 - val_loss: 11.4792 - val_categorical_accuracy: 0.0640\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0351 - categorical_accuracy: 0.9938 - val_loss: 12.3551 - val_categorical_accuracy: 0.0940\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0322 - categorical_accuracy: 0.9930 - val_loss: 8.2847 - val_categorical_accuracy: 0.0774\n",
      "Epoch 210/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0323 - categorical_accuracy: 0.9936 - val_loss: 14.1552 - val_categorical_accuracy: 0.0921\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0305 - categorical_accuracy: 0.9931 - val_loss: 14.0370 - val_categorical_accuracy: 0.1068\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0401 - categorical_accuracy: 0.9923 - val_loss: 13.1229 - val_categorical_accuracy: 0.0877\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0336 - categorical_accuracy: 0.9926 - val_loss: 6.7984 - val_categorical_accuracy: 0.1561\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0384 - categorical_accuracy: 0.9923 - val_loss: 8.9412 - val_categorical_accuracy: 0.0934\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0335 - categorical_accuracy: 0.9923 - val_loss: 11.6166 - val_categorical_accuracy: 0.1100\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0240 - categorical_accuracy: 0.9934 - val_loss: 10.7989 - val_categorical_accuracy: 0.1113\n",
      "Epoch 217/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0273 - categorical_accuracy: 0.9918 - val_loss: 8.7250 - val_categorical_accuracy: 0.1286\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0283 - categorical_accuracy: 0.9938 - val_loss: 7.8838 - val_categorical_accuracy: 0.0940\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0240 - categorical_accuracy: 0.9939 - val_loss: 13.0840 - val_categorical_accuracy: 0.0992\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0255 - categorical_accuracy: 0.9941 - val_loss: 8.1037 - val_categorical_accuracy: 0.1567\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0260 - categorical_accuracy: 0.9955 - val_loss: 11.6321 - val_categorical_accuracy: 0.0909\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0223 - categorical_accuracy: 0.9955 - val_loss: 8.2121 - val_categorical_accuracy: 0.0947\n",
      "Epoch 223/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0286 - categorical_accuracy: 0.9939 - val_loss: 12.0939 - val_categorical_accuracy: 0.1177\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0223 - categorical_accuracy: 0.9954 - val_loss: 13.4885 - val_categorical_accuracy: 0.1459\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0209 - categorical_accuracy: 0.9957 - val_loss: 12.5414 - val_categorical_accuracy: 0.0870\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0218 - categorical_accuracy: 0.9966 - val_loss: 13.2749 - val_categorical_accuracy: 0.0915\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0159 - categorical_accuracy: 0.9965 - val_loss: 6.5619 - val_categorical_accuracy: 0.1516\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0272 - categorical_accuracy: 0.9950 - val_loss: 10.5058 - val_categorical_accuracy: 0.1113\n",
      "Epoch 229/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0219 - categorical_accuracy: 0.9947 - val_loss: 11.9709 - val_categorical_accuracy: 0.1158\n",
      "Epoch 230/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0314 - categorical_accuracy: 0.9955 - val_loss: 14.2975 - val_categorical_accuracy: 0.1171\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0259 - categorical_accuracy: 0.9962 - val_loss: 8.9203 - val_categorical_accuracy: 0.0761\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0199 - categorical_accuracy: 0.9957 - val_loss: 11.2701 - val_categorical_accuracy: 0.1120\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0249 - categorical_accuracy: 0.9958 - val_loss: 14.4452 - val_categorical_accuracy: 0.0915\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0194 - categorical_accuracy: 0.9952 - val_loss: 9.5347 - val_categorical_accuracy: 0.1670\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0219 - categorical_accuracy: 0.9947 - val_loss: 13.1288 - val_categorical_accuracy: 0.1164\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0210 - categorical_accuracy: 0.9958 - val_loss: 8.5653 - val_categorical_accuracy: 0.0947\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0246 - categorical_accuracy: 0.9952 - val_loss: 9.1073 - val_categorical_accuracy: 0.1280\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0204 - categorical_accuracy: 0.9957 - val_loss: 11.3772 - val_categorical_accuracy: 0.1113\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0310 - categorical_accuracy: 0.9936 - val_loss: 14.0441 - val_categorical_accuracy: 0.0915\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0338 - categorical_accuracy: 0.9934 - val_loss: 9.3450 - val_categorical_accuracy: 0.1241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0224 - categorical_accuracy: 0.9939 - val_loss: 8.7214 - val_categorical_accuracy: 0.0992\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0252 - categorical_accuracy: 0.9946 - val_loss: 8.6888 - val_categorical_accuracy: 0.0953\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0228 - categorical_accuracy: 0.9952 - val_loss: 12.5600 - val_categorical_accuracy: 0.1587\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0213 - categorical_accuracy: 0.9944 - val_loss: 12.0020 - val_categorical_accuracy: 0.1305\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0234 - categorical_accuracy: 0.9966 - val_loss: 8.4611 - val_categorical_accuracy: 0.1344\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0168 - categorical_accuracy: 0.9960 - val_loss: 13.2931 - val_categorical_accuracy: 0.1036\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0216 - categorical_accuracy: 0.9955 - val_loss: 14.0914 - val_categorical_accuracy: 0.0953\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0226 - categorical_accuracy: 0.9958 - val_loss: 10.0168 - val_categorical_accuracy: 0.1094\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0224 - categorical_accuracy: 0.9949 - val_loss: 9.0085 - val_categorical_accuracy: 0.0947\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0193 - categorical_accuracy: 0.9958 - val_loss: 11.5575 - val_categorical_accuracy: 0.1305\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0238 - categorical_accuracy: 0.9941 - val_loss: 12.4467 - val_categorical_accuracy: 0.1068\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0320 - categorical_accuracy: 0.9952 - val_loss: 15.3802 - val_categorical_accuracy: 0.0947\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0257 - categorical_accuracy: 0.9942 - val_loss: 12.2771 - val_categorical_accuracy: 0.1088\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0271 - categorical_accuracy: 0.9930 - val_loss: 9.4068 - val_categorical_accuracy: 0.1715\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0280 - categorical_accuracy: 0.9933 - val_loss: 9.6484 - val_categorical_accuracy: 0.0960\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0291 - categorical_accuracy: 0.9946 - val_loss: 8.4818 - val_categorical_accuracy: 0.1286\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0337 - categorical_accuracy: 0.9946 - val_loss: 15.5277 - val_categorical_accuracy: 0.0793\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0255 - categorical_accuracy: 0.9942 - val_loss: 8.7222 - val_categorical_accuracy: 0.1004\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0215 - categorical_accuracy: 0.9952 - val_loss: 12.4419 - val_categorical_accuracy: 0.0819\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0138 - categorical_accuracy: 0.9966 - val_loss: 11.9972 - val_categorical_accuracy: 0.1004\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0177 - categorical_accuracy: 0.9966 - val_loss: 13.8054 - val_categorical_accuracy: 0.0972\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0116 - categorical_accuracy: 0.9973 - val_loss: 10.6099 - val_categorical_accuracy: 0.1203\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0184 - categorical_accuracy: 0.9963 - val_loss: 12.7348 - val_categorical_accuracy: 0.1004\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0174 - categorical_accuracy: 0.9962 - val_loss: 13.2140 - val_categorical_accuracy: 0.1094\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0212 - categorical_accuracy: 0.9957 - val_loss: 15.4578 - val_categorical_accuracy: 0.1440\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0160 - categorical_accuracy: 0.9963 - val_loss: 10.2586 - val_categorical_accuracy: 0.0857\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0134 - categorical_accuracy: 0.9970 - val_loss: 14.9988 - val_categorical_accuracy: 0.0972\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0138 - categorical_accuracy: 0.9978 - val_loss: 10.0920 - val_categorical_accuracy: 0.1472\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0194 - categorical_accuracy: 0.9973 - val_loss: 12.0775 - val_categorical_accuracy: 0.1139\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0161 - categorical_accuracy: 0.9965 - val_loss: 12.1874 - val_categorical_accuracy: 0.1670\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0145 - categorical_accuracy: 0.9966 - val_loss: 13.3963 - val_categorical_accuracy: 0.1228\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0205 - categorical_accuracy: 0.9965 - val_loss: 13.5534 - val_categorical_accuracy: 0.0966\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0178 - categorical_accuracy: 0.9973 - val_loss: 10.9579 - val_categorical_accuracy: 0.1081\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0157 - categorical_accuracy: 0.9966 - val_loss: 9.6425 - val_categorical_accuracy: 0.1823\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0184 - categorical_accuracy: 0.9963 - val_loss: 13.1108 - val_categorical_accuracy: 0.0845\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0204 - categorical_accuracy: 0.9968 - val_loss: 14.3582 - val_categorical_accuracy: 0.1126\n",
      "Epoch 277/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0187 - categorical_accuracy: 0.9957 - val_loss: 14.3679 - val_categorical_accuracy: 0.1056\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0204 - categorical_accuracy: 0.9960 - val_loss: 16.5040 - val_categorical_accuracy: 0.1132\n",
      "Epoch 279/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0174 - categorical_accuracy: 0.9966 - val_loss: 15.7024 - val_categorical_accuracy: 0.0921\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0210 - categorical_accuracy: 0.9958 - val_loss: 12.5495 - val_categorical_accuracy: 0.0915\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0241 - categorical_accuracy: 0.9949 - val_loss: 13.6482 - val_categorical_accuracy: 0.1088\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0250 - categorical_accuracy: 0.9954 - val_loss: 14.5178 - val_categorical_accuracy: 0.1228\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0240 - categorical_accuracy: 0.9960 - val_loss: 11.3225 - val_categorical_accuracy: 0.1779\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0248 - categorical_accuracy: 0.9949 - val_loss: 12.5663 - val_categorical_accuracy: 0.0902\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0189 - categorical_accuracy: 0.9960 - val_loss: 8.5079 - val_categorical_accuracy: 0.1056\n",
      "Epoch 286/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0201 - categorical_accuracy: 0.9942 - val_loss: 12.2344 - val_categorical_accuracy: 0.1056\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0174 - categorical_accuracy: 0.9965 - val_loss: 9.3692 - val_categorical_accuracy: 0.1324\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0132 - categorical_accuracy: 0.9978 - val_loss: 14.3670 - val_categorical_accuracy: 0.0972\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0200 - categorical_accuracy: 0.9966 - val_loss: 14.5439 - val_categorical_accuracy: 0.0953\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0150 - categorical_accuracy: 0.9962 - val_loss: 15.2272 - val_categorical_accuracy: 0.1081\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0117 - categorical_accuracy: 0.9979 - val_loss: 19.1833 - val_categorical_accuracy: 0.1440\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0116 - categorical_accuracy: 0.9976 - val_loss: 11.9141 - val_categorical_accuracy: 0.1491\n",
      "Epoch 293/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0095 - categorical_accuracy: 0.9984 - val_loss: 11.1322 - val_categorical_accuracy: 0.1241\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0083 - categorical_accuracy: 0.9982 - val_loss: 12.9535 - val_categorical_accuracy: 0.1318\n",
      "Epoch 295/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0114 - categorical_accuracy: 0.9976 - val_loss: 13.4165 - val_categorical_accuracy: 0.1113\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0094 - categorical_accuracy: 0.9976 - val_loss: 19.1067 - val_categorical_accuracy: 0.0576\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0135 - categorical_accuracy: 0.9966 - val_loss: 14.3050 - val_categorical_accuracy: 0.1567\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0287 - categorical_accuracy: 0.9958 - val_loss: 12.7598 - val_categorical_accuracy: 0.1465\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0233 - categorical_accuracy: 0.9949 - val_loss: 17.7975 - val_categorical_accuracy: 0.1516\n",
      "Epoch 300/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0242 - categorical_accuracy: 0.9955 - val_loss: 8.2958 - val_categorical_accuracy: 0.0940\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0293 - categorical_accuracy: 0.9928 - val_loss: 10.1449 - val_categorical_accuracy: 0.1843\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0310 - categorical_accuracy: 0.9936 - val_loss: 12.9929 - val_categorical_accuracy: 0.1587\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0215 - categorical_accuracy: 0.9954 - val_loss: 8.5268 - val_categorical_accuracy: 0.0736\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0206 - categorical_accuracy: 0.9962 - val_loss: 14.0780 - val_categorical_accuracy: 0.1657\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0199 - categorical_accuracy: 0.9939 - val_loss: 8.4124 - val_categorical_accuracy: 0.0717\n",
      "Epoch 306/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0195 - categorical_accuracy: 0.9954 - val_loss: 12.9535 - val_categorical_accuracy: 0.1056\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0161 - categorical_accuracy: 0.9965 - val_loss: 12.5382 - val_categorical_accuracy: 0.0928\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0182 - categorical_accuracy: 0.9962 - val_loss: 12.6908 - val_categorical_accuracy: 0.1081\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0219 - categorical_accuracy: 0.9954 - val_loss: 7.9166 - val_categorical_accuracy: 0.0928\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0225 - categorical_accuracy: 0.9960 - val_loss: 11.7907 - val_categorical_accuracy: 0.0563\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0215 - categorical_accuracy: 0.9947 - val_loss: 13.0673 - val_categorical_accuracy: 0.0934\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0301 - categorical_accuracy: 0.9946 - val_loss: 15.0079 - val_categorical_accuracy: 0.1580\n",
      "Epoch 313/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0236 - categorical_accuracy: 0.9947 - val_loss: 12.3243 - val_categorical_accuracy: 0.1574\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0191 - categorical_accuracy: 0.9960 - val_loss: 12.3331 - val_categorical_accuracy: 0.0864\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0169 - categorical_accuracy: 0.9957 - val_loss: 13.6202 - val_categorical_accuracy: 0.0998\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0218 - categorical_accuracy: 0.9952 - val_loss: 13.6092 - val_categorical_accuracy: 0.1235\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0195 - categorical_accuracy: 0.9965 - val_loss: 13.3144 - val_categorical_accuracy: 0.1075\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0138 - categorical_accuracy: 0.9962 - val_loss: 11.4399 - val_categorical_accuracy: 0.1619\n",
      "Epoch 319/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0122 - categorical_accuracy: 0.9981 - val_loss: 11.6631 - val_categorical_accuracy: 0.1081\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0077 - categorical_accuracy: 0.9981 - val_loss: 14.7134 - val_categorical_accuracy: 0.0953\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0103 - categorical_accuracy: 0.9979 - val_loss: 11.6686 - val_categorical_accuracy: 0.1708\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0158 - categorical_accuracy: 0.9966 - val_loss: 14.5837 - val_categorical_accuracy: 0.1203\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0156 - categorical_accuracy: 0.9962 - val_loss: 11.9176 - val_categorical_accuracy: 0.1593\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0172 - categorical_accuracy: 0.9954 - val_loss: 11.9864 - val_categorical_accuracy: 0.1081\n",
      "Epoch 325/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0198 - categorical_accuracy: 0.9968 - val_loss: 10.0079 - val_categorical_accuracy: 0.1043\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0203 - categorical_accuracy: 0.9962 - val_loss: 13.0930 - val_categorical_accuracy: 0.1203\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0134 - categorical_accuracy: 0.9965 - val_loss: 12.8616 - val_categorical_accuracy: 0.1107\n",
      "Epoch 328/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0120 - categorical_accuracy: 0.9968 - val_loss: 14.4395 - val_categorical_accuracy: 0.1164\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0125 - categorical_accuracy: 0.9970 - val_loss: 13.2191 - val_categorical_accuracy: 0.1164\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0197 - categorical_accuracy: 0.9960 - val_loss: 12.9922 - val_categorical_accuracy: 0.0902\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0203 - categorical_accuracy: 0.9965 - val_loss: 13.1461 - val_categorical_accuracy: 0.0921\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0129 - categorical_accuracy: 0.9970 - val_loss: 7.9936 - val_categorical_accuracy: 0.1465\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0154 - categorical_accuracy: 0.9965 - val_loss: 15.1047 - val_categorical_accuracy: 0.1427\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0097 - categorical_accuracy: 0.9976 - val_loss: 13.7212 - val_categorical_accuracy: 0.0883\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0102 - categorical_accuracy: 0.9982 - val_loss: 9.2132 - val_categorical_accuracy: 0.0998\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0179 - categorical_accuracy: 0.9971 - val_loss: 11.2142 - val_categorical_accuracy: 0.0979\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0145 - categorical_accuracy: 0.9971 - val_loss: 13.5901 - val_categorical_accuracy: 0.1727\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0129 - categorical_accuracy: 0.9971 - val_loss: 7.8505 - val_categorical_accuracy: 0.0813\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0136 - categorical_accuracy: 0.9973 - val_loss: 13.6612 - val_categorical_accuracy: 0.1024\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0078 - categorical_accuracy: 0.9984 - val_loss: 12.0478 - val_categorical_accuracy: 0.1139\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0068 - categorical_accuracy: 0.9982 - val_loss: 12.1678 - val_categorical_accuracy: 0.0909\n",
      "Epoch 342/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0118 - categorical_accuracy: 0.9976 - val_loss: 10.0291 - val_categorical_accuracy: 0.1536\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0243 - categorical_accuracy: 0.9973 - val_loss: 10.3447 - val_categorical_accuracy: 0.1555\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0183 - categorical_accuracy: 0.9965 - val_loss: 11.2241 - val_categorical_accuracy: 0.1427\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0194 - categorical_accuracy: 0.9949 - val_loss: 10.7966 - val_categorical_accuracy: 0.1337\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0210 - categorical_accuracy: 0.9955 - val_loss: 12.2125 - val_categorical_accuracy: 0.0928\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0209 - categorical_accuracy: 0.9957 - val_loss: 12.3911 - val_categorical_accuracy: 0.1734\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0195 - categorical_accuracy: 0.9958 - val_loss: 8.2621 - val_categorical_accuracy: 0.0864\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0193 - categorical_accuracy: 0.9970 - val_loss: 17.7147 - val_categorical_accuracy: 0.0902\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0186 - categorical_accuracy: 0.9973 - val_loss: 12.6726 - val_categorical_accuracy: 0.1139\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0120 - categorical_accuracy: 0.9979 - val_loss: 10.7780 - val_categorical_accuracy: 0.1132\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0130 - categorical_accuracy: 0.9974 - val_loss: 15.2042 - val_categorical_accuracy: 0.1024\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0100 - categorical_accuracy: 0.9978 - val_loss: 8.6977 - val_categorical_accuracy: 0.1721\n",
      "Epoch 354/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0106 - categorical_accuracy: 0.9978 - val_loss: 12.5120 - val_categorical_accuracy: 0.1068\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0124 - categorical_accuracy: 0.9978 - val_loss: 14.6168 - val_categorical_accuracy: 0.1484\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0213 - categorical_accuracy: 0.9966 - val_loss: 9.4744 - val_categorical_accuracy: 0.1593\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0212 - categorical_accuracy: 0.9971 - val_loss: 9.0538 - val_categorical_accuracy: 0.1772\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0184 - categorical_accuracy: 0.9976 - val_loss: 13.6019 - val_categorical_accuracy: 0.1043\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0139 - categorical_accuracy: 0.9966 - val_loss: 11.5078 - val_categorical_accuracy: 0.1145\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0205 - categorical_accuracy: 0.9960 - val_loss: 11.1713 - val_categorical_accuracy: 0.1689\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0186 - categorical_accuracy: 0.9960 - val_loss: 14.5323 - val_categorical_accuracy: 0.1574\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0142 - categorical_accuracy: 0.9971 - val_loss: 12.1354 - val_categorical_accuracy: 0.1081\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0073 - categorical_accuracy: 0.9984 - val_loss: 13.5753 - val_categorical_accuracy: 0.0972\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0174 - categorical_accuracy: 0.9978 - val_loss: 9.5495 - val_categorical_accuracy: 0.1459\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0161 - categorical_accuracy: 0.9978 - val_loss: 13.5349 - val_categorical_accuracy: 0.1088\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0115 - categorical_accuracy: 0.9976 - val_loss: 14.9178 - val_categorical_accuracy: 0.1152\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0121 - categorical_accuracy: 0.9970 - val_loss: 10.0370 - val_categorical_accuracy: 0.1164\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0150 - categorical_accuracy: 0.9966 - val_loss: 12.7165 - val_categorical_accuracy: 0.1120\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0205 - categorical_accuracy: 0.9960 - val_loss: 11.1679 - val_categorical_accuracy: 0.1209\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0154 - categorical_accuracy: 0.9962 - val_loss: 13.6762 - val_categorical_accuracy: 0.1126\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0227 - categorical_accuracy: 0.9968 - val_loss: 8.3350 - val_categorical_accuracy: 0.0979\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0212 - categorical_accuracy: 0.9965 - val_loss: 8.3702 - val_categorical_accuracy: 0.0953\n",
      "Epoch 373/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0124 - categorical_accuracy: 0.9970 - val_loss: 12.5805 - val_categorical_accuracy: 0.1177\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0066 - categorical_accuracy: 0.9984 - val_loss: 11.3951 - val_categorical_accuracy: 0.1190\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0068 - categorical_accuracy: 0.9986 - val_loss: 8.1989 - val_categorical_accuracy: 0.1567\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0123 - categorical_accuracy: 0.9982 - val_loss: 10.3654 - val_categorical_accuracy: 0.1382\n",
      "Epoch 377/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0094 - categorical_accuracy: 0.9982 - val_loss: 9.8306 - val_categorical_accuracy: 0.1401\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0079 - categorical_accuracy: 0.9984 - val_loss: 8.6867 - val_categorical_accuracy: 0.1785\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0084 - categorical_accuracy: 0.9982 - val_loss: 8.3578 - val_categorical_accuracy: 0.1702\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0131 - categorical_accuracy: 0.9976 - val_loss: 11.5871 - val_categorical_accuracy: 0.1094\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0133 - categorical_accuracy: 0.9984 - val_loss: 13.0214 - val_categorical_accuracy: 0.1004\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0098 - categorical_accuracy: 0.9984 - val_loss: 12.7744 - val_categorical_accuracy: 0.1075\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0094 - categorical_accuracy: 0.9982 - val_loss: 13.5831 - val_categorical_accuracy: 0.1721\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0106 - categorical_accuracy: 0.9982 - val_loss: 13.3289 - val_categorical_accuracy: 0.1606\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0118 - categorical_accuracy: 0.9978 - val_loss: 15.3394 - val_categorical_accuracy: 0.1670\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0127 - categorical_accuracy: 0.9978 - val_loss: 9.0091 - val_categorical_accuracy: 0.1804\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0150 - categorical_accuracy: 0.9968 - val_loss: 9.5094 - val_categorical_accuracy: 0.1190\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0163 - categorical_accuracy: 0.9965 - val_loss: 8.5623 - val_categorical_accuracy: 0.0793\n",
      "Epoch 389/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0249 - categorical_accuracy: 0.9955 - val_loss: 14.7799 - val_categorical_accuracy: 0.1075\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0224 - categorical_accuracy: 0.9939 - val_loss: 10.6718 - val_categorical_accuracy: 0.1062\n",
      "Epoch 391/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0140 - categorical_accuracy: 0.9966 - val_loss: 11.2578 - val_categorical_accuracy: 0.1644\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0148 - categorical_accuracy: 0.9958 - val_loss: 9.7086 - val_categorical_accuracy: 0.1062\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0110 - categorical_accuracy: 0.9973 - val_loss: 9.0579 - val_categorical_accuracy: 0.1759\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0179 - categorical_accuracy: 0.9958 - val_loss: 11.7732 - val_categorical_accuracy: 0.1196\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0187 - categorical_accuracy: 0.9970 - val_loss: 13.6806 - val_categorical_accuracy: 0.1651\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0178 - categorical_accuracy: 0.9966 - val_loss: 12.2718 - val_categorical_accuracy: 0.1113\n",
      "Epoch 397/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0112 - categorical_accuracy: 0.9973 - val_loss: 12.8998 - val_categorical_accuracy: 0.1491\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0129 - categorical_accuracy: 0.9974 - val_loss: 10.7062 - val_categorical_accuracy: 0.1631\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0192 - categorical_accuracy: 0.9973 - val_loss: 12.6207 - val_categorical_accuracy: 0.1062\n",
      "Epoch 400/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0144 - categorical_accuracy: 0.9966 - val_loss: 13.0253 - val_categorical_accuracy: 0.1580\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0125 - categorical_accuracy: 0.9970 - val_loss: 10.1120 - val_categorical_accuracy: 0.1516\n",
      "Epoch 402/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0122 - categorical_accuracy: 0.9970 - val_loss: 13.1398 - val_categorical_accuracy: 0.0985\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0220 - categorical_accuracy: 0.9968 - val_loss: 12.3331 - val_categorical_accuracy: 0.1203\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0205 - categorical_accuracy: 0.9970 - val_loss: 13.4298 - val_categorical_accuracy: 0.1126\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0184 - categorical_accuracy: 0.9966 - val_loss: 16.0227 - val_categorical_accuracy: 0.1663\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0171 - categorical_accuracy: 0.9973 - val_loss: 14.0759 - val_categorical_accuracy: 0.1619\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0103 - categorical_accuracy: 0.9976 - val_loss: 14.5418 - val_categorical_accuracy: 0.1260\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0076 - categorical_accuracy: 0.9987 - val_loss: 13.6369 - val_categorical_accuracy: 0.1024\n",
      "Epoch 409/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0067 - categorical_accuracy: 0.9978 - val_loss: 9.4252 - val_categorical_accuracy: 0.1459\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0124 - categorical_accuracy: 0.9974 - val_loss: 14.8008 - val_categorical_accuracy: 0.0940\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0113 - categorical_accuracy: 0.9971 - val_loss: 14.5457 - val_categorical_accuracy: 0.1452\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0090 - categorical_accuracy: 0.9978 - val_loss: 12.3067 - val_categorical_accuracy: 0.1510\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0088 - categorical_accuracy: 0.9981 - val_loss: 13.0137 - val_categorical_accuracy: 0.1062\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0088 - categorical_accuracy: 0.9970 - val_loss: 16.2681 - val_categorical_accuracy: 0.0889\n",
      "Epoch 415/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0122 - categorical_accuracy: 0.9976 - val_loss: 8.8190 - val_categorical_accuracy: 0.1216\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0076 - categorical_accuracy: 0.9978 - val_loss: 16.7462 - val_categorical_accuracy: 0.1139\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0088 - categorical_accuracy: 0.9982 - val_loss: 13.2095 - val_categorical_accuracy: 0.1516\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0097 - categorical_accuracy: 0.9981 - val_loss: 16.2367 - val_categorical_accuracy: 0.1139\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0079 - categorical_accuracy: 0.9982 - val_loss: 10.5336 - val_categorical_accuracy: 0.1139\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0071 - categorical_accuracy: 0.9987 - val_loss: 15.2632 - val_categorical_accuracy: 0.1184\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0083 - categorical_accuracy: 0.9973 - val_loss: 16.6551 - val_categorical_accuracy: 0.1606\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0118 - categorical_accuracy: 0.9968 - val_loss: 14.1912 - val_categorical_accuracy: 0.1196\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0230 - categorical_accuracy: 0.9954 - val_loss: 17.3646 - val_categorical_accuracy: 0.1036\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0206 - categorical_accuracy: 0.9957 - val_loss: 16.8588 - val_categorical_accuracy: 0.1152\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0159 - categorical_accuracy: 0.9971 - val_loss: 14.2854 - val_categorical_accuracy: 0.1139\n",
      "Epoch 426/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0113 - categorical_accuracy: 0.9970 - val_loss: 14.8052 - val_categorical_accuracy: 0.1126\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0097 - categorical_accuracy: 0.9984 - val_loss: 16.0898 - val_categorical_accuracy: 0.1056\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0072 - categorical_accuracy: 0.9978 - val_loss: 11.8180 - val_categorical_accuracy: 0.1811\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0160 - categorical_accuracy: 0.9973 - val_loss: 9.5443 - val_categorical_accuracy: 0.1235\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0135 - categorical_accuracy: 0.9971 - val_loss: 13.2370 - val_categorical_accuracy: 0.1663\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0158 - categorical_accuracy: 0.9974 - val_loss: 16.5551 - val_categorical_accuracy: 0.1062\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0114 - categorical_accuracy: 0.9978 - val_loss: 12.4955 - val_categorical_accuracy: 0.1536\n",
      "Epoch 433/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0105 - categorical_accuracy: 0.9971 - val_loss: 11.8199 - val_categorical_accuracy: 0.1126\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0064 - categorical_accuracy: 0.9984 - val_loss: 9.7021 - val_categorical_accuracy: 0.1203\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0037 - categorical_accuracy: 0.9994 - val_loss: 13.0027 - val_categorical_accuracy: 0.1280\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0086 - categorical_accuracy: 0.9992 - val_loss: 14.4024 - val_categorical_accuracy: 0.0883\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0104 - categorical_accuracy: 0.9982 - val_loss: 18.3757 - val_categorical_accuracy: 0.1395\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0182 - categorical_accuracy: 0.9970 - val_loss: 8.5288 - val_categorical_accuracy: 0.0953\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0151 - categorical_accuracy: 0.9976 - val_loss: 12.5000 - val_categorical_accuracy: 0.1657\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0111 - categorical_accuracy: 0.9978 - val_loss: 9.1723 - val_categorical_accuracy: 0.1152\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0161 - categorical_accuracy: 0.9970 - val_loss: 11.4617 - val_categorical_accuracy: 0.1567\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0185 - categorical_accuracy: 0.9971 - val_loss: 12.2247 - val_categorical_accuracy: 0.1228\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0135 - categorical_accuracy: 0.9970 - val_loss: 13.7378 - val_categorical_accuracy: 0.1292\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0183 - categorical_accuracy: 0.9966 - val_loss: 10.4494 - val_categorical_accuracy: 0.1120\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0228 - categorical_accuracy: 0.9965 - val_loss: 13.0723 - val_categorical_accuracy: 0.1068\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0166 - categorical_accuracy: 0.9970 - val_loss: 8.0918 - val_categorical_accuracy: 0.0928\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0170 - categorical_accuracy: 0.9965 - val_loss: 12.0345 - val_categorical_accuracy: 0.1158\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0181 - categorical_accuracy: 0.9965 - val_loss: 7.9330 - val_categorical_accuracy: 0.0998\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0175 - categorical_accuracy: 0.9960 - val_loss: 8.8511 - val_categorical_accuracy: 0.1254\n",
      "Epoch 450/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0095 - categorical_accuracy: 0.9981 - val_loss: 13.8843 - val_categorical_accuracy: 0.1695\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0106 - categorical_accuracy: 0.9973 - val_loss: 16.2234 - val_categorical_accuracy: 0.0851\n",
      "Epoch 452/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0066 - categorical_accuracy: 0.9986 - val_loss: 13.4794 - val_categorical_accuracy: 0.1241\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0079 - categorical_accuracy: 0.9981 - val_loss: 14.7702 - val_categorical_accuracy: 0.1171\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0112 - categorical_accuracy: 0.9974 - val_loss: 12.7055 - val_categorical_accuracy: 0.1248\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0141 - categorical_accuracy: 0.9974 - val_loss: 15.8295 - val_categorical_accuracy: 0.1126\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0151 - categorical_accuracy: 0.9965 - val_loss: 14.7879 - val_categorical_accuracy: 0.1139\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0091 - categorical_accuracy: 0.9981 - val_loss: 11.9800 - val_categorical_accuracy: 0.1260\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0104 - categorical_accuracy: 0.9973 - val_loss: 16.1536 - val_categorical_accuracy: 0.1177\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0114 - categorical_accuracy: 0.9979 - val_loss: 8.4013 - val_categorical_accuracy: 0.1280\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0073 - categorical_accuracy: 0.9984 - val_loss: 15.3655 - val_categorical_accuracy: 0.1593\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0053 - categorical_accuracy: 0.9989 - val_loss: 15.5759 - val_categorical_accuracy: 0.1222\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0089 - categorical_accuracy: 0.9984 - val_loss: 12.6716 - val_categorical_accuracy: 0.1740\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0108 - categorical_accuracy: 0.9976 - val_loss: 8.6308 - val_categorical_accuracy: 0.0832\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0140 - categorical_accuracy: 0.9979 - val_loss: 15.3651 - val_categorical_accuracy: 0.0832\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0110 - categorical_accuracy: 0.9981 - val_loss: 14.4725 - val_categorical_accuracy: 0.1606\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0085 - categorical_accuracy: 0.9979 - val_loss: 15.1721 - val_categorical_accuracy: 0.1120\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0102 - categorical_accuracy: 0.9989 - val_loss: 14.2545 - val_categorical_accuracy: 0.1030\n",
      "Epoch 468/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0099 - categorical_accuracy: 0.9973 - val_loss: 18.5659 - val_categorical_accuracy: 0.1599\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0132 - categorical_accuracy: 0.9978 - val_loss: 12.7805 - val_categorical_accuracy: 0.1139\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0083 - categorical_accuracy: 0.9979 - val_loss: 14.2110 - val_categorical_accuracy: 0.1510\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0048 - categorical_accuracy: 0.9987 - val_loss: 13.5228 - val_categorical_accuracy: 0.1638\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0066 - categorical_accuracy: 0.9986 - val_loss: 8.5589 - val_categorical_accuracy: 0.1344\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0104 - categorical_accuracy: 0.9989 - val_loss: 13.6133 - val_categorical_accuracy: 0.1267\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0119 - categorical_accuracy: 0.9982 - val_loss: 8.6901 - val_categorical_accuracy: 0.1408\n",
      "Epoch 475/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0079 - categorical_accuracy: 0.9986 - val_loss: 13.6772 - val_categorical_accuracy: 0.1145\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0034 - categorical_accuracy: 0.9992 - val_loss: 13.7084 - val_categorical_accuracy: 0.1113\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0042 - categorical_accuracy: 0.9990 - val_loss: 14.2087 - val_categorical_accuracy: 0.1228\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0144 - categorical_accuracy: 0.9971 - val_loss: 14.7635 - val_categorical_accuracy: 0.1695\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0165 - categorical_accuracy: 0.9971 - val_loss: 15.3244 - val_categorical_accuracy: 0.1171\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0145 - categorical_accuracy: 0.9970 - val_loss: 14.2504 - val_categorical_accuracy: 0.1190\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0130 - categorical_accuracy: 0.9974 - val_loss: 13.2278 - val_categorical_accuracy: 0.1024\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0121 - categorical_accuracy: 0.9966 - val_loss: 13.0935 - val_categorical_accuracy: 0.1715\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0120 - categorical_accuracy: 0.9973 - val_loss: 15.9179 - val_categorical_accuracy: 0.1510\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0150 - categorical_accuracy: 0.9965 - val_loss: 10.6728 - val_categorical_accuracy: 0.1094\n",
      "Epoch 485/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0145 - categorical_accuracy: 0.9970 - val_loss: 13.1067 - val_categorical_accuracy: 0.1222\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0116 - categorical_accuracy: 0.9974 - val_loss: 14.5473 - val_categorical_accuracy: 0.1657\n",
      "Epoch 487/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0104 - categorical_accuracy: 0.9979 - val_loss: 13.5395 - val_categorical_accuracy: 0.1222\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0086 - categorical_accuracy: 0.9978 - val_loss: 14.8276 - val_categorical_accuracy: 0.1145\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0111 - categorical_accuracy: 0.9974 - val_loss: 10.6319 - val_categorical_accuracy: 0.1280\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0092 - categorical_accuracy: 0.9981 - val_loss: 10.0744 - val_categorical_accuracy: 0.1759\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0083 - categorical_accuracy: 0.9987 - val_loss: 10.7742 - val_categorical_accuracy: 0.1107\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0079 - categorical_accuracy: 0.9979 - val_loss: 14.3854 - val_categorical_accuracy: 0.1184\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0098 - categorical_accuracy: 0.9982 - val_loss: 12.0357 - val_categorical_accuracy: 0.1100\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0060 - categorical_accuracy: 0.9982 - val_loss: 11.0351 - val_categorical_accuracy: 0.1190\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0076 - categorical_accuracy: 0.9987 - val_loss: 10.9259 - val_categorical_accuracy: 0.1139\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0064 - categorical_accuracy: 0.9986 - val_loss: 15.1978 - val_categorical_accuracy: 0.1030\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0078 - categorical_accuracy: 0.9982 - val_loss: 13.7654 - val_categorical_accuracy: 0.1382\n",
      "Epoch 498/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0167 - categorical_accuracy: 0.9976 - val_loss: 15.4945 - val_categorical_accuracy: 0.1248\n",
      "Epoch 499/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0146 - categorical_accuracy: 0.9968 - val_loss: 9.7274 - val_categorical_accuracy: 0.1068\n",
      "Epoch 500/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0103 - categorical_accuracy: 0.9981 - val_loss: 14.6710 - val_categorical_accuracy: 0.1580\n",
      "Finished.\n",
      "Training Sequential Activation Neural Network...\n",
      "Epoch 1/500\n",
      "49/49 [==============================] - 5s 70ms/step - loss: 2.8987 - categorical_accuracy: 0.0458 - val_loss: 2.7325 - val_categorical_accuracy: 0.0736\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.3578 - categorical_accuracy: 0.2439 - val_loss: 2.7565 - val_categorical_accuracy: 0.0736\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.8904 - categorical_accuracy: 0.5194 - val_loss: 2.7525 - val_categorical_accuracy: 0.0736\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.4709 - categorical_accuracy: 0.7169 - val_loss: 2.9718 - val_categorical_accuracy: 0.0736\n",
      "Epoch 5/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.2193 - categorical_accuracy: 0.7987 - val_loss: 2.9774 - val_categorical_accuracy: 0.0736\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0460 - categorical_accuracy: 0.8246 - val_loss: 3.3887 - val_categorical_accuracy: 0.0934\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0138 - categorical_accuracy: 0.7772 - val_loss: 3.6038 - val_categorical_accuracy: 0.1644\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8547 - categorical_accuracy: 0.8262 - val_loss: 3.6882 - val_categorical_accuracy: 0.0678\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.6763 - categorical_accuracy: 0.8825 - val_loss: 4.0667 - val_categorical_accuracy: 0.1644\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.5579 - categorical_accuracy: 0.9195 - val_loss: 4.1749 - val_categorical_accuracy: 0.0736\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.4651 - categorical_accuracy: 0.9475 - val_loss: 4.1483 - val_categorical_accuracy: 0.0755\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.3952 - categorical_accuracy: 0.9592 - val_loss: 4.1597 - val_categorical_accuracy: 0.1043\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.3340 - categorical_accuracy: 0.9680 - val_loss: 4.1082 - val_categorical_accuracy: 0.0787\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.2837 - categorical_accuracy: 0.9755 - val_loss: 4.1105 - val_categorical_accuracy: 0.1049\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.2424 - categorical_accuracy: 0.9806 - val_loss: 4.2825 - val_categorical_accuracy: 0.1049\n",
      "Epoch 16/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2081 - categorical_accuracy: 0.9864 - val_loss: 4.4148 - val_categorical_accuracy: 0.1094\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1792 - categorical_accuracy: 0.9912 - val_loss: 4.4089 - val_categorical_accuracy: 0.1056\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1564 - categorical_accuracy: 0.9931 - val_loss: 6.3512 - val_categorical_accuracy: 0.1056\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1393 - categorical_accuracy: 0.9958 - val_loss: 5.4776 - val_categorical_accuracy: 0.0371\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1223 - categorical_accuracy: 0.9955 - val_loss: 5.5326 - val_categorical_accuracy: 0.0838\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1063 - categorical_accuracy: 0.9973 - val_loss: 7.4710 - val_categorical_accuracy: 0.0448\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0942 - categorical_accuracy: 0.9966 - val_loss: 3.8414 - val_categorical_accuracy: 0.1491\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0914 - categorical_accuracy: 0.9968 - val_loss: 7.2667 - val_categorical_accuracy: 0.0345\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1051 - categorical_accuracy: 0.9906 - val_loss: 5.6274 - val_categorical_accuracy: 0.0313\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1140 - categorical_accuracy: 0.9875 - val_loss: 8.4300 - val_categorical_accuracy: 0.0505\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1598 - categorical_accuracy: 0.9738 - val_loss: 5.8751 - val_categorical_accuracy: 0.0122\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1778 - categorical_accuracy: 0.9637 - val_loss: 7.5447 - val_categorical_accuracy: 0.0493\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.2195 - categorical_accuracy: 0.9515 - val_loss: 4.8962 - val_categorical_accuracy: 0.0998\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1673 - categorical_accuracy: 0.9691 - val_loss: 5.2783 - val_categorical_accuracy: 0.1011\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0999 - categorical_accuracy: 0.9858 - val_loss: 5.4278 - val_categorical_accuracy: 0.0883\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0736 - categorical_accuracy: 0.9938 - val_loss: 5.5372 - val_categorical_accuracy: 0.0998\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0619 - categorical_accuracy: 0.9962 - val_loss: 4.9211 - val_categorical_accuracy: 0.0960\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0502 - categorical_accuracy: 0.9979 - val_loss: 6.1728 - val_categorical_accuracy: 0.0953\n",
      "Epoch 34/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0441 - categorical_accuracy: 0.9978 - val_loss: 6.0941 - val_categorical_accuracy: 0.1036\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0375 - categorical_accuracy: 0.9987 - val_loss: 5.4930 - val_categorical_accuracy: 0.1158\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0346 - categorical_accuracy: 0.9986 - val_loss: 5.6226 - val_categorical_accuracy: 0.1209\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0306 - categorical_accuracy: 0.9989 - val_loss: 5.8463 - val_categorical_accuracy: 0.1056\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0287 - categorical_accuracy: 0.9994 - val_loss: 5.9333 - val_categorical_accuracy: 0.1414\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0258 - categorical_accuracy: 0.9992 - val_loss: 5.6964 - val_categorical_accuracy: 0.1484\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0251 - categorical_accuracy: 0.9990 - val_loss: 5.5234 - val_categorical_accuracy: 0.1504\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0226 - categorical_accuracy: 0.9990 - val_loss: 5.3706 - val_categorical_accuracy: 0.1561\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0204 - categorical_accuracy: 0.9992 - val_loss: 6.6267 - val_categorical_accuracy: 0.1132\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0191 - categorical_accuracy: 0.9992 - val_loss: 6.4020 - val_categorical_accuracy: 0.1145\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0180 - categorical_accuracy: 0.9990 - val_loss: 6.5880 - val_categorical_accuracy: 0.0934\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0179 - categorical_accuracy: 0.9992 - val_loss: 6.5210 - val_categorical_accuracy: 0.1337\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0161 - categorical_accuracy: 0.9997 - val_loss: 7.0997 - val_categorical_accuracy: 0.1017\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0150 - categorical_accuracy: 0.9998 - val_loss: 6.2537 - val_categorical_accuracy: 0.1484\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0141 - categorical_accuracy: 0.9995 - val_loss: 5.7407 - val_categorical_accuracy: 0.1536\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0135 - categorical_accuracy: 0.9997 - val_loss: 5.3413 - val_categorical_accuracy: 0.1542\n",
      "Epoch 50/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0132 - categorical_accuracy: 0.9997 - val_loss: 7.0120 - val_categorical_accuracy: 0.1459\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0120 - categorical_accuracy: 0.9997 - val_loss: 5.5278 - val_categorical_accuracy: 0.1599\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0128 - categorical_accuracy: 0.9994 - val_loss: 6.6925 - val_categorical_accuracy: 0.0915\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0130 - categorical_accuracy: 0.9995 - val_loss: 7.8636 - val_categorical_accuracy: 0.1228\n",
      "Epoch 54/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0104 - categorical_accuracy: 0.9998 - val_loss: 6.0303 - val_categorical_accuracy: 0.1414\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0096 - categorical_accuracy: 0.9997 - val_loss: 5.9298 - val_categorical_accuracy: 0.1561\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0090 - categorical_accuracy: 0.9998 - val_loss: 4.8983 - val_categorical_accuracy: 0.1727\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0090 - categorical_accuracy: 0.9998 - val_loss: 5.6320 - val_categorical_accuracy: 0.1516\n",
      "Epoch 58/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0084 - categorical_accuracy: 0.9997 - val_loss: 5.1488 - val_categorical_accuracy: 0.1497\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0081 - categorical_accuracy: 0.9998 - val_loss: 10.4097 - val_categorical_accuracy: 0.1075\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0078 - categorical_accuracy: 0.9997 - val_loss: 7.8333 - val_categorical_accuracy: 0.1132\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0083 - categorical_accuracy: 0.9998 - val_loss: 8.4513 - val_categorical_accuracy: 0.1587\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0079 - categorical_accuracy: 0.9995 - val_loss: 7.7710 - val_categorical_accuracy: 0.1401\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0078 - categorical_accuracy: 0.9995 - val_loss: 7.0834 - val_categorical_accuracy: 0.0896\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0109 - categorical_accuracy: 0.9994 - val_loss: 10.6794 - val_categorical_accuracy: 0.0685\n",
      "Epoch 65/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0106 - categorical_accuracy: 0.9990 - val_loss: 8.9153 - val_categorical_accuracy: 0.0857\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0076 - categorical_accuracy: 0.9997 - val_loss: 7.6896 - val_categorical_accuracy: 0.1030\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0070 - categorical_accuracy: 0.9995 - val_loss: 6.6552 - val_categorical_accuracy: 0.1248\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0062 - categorical_accuracy: 0.9997 - val_loss: 7.3475 - val_categorical_accuracy: 0.1171\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0058 - categorical_accuracy: 0.9995 - val_loss: 6.6159 - val_categorical_accuracy: 0.1427\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0058 - categorical_accuracy: 0.9997 - val_loss: 5.5089 - val_categorical_accuracy: 0.1548\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0060 - categorical_accuracy: 0.9995 - val_loss: 6.4719 - val_categorical_accuracy: 0.1241\n",
      "Epoch 72/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0068 - categorical_accuracy: 0.9994 - val_loss: 7.4492 - val_categorical_accuracy: 0.0819\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0077 - categorical_accuracy: 0.9992 - val_loss: 9.0434 - val_categorical_accuracy: 0.1107\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0075 - categorical_accuracy: 0.9990 - val_loss: 11.6364 - val_categorical_accuracy: 0.1081\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0091 - categorical_accuracy: 0.9984 - val_loss: 9.2997 - val_categorical_accuracy: 0.0576\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0120 - categorical_accuracy: 0.9982 - val_loss: 9.1600 - val_categorical_accuracy: 0.0749\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0184 - categorical_accuracy: 0.9970 - val_loss: 9.3213 - val_categorical_accuracy: 0.0480\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0240 - categorical_accuracy: 0.9942 - val_loss: 7.6669 - val_categorical_accuracy: 0.1235\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0569 - categorical_accuracy: 0.9886 - val_loss: 9.5434 - val_categorical_accuracy: 0.1004\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1289 - categorical_accuracy: 0.9662 - val_loss: 12.0226 - val_categorical_accuracy: 0.0998\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1830 - categorical_accuracy: 0.9515 - val_loss: 8.8308 - val_categorical_accuracy: 0.1011\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1370 - categorical_accuracy: 0.9603 - val_loss: 12.4988 - val_categorical_accuracy: 0.0333\n",
      "Epoch 83/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0672 - categorical_accuracy: 0.9818 - val_loss: 11.9626 - val_categorical_accuracy: 0.0333\n",
      "Epoch 84/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0406 - categorical_accuracy: 0.9902 - val_loss: 12.0669 - val_categorical_accuracy: 0.0333\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0289 - categorical_accuracy: 0.9939 - val_loss: 11.1873 - val_categorical_accuracy: 0.0345\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0183 - categorical_accuracy: 0.9971 - val_loss: 11.2690 - val_categorical_accuracy: 0.0429\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0163 - categorical_accuracy: 0.9981 - val_loss: 9.4455 - val_categorical_accuracy: 0.0429\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0142 - categorical_accuracy: 0.9982 - val_loss: 10.4667 - val_categorical_accuracy: 0.0685\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0097 - categorical_accuracy: 0.9994 - val_loss: 7.5459 - val_categorical_accuracy: 0.1120\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0081 - categorical_accuracy: 0.9995 - val_loss: 7.5199 - val_categorical_accuracy: 0.1344\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0088 - categorical_accuracy: 0.9992 - val_loss: 7.4737 - val_categorical_accuracy: 0.1395\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0079 - categorical_accuracy: 0.9989 - val_loss: 7.3147 - val_categorical_accuracy: 0.1241\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0065 - categorical_accuracy: 0.9994 - val_loss: 7.1109 - val_categorical_accuracy: 0.1376\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0069 - categorical_accuracy: 0.9994 - val_loss: 5.6954 - val_categorical_accuracy: 0.1612\n",
      "Epoch 95/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0066 - categorical_accuracy: 0.9992 - val_loss: 7.5444 - val_categorical_accuracy: 0.1651\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0069 - categorical_accuracy: 0.9994 - val_loss: 7.7103 - val_categorical_accuracy: 0.1184\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0053 - categorical_accuracy: 0.9992 - val_loss: 7.6412 - val_categorical_accuracy: 0.1145\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0054 - categorical_accuracy: 0.9997 - val_loss: 8.8431 - val_categorical_accuracy: 0.1260\n",
      "Epoch 99/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0041 - categorical_accuracy: 0.9997 - val_loss: 7.0789 - val_categorical_accuracy: 0.1369\n",
      "Epoch 100/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0037 - categorical_accuracy: 1.0000 - val_loss: 5.8303 - val_categorical_accuracy: 0.1638\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0043 - categorical_accuracy: 0.9997 - val_loss: 6.5498 - val_categorical_accuracy: 0.1286\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0048 - categorical_accuracy: 0.9995 - val_loss: 6.5713 - val_categorical_accuracy: 0.1350\n",
      "Epoch 103/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0031 - categorical_accuracy: 0.9998 - val_loss: 6.5655 - val_categorical_accuracy: 0.1555\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0030 - categorical_accuracy: 0.9998 - val_loss: 6.5307 - val_categorical_accuracy: 0.1286\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0047 - categorical_accuracy: 0.9992 - val_loss: 6.3333 - val_categorical_accuracy: 0.1606\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0115 - categorical_accuracy: 0.9976 - val_loss: 11.1403 - val_categorical_accuracy: 0.1894\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0060 - categorical_accuracy: 0.9989 - val_loss: 10.8979 - val_categorical_accuracy: 0.1209\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0051 - categorical_accuracy: 0.9994 - val_loss: 7.4689 - val_categorical_accuracy: 0.1548\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0048 - categorical_accuracy: 0.9994 - val_loss: 7.4347 - val_categorical_accuracy: 0.1516\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0035 - categorical_accuracy: 0.9997 - val_loss: 7.7659 - val_categorical_accuracy: 0.1516\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0041 - categorical_accuracy: 0.9994 - val_loss: 7.3982 - val_categorical_accuracy: 0.1574\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0035 - categorical_accuracy: 0.9995 - val_loss: 6.7443 - val_categorical_accuracy: 0.1260\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0030 - categorical_accuracy: 0.9998 - val_loss: 8.2066 - val_categorical_accuracy: 0.1702\n",
      "Epoch 114/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 9.6421 - val_categorical_accuracy: 0.1241\n",
      "Epoch 115/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0028 - categorical_accuracy: 0.9995 - val_loss: 9.3162 - val_categorical_accuracy: 0.1209\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0027 - categorical_accuracy: 0.9998 - val_loss: 8.5000 - val_categorical_accuracy: 0.1715\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 7.7326 - val_categorical_accuracy: 0.1651\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0023 - categorical_accuracy: 0.9998 - val_loss: 7.2863 - val_categorical_accuracy: 0.1593\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 7.1045 - val_categorical_accuracy: 0.1657\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 6.8199 - val_categorical_accuracy: 0.1593\n",
      "Epoch 121/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 6.7876 - val_categorical_accuracy: 0.1318\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0018 - categorical_accuracy: 0.9998 - val_loss: 6.7177 - val_categorical_accuracy: 0.1305\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 6.4166 - val_categorical_accuracy: 0.1446\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0020 - categorical_accuracy: 0.9997 - val_loss: 6.9435 - val_categorical_accuracy: 0.1580\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 12.2176 - val_categorical_accuracy: 0.1241\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 9.2153 - val_categorical_accuracy: 0.1593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 8.6905 - val_categorical_accuracy: 0.1497\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9995 - val_loss: 7.3225 - val_categorical_accuracy: 0.1529\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 11.8869 - val_categorical_accuracy: 0.1056\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 10.8463 - val_categorical_accuracy: 0.1184\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 8.2679 - val_categorical_accuracy: 0.1497\n",
      "Epoch 132/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 8.4528 - val_categorical_accuracy: 0.1702\n",
      "Epoch 133/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 7.3179 - val_categorical_accuracy: 0.1651\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 6.9161 - val_categorical_accuracy: 0.1382\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 6.6757 - val_categorical_accuracy: 0.1529\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 7.7314 - val_categorical_accuracy: 0.1587\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 8.6333 - val_categorical_accuracy: 0.1248\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 7.8591 - val_categorical_accuracy: 0.1292\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 6.8955 - val_categorical_accuracy: 0.1599\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 10.5331 - val_categorical_accuracy: 0.1235\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9995 - val_loss: 9.4583 - val_categorical_accuracy: 0.1305\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 9.4561 - val_categorical_accuracy: 0.1177\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0032 - categorical_accuracy: 0.9992 - val_loss: 10.8927 - val_categorical_accuracy: 0.1273\n",
      "Epoch 144/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0023 - categorical_accuracy: 0.9997 - val_loss: 7.7970 - val_categorical_accuracy: 0.1465\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0039 - categorical_accuracy: 0.9992 - val_loss: 10.3826 - val_categorical_accuracy: 0.1024\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0175 - categorical_accuracy: 0.9970 - val_loss: 12.3787 - val_categorical_accuracy: 0.1036\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0228 - categorical_accuracy: 0.9957 - val_loss: 15.7888 - val_categorical_accuracy: 0.0461\n",
      "Epoch 148/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0360 - categorical_accuracy: 0.9920 - val_loss: 14.9559 - val_categorical_accuracy: 0.1043\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0474 - categorical_accuracy: 0.9878 - val_loss: 13.6511 - val_categorical_accuracy: 0.1356\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0912 - categorical_accuracy: 0.9754 - val_loss: 13.2794 - val_categorical_accuracy: 0.0467\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1021 - categorical_accuracy: 0.9730 - val_loss: 11.0369 - val_categorical_accuracy: 0.0550\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0570 - categorical_accuracy: 0.9835 - val_loss: 11.9573 - val_categorical_accuracy: 0.0505\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0328 - categorical_accuracy: 0.9907 - val_loss: 11.0358 - val_categorical_accuracy: 0.0525\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0223 - categorical_accuracy: 0.9934 - val_loss: 8.0810 - val_categorical_accuracy: 0.1132\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0165 - categorical_accuracy: 0.9973 - val_loss: 10.9348 - val_categorical_accuracy: 0.1414\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0100 - categorical_accuracy: 0.9979 - val_loss: 11.2786 - val_categorical_accuracy: 0.0717\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0062 - categorical_accuracy: 0.9989 - val_loss: 10.3175 - val_categorical_accuracy: 0.0902\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0070 - categorical_accuracy: 0.9984 - val_loss: 8.2725 - val_categorical_accuracy: 0.0985\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0051 - categorical_accuracy: 0.9992 - val_loss: 10.4506 - val_categorical_accuracy: 0.1465\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0049 - categorical_accuracy: 0.9992 - val_loss: 9.9894 - val_categorical_accuracy: 0.1472\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0055 - categorical_accuracy: 0.9987 - val_loss: 10.2711 - val_categorical_accuracy: 0.1580\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0048 - categorical_accuracy: 0.9992 - val_loss: 8.9038 - val_categorical_accuracy: 0.1107\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0049 - categorical_accuracy: 0.9994 - val_loss: 9.4438 - val_categorical_accuracy: 0.1350\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0042 - categorical_accuracy: 0.9990 - val_loss: 9.1750 - val_categorical_accuracy: 0.1107\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0040 - categorical_accuracy: 0.9992 - val_loss: 9.6187 - val_categorical_accuracy: 0.0902\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0035 - categorical_accuracy: 0.9994 - val_loss: 9.9358 - val_categorical_accuracy: 0.1260\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0025 - categorical_accuracy: 0.9997 - val_loss: 10.2796 - val_categorical_accuracy: 0.1561\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0027 - categorical_accuracy: 0.9995 - val_loss: 9.9173 - val_categorical_accuracy: 0.1440\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0034 - categorical_accuracy: 0.9992 - val_loss: 9.1440 - val_categorical_accuracy: 0.1190\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0032 - categorical_accuracy: 0.9989 - val_loss: 9.8676 - val_categorical_accuracy: 0.0972\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9995 - val_loss: 9.6584 - val_categorical_accuracy: 0.1273\n",
      "Epoch 172/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0026 - categorical_accuracy: 0.9994 - val_loss: 8.7241 - val_categorical_accuracy: 0.1177\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0037 - categorical_accuracy: 0.9990 - val_loss: 13.7377 - val_categorical_accuracy: 0.1478\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0035 - categorical_accuracy: 0.9995 - val_loss: 12.3880 - val_categorical_accuracy: 0.1164\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0023 - categorical_accuracy: 0.9995 - val_loss: 8.5968 - val_categorical_accuracy: 0.1440\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 9.3641 - val_categorical_accuracy: 0.1113\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 7.9647 - val_categorical_accuracy: 0.1388\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0025 - categorical_accuracy: 0.9995 - val_loss: 10.9417 - val_categorical_accuracy: 0.1625\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 10.0122 - val_categorical_accuracy: 0.1612\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0019 - categorical_accuracy: 0.9995 - val_loss: 9.1250 - val_categorical_accuracy: 0.1280\n",
      "Epoch 181/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 0.9995 - val_loss: 9.6004 - val_categorical_accuracy: 0.1324\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 0.9998 - val_loss: 11.9867 - val_categorical_accuracy: 0.1561\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 9.3807 - val_categorical_accuracy: 0.1587\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0018 - categorical_accuracy: 0.9994 - val_loss: 12.5453 - val_categorical_accuracy: 0.0640\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9998 - val_loss: 10.5511 - val_categorical_accuracy: 0.1184\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 9.0862 - val_categorical_accuracy: 0.1388\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 8.7846 - val_categorical_accuracy: 0.1638\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 10.5099 - val_categorical_accuracy: 0.1388\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 10.5703 - val_categorical_accuracy: 0.1567\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 10.5708 - val_categorical_accuracy: 0.0966\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.2105e-04 - categorical_accuracy: 0.9998 - val_loss: 8.5977 - val_categorical_accuracy: 0.1177\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 9.3797 - val_categorical_accuracy: 0.1414\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9995 - val_loss: 10.9943 - val_categorical_accuracy: 0.1299\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.5899e-04 - categorical_accuracy: 1.0000 - val_loss: 9.7466 - val_categorical_accuracy: 0.1433\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.1340e-04 - categorical_accuracy: 0.9998 - val_loss: 12.0116 - val_categorical_accuracy: 0.1555\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 11.3278 - val_categorical_accuracy: 0.1484\n",
      "Epoch 197/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0018 - categorical_accuracy: 0.9995 - val_loss: 9.8984 - val_categorical_accuracy: 0.1472\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0016 - categorical_accuracy: 0.9995 - val_loss: 10.3561 - val_categorical_accuracy: 0.1414\n",
      "Epoch 199/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0034 - categorical_accuracy: 0.9990 - val_loss: 10.7818 - val_categorical_accuracy: 0.1145\n",
      "Epoch 200/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 0.9994 - val_loss: 11.1229 - val_categorical_accuracy: 0.1561\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9995 - val_loss: 11.6778 - val_categorical_accuracy: 0.1171\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 11.8769 - val_categorical_accuracy: 0.1401\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0034 - categorical_accuracy: 0.9990 - val_loss: 10.1687 - val_categorical_accuracy: 0.0972\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0051 - categorical_accuracy: 0.9989 - val_loss: 9.9207 - val_categorical_accuracy: 0.1196\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0042 - categorical_accuracy: 0.9989 - val_loss: 12.1681 - val_categorical_accuracy: 0.1452\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0122 - categorical_accuracy: 0.9970 - val_loss: 10.0456 - val_categorical_accuracy: 0.1017\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0572 - categorical_accuracy: 0.9891 - val_loss: 16.7666 - val_categorical_accuracy: 0.1068\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0404 - categorical_accuracy: 0.9920 - val_loss: 10.3077 - val_categorical_accuracy: 0.1254\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0253 - categorical_accuracy: 0.9936 - val_loss: 9.6963 - val_categorical_accuracy: 0.1472\n",
      "Epoch 210/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0209 - categorical_accuracy: 0.9942 - val_loss: 10.3554 - val_categorical_accuracy: 0.0915\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0143 - categorical_accuracy: 0.9962 - val_loss: 12.7026 - val_categorical_accuracy: 0.1516\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0152 - categorical_accuracy: 0.9955 - val_loss: 18.3283 - val_categorical_accuracy: 0.1427\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0150 - categorical_accuracy: 0.9965 - val_loss: 13.4191 - val_categorical_accuracy: 0.1440\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0087 - categorical_accuracy: 0.9982 - val_loss: 9.3707 - val_categorical_accuracy: 0.1408\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0087 - categorical_accuracy: 0.9984 - val_loss: 12.2012 - val_categorical_accuracy: 0.1075\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0105 - categorical_accuracy: 0.9971 - val_loss: 12.2709 - val_categorical_accuracy: 0.1363\n",
      "Epoch 217/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0106 - categorical_accuracy: 0.9973 - val_loss: 11.2803 - val_categorical_accuracy: 0.1523\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0060 - categorical_accuracy: 0.9987 - val_loss: 11.1347 - val_categorical_accuracy: 0.1497\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0047 - categorical_accuracy: 0.9994 - val_loss: 15.0837 - val_categorical_accuracy: 0.1241\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0052 - categorical_accuracy: 0.9989 - val_loss: 10.8940 - val_categorical_accuracy: 0.1395\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0060 - categorical_accuracy: 0.9987 - val_loss: 10.3966 - val_categorical_accuracy: 0.1427\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0040 - categorical_accuracy: 0.9989 - val_loss: 12.3683 - val_categorical_accuracy: 0.0909\n",
      "Epoch 223/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0031 - categorical_accuracy: 0.9992 - val_loss: 16.2472 - val_categorical_accuracy: 0.1446\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0035 - categorical_accuracy: 0.9990 - val_loss: 12.7907 - val_categorical_accuracy: 0.1433\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0032 - categorical_accuracy: 0.9992 - val_loss: 14.7498 - val_categorical_accuracy: 0.1248\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0032 - categorical_accuracy: 0.9994 - val_loss: 10.9989 - val_categorical_accuracy: 0.1414\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0028 - categorical_accuracy: 0.9994 - val_loss: 11.8308 - val_categorical_accuracy: 0.1043\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0042 - categorical_accuracy: 0.9992 - val_loss: 11.0191 - val_categorical_accuracy: 0.1504\n",
      "Epoch 229/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0039 - categorical_accuracy: 0.9992 - val_loss: 10.7835 - val_categorical_accuracy: 0.1446\n",
      "Epoch 230/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0024 - categorical_accuracy: 0.9994 - val_loss: 11.0708 - val_categorical_accuracy: 0.1427\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 10.5856 - val_categorical_accuracy: 0.1056\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 11.9345 - val_categorical_accuracy: 0.0921\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0019 - categorical_accuracy: 0.9995 - val_loss: 9.8158 - val_categorical_accuracy: 0.1216\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 11.2309 - val_categorical_accuracy: 0.1612\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 10.9150 - val_categorical_accuracy: 0.1561\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 9.1072 - val_categorical_accuracy: 0.1587\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 10.6094 - val_categorical_accuracy: 0.0813\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 9.8280 - val_categorical_accuracy: 0.1158\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.5525e-04 - categorical_accuracy: 0.9998 - val_loss: 11.3799 - val_categorical_accuracy: 0.1420\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.4968e-04 - categorical_accuracy: 1.0000 - val_loss: 12.3472 - val_categorical_accuracy: 0.1427\n",
      "Epoch 241/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 11.6576 - val_categorical_accuracy: 0.1567\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0022 - categorical_accuracy: 0.9998 - val_loss: 9.0997 - val_categorical_accuracy: 0.1459\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0025 - categorical_accuracy: 0.9992 - val_loss: 16.2592 - val_categorical_accuracy: 0.1452\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0026 - categorical_accuracy: 0.9994 - val_loss: 14.5226 - val_categorical_accuracy: 0.1504\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9994 - val_loss: 12.2011 - val_categorical_accuracy: 0.1510\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 9.8248 - val_categorical_accuracy: 0.1363\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 11.2910 - val_categorical_accuracy: 0.1408\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.3480e-04 - categorical_accuracy: 1.0000 - val_loss: 11.5873 - val_categorical_accuracy: 0.1555\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.0025e-04 - categorical_accuracy: 0.9998 - val_loss: 11.5848 - val_categorical_accuracy: 0.1504\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 12.2699 - val_categorical_accuracy: 0.1612\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0029 - categorical_accuracy: 0.9992 - val_loss: 16.2634 - val_categorical_accuracy: 0.1100\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9998 - val_loss: 11.1366 - val_categorical_accuracy: 0.1177\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 0.9997 - val_loss: 11.5712 - val_categorical_accuracy: 0.1100\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0023 - categorical_accuracy: 0.9995 - val_loss: 13.7755 - val_categorical_accuracy: 0.1286\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9994 - val_loss: 10.9661 - val_categorical_accuracy: 0.1702\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0024 - categorical_accuracy: 0.9995 - val_loss: 11.2248 - val_categorical_accuracy: 0.0979\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9994 - val_loss: 12.3743 - val_categorical_accuracy: 0.1145\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.4655e-04 - categorical_accuracy: 0.9998 - val_loss: 14.5546 - val_categorical_accuracy: 0.1228\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 11.0000 - val_categorical_accuracy: 0.1516\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 14.7793 - val_categorical_accuracy: 0.1401\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0023 - categorical_accuracy: 0.9994 - val_loss: 19.7885 - val_categorical_accuracy: 0.0147\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0050 - categorical_accuracy: 0.9990 - val_loss: 13.4777 - val_categorical_accuracy: 0.1017\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0027 - categorical_accuracy: 0.9994 - val_loss: 13.4941 - val_categorical_accuracy: 0.0774\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0027 - categorical_accuracy: 0.9997 - val_loss: 11.5174 - val_categorical_accuracy: 0.0787\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0102 - categorical_accuracy: 0.9973 - val_loss: 18.4961 - val_categorical_accuracy: 0.1663\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0116 - categorical_accuracy: 0.9973 - val_loss: 16.0105 - val_categorical_accuracy: 0.0473\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0101 - categorical_accuracy: 0.9976 - val_loss: 10.4882 - val_categorical_accuracy: 0.0902\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0165 - categorical_accuracy: 0.9965 - val_loss: 17.8997 - val_categorical_accuracy: 0.0493\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0176 - categorical_accuracy: 0.9958 - val_loss: 20.5213 - val_categorical_accuracy: 0.0416\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0215 - categorical_accuracy: 0.9941 - val_loss: 15.9899 - val_categorical_accuracy: 0.1382\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0172 - categorical_accuracy: 0.9962 - val_loss: 19.1784 - val_categorical_accuracy: 0.1376\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0112 - categorical_accuracy: 0.9973 - val_loss: 14.1778 - val_categorical_accuracy: 0.1401\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0087 - categorical_accuracy: 0.9966 - val_loss: 16.2247 - val_categorical_accuracy: 0.1401\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0069 - categorical_accuracy: 0.9982 - val_loss: 19.7928 - val_categorical_accuracy: 0.0972\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0062 - categorical_accuracy: 0.9982 - val_loss: 14.2135 - val_categorical_accuracy: 0.1088\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0065 - categorical_accuracy: 0.9984 - val_loss: 18.3831 - val_categorical_accuracy: 0.1030\n",
      "Epoch 277/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0060 - categorical_accuracy: 0.9984 - val_loss: 19.8044 - val_categorical_accuracy: 0.1088\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0037 - categorical_accuracy: 0.9994 - val_loss: 13.6422 - val_categorical_accuracy: 0.0665\n",
      "Epoch 279/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0027 - categorical_accuracy: 0.9994 - val_loss: 13.2141 - val_categorical_accuracy: 0.1158\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9995 - val_loss: 9.9967 - val_categorical_accuracy: 0.1196\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 11.5083 - val_categorical_accuracy: 0.1401\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 12.3256 - val_categorical_accuracy: 0.1248\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.3463e-04 - categorical_accuracy: 1.0000 - val_loss: 9.4147 - val_categorical_accuracy: 0.1324\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 13.7586 - val_categorical_accuracy: 0.0313\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 14.6819 - val_categorical_accuracy: 0.0441\n",
      "Epoch 286/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 16.3726 - val_categorical_accuracy: 0.0294\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.8242e-04 - categorical_accuracy: 0.9998 - val_loss: 17.2971 - val_categorical_accuracy: 0.0365\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 14.0741 - val_categorical_accuracy: 0.1587\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 15.8918 - val_categorical_accuracy: 0.0768\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 15.1582 - val_categorical_accuracy: 0.0563\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 9.4135 - val_categorical_accuracy: 0.1478\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.4139e-04 - categorical_accuracy: 0.9998 - val_loss: 10.0512 - val_categorical_accuracy: 0.1408\n",
      "Epoch 293/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 9.7163e-04 - categorical_accuracy: 1.0000 - val_loss: 15.3729 - val_categorical_accuracy: 0.1548\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.8479e-04 - categorical_accuracy: 0.9998 - val_loss: 14.6034 - val_categorical_accuracy: 0.1555\n",
      "Epoch 295/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0029 - categorical_accuracy: 0.9997 - val_loss: 13.7554 - val_categorical_accuracy: 0.1651\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0029 - categorical_accuracy: 0.9989 - val_loss: 15.2573 - val_categorical_accuracy: 0.0275\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0075 - categorical_accuracy: 0.9976 - val_loss: 14.4841 - val_categorical_accuracy: 0.0870\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0084 - categorical_accuracy: 0.9982 - val_loss: 14.2551 - val_categorical_accuracy: 0.0947\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0104 - categorical_accuracy: 0.9973 - val_loss: 17.5969 - val_categorical_accuracy: 0.1004\n",
      "Epoch 300/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0140 - categorical_accuracy: 0.9973 - val_loss: 15.9729 - val_categorical_accuracy: 0.1049\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0077 - categorical_accuracy: 0.9986 - val_loss: 14.8111 - val_categorical_accuracy: 0.1068\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0067 - categorical_accuracy: 0.9992 - val_loss: 12.2428 - val_categorical_accuracy: 0.1132\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0044 - categorical_accuracy: 0.9992 - val_loss: 15.0454 - val_categorical_accuracy: 0.1459\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0027 - categorical_accuracy: 0.9994 - val_loss: 13.7072 - val_categorical_accuracy: 0.1472\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0026 - categorical_accuracy: 0.9992 - val_loss: 13.8665 - val_categorical_accuracy: 0.1331\n",
      "Epoch 306/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0023 - categorical_accuracy: 0.9994 - val_loss: 19.1286 - val_categorical_accuracy: 0.1081\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0039 - categorical_accuracy: 0.9998 - val_loss: 12.5400 - val_categorical_accuracy: 0.0992\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0026 - categorical_accuracy: 0.9992 - val_loss: 15.0494 - val_categorical_accuracy: 0.0864\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0039 - categorical_accuracy: 0.9994 - val_loss: 21.3435 - val_categorical_accuracy: 0.0173\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0038 - categorical_accuracy: 0.9990 - val_loss: 13.4384 - val_categorical_accuracy: 0.1030\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9997 - val_loss: 12.1212 - val_categorical_accuracy: 0.1388\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0035 - categorical_accuracy: 0.9990 - val_loss: 13.9276 - val_categorical_accuracy: 0.1567\n",
      "Epoch 313/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0040 - categorical_accuracy: 0.9989 - val_loss: 14.2761 - val_categorical_accuracy: 0.1536\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0041 - categorical_accuracy: 0.9990 - val_loss: 15.9038 - val_categorical_accuracy: 0.0985\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0051 - categorical_accuracy: 0.9989 - val_loss: 14.0462 - val_categorical_accuracy: 0.1574\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0053 - categorical_accuracy: 0.9984 - val_loss: 14.7307 - val_categorical_accuracy: 0.1478\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0053 - categorical_accuracy: 0.9987 - val_loss: 17.8732 - val_categorical_accuracy: 0.0537\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 18.8596 - val_categorical_accuracy: 0.1043\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9995 - val_loss: 12.4978 - val_categorical_accuracy: 0.1196\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0026 - categorical_accuracy: 0.9994 - val_loss: 19.0730 - val_categorical_accuracy: 0.1011\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0042 - categorical_accuracy: 0.9992 - val_loss: 17.0086 - val_categorical_accuracy: 0.0838\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0052 - categorical_accuracy: 0.9978 - val_loss: 14.5602 - val_categorical_accuracy: 0.0678\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0035 - categorical_accuracy: 0.9992 - val_loss: 17.6423 - val_categorical_accuracy: 0.0800\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0023 - categorical_accuracy: 0.9995 - val_loss: 16.8826 - val_categorical_accuracy: 0.1088\n",
      "Epoch 325/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0031 - categorical_accuracy: 0.9986 - val_loss: 12.4395 - val_categorical_accuracy: 0.1171\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0045 - categorical_accuracy: 0.9986 - val_loss: 16.9907 - val_categorical_accuracy: 0.1036\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0045 - categorical_accuracy: 0.9987 - val_loss: 21.4976 - val_categorical_accuracy: 0.0998\n",
      "Epoch 328/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0041 - categorical_accuracy: 0.9987 - val_loss: 17.1251 - val_categorical_accuracy: 0.1043\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0064 - categorical_accuracy: 0.9989 - val_loss: 18.4649 - val_categorical_accuracy: 0.1030\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0034 - categorical_accuracy: 0.9990 - val_loss: 19.5539 - val_categorical_accuracy: 0.1049\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9994 - val_loss: 16.9822 - val_categorical_accuracy: 0.0819\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0050 - categorical_accuracy: 0.9989 - val_loss: 17.5197 - val_categorical_accuracy: 0.1024\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0035 - categorical_accuracy: 0.9990 - val_loss: 16.8835 - val_categorical_accuracy: 0.0781\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0069 - categorical_accuracy: 0.9987 - val_loss: 13.2151 - val_categorical_accuracy: 0.1126\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0068 - categorical_accuracy: 0.9978 - val_loss: 20.4103 - val_categorical_accuracy: 0.0934\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0043 - categorical_accuracy: 0.9986 - val_loss: 18.8172 - val_categorical_accuracy: 0.1657\n",
      "Epoch 337/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0069 - categorical_accuracy: 0.9984 - val_loss: 20.6350 - val_categorical_accuracy: 0.0512\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0051 - categorical_accuracy: 0.9986 - val_loss: 24.5203 - val_categorical_accuracy: 0.0441\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0032 - categorical_accuracy: 0.9989 - val_loss: 24.0700 - val_categorical_accuracy: 0.0512\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0022 - categorical_accuracy: 0.9995 - val_loss: 22.6022 - val_categorical_accuracy: 0.0518\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 14.0105 - val_categorical_accuracy: 0.0940\n",
      "Epoch 342/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9995 - val_loss: 15.5155 - val_categorical_accuracy: 0.1190\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9994 - val_loss: 18.5108 - val_categorical_accuracy: 0.1113\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9994 - val_loss: 22.1662 - val_categorical_accuracy: 0.1107\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 16.8386 - val_categorical_accuracy: 0.1132\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.4461e-04 - categorical_accuracy: 1.0000 - val_loss: 12.8253 - val_categorical_accuracy: 0.1248\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.7814e-04 - categorical_accuracy: 0.9998 - val_loss: 11.2447 - val_categorical_accuracy: 0.1305\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.5590e-04 - categorical_accuracy: 1.0000 - val_loss: 14.8735 - val_categorical_accuracy: 0.1075\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 19.3445 - val_categorical_accuracy: 0.1036\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.6928e-04 - categorical_accuracy: 0.9998 - val_loss: 17.8378 - val_categorical_accuracy: 0.1120\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0016 - categorical_accuracy: 0.9995 - val_loss: 17.9446 - val_categorical_accuracy: 0.1561\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9994 - val_loss: 16.0901 - val_categorical_accuracy: 0.1683\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0016 - categorical_accuracy: 0.9994 - val_loss: 12.0094 - val_categorical_accuracy: 0.1420\n",
      "Epoch 354/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 15.3749 - val_categorical_accuracy: 0.1260\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0020 - categorical_accuracy: 0.9994 - val_loss: 19.9668 - val_categorical_accuracy: 0.1075\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.2060e-04 - categorical_accuracy: 1.0000 - val_loss: 21.7901 - val_categorical_accuracy: 0.1107\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9995 - val_loss: 19.6680 - val_categorical_accuracy: 0.1254\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.8445e-04 - categorical_accuracy: 0.9998 - val_loss: 14.9003 - val_categorical_accuracy: 0.1350\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9997 - val_loss: 19.1407 - val_categorical_accuracy: 0.1139\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0019 - categorical_accuracy: 0.9995 - val_loss: 13.0242 - val_categorical_accuracy: 0.1120\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0018 - categorical_accuracy: 0.9995 - val_loss: 13.3669 - val_categorical_accuracy: 0.1497\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 0.9995 - val_loss: 15.6944 - val_categorical_accuracy: 0.0928\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.2651e-04 - categorical_accuracy: 1.0000 - val_loss: 14.9776 - val_categorical_accuracy: 0.1216\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 3.1166e-04 - categorical_accuracy: 1.0000 - val_loss: 13.6220 - val_categorical_accuracy: 0.1228\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.5089e-04 - categorical_accuracy: 0.9998 - val_loss: 17.3187 - val_categorical_accuracy: 0.1190\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 19.3858 - val_categorical_accuracy: 0.0601\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 7.9487e-04 - categorical_accuracy: 0.9998 - val_loss: 17.2983 - val_categorical_accuracy: 0.0633\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.3105e-04 - categorical_accuracy: 0.9998 - val_loss: 13.7234 - val_categorical_accuracy: 0.1254\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 8.2602e-04 - categorical_accuracy: 0.9997 - val_loss: 12.2460 - val_categorical_accuracy: 0.1177\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0015 - categorical_accuracy: 0.9992 - val_loss: 14.3656 - val_categorical_accuracy: 0.1312\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.3717e-04 - categorical_accuracy: 0.9998 - val_loss: 14.2167 - val_categorical_accuracy: 0.1344\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.8817e-04 - categorical_accuracy: 0.9998 - val_loss: 17.6916 - val_categorical_accuracy: 0.1068\n",
      "Epoch 373/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.9585e-04 - categorical_accuracy: 0.9998 - val_loss: 18.3458 - val_categorical_accuracy: 0.1113\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0012 - categorical_accuracy: 0.9995 - val_loss: 13.6304 - val_categorical_accuracy: 0.1574\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.4675e-04 - categorical_accuracy: 0.9998 - val_loss: 16.1205 - val_categorical_accuracy: 0.1158\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0052 - categorical_accuracy: 0.9990 - val_loss: 14.6192 - val_categorical_accuracy: 0.1216\n",
      "Epoch 377/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0076 - categorical_accuracy: 0.9981 - val_loss: 18.5273 - val_categorical_accuracy: 0.1395\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0081 - categorical_accuracy: 0.9973 - val_loss: 24.3161 - val_categorical_accuracy: 0.1049\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0158 - categorical_accuracy: 0.9958 - val_loss: 14.9635 - val_categorical_accuracy: 0.0736\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0154 - categorical_accuracy: 0.9946 - val_loss: 20.2016 - val_categorical_accuracy: 0.0768\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0267 - categorical_accuracy: 0.9918 - val_loss: 20.8912 - val_categorical_accuracy: 0.0736\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0161 - categorical_accuracy: 0.9938 - val_loss: 15.8571 - val_categorical_accuracy: 0.0998\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0168 - categorical_accuracy: 0.9957 - val_loss: 13.1428 - val_categorical_accuracy: 0.1049\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0110 - categorical_accuracy: 0.9965 - val_loss: 13.3815 - val_categorical_accuracy: 0.1139\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0070 - categorical_accuracy: 0.9978 - val_loss: 19.0589 - val_categorical_accuracy: 0.1011\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0054 - categorical_accuracy: 0.9987 - val_loss: 18.3775 - val_categorical_accuracy: 0.1004\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0052 - categorical_accuracy: 0.9989 - val_loss: 17.2105 - val_categorical_accuracy: 0.0838\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0020 - categorical_accuracy: 0.9997 - val_loss: 12.9400 - val_categorical_accuracy: 0.1433\n",
      "Epoch 389/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 12.9512 - val_categorical_accuracy: 0.1363\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 11.2889 - val_categorical_accuracy: 0.1299\n",
      "Epoch 391/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.8223e-04 - categorical_accuracy: 0.9998 - val_loss: 11.1043 - val_categorical_accuracy: 0.1695\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 13.3794 - val_categorical_accuracy: 0.1555\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 20.6165 - val_categorical_accuracy: 0.1100\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0025 - categorical_accuracy: 0.9995 - val_loss: 13.9382 - val_categorical_accuracy: 0.1254\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 13.4179 - val_categorical_accuracy: 0.1299\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9995 - val_loss: 16.0426 - val_categorical_accuracy: 0.1088\n",
      "Epoch 397/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9995 - val_loss: 12.4955 - val_categorical_accuracy: 0.1075\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 13.6801 - val_categorical_accuracy: 0.1292\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.2952e-04 - categorical_accuracy: 1.0000 - val_loss: 12.6083 - val_categorical_accuracy: 0.1286\n",
      "Epoch 400/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.3581e-04 - categorical_accuracy: 0.9997 - val_loss: 13.6588 - val_categorical_accuracy: 0.1068\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.7536e-04 - categorical_accuracy: 0.9998 - val_loss: 13.1611 - val_categorical_accuracy: 0.1216\n",
      "Epoch 402/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.9342e-04 - categorical_accuracy: 0.9998 - val_loss: 15.8529 - val_categorical_accuracy: 0.0819\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.8624e-04 - categorical_accuracy: 0.9998 - val_loss: 12.3132 - val_categorical_accuracy: 0.1356\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9998 - val_loss: 21.6657 - val_categorical_accuracy: 0.0979\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.2389e-04 - categorical_accuracy: 0.9998 - val_loss: 21.5924 - val_categorical_accuracy: 0.0531\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 12.0421 - val_categorical_accuracy: 0.1324\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.4350e-04 - categorical_accuracy: 1.0000 - val_loss: 17.7613 - val_categorical_accuracy: 0.1056\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.9438e-04 - categorical_accuracy: 1.0000 - val_loss: 17.8593 - val_categorical_accuracy: 0.1088\n",
      "Epoch 409/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.1251e-04 - categorical_accuracy: 0.9998 - val_loss: 16.3219 - val_categorical_accuracy: 0.1228\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.9036e-04 - categorical_accuracy: 0.9998 - val_loss: 13.4979 - val_categorical_accuracy: 0.1555\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.1871e-04 - categorical_accuracy: 0.9998 - val_loss: 18.2861 - val_categorical_accuracy: 0.0838\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.6911e-04 - categorical_accuracy: 0.9998 - val_loss: 12.6847 - val_categorical_accuracy: 0.1228\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.6250e-04 - categorical_accuracy: 1.0000 - val_loss: 11.0480 - val_categorical_accuracy: 0.1344\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9992 - val_loss: 15.0666 - val_categorical_accuracy: 0.0704\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0045 - categorical_accuracy: 0.9992 - val_loss: 23.2414 - val_categorical_accuracy: 0.1030\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0042 - categorical_accuracy: 0.9989 - val_loss: 23.8881 - val_categorical_accuracy: 0.0473\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0020 - categorical_accuracy: 0.9997 - val_loss: 21.4015 - val_categorical_accuracy: 0.1107\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 21.3802 - val_categorical_accuracy: 0.0569\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.2008e-04 - categorical_accuracy: 1.0000 - val_loss: 17.3154 - val_categorical_accuracy: 0.0704\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9997 - val_loss: 17.7342 - val_categorical_accuracy: 0.1107\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 15.7923 - val_categorical_accuracy: 0.0864\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.4066e-04 - categorical_accuracy: 0.9997 - val_loss: 15.3706 - val_categorical_accuracy: 0.1100\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0016 - categorical_accuracy: 0.9994 - val_loss: 18.4930 - val_categorical_accuracy: 0.0531\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 15.9608 - val_categorical_accuracy: 0.0685\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 12.3686 - val_categorical_accuracy: 0.1516\n",
      "Epoch 426/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0025 - categorical_accuracy: 0.9992 - val_loss: 17.4901 - val_categorical_accuracy: 0.1068\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0037 - categorical_accuracy: 0.9994 - val_loss: 23.3914 - val_categorical_accuracy: 0.1030\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0022 - categorical_accuracy: 0.9994 - val_loss: 13.6677 - val_categorical_accuracy: 0.1017\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9994 - val_loss: 18.5086 - val_categorical_accuracy: 0.0781\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9995 - val_loss: 19.6420 - val_categorical_accuracy: 0.1094\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0019 - categorical_accuracy: 0.9994 - val_loss: 16.6250 - val_categorical_accuracy: 0.1030\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0035 - categorical_accuracy: 0.9995 - val_loss: 18.9269 - val_categorical_accuracy: 0.1152\n",
      "Epoch 433/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.7591e-04 - categorical_accuracy: 1.0000 - val_loss: 14.6281 - val_categorical_accuracy: 0.1152\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0031 - categorical_accuracy: 0.9986 - val_loss: 23.9063 - val_categorical_accuracy: 0.1036\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0113 - categorical_accuracy: 0.9968 - val_loss: 24.2698 - val_categorical_accuracy: 0.0960\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0121 - categorical_accuracy: 0.9973 - val_loss: 12.4990 - val_categorical_accuracy: 0.1561\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0125 - categorical_accuracy: 0.9952 - val_loss: 13.6725 - val_categorical_accuracy: 0.0723\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0111 - categorical_accuracy: 0.9971 - val_loss: 13.5954 - val_categorical_accuracy: 0.0857\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0122 - categorical_accuracy: 0.9971 - val_loss: 14.2001 - val_categorical_accuracy: 0.0992\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0032 - categorical_accuracy: 0.9994 - val_loss: 21.9953 - val_categorical_accuracy: 0.1024\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0049 - categorical_accuracy: 0.9989 - val_loss: 18.4028 - val_categorical_accuracy: 0.1011\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0028 - categorical_accuracy: 0.9992 - val_loss: 11.9574 - val_categorical_accuracy: 0.1184\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0021 - categorical_accuracy: 0.9995 - val_loss: 16.8659 - val_categorical_accuracy: 0.0678\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0037 - categorical_accuracy: 0.9987 - val_loss: 18.5347 - val_categorical_accuracy: 0.0736\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0020 - categorical_accuracy: 0.9994 - val_loss: 19.8125 - val_categorical_accuracy: 0.0685\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 8.8255e-04 - categorical_accuracy: 0.9998 - val_loss: 13.8416 - val_categorical_accuracy: 0.1280\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0025 - categorical_accuracy: 0.9994 - val_loss: 12.3250 - val_categorical_accuracy: 0.1203\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0018 - categorical_accuracy: 0.9995 - val_loss: 23.9243 - val_categorical_accuracy: 0.1056\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9995 - val_loss: 22.2485 - val_categorical_accuracy: 0.1036\n",
      "Epoch 450/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 15.8960 - val_categorical_accuracy: 0.0851\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0050 - categorical_accuracy: 0.9987 - val_loss: 23.2933 - val_categorical_accuracy: 0.1036\n",
      "Epoch 452/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0019 - categorical_accuracy: 0.9994 - val_loss: 15.2228 - val_categorical_accuracy: 0.1459\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 9.9887e-04 - categorical_accuracy: 1.0000 - val_loss: 12.8099 - val_categorical_accuracy: 0.1369\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 16.4656 - val_categorical_accuracy: 0.0934\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 7.3952e-04 - categorical_accuracy: 1.0000 - val_loss: 12.1492 - val_categorical_accuracy: 0.1408\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.9621e-04 - categorical_accuracy: 0.9998 - val_loss: 10.8108 - val_categorical_accuracy: 0.1440\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.3147e-04 - categorical_accuracy: 0.9998 - val_loss: 11.1844 - val_categorical_accuracy: 0.1228\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.5416e-04 - categorical_accuracy: 0.9997 - val_loss: 19.8437 - val_categorical_accuracy: 0.1062\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.5148e-04 - categorical_accuracy: 0.9998 - val_loss: 11.3301 - val_categorical_accuracy: 0.1324\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.9193e-04 - categorical_accuracy: 0.9997 - val_loss: 12.3910 - val_categorical_accuracy: 0.1574\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 6.3860e-04 - categorical_accuracy: 0.9998 - val_loss: 15.4258 - val_categorical_accuracy: 0.1356\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.5172e-04 - categorical_accuracy: 0.9998 - val_loss: 23.9339 - val_categorical_accuracy: 0.1043\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.4270e-04 - categorical_accuracy: 1.0000 - val_loss: 21.9426 - val_categorical_accuracy: 0.1094\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 9.0531e-04 - categorical_accuracy: 0.9997 - val_loss: 22.3469 - val_categorical_accuracy: 0.1094\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 8.4843e-04 - categorical_accuracy: 0.9998 - val_loss: 15.7086 - val_categorical_accuracy: 0.1017\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.4412e-04 - categorical_accuracy: 0.9998 - val_loss: 17.8644 - val_categorical_accuracy: 0.0761\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 10.3792 - val_categorical_accuracy: 0.1510\n",
      "Epoch 468/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0013 - categorical_accuracy: 0.9995 - val_loss: 15.8173 - val_categorical_accuracy: 0.1164\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0020 - categorical_accuracy: 0.9997 - val_loss: 17.1292 - val_categorical_accuracy: 0.1088\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0030 - categorical_accuracy: 0.9998 - val_loss: 14.9797 - val_categorical_accuracy: 0.0979\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0018 - categorical_accuracy: 0.9995 - val_loss: 11.8565 - val_categorical_accuracy: 0.1459\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.2955e-04 - categorical_accuracy: 0.9997 - val_loss: 14.3499 - val_categorical_accuracy: 0.1446\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0014 - categorical_accuracy: 0.9994 - val_loss: 15.1267 - val_categorical_accuracy: 0.0998\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0029 - categorical_accuracy: 0.9995 - val_loss: 14.9126 - val_categorical_accuracy: 0.1472\n",
      "Epoch 475/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.1286e-04 - categorical_accuracy: 0.9998 - val_loss: 13.8570 - val_categorical_accuracy: 0.1651\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 5.8883e-04 - categorical_accuracy: 0.9998 - val_loss: 13.4942 - val_categorical_accuracy: 0.1350\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 4.6649e-04 - categorical_accuracy: 1.0000 - val_loss: 11.8160 - val_categorical_accuracy: 0.1350\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 7.7223e-04 - categorical_accuracy: 0.9998 - val_loss: 15.5985 - val_categorical_accuracy: 0.1017\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0022 - categorical_accuracy: 0.9998 - val_loss: 18.5637 - val_categorical_accuracy: 0.1011\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.0607e-04 - categorical_accuracy: 0.9997 - val_loss: 20.7275 - val_categorical_accuracy: 0.1049\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 22.3487 - val_categorical_accuracy: 0.1056\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0042 - categorical_accuracy: 0.9990 - val_loss: 14.8623 - val_categorical_accuracy: 0.1625\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0052 - categorical_accuracy: 0.9982 - val_loss: 22.5021 - val_categorical_accuracy: 0.1011\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0059 - categorical_accuracy: 0.9981 - val_loss: 22.8995 - val_categorical_accuracy: 0.0966\n",
      "Epoch 485/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0099 - categorical_accuracy: 0.9979 - val_loss: 21.2915 - val_categorical_accuracy: 0.1030\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0060 - categorical_accuracy: 0.9987 - val_loss: 22.7891 - val_categorical_accuracy: 0.0992\n",
      "Epoch 487/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0055 - categorical_accuracy: 0.9992 - val_loss: 13.7219 - val_categorical_accuracy: 0.1280\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0096 - categorical_accuracy: 0.9981 - val_loss: 20.6973 - val_categorical_accuracy: 0.0940\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0117 - categorical_accuracy: 0.9968 - val_loss: 20.9683 - val_categorical_accuracy: 0.0966\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0133 - categorical_accuracy: 0.9958 - val_loss: 21.0939 - val_categorical_accuracy: 0.0979\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0080 - categorical_accuracy: 0.9978 - val_loss: 24.0893 - val_categorical_accuracy: 0.0992\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0047 - categorical_accuracy: 0.9987 - val_loss: 22.9708 - val_categorical_accuracy: 0.1068\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0045 - categorical_accuracy: 0.9986 - val_loss: 21.5879 - val_categorical_accuracy: 0.1107\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0049 - categorical_accuracy: 0.9986 - val_loss: 19.9955 - val_categorical_accuracy: 0.0685\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0043 - categorical_accuracy: 0.9990 - val_loss: 19.2047 - val_categorical_accuracy: 0.0928\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0039 - categorical_accuracy: 0.9992 - val_loss: 15.6969 - val_categorical_accuracy: 0.1260\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9995 - val_loss: 12.6187 - val_categorical_accuracy: 0.1036\n",
      "Epoch 498/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0017 - categorical_accuracy: 0.9998 - val_loss: 11.4025 - val_categorical_accuracy: 0.1190\n",
      "Epoch 499/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0014 - categorical_accuracy: 0.9995 - val_loss: 13.1686 - val_categorical_accuracy: 0.1606\n",
      "Epoch 500/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 13.9331 - val_categorical_accuracy: 0.1516\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Create and fit all neural networks for evaluations\n",
    "models, histories = test(X_train, y_train.to_numpy(), X_test=X_test, y_test=y_test.to_numpy(), num_classes=len(one_hot.categories_[0]), task='classification', epochs=500, batch_size=128, task_name='NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29664b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss over the epochs\n",
    "plt.plot(np.array(range(len(histories['MANN'].history['loss']))), histories['MANN'].history['loss'], label='MANN')\n",
    "plt.plot(np.array(range(len(histories['MANN_dropout'].history['loss']))), histories['MANN_dropout'].history['loss'], label='MANN_dropout')\n",
    "plt.plot(np.array(range(len(histories['Sigmoid'].history['loss']))), histories['Sigmoid'].history['loss'], label='Sigmoid')\n",
    "plt.plot(np.array(range(len(histories['Tanh'].history['loss']))), histories['Tanh'].history['loss'], label='Tanh')\n",
    "plt.plot(np.array(range(len(histories['LeakyReLU'].history['loss']))), histories['LeakyReLU'].history['loss'], label='Leaky ReLU')\n",
    "plt.plot(np.array(range(len(histories['ELU'].history['loss']))), histories['ELU'].history['loss'], label='ELU')\n",
    "plt.plot(np.array(range(len(histories['Swish'].history['loss']))), histories['Swish'].history['loss'], label='Swish')\n",
    "plt.plot(np.array(range(len(histories['Sequential'].history['loss']))), histories['Sequential'].history['loss'], label='Sequential')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dec42fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAGoCAYAAACNPguRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd7wU5fX/PzOz7XaK0hQRQxQroomIGkVFQVFjJPbyQ1ATRRNjDRbEEtsX29f6jSKYWDAmSmLDIAoWiqIgKoiKIFIv7fYtU57fH888z8zszu6d3bu3wXm/Xle8u7Ozz+7dnTlzzud8jsIYYyAIgiAIgiDyRm3vBRAEQRAEQXRWKJAiCIIgCIIoEAqkCIIgCIIgCoQCKYIgCIIgiAKhQIogCIIgCKJAKJAiCIIgCIIoEAqkCIIgCIIgCiTU3gsgCIIgiEIxTRO6rrf3MogdjHA4DE3TAm1LgRRBEATR6WCMYePGjaipqWnvpRA7KF26dEGvXr2gKErO7SiQIgiCIDodIojq0aMHSktLmz3ZEURQGGNoampCdXU1AKB37945t6dAiiAIguhUmKYpg6ju3bu393KIHZCSkhIAQHV1NXr06JGzzEdic4IgCKJTITRRpaWl7bwSYkdGfL6a0+BRIEUQBEF0SqicR7QmQT9fFEgRBEEQBEEUCAVSBEEQBEEQBUKBFEEQBEEQRIFQIEUQBEEQbcSYMWOgKAp+//vfZ9w3fvx4KIqCMWPGeG6fP38+NE3DqFGjMh6zevVqKIqCHj16oL6+3nPfwQcfjEmTJsnfhw0bBkVRMH36dM92Dz/8MPbcc8+CX9PODgVSBEEQBNGG9O3bF9OnT0c8Hpe3JRIJvPjii9hjjz0ytp8yZQquuuoqfPDBB1i/fr3vPuvr6zF58uRmnzsWi+GWW24hN/giQoEUQRAEQbQhhxxyCPr27YtXX31V3vbqq69ijz32wODBgz3bNjQ04OWXX8bll1+OUaNGYdq0ab77vOqqq/Dggw9KE8lsnHvuuaipqcHTTz/d4tdBcDqlIadlWVi/fj0qKiqo/ZUgCGInI5VKwbIsmKYJ0zTl7YwxGBZr07WEVCWv8xBjDIwxjBkzBs8++yzOOeccADzr9P/+3//D3LlzwRiTr2v69OkYOHAgBgwYgHPPPRfXXnstbrjhBvmcYruzzjoLs2bNwu23347//d//lc8n3ifx3BUVFZgwYQLuuOMOXHDBBSgrK4NlWZ59tSaMMViWhXA4vMOcvztlILV+/Xr07du3vZdBEARBtAP9+vXDU0895SmNAYBhMZzzau6MTLGZfkYPhNTgAcHWrVvR0NCAgw46CDfddBPeeustAMDHH3+MCRMm4D//+Q9M08TixYsBAI8++iiGDx+OxYsXo2fPnti6dSumTJmCQw89FABkqW/FihUYO3YsrrnmGpxwwgnYfffd0dTUhI0bN8p9NTQ0oLq6GmeffTZUVcUNN9yASy65BGvXrkUqlZLbtQUHHXQQIpFImz1fa9IpA6mKigoAwE8//YTKysp2Xg1BEATRlqRSKWzatAl77rknYrGYvJ0xhm8O7tgZqe7du0PTNBx33HEYNWoUFi1aBMYYRo0ahWOPPRaPPvoounTpgsGDB2PFihVYtmwZZs6ciR49egAAzjvvPHz44Ye45JJLAABdu3YFAAwcOBAHH3wwXn31Vbz88st4/vnnUVpail69eslyYXl5OXr06IEhQ4bg7rvvxh//+Efcfvvt2H333RGJRDLKiq2BaZpYunQpVHXHURZ1ykBKfGgrKyspkCIIgtjJSCQS2Lx5MzRNy5iB1tFPaorCAy9N0zBu3DhceeWVAIDHH38cmqZ57p82bRoMw/BUYBhjiEajePzxx1FVVSVfv3gv7rvvPgwdOhQ33HADAEBVVbmNe98XXXQRHnzwQdxzzz2yYy/XPLnWeB92FHackJAgCIIgOhEjR45EKpWCrusYMWKE5z7DMPC3v/0NDzzwAJYsWSJ/vvjiC/Tp0wcvvfSS7z4PO+wwnHHGGfjzn/+c87lVVcU999yDJ598EqtXry7WS9op6ejBO0EQBEHskGiahuXLl8v/d/PGG29g+/btGDduHKqqqjz3jR49GlOmTPH1ogKAv/zlL9h///0RCuU+xY8aNQpDhgzB//3f/6Fnz54teCU7N5SRIgiCIIh2IptEZcqUKRg+fHhGEAXwQGrRokVYunSp7z733ntvjB07FolEotnnv++++wJtR2RHYYy1rTKvCNTV1aGqqgq1tbWkkSIIgtjJSCQSWLVqFfr37+8RmxMdH9GROHjw4DbVZBVC0M8ZZaQIgiAIgiAKhAIpgiAIgiCIAqFAiiAIgiAIokAokCIIgiAIgigQCqQIgiAIgiAKhAIpgiAIgiCIAqFAiiAIgiAIokAokCIIgiAIgigQCqQIgiAIgiAKhAIpAgDw+X9/xJJ317T3MgiCIIhOxqRJk3DwwQe39zLaDQqkCABAokFHokFv72UQBEHs0IwZMwaKovgOHB4/fjwURcGYMWM8t8+fPx+apmHUqFEZj1m9ejUURUGPHj1QX1/vue/ggw/GpEmT5O/Dhg2DoiiYPn26Z7uHH34Ye+65Z8GvqbNR7MCPAimCw4DON3WRIAii89G3b19Mnz4d8Xhc3pZIJPDiiy9ijz32yNh+ypQpuOqqq/DBBx9g/fr1vvusr6/H5MmTm33uWCyGW265BbredhfOqVSqzZ6rPaBAigAAMACdcH41QRBEp+OQQw5B37598eqrr8rbXn31Veyxxx4YPHiwZ9uGhga8/PLLuPzyyzFq1ChMmzbNd59XXXUVHnzwQVRXV+d87nPPPRc1NTV4+umnC17/vffei549e6KiogLjxo1DIpHw3D9mzBicfvrp+Mtf/oI+ffpgn332AQB8+eWXGD58OI466ij06NEDl112GRoaGjIed/vtt2PXXXdFZWUlfv/733sCsWQyiT/84Q/o0aMHYrEYjjrqKHz66afy/mnTpqFLly6e9cyYMQOKosj7b7/9dnzxxRdQFAWKomR9T4NCgRTBYYwyUgRBdG4YA0y9bX8KPHCOHTsWU6dOlb8/++yzuPjiizO2+8c//oGBAwdin332wQUXXIBnn33W96L33HPPxYABA3DHHXfkfN7KykrcfPPNuOOOO9DY2Jj3uv/xj39g0qRJuPvuu7Fo0SL07t0bTzzxRMZ2s2fPxooVKzBr1iy88cYbaGxsxIgRI9C1a1dMmzYN06dPx7vvvosrr7wy43HLly/HnDlz8NJLL+HVV1/F7bffLu+/4YYb8K9//QvPPfccPv/8cwwYMAAjRozAtm3bAq3/7LPPxrXXXov9998fGzZswIYNG3D22Wfn/T64CbXo0cQOAwOotkcQROfGMoA7d2nb57x1C6CF837YBRdcgAkTJuDHH38EAHz88ceYPn065syZ49luypQpuOCCCwAAI0eORG1tLebOnYthw4Z5tlMUBffeey9OPfVU/OlPf8LPfvazrM99xRVX4JFHHsGDDz6IW2+9Na91P/zwwxg3bhzGjRsHALjrrrvw7rvvZmSlysrK8MwzzyASiQAAnn76aSQSCUybNg3ffvstBg8ejMceewynnnoq7rvvPvTs2RMAEIlE8Oyzz6K0tBT7778/7rjjDlx//fW48847EY/H8eSTT2LatGk46aST5H5nzZqFKVOm4Prrr292/SUlJSgvL0coFEKvXr3yeu3ZoECK4DD7hyAIorOihnhg09bPWQC77rqrLNUxxjBq1Cjssos3CFyxYgU++eQTvPbaawCAUCiEs88+G1OmTMkIpABgxIgROOqoo3DrrbfixRdfzPrc0WgUd9xxB6666ipcfvnlea17+fLlGUL5oUOH4v333/fcduCBB8ogSjxu0KBBKCsrk7cdeeSRsCwLK1askIHUoEGDUFpa6tl3Q0MDfvrpJ9TW1kLXdRx55JHy/nA4jMMOOwzLly/P63UUEwqkCA4jjRRBEJ0cRSkoO9RejB07Vpa2Hn/88Yz7p0yZAsMw0KdPH3kbYwzRaBSPPfYYqqqqMh5z7733YujQoc1mZy644AJMnjwZd911V6t07LkDprZEVdWMc1lrC+tJI0UAABhII0UQBNGWjBw5EqlUCrquY8SIEZ77DMPA3/72NzzwwANYsmSJ/Pniiy/Qp08fvPTSS777POyww3DGGWfgz3/+c87nVlUV99xzD5588kmsXr068Jr33XdfLFy40HPbggULAj3uiy++8OiyPv74Y6iqKsXoAPDFF194uhkXLFiA8vJy9O3bFz/72c8QiUTw8ccfy/t1Xcenn36K/fbbDwDP9NXX13ueZ8mSJZ61RCIRmKYZ7AUHgAIpgkMZKYIgiDZF0zQsX74cy5Ytg6ZpnvveeOMNbN++HePGjcMBBxzg+Rk9ejSmTJmSdb9/+ctf8N5772HFihU5n3/UqFEYMmQI/u///i/wmv/4xz/i2WefxdSpU/Htt9/itttuw9dff93s484//3zEYjFcfPHF+P777/H+++/jqquuwoUXXijLegC3Shg3bhyWLVuGt956C7fddhuuvPJKqKqKsrIyXH755bj++usxc+ZMLFu2DJdeeimampqkZmvIkCEoLS3FTTfdhJUrV+LFF1/M6Mrbc889sWrVKixZsgRbtmxBMpkM/Pr9oECKACDsD9p7FQRBEDsXlZWVqKyszLh9ypQpGD58uG/5bvTo0Vi0aBGWLl3qu8+9994bY8eOzRCA+3HfffcF2k5w9tln49Zbb8UNN9yAQw89FD/++GMgnVVpaSneeecdbNu2DWPGjMHZZ5+N448/Ho899phnu+OPPx4///nPcfTRR+Pss8/Gaaed5jEVvffeezF69GhceOGFOOSQQ/D999/jnXfeQdeuXQEA3bp1w/PPP4+33noLBx54IF566SXP4wH+/o0cORLHHnssdt1116zZvaAorBOmIerq6lBVVYXa2lrfDyCRPx9M/xamaeHY8we291IIgiBykkgksGrVKvTv3x+xWKy9l0PkgWmaWLx4MQYPHpyRhRszZgxqamowY8aM9llcGkE/Z3llpO655x788pe/REVFBXr06IHTTz89I3UoLOjdP+kK/zVr1mDUqFEoLS1Fjx49cP3118MwjHyWQhQbxgCr08XUBEEQBNGu5BVIzZ07F+PHj8eCBQswa9Ys6LqOE088McPU69JLL5VGVxs2bMD9998v7zNNE6NGjUIqlcK8efPw3HPPYdq0aZg4cWJxXhFREFTaIwiCIPbff3+Ul5f7/rzwwgvtvbwOSV72BzNnzvT8Pm3aNPTo0QOfffYZjj76aHl7aWlpVqOr//73v1i2bBneffdd9OzZEwcffDDuvPNO3HjjjZg0aZLHd4JoOxiJzQmCIHZ63nrrrax2AW5ReGvQ0lEt7UWLxOa1tbUAuLjLzQsvvIBddtkFBxxwACZMmICmpiZ53/z583HggQd6/iAjRoxAXV1dVuV/MplEXV2d54coMjQihiAIYqenX79+GDBggO9PRUVFey+vQ1KwIadlWbj66qtx5JFH4oADDpC3n3feeejXrx/69OmDpUuX4sYbb8SKFSvkcMaNGzdmRLXi940bN/o+1z333OOZtUMUHxpaTBAEQRD5U3AgNX78eHz11Vf46KOPPLdfdtll8v8PPPBA9O7dG8cffzxWrlyZc/ZPLiZMmIBrrrlG/l5XV4e+ffsWtnDCHwYwq70XQRAEQRCdi4JKe1deeSXeeOMNvP/++9h9991zbjtkyBAAwPfffw8A6NWrFzZt2uTZRvyeTVcVjUal10Y2zw2ihTBGGSmCIAiCyJO8AinGGK688kq89tpreO+999C/f/9mHyOs2Xv37g2ADyD88ssvUV1dLbeZNWsWKisrpcU70fYwUEaKIAiCIPIlr9Le+PHj8eKLL+Lf//43KioqpKapqqoKJSUl0o795JNPRvfu3bF06VL86U9/wtFHH42DDjoIAHDiiSdiv/32w4UXXoj7778fGzduxC233ILx48cjGo0W/xUSwSD/A4IgCILIm7wyUk8++SRqa2sxbNgw9O7dW/68/PLLAPggwHfffRcnnngiBg4ciGuvvRajR4/G66+/LvehaRreeOMNaJqGoUOH4oILLsBFF12EO+64o7ivjMgLiqMIgiDaH0VROoSz95w5c6AoCmpqarJuM23aNHTp0qXN1tRRySsj1ZyGpm/fvpg7d26z++nXrx/eeuutfJ6aaG1II0UQBNHqbN68GRMnTsSbb76JTZs2oWvXrhg0aBAmTpyII488Ehs2bJBz49qTI444Ahs2bPCd9Ud4Kbhrj9jBYJSRIgiCaG1Gjx6NVCqF5557DnvttRc2bdqE2bNnY+vWrQCyN121NZFIpMOspaPTIkNOYseBfKQIgiBal5qaGnz44Ye47777cOyxx6Jfv3447LDDMGHCBJx22mkAMkt78+bNw8EHH4xYLIZf/OIXmDFjBhRFkY1cogT3zjvvYPDgwSgpKcFxxx2H6upqvP3229h3331RWVmJ8847z2OOnUwm8Yc//AE9evRALBbDUUcdhU8//VTe71famzZtGvbYYw+UlpbiN7/5jQz+dnYokCI45CNFEEQnhzEG3dLb9CefC1Axs27GjBlIJpPNbl9XV4dTTz0VBx54ID7//HM5Ts2PSZMm4bHHHsO8efPw008/4ayzzsLDDz+MF198EW+++Sb++9//4tFHH5Xb33DDDfjXv/6F5557Dp9//jkGDBiAESNGYNu2bb77X7hwIcaNG4crr7wSS5YswbHHHou77ror8GvfkaHSHgEAYFTbIwiik2MwA4f8/ZA2fc7PL/wcYSUcaNtQKIRp06bh0ksvxVNPPYVDDjkExxxzDM455xzZ2e7mxRdfhKIoePrppxGLxbDffvth3bp1uPTSSzO2veuuu3DkkUcCAMaNG4cJEyZg5cqV2GuvvQAAv/3tb/H+++/jxhtvRGNjI5588klMmzYNJ510EgDg6aefxqxZszBlyhRcf/31Gft/5JFHMHLkSNxwww0AgL333hvz5s3LmMG7M0KBFMGhocUEQXRyQkoIn1/4eZs/Zz6MHj0ao0aNwocffogFCxbg7bffxv33349nnnkGY8aM8Wy7YsUKHHTQQYjFYvK2ww47zHe/7kCsZ8+eKC0tlUGUuO2TTz4BAKxcuRK6rsvACwDC4TAOO+wwLF++3Hf/y5cvx29+8xvPbUOHDqVAClTaI2wYJaQIgujkKIqCsBpu0x9FUfJeZywWwwknnIBbb70V8+bNw5gxY3Dbbbe16LWHw05WTFEUz+/iNssi/UZrQIEUIaGMFEEQRNuz3377obGxMeP2ffbZB19++aVHT+UWhBfKz372M0QiEXz88cfyNl3X8emnn2adMLLvvvti4cKFntsWLFjQ4rXsCFAgRXAYI7E5QRBEK7J161Ycd9xxeP7557F06VKsWrUKr7zyCu6//378+te/ztj+vPPOg2VZuOyyy7B8+XK88847mDx5MgAUlAkTlJWV4fLLL8f111+PmTNnYtmyZbj00kvR1NSEcePG+T7mD3/4A2bOnInJkyfju+++w2OPPUZlPRsKpAgAZH9AEATR2pSXl2PIkCF46KGHcPTRR+OAAw7ArbfeiksvvRSPPfZYxvaVlZV4/fXXsWTJEhx88MG4+eabMXHiRADw6KYK4d5778Xo0aNx4YUX4pBDDsH333+Pd955J6sZ6OGHH46nn34ajzzyCAYNGoT//ve/uOWWW1q0hh0FhXXCs2ddXR2qqqpQW1uLysrK9l7ODsE7T3+Fxpokzrj+0PZeCkEQRE4SiQRWrVqF/v37tzig6Gy88MILuPjii1FbW4uSkpL2Xk7emKaJxYsXY/DgwdA0rb2Xk5OgnzPq2iMACLF5p4upCYIgdmj+9re/Ya+99sJuu+2GL774AjfeeCPOOuusThlE7ahQIEXYMOraIwiC6GBs3LgREydOxMaNG9G7d2+ceeaZ+Mtf/tLeyyJcUCBFcBjALIqkCIIgOhI33HCDNMEkOiYkNicACLF5e6+CIAiCIDoXFEgRHNJIEQRBEETeUCBFAOBBFPlIEQRBEER+UCBFSCgjRRAEQRD5QYEUAYBm7REEQRBEIVAgRThQJEUQBEEQeUGBFAHA1khRHEUQBNEpWb16NRRFwZIlS9p7KTsdFEgRHPKRIgiCaDUURcn5M2nSpPZeIlEgZMhJAKARMQRBEK3Jhg0b5P+//PLLmDhxIlasWCFvKy8vb49lEUWAMlKEDZX2CIIgWotevXrJn6qqKiiKIn9vbGzE+eefj549e6K8vBy//OUv8e6773oev+eee+Luu+/G2LFjUVFRgT322AN//etfM57nhx9+wLHHHovS0lIMGjQI8+fPb6uXuNNCgRTBoYwUQRCdHMYYmK637U8RjpsNDQ04+eSTMXv2bCxevBgjR47EqaeeijVr1ni2e+CBB/CLX/wCixcvxhVXXIHLL7/ck9UCgJtvvhnXXXcdlixZgr333hvnnnsuDMNo8RqJ7FBpjwDAR8SA4iiCIDozhoFvDjyoTZ9y4JdLgXC4RfsYNGgQBg0aJH+/88478dprr+E///kPrrzySnn7ySefjCuuuAIAcOONN+Khhx7C+++/j3322Uduc91112HUqFEAgNtvvx37778/vv/+ewwcOLBFaySyQ4EUwWGMxOYEQXRuQiEe2LTxc7aUhoYGTJo0CW+++SY2bNgAwzAQj8czMlIHHeQEiaI0WF1dnXWb3r17AwCqq6spkGpFKJAiAJAhJ0EQnR9FUVqcHWoPrrvuOsyaNQuTJ0/GgAEDUFJSgt/+9rdIpVKe7cJpr01RFFiWlXUbRVEAIGMborhQIEVISCNFEATR9nz88ccYM2YMfvOb3wDgGarVq1e376KIwJDYnABAGSmCIIj24uc//zleffVVLFmyBF988QXOO+88yiJ1IiiQImwYZaQIgiDagQcffBBdu3bFEUccgVNPPRUjRozAIYcc0t7LIgKisE549qyrq0NVVRVqa2tRWVnZ3svZIZjx4OfYsrYBlzx4dHsvhSAIIieJRAKrVq1C//79EYvF2ns5RB6YponFixdj8ODB0DStvZeTk6CfM8pIEQDs0h517REEQRBEXlAgRUg6X26SIAiCINoXCqQIALYjMGWkCIIgCCIvKJAiJJSRIgiCIIj8oECK4NCsPYIgCILIGwqkCADkI0UQBEEQhUCBFGFDPlIEQRAEkS8USBEA7GwUlfcIgiAIIi8okCK8UBxFEATRKVm9ejUURcGSJUvaeyk7FRRIEQAcfRRlpAiCIFqHMWPG4PTTT2/vZeTFsGHDoCgKFEVBLBbD3nvvjXvuuSevc8WcOXOgKApqamoy7ps2bRq6dOni+zhFUTBjxozCFt6GUCBFcOwvBcVRBEEQhJtLL70UGzZswIoVKzBhwgRMnDgRTz31VHsvq8NAgRThgTJSBEEQ7cNXX32Fk046CeXl5ejZsycuvPBCbNmyRd4/c+ZMHHXUUejSpQu6d++OU045BStXrsy6P9M0MXbsWAwcOBAffPABVFXFokWLPNs8/PDD6NevHyzLyrqf0tJS9OrVC/369cPFF1+Mgw46CLNmzZL3J5NJXHfdddhtt91QVlaGIUOGYM6cOYW/EZ0MCqQIAO7SXvuugyAIYmekpqYGxx13HAYPHoxFixZh5syZ2LRpE8466yy5TWNjI6655hosWrQIs2fPhqqq+M1vfuMbBCWTSZx55plYsmQJPvzwQxx99NEYPnw4pk6d6tlu6tSpGDNmDFS1+XCAMYYPP/wQ33zzDSKRiLz9yiuvxPz58zF9+nQsXboUZ555JkaOHInvvvuuBe9I5yHU3gsgOhY0JoYgiM4KYwxWGx/DVJXrh1rKY489hsGDB+Puu++Wtz377LPo27cvvv32W+y9994YPXq05zHPPvssdt11VyxbtgwHHHCAvL2hoQGjRo1CMpnE+++/j6qqKgDAJZdcgt///vd48MEHEY1G8fnnn+PLL7/Ev//975xre+KJJ/DMM88glUpB13XEYjH84Q9/AACsWbMGU6dOxZo1a9CnTx8AwHXXXYeZM2di6tSpntezo0KBFAHAVdKjOIogiE6KZTE8NX5Omz7n7x8fBk1reSD1xRdf4P3330d5eXnGfStXrsTee++N7777DhMnTsTChQuxZcsWmYlas2aNJ5A699xzsfvuu+O9995DSUmJvP3000/H+PHj8dprr+Gcc87BtGnTcOyxx2LPPffMubbzzz8fN998M7Zv347bbrsNRxxxBI444ggAwJdffgnTNLH33nt7HpNMJtG9e/dC345OBQVShAfSSBEE0VlRVQW/f3xYmz9nMWhoaMCpp56K++67L+O+3r17AwBOPfVU9OvXD08//TT69OkDy7JwwAEHIJVKebY/+eST8fzzz2P+/Pk47rjj5O2RSAQXXXQRpk6dijPOOAMvvvgiHnnkkWbXVlVVhQEDBgAA/vGPf2DAgAE4/PDDMXz4cDQ0NEDTNHz22WfQNM3zOL+gMJ3Kyko0NjbCsixPeVF0+IlsWkeGAikCAMDsEjvFUQRBdFYURSlKdqg9OOSQQ/Cvf/0Le+65J0KhzFPz1q1bsWLFCjz99NP41a9+BQD46KOPfPd1+eWX44ADDsBpp52GN998E8ccc4y875JLLsEBBxyAJ554AoZh4IwzzshrneXl5fjjH/+I6667DosXL8bgwYNhmiaqq6vluvJhn332gWEYWLJkCQ455BB5++effw4AGZmujggFUoSNsD+gSIogCKK1qK2tzTDM7N69O8aPH4+nn34a5557Lm644QZ069YN33//PaZPn45nnnkGXbt2Rffu3fHXv/4VvXv3xpo1a/DnP/856/NcddVVME0Tp5xyCt5++20cddRRAIB9990Xhx9+OG688UaMHTvWU/oLyu9+9zvceeed+Ne//oXf/va3OP/883HRRRfhgQcewODBg7F582bMnj0bBx10EEaNGiUf9+WXX6K0tBQrVqyAoigIhUIYNGgQTjzxRIwdOxYPPPAA9tprL6xYsQJXX301zj77bOy22255r6+toUCKAODq2sveAUsQBEG0kDlz5mDw4MGe28aNG4dnnnkGH3/8MW688UaceOKJSCaT6NevH0aOHAlVVaEoCqZPn44//OEPOOCAA7DPPvvgf//3fzFs2LCsz3X11VfDsiycfPLJmDlzptQ1jRs3DvPmzcPYsWMLeg3dunXDRRddhEmTJuGMM87A1KlTcdddd+Haa6/FunXrsMsuu+Dwww/HKaec4nnc0Ucf7fld0zQYhoGXX34Zt912G373u99h/fr12H333fGb3/wGt956a0Hra2sU1glTEHV1daiqqkJtbS0qKyvbezk7BC/dsRDb1jdizH1Hoqwq2t7LIQiCyEoikcCqVavQv39/xGKx9l5Op+POO+/EK6+8gqVLl7b5c5umKUuC6ZqqjkbQzxn5SBEAXNqoThdWEwRBEEFoaGjAV199hcceewxXXXVVey9nh4ECKYJjR1Jt7cFCEARBtA1XXnklDj30UAwbNqzgsh6RCWmkCA+dsNJLEARBBGDatGmYNm1aey9jhyOvjNQ999yDX/7yl6ioqECPHj1w+umnY8WKFZ5tEokExo8fj+7du6O8vByjR4/Gpk2bPNusWbMGo0aNQmlpKXr06IHrr78ehmG0/NUQBUOlPYIgCILIn7wCqblz52L8+PFYsGABZs2aBV3XceKJJ6KxsVFu86c//Qmvv/46XnnlFcydOxfr16/3+FSYpolRo0YhlUph3rx5eO655zBt2jRMnDixeK+KKBjKSBEEQRBEcPIq7c2cOdPz+7Rp09CjRw989tlnOProo1FbW4spU6bgxRdflG6qU6dOxb777osFCxbg8MMPx3//+18sW7YM7777Lnr27ImDDz4Yd955J2688UZMmjTJMwhRkEwmkUwm5e91dXWFvFYiByKAIvsDgiAIgghOi8TmtbW1ALinBAB89tln0HUdw4cPl9sMHDgQe+yxB+bPnw8AmD9/Pg488ED07NlTbjNixAjU1dXh66+/9n2ee+65B1VVVfKnb9++LVk24YfwkaKMFEEQBEEEpuBAyrIsXH311TjyyCPlsMSNGzciEomgS5cunm179uyJjRs3ym3cQZS4X9znx4QJE1BbWyt/fvrpp0KXTWRBSqQojiIIgiCIwBTctTd+/Hh89dVXWWf9FJNoNIpolEwiWxVGI2IIgiAIIl8KykhdeeWVeOONN/D+++9j9913l7f36tULqVRKTm0WbNq0Cb169ZLbpHfxid/FNkQ7QnEUQRAEQQQmr0CKMYYrr7wSr732Gt577z3079/fc/+hhx6KcDiM2bNny9tWrFiBNWvWYOjQoQCAoUOH4ssvv0R1dbXcZtasWaisrMR+++3XktdCtABGGimCIIhWZ8yYMVAUJeNn5MiRAIA999wTDz/8sO9jFUXBjBkzfPd5+umnt96iiZzkVdobP348XnzxRfz73/9GRUWF1DRVVVWhpKQEVVVVGDduHK655hp069YNlZWVuOqqqzB06FAcfvjhAIATTzwR++23Hy688ELcf//92LhxI2655RaMHz+eynftCQ0tJgiCaBNGjhyJqVOnem6j81/nJa9A6sknnwSAjGnTU6dOxZgxYwAADz30EFRVxejRo5FMJjFixAg88cQTcltN0/DGG2/g8ssvx9ChQ1FWVob/9//+H+64446WvRKiRTCQRoogCKItiEajJGXZgcgrkApyko3FYnj88cfx+OOPZ92mX79+eOutt/J5aqK1YQAU6tojCIIgiHygWXuERFUUykgRBNFpYYzBMs02fU5V06AoSl6PeeONN1BeXu657aabbsJNN91UzKURbQQFUgQAnolSVIW69giC6LRYpomHzz+9TZ/z6hdmQAvldyo99thjpVRGIIytic4HBVIEhzEoKsAsiqQIguicqJqGq1+Y0ebPmS9lZWUYMGBA3o+rqKiQE0Xc1NTUoKqqKu/9EcWhRSNiiB0HBp6RosoeQRCdFUVRoIVCbfqTb1mvJeyzzz747LPPPLeZpokvvvgCe++9d5utg/BCGSmCwwBVJY0UQRBEa5NMJjNGooVCIeyyyy4AgHXr1mHJkiWe+/v164drrrkG48aNw8CBA3HCCSegsbERjz76KLZv345LLrmkrZZPpEGBFAHAzkgplJEiCIJobWbOnInevXt7bttnn33wzTffAAAmT56MyZMne+7/+9//jgsuuACMMTz44IP485//jNLSUhx66KH44IMPMmbYEm0HBVIEhzRSBEEQrc60adMwbdq0rPevXr065+PPO+88nHfeecVdFNEiSCNFSBQq7REEQRBEXlAgRQDg9gcqic0JgiAIIi8okCI4zNZIUWmPIAiCIAJDgRQBgDsCKyrIkJMgCIIg8oACKUJCGimCIAiCyA8KpAgApJEiCIIgiEKgQIrgMEYZKYIgCILIEwqkCACuETFWe6+EIAiCIDoPFEgRHBoRQxAEQRB5Q4EUAUCMiAF17REEQXQSxowZg9NPP73o2xL5QYEUwSGNFEEQRKuzefNmXH755dhjjz0QjUbRq1cvjBgxAh9//HHe+3rkkUdyjpsh2gaatUdwqGuPIAii1Rk9ejRSqRSee+457LXXXti0aRNmz56NrVu35r2vqqqqVlghkS+UkSIAuMTmFEkRBEG0CjU1Nfjwww9x33334dhjj0W/fv1w2GGHYcKECTjttNNw3XXX4ZRTTpHbP/zww1AUBTNnzpS3DRgwAM888wyAzHLdP//5Txx44IEoKSlB9+7dMXz4cDQ2NnrWMHnyZPTu3Rvdu3fH+PHjoet6677onQAKpAgOo649giCI1qS8vBzl5eWYMWMGkslkxv3HHHMMPvroI5imCQCYO3cudtllF8yZMwcAsG7dOqxcuRLDhg3LeOyGDRtw7rnnYuzYsVi+fDnmzJmDM844w3Nx/P7772PlypV4//338dxzz2HatGlUGiwCFEgRAAAGBlUFZaQIgui0MMbATKttf/I4ZoZCIUybNg3PPfccunTpgiOPPBI33XQTli5dCgD41a9+hfr6eixevBiMMXzwwQe49tprZSA1Z84c7LbbbhgwYEDGvjds2ADDMHDGGWdgzz33xIEHHogrrrgC5eXlcpuuXbvisccew8CBA3HKKadg1KhRmD17dsvedII0UoSNnZGirj2CIDotFsO6m/MXbbeE3f5yJKApgbcfPXo0Ro0ahQ8//BALFizA22+/jfvvvx/PPPMMxowZg0GDBmHOnDmIRCKIRCK47LLLcNttt6GhoQFz587FMccc47vfQYMG4fjjj8eBBx6IESNG4MQTT8Rvf/tbdO3aVW6z//77Q9M0+Xvv3r3x5ZdfFv7iCQAUSBECRhopgiA6OarCA5s2fs58icViOOGEE3DCCSfg1ltvxSWXXILbbrsNY8aMwbBhwzBnzhxEo1Ecc8wx6NatG/bdd1989NFHmDt3Lq699lrffWqahlmzZmHevHn473//i0cffRQ333wzFi5ciP79+wMAwuGw5zGKosCySM/RUqi0RwAQPlLUtUcQROdFURQomtq2P0r+gVQ6++23nxSFC53U7NmzpRZq2LBheOmll/Dtt9/66qPcr//II4/E7bffjsWLFyMSieC1115r8fqI3FBGiuAwxu0PLIqkCIIgWoOtW7fizDPPxNixY3HQQQehoqICixYtwv33349f//rXAICjjz4a9fX1eOONN3DvvfcC4IHUb3/7W/Tu3Rt77723774XLlyI2bNn48QTT0SPHj2wcOFCbN68Gfvuu2+bvb6dFQqkCADC/oDE5gRBEK1FeXk5hgwZgoceeggrV66Eruvo27cvLr30Utx0000AuCD8wAMPxKZNmzBw4EAAPLiyLCurPgoAKisr8cEHH+Dhhx9GXV0d+vXrhwceeAAnnXRSm7y2nRmFdcIzZ11dHaqqqlBbW4vKysr2Xs4OweO/fw8DftEDvfpXYdDxfdt7OQRBEFlJJBJYtWoV+vfvj1gs1t7LIfLANE0sXrwYgwcP9gjfOyJBP2ekkSIkXCPV6eJqgiAIgmg3KJAiZPBEI2IIgiAIIj8okCKkdxRppAiCIAgiPyiQIqQHJxlyEgRBEER+UCBFQNTzyJCTIAiCIPKDAilCJqFUGlpMEARBEHlBgRTh0khRRoogCIIg8oECKUIGUiqNiCEIgiCIvKBAigCD0EhR1x5BEARB5AMFUoSntEddewRBEEShrF69GoqiYMmSJYEfM2bMGJx++umttqbWhgIpQpbzFBpaTBAE0aps3rwZl19+OfbYYw9Eo1H06tULI0aMwMcff9zeS8sbvwCob9++2LBhAw444ID2WVQ7QEOLCY+zuWVSIEUQBNFajB49GqlUCs899xz22msvbNq0CbNnz8bWrVvbe2lFQdM09OrVq72X0aZQRopwUEgjRRAE0VrU1NTgww8/xH333Ydjjz0W/fr1w2GHHYYJEybgtNNOk9tccskl2HXXXVFZWYnjjjsOX3zxhWc/9957L3r27ImKigqMGzcOf/7zn3HwwQfL+4cNG4arr77a85jTTz8dY8aMkb8nk0lcd9112G233VBWVoYhQ4Zgzpw58v5p06ahS5cueOedd7DvvvuivLwcI0eOxIYNGwAAkyZNwnPPPYd///vfUBQFiqJgzpw5GaU90zQxbtw49O/fHyUlJdhvv/3w0ksvFe097QhQIEVwXZQihha392IIgiB2TMrLy1FeXo4ZM2YgmUz6bnPmmWeiuroab7/9Nj777DMccsghOP7447Ft2zYAwD/+8Q9MmjQJd999NxYtWoTevXvjiSeeyHstV155JebPn4/p06dj6dKlOPPMMzFy5Eh89913cpumpiZMnjwZf//73/HBBx9gzZo1uO666wAA1113Hc466ywZXG3YsAFHHHFExvNYloXdd98dr7zyCpYtW4ZbbrkFTzzxBF555ZW819xRodIeIeIoKJSRIgiiE8MYg2W1rauwqqpQFCXQtqFQCNOmTcOll16Kp556CocccgiOOeYYnHPOOTjooIPw0Ucf4ZNPPkF1dTWi0SgAYPLkyZgxYwb++c9/4rLLLsPDDz+McePGYdy4cQCAu+66C++++y4SiUTgNa9ZswZTp07FmjVr0KdPHwA8MJo5cyamTp2Ku+++GwCg6zqeeuop/OxnPwPAg6877rgDAA8KS0pKkEwmc5bywuEwbr/9dvn7Hnvsgddffx2vvPIKzjnnnMBr7shQIEVwtbmdmgU5mxME0UmxLAt33nlnmz7nrbfeCk3TAm8/evRojBo1Ch9++CEWLFiAt99+G/fffz+eeeYZNDY2oqGhAd27d/c8Jh6PY+XKlQCA5cuX4/e//73n/qFDh+L9998PvIYvv/wSpmli77339tyeTCY9z11aWiqDKADo3bs3qqurAz+P4PHHH8ezzz6LNWvWIB6PI5lMekqRnR0KpAgeR4H7SFmUkSIIopOiqipuvfXWNn/OfInFYjjhhBNwwgkn4NZbb8Ull1yC2267DVdccQV69+7t0SoJunTpktea0qsLuq7L/29oaICmafjss88ygsDy8nL5/+Fw2HMfl3/kd46YPn06rrvuOjzwwAMYOnQoSktLMWHCBPzwww957acjQ4EUwVFhZ6QokCIIonOiKEpe2aGOwn777YcZM2bgkEMOwcaNGxEKhbDnnnv6brvvvvti4cKFuOiii+RtCxYs8Gyz6667SlE4wAXfX331FY499lgAwODBg2GaJqqrq/GrX/2q4HVHIhGYpplzm48//hhHHHEErrjiCrmWtWvXFvycHRESmxMAAxQodtdeey+GIAhix2Tr1q047rjj8Pzzz2Pp0qVYtWoVXnnlFdx///349a9/jeHDh2Po0KE4/fTT8d///herV6/GvHnzcPPNN2PRokUAgD/+8Y949tlnMXXqVHz77be47bbb8PXXX3ue57jjjsObb76JN998E9988w0uv/xy1NTUyPv33ntvnH/++bjooovw6quvYtWqVfjkk09wzz334M033wz8evbcc08sXboUK1aswJYtWzxZL8HPf/5zLFq0CO+88w6+/fZbTJw4EcuWLSvsDeygUEaK4CNilMLStgRBEEQwysvLMWTIEDz00ENYuXIldF1H3759cemll+Kmm26Coih46623cPPNN+Piiy/G5s2b0atXLxx99NHo2bMnAODss8/GypUrccMNNyCRSGD06NG4/PLL8c4778jnGTt2LL744gtcdNFFCIVC+NOf/iSzUYKpU6firrvuwrXXXot169Zhl112weGHH45TTjkl8Ou59NJLMWfOHPziF79AQ0MD3n///YxM2u9+9zssXrwYZ599NhRFwTnnnIPf/va3eTmfd3QU1gnPnHV1daiqqkJtbS0qKyvbezmdnnh9Cn+7aR6G/HovbN/YhGMvGNjeSyIIgshKIpHAqlWr0L9/f8RisfZeTrszadIkzJgxo1MEJ6ZpYvHixRg8eHCHL8MG/ZxRaY/g5TzKSBEEQRBE3lAgRXAUBYpKGimCIAiCyAcKpAgwxmxDTuraIwiC6GxMmjSpU5T1dlQokCI4inA2b++FEARBEETngQIpwrY/AEAaKYIgOhF0vCJak6Cfr7wDqQ8++ACnnnoq+vTpA0VRMGPGDM/9Y8aMkZOgxc/IkSM922zbtg3nn38+Kisr0aVLF4wbNw4NDQ35LoUoElxsrlBGiiCIToFw3G5qamrnlRA7MuLzle7wnk7ePlKNjY0YNGgQxo4dizPOOMN3m5EjR2Lq1KnydzF8UXD++edjw4YNmDVrFnRdx8UXX4zLLrsML774Yr7LIYoCg6IAikoZKYIgOj6apqFLly5y7ltpaWngwcFE+yKc0BOJRIe1P2CMoampCdXV1ejSpUuz68w7kDrppJNw0kkn5dwmGo1mnQa9fPlyzJw5E59++il+8YtfAAAeffRRnHzyyZg8ebKcRO0mmUwimUzK3+vq6vJdNpEDETspigJGQ4sJgugEiHNMIUN0ifbDsixs2bIFq1evLmhOYVvSpUuXrLGMm1ZxNp8zZw569OiBrl274rjjjsNdd90lJ0rPnz8fXbp0kUEUAAwfPhyqqmLhwoX4zW9+k7G/e+65B7fffntrLJUQKHxoMdX2CILoDCiKgt69e6NHjx6+o0mIjklDQwNGjRqFRYsWeQYkdzTC4XDgjFnRA6mRI0fijDPOQP/+/bFy5UrcdNNNOOmkkzB//nxomoaNGzeiR48e3kWEQujWrRs2btzou88JEybgmmuukb/X1dWhb9++xV76Tgu3P1BsQ872Xg1BEERwNE3rsCUiIpNUKoUff/wRkUhkh3GlL3ogdc4558j/P/DAA3HQQQfhZz/7GebMmYPjjz++oH1Go9EMnRVRRKSzOXXBEARBEEQ+tHqBcq+99sIuu+yC77//HgCva6fXtA3DwLZt2wLVIonWQZEjYtp7JQRBEATReWj1QGrt2rXYunUrevfuDQAYOnQoampq8Nlnn8lt3nvvPViWhSFDhrT2cggfZPBEGSmCIAiCyIu8A6mGhgYsWbJE2tGvWrUKS5YswZo1a9DQ0IDrr78eCxYswOrVqzF79mz8+te/xoABAzBixAgAwL777ouRI0fi0ksvxSeffIKPP/4YV155Jc455xzfjr2dnXn/+h6b19S38rMw20eKuvYIgiAIIh/yDqQWLVqEwYMHY/DgwQCAa665BoMHD8bEiROhaRqWLl2K0047DXvvvTfGjRuHQw89FB9++KFH4/TCCy9g4MCBOP7443HyySfjqKOOwl//+tfivaodiOo1dajflmjV52C2szkfWkwZKYIgCIIISt5i82HDhuU82b7zzjvN7qNbt25kvhkU1gbBjRSbK2A0tJggCIIgAtOx3bAIrl9qg9hGAQ0tJghix4ZZFmr++c/2Xgaxg0GBVAeHMdbqwQ1jjkaKIimCIHZUzNpabJhE5s5EcaFAqhPQ2qU9O46yu/Za9akIgiDaD8boIEcUHQqkOjptUdoTs/ZoaDFBEDsylsV/CKKIUCDVwWGMgbVyJMXAHGdzOsYQBLGDwiwLYIwuGImiQoFUB4exNghuGFyz9ugAQxDEDorIRtFxjigiFEgRALiHFGnNCYLYoaFAimgFKJDq4LA28JESu6euPYIgdmSET565bRvq3n67nVdD7ChQINXRYawNfKRs+wOV4iiCIHZgbJ1E/OuvsXXqtPZdC7HDQIFUB6etMlIKAJBGiiCIHRlR2jNNumokigYFUp2AVv++e0bEtPJzEQRBtBPMtOx/TbJBIIoGBVIdHNYmpT0eRHGJFF2lEQSxgyKuFG0bBIIoBhRIdXDaprTH988NOVv1qTo8qfUN0Dc3tfcyCIJoDewsFDNMumgkigYFUh2dNppooNiGnDt7JNW0aBPiX25p72UQBNEKiK49mAaV9oiiQYFUh6f1Iym3/cFOHke1WSmVIIh2gDkZqZ3+YEcUDQqkOjhtMmOTwbE/sOjgQgdYgtgxYabJ/7VMmodFFA0KpDo4bRFIMTC7tEf2B21VSiUIoh2QpT2TLhqJokGBVEeHMbR6rUnsnoYWt1EKkCCIdoFKe0QrQIFUB6dNhhYDlJEStEHc2hmwmprAUqn2XgZBFBdpyElic6J4UCBF2BdmCg0tFtCbgOoHH8L2f/6zvZdBEEVFlPMoI0UUEwqkOjiMsdbPEtkzYtorI9WRsmDMYlTeBGAl4rAaGtt7GQRRXCxHbN6RjjtE54YCqY5Om4jN7dJeOw0t/mbf/VA/Z07bP3E26AALWAxMp9IesWPBZGnPotIeUTQokOrg5MpIbXv+BWyd8mwRnoT/o7Rjbc/curVdnjcD0khxLAtM19t7FQRRXERpzzTogokoGhRIdQayfN+NLZthbCmGCzfjQVQ7dO2Jk7XWrVvbPnE2qGuPwxhYigIpYgdDHOBME2wnrOGv/ePVSP6wqr2XscNBgVQHJ+esvSKlp73O5m0bRBh2JkqNRtv0eXNCcRQYo4wUsePBLLf9QTsvph1IrVoFc1sHyf7vQFAg1dHJ8WXngskiXFUxt/1By3eXD8bmzXwJZge5OmyDIdGdAtJIETsi4sLTMndOjRSzOs6xdgeCAqkODmM5usgs5jj1tuQ57H+52LyNM1J2INVhWuVo1h6HNFLEjog7I7UTBlLMYrJzkSgeFEh1CrKc2Yt1VcV4SqpdMlLVIiPVMb7cjKEowWlnhzGLNFLEDocs7Zkm2M54xWRZTuciUTQokOrg5NI+M4sVpbQn7Q8UtHkQ4WSkOtBBrQMtpd2wGGWkiB0PcZwxjZ3zgski24fWgAKpDg63P8hyp2kW52Bgf6/aJyNVDSB4RurYyXPQkDQCbcsYg1lbm9+C2sIAtTNApT1iR0RmpHbOgIIx1mGy/zsSFEh1dHKIn1mRSnsMjGejlGAaqQ23TkTDBx+0+HkBp2svaEC4riaOhB7sQJD85husGTsuvwWRjxQA0bVHYnNix0IIrXdaHynGdsoAsrWhQKqDw+R/fChSaY937SlQ1GAZKWPzZpjbt7f8eQGwZJL/T0ABJGMMVsADoBVPwEok8lwQ+UgB4J8t0kgROxrieGnspCNiqLTXKlAg1dHJUWriGakide3ZGqkgBxdmmUVroWVy9lWw/eUX5xRw9UUZKQ6V9ogdEVHas3bOocWM7A9aBQqkOjg5AwerSGlaYcipKsF8lEyreHYFpgWoauDXYeWRkSrk6ouBfKQAMuQkdkyYuPDcSe0PQPYHrQIFUh2dXBkS0yxKQMMYHxGjKK7nzLW9ZRZNsMgsE0o4nEcgFfxCkllW/kER2R9w2M7dtdcwdy62vfhiey+DKDZMZKR20hIX2R+0CqH2XgCRG4ZcpT2rqOlpxY6kGGNQoGTf0LSKF2yYFpRwOFC6WbwPgTNSDAWU9hjAcrz2nQWLgaV2XrF5cuUPSK36ob2XQRQZeQFoGjtlBZ+xnTSAbGUoI9XRyZWRKtZVFXP5SKH5JBezTKltavFTWyaUUChQZk3ET4Fjx0IOGiyfJ9iB2dk1Uoyu3HdI7AvAndXZHBbZH7QGlJHq4OQaWly0YAawxeZORionpsV/ioHMSDX/WsSq8tFIFaJ3ojiKNFK89EMfhB0OUdozjZ0zkGLFGStGeKFAqqPDcgwyKNYXgjHwSMr1a67NreJos+S+wqFAr0UEUME1UoV07VFpDwA5mxerkYPoUMgso1lcWUSnwbJIbN4KUCDVwWGAdB7PwDKBXFqmoM8hS3tKMFNOs4gttCIjFeDLLZYVXCOV/8mQMUDZGQ+w6VjWTq2RArOK49FGdCxEac/cOX2kuLM5fa6LDWmkOjiMIetwTWYW/2AfZExMsRzVAQCWCSUUzisjFTgRxwrp2mPkIwUq7VFpbwdFXLAZO6mzuVVE6xpCQoFURyfXrL1iHeyZIzRXFJfXSjZMq3j6LDsjlV+6OdhrLrjFeWc8wKZDpT0q7e2AiNIeM3dWsblFYvNWgAKpjk6Orr1iztoTkZSiKM3HKUVyVAcAmLxrL0iHVP4ZqcKczZsNJHcGLAswjJ23c82i0t4OiSjt7bTO5qx4jUKEhAKpDk5Op+1iztqz/zfImBg+Ob1Y9gd2RirAl1vEN/lopKi0Vxjic7WzZqW43w59EHY4mEtsjp1wigGV9loFCqQ6OIwx1GxYBj2VzLyzWLP27KY9AECQwcWmWbxMhZmPj5SdkQr61IUYlpKPFEd4du2kgRSV9nZMPKU9wPdvvPaqP8BsaGzLZbUdJDZvFSiQ6ugwYO3Xr2Pz6lWZd5nFdKkVpb0AGSmreD5SIiMV5MstYsYchhDefRfYtUcZKTjDXXfaQIpKezsk4jhjGPxfn2Nd4/z5MGtq2m5NbQnZH7QKZH/Q0bENOX0zQEVK0/JZe/z/FUVpfpemWbyTjGn7SAXZX77O5gVlFXKI+3cmRCC1s1ogUGlvx4Q1n5Hirv475uee7A9aBwqkOjiMW5v7BlLFzAzB3bXXrEbKbIWMVPNXSY7YPLAjZ2FDiwn5vu2sGamCzFyJDo9sJLGPN3yuaNo2jDkZqx0N0ki1ChRIdXB4pcmC5ZeOLeasPft/uY9Uc6W94jmbc41UMB8pZ0RMwH0X8v5QIMWRGamdM5Ci0t4OSrpGyu9YZ1lgO3AgRfYHxYc0Uh0dW/xs+Xz4mVWcEpvH/kBF88FEEZ3NZUYqQN3eGRHTehopmkVls7NrpNq4tJdYvhz1c+a02fPttAQu7e14n3t53KTSXtGhQKoDw1yBg69GyiyeIackQEYKxTSzE117reFsbhVgf4CdsCXaB2l/sJNqpNq6tNe4cCHq/zurzZ5vZ4Wlic39POMYYztmRkpcHFGmtehQINWREd9xxlq1tMdYurN5M9tbRXQ2t/JwNpdi8+AaKeraKxBhXLgDXpkHoq21JKYpdTtEK5Je2vP7slsWmL4DBlKUkWo1KJDqwMg4ChasLGLz1pm1FyQj1R7O5vzfwM9caGmPMlL8fVPVnTeQYlabOty3xtzM1qD+vfdgdeIspXyPO2lpj6VSqH///cIeLF4r2R8UnbwDqQ8++ACnnnoq+vTpA0VRMGPGDM/9jDFMnDgRvXv3RklJCYYPH47vvvvOs822bdtw/vnno7KyEl26dMG4cePQ0NDQoheyQ8JkCsZfIFi0WXuMj4aB6NprZvMiepHk42wu/KOsgK9ZnAipcy9/GLOgRKMd9oTS2vCO2DY84ZhGp9DmbfrL3UitXFnw47e9+CLWXv0nGFu3FnFVeSCOCVnE5lJOYXTMz33yhx+w6c67CnqsfG2d4HPW2cg7kGpsbMSgQYPw+OOP+95///3343//93/x1FNPYeHChSgrK8OIESOQSCTkNueffz6+/vprzJo1C2+88QY++OADXHbZZYW/ih0U5ipl+WekijVrD479gRosI1U0LxLThBLQR8oZERNw3/IKLI+1krM5hwFqJCI1Ut8ddxyseLydF9WGFGv8UkCKOXapNWGmmZd+KPXjj/jp8ivk74mvv0b9zJlonDevNZbXPKK0l/Zvxv0d9QLCsgqfKmGlZeOIopG3/cFJJ52Ek046yfc+xhgefvhh3HLLLfj1r38NAPjb3/6Gnj17YsaMGTjnnHOwfPlyzJw5E59++il+8YtfAAAeffRRnHzyyZg8eTL69OnTgpezg8Gc//HPSLXSrL0AGqniaLPsMlo4DJbwGYHjtz3yyTCJyMsCNC3ooiiOAgDLyUgxxmCs3wArkYBaUtLeK2sTWDEHcwd5PtPoFJkCZhp5BVLGli1I/fCD6wbbv6mdNEhS25nN2Vwc1zqo2JyZLciUZgseiRZTVI3UqlWrsHHjRgwfPlzeVlVVhSFDhmD+/PkAgPnz56NLly4yiAKA4cOHQ1VVLFy40He/yWQSdXV1np+dAVHKYsxfI1UsrZJ71l5QjVRRxOb2AYF37QWZtWf/a1lo+nxx89vLLpU83iOGTlFiaXVcgdROeSXb1oacLTlBtiWGmVeQwQzTcxEo/p+Z7RSoiNKe+NtmLe11zECKa/cK+1zK4yAFUkWnqIHUxo0bAQA9e/b03N6zZ09538aNG9GjRw/P/aFQCN26dZPbpHPPPfegqqpK/vTt27eYy+64NNO1V8zMkNRIqUpOjZD8EhcjgLP3pYQjgQIzcRxQ1q7Buj/9qfknsAo4cFDXHgD7M2EPk3ZOfsHfR7O+Holvvmmt5WWgr1+Pupkzi7fDNjbkZKbRKcTmzDTzMnRkhu4JSmQA1V6BSnrGKVtpr6Ma0bZEuyczUp0gYO9kdIquvQkTJqC2tlb+/PTTT+29pDaBuUt7rThrD0DWETEslULjwk+c7WS3S7EzUnn4SBkBywsFXIHJcmMR2XjnXUi6yxutTPyLL2A1NbVsJ5YFJaTZ44Dsv3UeWYTGjz5C9YMPtmwNeRBf+iVq/vGP4u2wrWftGW1bSiwYw8ivLJf+XTUMQNPar7SXdrzMKKeKYKMdM1JWIgFj+3bf+1hLnMnJ/qDVKGog1atXLwDApk2bPLdv2rRJ3terVy9UV1d77jcMA9u2bZPbpBONRlFZWen52RlwNEEWLJ8PP/dzKo4hp5w3lTa0OLFsGTZOmuR5Tv5vETJSpgUoChRNzc/ZPKhOgxW21mJrpOJffAF9/Ybi7jQHm+65F02ffdaynVgWoPEAV2Si8spEmJbUw7QJllnUk3NbG3K2eZdggfCMVD6lPQNwCbeZYUKNxdpvTEnGsSCttCcDqfbLSNW+/jo23Xmn/50t+Jw45UwKpIpNUQOp/v37o1evXpg9e7a8ra6uDgsXLsTQoUMBAEOHDkVNTQ0+cx3o33vvPViWhSFDhhRzOZ0Kff367Hcy5h9oFOngy1yOnOkZKSuZ8h70ZHaiCAdCy+QicFXLa9ZeUJ1GQQeOVshIMcvMK5vT4uczWx5UMMagaBr/G9mfvbyu0q38urtaCrOK7Ebd1rP2WqG0Z2ze3PLMZBrMzFMjpRtpGikDSizWfoFK+nG0A3btsXgcqXXr/O8zW9C1Jy9EKZAqNnkHUg0NDViyZAmWLFkCgAvMlyxZgjVr1kBRFFx99dW466678J///AdffvklLrroIvTp0wenn346AGDffffFyJEjcemll+KTTz7Bxx9/jCuvvBLnnHPOTtuxZzY0YuVJJ2fe4bY/8M1IFWfWnhsuNnc9RyrpCZocAXcRtFmmCUVVAVUJFJg5QtCAJ+mOopFyneTNhkZs+b+/FvkJAH3DBqRWr+a/5Jk18MWypFEqKyB4ZmYbD0ctduDWxqU9VqxxTy6qJ09G3dtvF21/jDG7VJfP5yC9tGdCiUbaTSOVEYR0wK49lkrB2Lgpy50t10h1hsxnZyPvQGrRokUYPHgwBg8eDAC45pprMHjwYEycOBEAcMMNN+Cqq67CZZddhl/+8pdoaGjAzJkzEYvF5D5eeOEFDBw4EMcffzxOPvlkHHXUUfjrX4t/culIxL/6Ghtuneh/p6GDJZMZX3InM5QlIxXw4GvW1MDMYXjqGRGjpmmkksksGakiBHC2LYGiaYECM9m1l6dGKq8ruNbwkTJNefLR16/Dtr//vbj7B/DjRf8PK0dyW5J8swa+WBYguiml2DyPA7BltenJiFlWUQOpNi/tmUbRfaSsVApWsnlbkeA7LEA/lPZdZaYJNRrLKxgrKlZ6Ka/jde0xXYexebP/GlqgkSrmRTDhJW8fqWHDhuVsJ1cUBXfccQfuuOOOrNt069YNL774Yr5P3akxqquzCo6Z+0pBdWJbXmXiKRJf+4OAXXvVjzyCcJ8+2OXSS7Nv5LI/gKe055+RKkadXWakFDVQYCaPeabBgxNXt6H/E/i3ODe7riIfZxiznNIeY2BFLrdkUITsjCjt8YxU/idQZuXX3dVizCIHbm0+a68VRtIU+T1xMpN5aqQMQ35XndJeOwUq6X/T9N/z6Npbf+Of0evOO6BGIsVaHX9u23LEqK5GOK1KwzOXVvPHPt8dk9i8tegUXXs7BLlcyHNe6WXPqgSdtaevX5/b8JIxKHBppFy7ZMmU97kLaIXPisxIqYFOWtJXS1zNNnMwZgWV9lph1p7pLY9Z8Xj+Y2uaQevSRf4/M62WX/HbpT3up1SALs7KYiLbWrDiZqQKmbW39qo/FGz5wOyLg2LCLLO4mR/7/c0roBZaPfEYw+SO+e2kkQpa2mvuNTLDQO2//43kt9/l3K4QhD5L9yvvieNkIdlSsj9oNSiQaiPElYTvfRkTye3bmSPYsVowa8/YVJ1TPOk25ESaISdLJT0BiwygilH2cGWkggRm8intK+JmT9QFlPZcb3nRYK6OMmbxQI25RiYVA28gZbT8RMUYEOJicycjlU8gVYTyYh7w4LF9S3uptWuR+nFNYU9oFF/viCIL8KWfWB6NDOL55WMNnpFq045ON+nHmXQ5hRWstMfskmlyRX6Bc+Mnn6D2P//JvW97LJOxMbPTtxC9ovNgyki1FhRItRWWmf2ELj7g6V9eJv+TZdZesNKesXFjswcGz4gYt9g8XbslOriKcFXDxOgWTQ30Ohz7g4BdZAWW9oqekbKYI/6211TsuXXuQKooJR3LghIK22359r7yKekUObBp/gmL/HyFmN0aBszamoKejhVrALkb0yxq5scJivJ4n01vFouZJpRYtMOU9jIyw+L72dCAn64Yj7V/+KPvbiw72El8syKvp098vQyNn3BfvsZ58xD/8quMzsrcGakCdJ/ioeLzRRqpokOBVBuRM+jJkk5mrkCK2bqX2tffcDYwm7+KtRIJmDU1OQ+ouUbEpNsfOBmpIhz07YyUoqr5HRjklXHuk4Tjwp7Hvq3cs/YaFyzEjxdfjIYPPgi+T7eppb0Wq6nIgVRVFd+v3RxQNPsD06WRylNs3palPVbkoEHoUPJag2HArKkt7PlapbRXZC8vM1hJ3bMGEUCJ76ph2GLz9uraSw+c/Et7qTVr0PDee0h+/73/fmwNVTLfUq5lyr/Jlr8+jdVnnYUVh/4CxpYtzr51HdGf/xzbn38eqR9/9D6vvIgsJCMlvscUSBUbCqTaihx6ptwnKicjpW/Y4DHHDFLaM4Q5as4Dl8tHSs3MSHkO8CITlSUjlVy5Ek2Lm5+DB9ivV/pI5Z+RavbEI15HvldvOU6giWXL0DR/ARoX+M+F9N2d5WiWmAykGvNbU3Oo/O9nbttm2x+0XCOFkMYPvlb+B2/WxqU9WAwopiEnyz8jxUwTZk1NYc9n5h+4NUuxOxkLOImna6RkRqrdZu1ZnoaebKU9s44HxNneP6angFAI8a++wgb3MbkZ0u1Edn/8MWi7dIfl6qpmKR1dzj0HJQcPQv27s707kLrPAr7fZH/QalAg1UbwURvZSnv+3iXpGimmGx6hcpDSnkgP58pQMOYu7SmeqzaW8pb25ME0SwBXP2sWav71r5xrcu+LZ6SUvGbtBRa9FjS0mOXUSInntOJ5dN5ZlpMtEWsqcmlPXOUaW7cVJztjWVC0kO0HJQ7A+RhytrHYvNg+UoXYH7SktNdaYvNiBiyFiM2N9NIez0gVM+jNC2bxTKv8PUtpr64eSg5RPEulENplF+z+2KNo/PCj4M9vMafcaTd0KOGw1yJCT0EJh6F16ZJ5XGQFZIflQ8n+oLWgQKqtyHVgztYp4vI0YuJkbFlS6BhEx2FUb/Lfd/rzuGbtuQMJK+kVmzd3VWM1NgVv7xcaqYDO5pkaqeYyUgWU9hhyroUZOj/w5VGa84z/EBmpIgdS4oBrbtvKn6sY9gf20GKZkcqrtNe29get42zelqW9VnBSbyX7g/xGxOiex3JDzvbTSDGLcX809+9u7O+nWV8PtbIya8DHUikokQjCvfsU4PjvOhYoKtciusfo6Dq3VNBCGRffLO04khckNm81KJBqK3K4kGfv2gPcGSnIbEhcDtdt7mBvVFfbQ0JzaaQYFNWJpLyGnCn+PGlrzKZpshobYTYGK1vl7Wwu/kcelIuvkWrW/cAwoFZW5hcIeUp79t+z2F5S9sHRyUgVp7Tn3ld+PlLMM2Ot1SlyRqrtS3uGDOATy5bBrK8vaD8erCLYYLjIZTtibN/u/9rT9IzMNKHGou03a8800zJS6aU9kZGqg1Zenr20l0pBiYShRMJ5jZPh81Gdhh1FUzMzUil+saaoambQKrsKCy/t5cr+m/X17Toep7NCgVQbwUwrR2nPv+XWXdpjliU/4FZjU+CZdyyVglpSkvMkw53N3bP2XPeJ7Ff6lVC2QKqpCawxv4xUcGdzcUUVtGvP/icvYXzuSIrpOrR8Ayn3yBZROiiy2FycmKRGqhhde1pLfKTaOiNlSePHotDGpT2YTtayevIDaPx4HhhjqP33vwt+TcV2e3c68DL/rtuenYptL7yQuYZ0jZRhQIm236w91mxpj8l/1crKZgKpCB+jlM977B7mbVqAqvF9pGWkEA5zjWKGXUNujWpOxGvLcTz89peHYeuUZ/Pf904OBVJtRS5DzpzdMEJs7pwcWbwpsP6HGWazQ0KZxeSIGFVVYJlpPlLIzJplu6qxmpqCZ1tMfkUW1NncPSLGvZasFOLC3oyPFNMNqBUVeWmkPN1TsrRX7IyUya9s9VSLNVLiMyVKe04zRB6ZvWII3vNBrK1YgUMbl/aYqwOXpVJ8DFIigfU3/rlwJ/xizFxMWyPgfwHDUimPGzgzDKwcMRJWMuF9jGFAiUXbTyOVUdrL7iulVVTkDKTUcMT+zuWRkWKW9xiqKvY+3BkprpHiGsW0KoXISAX4LiZWrMDWqdMyHpvtgsjYvBkAoJaVBX49BIcCqTaC5TgwO1+O3Iac4stmNTUFLltxcWfuA5e7tKdqXrG5leR+KfIEJZ/X/7XkE0gxy74iC+wjxf9VAhoDskI1UrkyUobBD7D5ZJRcmQEZlBS5tMcsyxbHmjI7UzD2+6WENNtINv/RILBY23btiSCkSM/ZktJeQRkkw5DBIDMMwDRg2SXyQl8TY0XuZDSyfw5444tz/LISCaR+/BFWg/c1yFl77VXas9IzUt673YGVWpk9kLIKzUi5xOawuMWIX0aKa6TUzMyTPP42//4lv/0OjR+6bFrEdyTL57p+9nsAwANdIi8okGorXKn7DLKdBDw+Uq7SXjzebInNeV4TSklu3xbv0GIFlrtrL+nNSDVXUsw3IwVNBQL6SFmytBfQIFIK9fMt7eW419ChVlbkVdrjLc+ta8gJ07BFvLo9KLYFJyrxPttDix2NVH72B615ssy46PCxENl411+QWrs20P5WnXW2DFwAFFTaE8OirYAaQc9jXY0jTNfBDFO2xBesWSl2VlCU9vyCM9P0ZEmEO3d6MNjehpyM2bYe8gYrfQP5v1pFJaDrvoGxLO2Fw1m38cUtNrdnq3KNlDeQkhkpIz0j5f0u1vzrVXx/3PFo+PDDzDUahjQO5c+d+5yR+Ppre10kRs8XCqTaCJZDbC4/2H6GnMyVkbK/bO6MVLOlPd02wMslNrecAZiqpsByHxDTNFLNPa/V2Bg8I2VaUFSN+7oEOGnJ0l5QjVQhTr5SIpEle2gY0CoqYeUz4sVV2nN8pIqtkbKgRKP8M8Ra2MEmMlJaiB+4ZddenlfellWQA3MQVp9zrncIuCsIETQtXAh97bpA+0ssWwazwR1I5Vfa49kfHUokUpDgnJmOvosHUoZs2ig0kCq2RipnaY95LxTFcUMeC1ylPVUE/O2BaWv/BLlKe5UV9mMyg1GW0mVGCkDg7KvbR4rZ2TElnJmR4oGUX0bK6yOVWL4c+vr10Nf7jJPR08qtlnNR7of4W9EsvvyhQKqtsFjWclh2Q07mDOp1HRStpnim+DsL/AowQEZKlvZUj0bKEhqp9ExUMxmpQCchi2ekgjqby32KoKS5skUBpT257GzL1w1oVZV5leY8Jnyt1bVnmVAiYXkFWjSNlMVcPlL5ic0BtFp5z6ypgVVXJ39nPs/HdD1QEMKYXYZ0BYp5l/bsbdXycufiIx9cGWtmGGCmkVEWyxvLyq8c2ww5R8SY3qBZBlJ+GaloO87ayyjteb/ontJeRSW/LYsmTIlEuCgceQS7FvMeQxWV78PTtZfit/lkpJyLGnHOMDy3e9ZoGN51sdzfY6upib8mykjlDQVSbYVlBijt+dkf2BkMy5Tt5FY8uEYKprgCbEYj5RKbeww5bY2U4yGTW8BtNXEhfJChvE5GKpizuVxV0AxJIaW9ZjpbmK5DrSiga08acvK1F1tszgwTaiQq/17F0EiJocUFOZsXMlYmD5hheD/TPsNm+TYBTnB+mZY8S3vidSqRSGFmiabhiM11HTBMJwgptLTnGpZdFHI0xbC045vQVroDKcZ4ENGRSnuZPlLO72p5GbeDyRFIKYoC5KOTcpW8eQdhdh8pRVMzskPOcd/V+QfAV3xuGLLEyh8jqglZjt3xONSKisI6AndyKJBqI3KOgJCGnGkHTLcNgVuw3OR07TXnJRW8a8+2P9AUmO6uvQz7A5MfOLJctYhMS6CMi8xIBXM2FxopJccB3U1BQzqbyUgxw4BWWcG7lIKeMF2GnLI02gqGnEok4mjaWnLFL0p7qsaNLtOvfvPYR6vppNJ1YFZmMBQ4I+Xn2J1v1579PEo4nLe2CgA/IYpg0C7ttTSQ4q70xfeR8v1smZbnOyy6fWW5SHec25u7sGtVLOYt7WVopFwZqZLSDCG43Mz2kQKQV+cecw8wNy1u/5LetWeX9qBpmZm7NB8p+Z77ZaR03RtINWPIaTU1ce8sykjlDQVSbUUO+4NsbalZu/aE2FzU53MFUqYBNZZ7JAMv7fH/T+/akydm15VPtpMFM02weBxqaWmgQEpmpDTH2Vxftw7fDTsWG26b5LtOAI7oNaj9Qb5de0BOjZRaxq9Ug2SlZOAk7Q/sv2dQr62g2BopaVfRghMVY4zr1lTV20IfwLNszaWX8f9v5dKeKH/J32UQ4s1IBXl+5lMqzre0x0x+gaEE1Pv5Pj69tNcoxOaFl/aKqUVipk/AKZ/L9JygM0p7ppNBVGKxopYc86KZ0p77b6eWlmSU3eTDdLu0B+TXuefRS9ojsny69rghp5Z5gZkeOJlpxxfPGr0ZKZamr8pYWlMj1PJyykgVAAVSbYRnTEjmnfwf3yyC07IqNVKNTVKoyG/IceA2mu/aA3OJzdN8pGTXh6sWr4RCvpomK54AFAVat255ZaSgOM7mxpYtMDZu9J2qbqVdUQXVSOUneGaefzLutUfEqCUlAV9jWjanlbr2mGlAiUZkSaXFYnMxA5FZOQ/WnofF42j88EO7A83f0qNYiA45iQxCvCekQJkCMcbEHXTkW9ozDK4pU9XCrugNr9gcpru0l8r1yOxrcvuXFYMcI2JYWkbKSgukZAZRUXjmtJ18pJj7AhSZxwb3CBm1pCRrkMRSKW5RgHwzUq5OSou5uvZ8NFKhzIxUuo8UMw1+/MxDI5WrmqBWVFBGqgAokGorcpT2mM9JABAXS8KQM83+wDSdjpEcB3zp25Lji25Zjv0B79pLy0gpikfzki0jZTU2Qi0thVpWFijjIjJSbmdzGSz6nDzkqrK8Xxnbu1yKAyNLe1keY58wlZKSQOU5eaAW5SPLglpZCbM207gx9eOPhXe5mZantNdSjZSiKM4MxICaNHkyMAvTVeUDz9q4Skk+g78zdFTZ9uXXQJFv155h8Asbv06rII93l391HUw3YBbD/qCYXXvib+kXBGVkpOzvr31wEd5YCIXy914qJs34SIFZTqYpRyAlfKQAZC3/+T9/mti8uYxU+oWIT0ZKCYd9g5+M0l4zGXrW2AStgjJShUCBVBvBcjmb5yrtSZlPuv0Bk4FUTo2UaQTo2nMZcvr4SCklJa6TqchIZX7ZrCZXIJVXRkrNyDJ5DgCudQKAErDU5LQKF69rj+n8ZKCWlATLKplpAYVlIbzbbtA3bszY9Kfx45FYtjzwWj3rsoTYvJilPcUWx4ogpZnSnmuemvOYVmpzt4MNiekNxMV6CtZI5du1J0t7WkFX9HzWniM2Zy5DzkKDYreLdlHIUVJPz0iJEjPAS3lM54GvNKAs4rq2v/yP4JYTGYFUpv2BanfiORqpLGLzcP4ZKfjaHzg+UowxR2wumj3cz5smFRDaSP+MlJ5Z2guHs9sfxONQyykjVQgUSLUS8S+/yugCypptyFbac3ft2ZPclWiUd3zZom9+Z+7Sntpcl4wFj4+UTB8z5szqM71XQH5dbVZTE9SyMlsj1bwpoZORcnQlzDB4tieVeWCSLzOXMaDfA/Jyms6dxWK6DiUUDh5IpYuuLQvhXr1g1dd7fYvAr+JZosCSn2Hyz0YRNFJOaU/zmIk2d/LzZqRauWvPNL06m7SMpvB1ClRCMjI/T6wFpb28mhsEdsZarNtb2is0I1VsjZSZtYstIyPlOoEL3yiRteNZnuKta9tzzyG5cmWgbRlzSne8JJZZ2lOi3NlbLS3JulaW9GakgvtIpWkO1TQfKaEjC4cBVfOxP0jTOZnORIOM57IzUk5m3g4i/QJhe1vSSBUGBVKtQMOHH2H1mWei6fPPnRtzis2zdO3xW/nD7dKeWlkhLQYUVfWU3Xz3bZpQYiWyq8gPizGX2FyVhpziYKiWlnq69pRQyP/L2NTEM1KlpcHE1JbJheYuHylm6FBLS/0zUuJ/AneRFWJ/gJyPESdMpbTQ0h6DEg4j1LMnjA3rM/bt97oDLduyD6gpofdpQSAlNHOqnSmUPlLNlPZSroxUK5b2hAu4p7SXrpuTwVE+GSm3RspCcx2x6ftQNI17ogUIHplpYuNdf/H8Dpfui+kt95FilllUjVSuDuBsGimAl8ggXl8oBGihoo6usRLxvDpoZUYqFMr8+7pKe2pJCRD2D5KYu7QXyScjxRyxuV0JcGe05H7CYT6iKYvYPF1q4dv1LNYt9mlZPDD0CfSteJxn2mMxykgVAAVSrcC25//O/yf9QJ93aQ+QwYDdtadVVoE1xfnJxA5Ccl0B86695jJSLvsDl9icJZP8Cx0Oe3yklEjY9wRjuQOpwBkp1etsbhhZA6l0+4PmTjAyiCmy/YESDkEtKc2vtOc2UFVVhHv3hr4hzY04faRDPpgmlGhxNFJMZKQ0/tkKGhTJ8oRpuj7TxdfCMJ8MUrqFiG+5rpn9ed6zfLOZpsnFwVowTzQrHsf255/3ZPFEWQfg72HLfaRa6HCfjpjb6Wt/kEUjBfCTs7u0Fy5uaY+5DYqb29YypY8U77DM7NrzaqTCvu+hO5BClm18cV8AmPaFpCujJYTmUqOYITYXOidnH0o47GtpIGUSulM25Bkpn0DKPnYXqvHb2aFAqjXQfbIClpm9tJflROWxP7C79rTKSp6RMk2uYbGDkLqZM30FzLzk08yIGAbfrj2WTEINh73pYMsEQmHfA5fV2AilLP+MlOLJSGUPpOQ5LWhrfQEaKWcOTZa7PV17ATJSohNLrJXx4DHcpw/09UXMSJkmVI+PVMsyUlAUQLE70AKaa8rPmFts3hqlPR+HbeY6sbjXEqTjTepNPOL1/D47PFMZtnVlAR4jXkPSNTnALQ43DVgNDba+qCWz9oorNleyeEAxK00jlUzTSNkdZE5pr5gZqUTwLIrbR0rTkP5F95b2SnN27RXmI+VqKrCrCko47GRzdV1qtHwzUmkGnDk1UqI5SRxT7I5Ef31rE+9SLFDjt7NDgVQr4HjapM05SjvArrv+BsS//toTRHh3JP8DyzKd0l48zr/wqgZFUcAsC1v+769ILM8UKjOzeY2Ut7TniM3dxnCejFQWwaJltwSrpSWBtD7MNO2MlHMVz/RcgZQrIxXyGZ+Q+QD+T15Di8G/FdkyETov7XGNVIBgMc08lJmujFTafCxmmr7asECYJpRIVL5vxdBIiaDACVKa2afrNfr5OhULjxZLkOZsnl9GSpzEfDJSgQMpO9sS8EQkvk/yJGdwsbkTAHKxudalS8HvIbOsopbQeONK1D84Ts9IucTm0oDTNIFwiHfpFimQYmKKQtCA0VXaU/yyh8yCWlqK3R55RM7S8xWbp/tIBX2f0zNSqurJesljLsC/gxkX12myBqGR8stIySyXLl+bGPuUsaymuJORai0T3R0YCqRaA3lVbKDhgw9Q/eBDHgGuILVqFYyNG52Ttt/BQAYDdkaqvIIfOCzTMU1kDDCyCGsNg8+2snIMkE0fWuz2AArZB750jZTfvkyLiydjJdxTqjns8qTb2dydkUovH7rtD4K4I0stQL6lPUXJGkcxw27hjsXAEs3PVJNBsnj/mAWoCsK79UHdW2+hfvZsz75bpJGKRl2z9oId2Df9z/9kliht+wNF0zxeRM0FCE5GynC1eLdVac/03CbXEiRT4GenIf5ugUt7Bu+yClgakRcmIiNl2y2kl/Z4IFVoaa/YXXvcSsWvEzM9I+XVSHEDTl7aC/GMdrECqTTD4OYfYHlKexnHRDtLVDniRP4dyCI2t4riI2U5PlJujZTIdPn59cmSeZpGys/bS35P7GOCrZHyrSbYHdd8UDllpPKFAqlWQJi+sVQKP132O2ybNs0JFFwHZqbrPOBId78W9zNnaLFlcvsDtbKCp7Itr76IpfQsRnkm1JKYvX//g5fb2dytkYKtaXDrPqSzuZ/Y3DKhaCrUkhhYMsisPTsj5XI2F2JzABknQamRsniJodmTdJ6lPZnxUpWsGSnRtZduopd9Dd5AilkWFEVF5ciRKBk0CA1zP3C2zTOQMjZvxobbb5ePLcRHqmb6yzC2bPHcJu0PFNWTkQrqI8VcQXtrlPb8hucy1+cHcAdUhWmkCintIRSGogQbwA1XICVm0GWU9pqaoFVWFj4ixrKKlvkB4CrtZclIpc/oFBdnsRKukRKC/HAIYKwonw1xERC0hMncpb1QCOklfKEPlIRzjYhxO5vnIzZ3vifppU5uq2AHUpqW+T3O8JHKpZGyvwsiI2UxIKT5VxPcGqn2cp3vxFAg1RrYehU5Z8rl9OwRoOs6WCLu1LvTvjSO2Nw+ONsZKSuRcLI5dmlPuCGnw0zTEUVmOSC7Z+1pmgJmujNStobJ8GakfK/URUYqGguWkbJnTXEfKacEpojALyOQEo+zB58GtD8IfIUl9q8qGQdYuYktNg98FZqe7bDdjLUuXVBy8MHe8m+egZS+cSMaZr/HH2tZUKP5a6RYKpX5nGlic3mQDugj5bE/aA1DTr/SXnoJVVyFt2DWnuffZveRedGRc3tR2ksmPcJ2WZrVuaZILS0t3CrA1QVYDIR7vq9miFneY1syyQfgAvzCSpT2QposrRUjyJOds0EzUuLiEHagkjFrj/Hvv42SJXvGUroTSBXoIyXtDyLejJRq+1NBzQx6mOuCVvyuRCK+uifnoiIlHsxfj8/nkzU1QSkljVShUCDVCsgyi9DQMOZ80F0fYpmRSq97yw3s/yga10ildKjl5fzgYZo8c2KX9riYM0tpLxTiRmzZAikGacipuAw5+ckhxFPhrrbbIBkpK4hGyt5e0VTXeAwu2lUikYwONrdGSo02M/ZGvDD3v80uyP5XVXx1BIAIpMKB3YxlwOkKRKHxr507qyVb+vMYByJ0NADsrr0owFjgbJkoJWW8DsuS9geyrd3VuZlrPQA89gdtVdpLd8aHX3CUDbmtW3NVQGkvD/sDJyPlHX7tFp+zVApqWVnLSntF7dqzTV/9/qamVzpgpZLQ7EBKsb+r8ngi7AeKsDYrwS/YAmekXKU9aD7ZGTtjLMgtNheBVD4+UjzgFM8r7Q8MJ5CSIvaQlvm60q1fTJNv7xf8pJkbi9Jesxkp6trLm1DzmxB5Y5/UnKslR4jJGIO43mG6zktglv8VPy/rMSiKJtP0akU5wBg/gKiaU9rTs5f2oOUey8AYc42IcXyknJOD5s1IhZvJSMViYEEzUuI1uCwNlFDI44nkrJP/q1i2n01zpSaWX1YBrtJerqHFSijkOfjlJM3+gLkO1H5GfPlkpJihc5d7u0winZajWQTB6WTxWmIWc/R3Fs9IqeFw8z5SnoyUK6tZZJwuO9d60p3x0315cu3PRyNVUGkvHPKUqQM9ZyqZkckR+2O63qJAKud8z0L2Z/tI+QnYmWVKWxKAB4hqZSWwbh3PHhu6czxRFB6YFyOQEseZoN9xV2mPZ6TSu/a8pb2czuYBMlKMMdS+NgNKJILYfvu5MrX2PkVpz/15lWJzH6sCcUzzaKSyZKRkaU9kpIT9QZauvdJSykgVCAVSrQDPSPHSnhLlYzvkhzmttGfFEy59R2ZGSlUAKKqtkTKgxvhEcqux0XafVp0rT78rJ1sEmzOQShebp5f2AmakRLZFLSmRV4q53yc7I+XykfIEUmnZGaEXU0wDamk0sP1B3uJJFchW2oOuy0DKCqIDSzPkFKU9AN4r0fQuriAYBs9GNjXx99Ju21ai0UAia3mlmv6czJKfLeHEzNfaTEbK/VpcDRfFJt0rSq7Z1Q2WV9demokngAJLeyE5Vqf57R37A3ewKZsF7O+PWlpaeObGNMEUpfntAiI96Xy79rwZKZZKyYyUGivhr9Nu1ABQtM49Zmf9A5eQLYsfzyC69tJ9pNJKe+EcGSlRgstxbLXq6rDh5pt5Gd80EeraVT4egLQ/cGePFLf9Qdp77bY9AOBopPyczdMvlMRAZt+MVBxqCXXtFQqV9loDOwVuNcWhxmy9j0yvponNE3F5lZGeYWEMgMKgQJM6KCXM3WetpiYpNpclGr+DiWHyq54cV4BusbmqKp7Ajp8cvBmpbF9GMfJFjcXkiSD3++RkpLhAmcGoK3E0SGknePGUil06DWp/ECRDwLe3959FbC67qkLh4G7G6Vegdtce4L2SZYVkpOzHmo2NvA06KjJS/jqWbI/PXtqzTzSyxTqYRoq5ShfF9DGSyPKd66LEFJ8J72sKlpHKrpEK7Gzuzt4GuaK3928lk/z1iLmZdkbKamoCFMXWAuafkXJKykZew5dzYtgWG74+UmZGZk2t9GqkmOEMWleC2JcEQF6wBSxHMWZxZ3XA10cKzFvaQ7YRMekZqSy2JcyuTvS47lp+jBafK/E9tw05/TVSPkGNlZaRsmyD5EAZqeylPfF6FL9yJ9EsFEi1BsyCEuM6ISUa5e30rg+z3EzXweIJ5wSVMWuPQVFsjZTdtafYNv5WY5PtbK7IjJTvAc7kB69cmh7G/DNSTteempmRgk+mx85I8dcePCMlSkhWQwrG1t25vUAkkhFUuO0PlObc2vkTeP9tbj2ydphFbG7/nfIRmzv+W67SnuqMqJBXoumeL0HWaz/GamyUhpwAuI6lBYFUxtBike1qbp9uEbg84LdCaS/tPQUAOWw2TT8VqPzqq7nK08xVlvaCzdqT5clkymlLhyuQSiS4Fs+nxB0IPyF+C2G5vncZGakktIpKAIASK+HHJzvYBMR8upbP25Nde0GDMtPtI8WPO/q6dah5bQb06mqf0l42sbnLkDOHs7noVJRBkfTLs1+7oni1krrOP0eA73DnTB+pHF17Bp/N6tFIZZu1J471fsEb0SxU2msFmGl3UMXj/EMeCjllqvTSXiKBdDNBeT8AqAyABsvSAcsWOpeUcBdxReHt1gbvzsnmJSJabLOdCJklO5UzxObcRyrkXGVbJj+4ALK7y/26ZUYq0PgUW1MlM1IAmCLF5hkZKfvkplpCbJ77QMwKLu35+0iJv4/USAXJFAgRvctAz1Pac+uKkG9GSgRSTY7YHME1UhlXrO41K4r9dyk0IyV0R60QSPkEScLhOb2ckVfXnpmZkcq3tKcIN/jmEO9Pipe8FFUFU1XnpNfUZBtCFqYl8gQ1ouGkpcgRMT7rSctIWckUNJGRkhop0xF6F8ndnAXISG177jmU/vKXUqMkSntQNdS/+y423DoRSkkJdk0moJaVB9NI2U0nQDNde0KqILz4mCuQUlXbq8qbmZbHV7+gxkzLSNld2aJD3LvGtLmlFuPCeIgLOlcexTQoI9UCKCPVGojSXmMTD3w0zRkB4DLYhGFwB/CsXXsMqgLpTcNSuhwsaTWJjJTquAj7HZgMg2+XxQ9FrslXI8UP8IqmOuUPcQUE5MhI5aeRki3jduCjZMlIySyRCBqKXtpjgGK/FX6lPcOwbQHs+VhB7Q/cGgZmOR2SbkfjgsTmroyUZUGJuDRSAUo6Tqt9ZmlPjh8yTXmwblbcrztXyVKP0Spde0Kg78662MGeyPSIbQL5SDmNDhJpnZFfaY9/loNopNLsD0JcqG7ZJq+WfRGWV2u9G08gVaSMlBg35Zv5TstIJZNQy52uPbi79uCfbSkEMaYp12vcdM+92DrlWb4dY7K0p2gakt+vRNXpp6P8V7/i+3B9P+U6s2X6Xdm1bBd1wtQYdiZIapxSKdm96MlIpZc/098jca4IopGymxUsdzVEBNTptgq2BIQL3CkjlS8USLUCjv1BnJeBNA2WyEilaWasRNIlSE5P4wI8etBgmZa8WlFKYjwjZZdfnLEgWVK2oVDu9DPj2iggs7THB7GGPFdCSrYvo8hIlQQr7cmMlCJGkVgAVP6eRXw0Ui5DzmYHMbvXF9TZnAFQwCMpnxMos4XmgLgKDXCSthhU99Bny5KCNK9GqoCMlH3wthobpSEnwEdyAGi2FJe1tGd3FiqqKv2BlEgksI8Un89negKbouJX2mMt0EjJwMyntBf0syP8xfzcsv0QFybJFD952tkJlkryDEM8zjMEhQZS4r0Jh4tSQgMgfaR8pyS4GgwAHkhplRWOc7dhyq49IM+xKjmQNivNBK+hXj3t7ZzSnjBNVkRDjWl4vp9AdrE5XFm+nF17oiIgMj0ujZQiM9MujZShO2J4n4wUS89IWRafsWlZSK1d5714EuO2xL4tSwayGf5Upp1R1QJ+fgkPFEi1BnbGxIrH+YEsFHIyUuKLIT7ciXjW0h4YbI2U3T1lp5PVqJ2RUlWerZLeM9mvnJrr2hOeDKqPjxT3xhF+R6ZMD2cKIR2NVKDSnvBUEgc2EbxoIajhTB8pcbdqZ1+aLTUx52ATCAbwlJT4/zQCHjy9i/aWnLxde277gyxltlykZaRUITa3A6pmR+hkK+1J+wMuNpcH6+beb6mR4icktUgt7tmex1PaszNSjhDdQK4GCw9+HYYFlPaghewsXgCNlDgRJpNOA4fKv8tKSYk3I1VoaU+cwIuVYTBN2TyTHqRnjIhJJaFWVNpl8JCtkTLTuvZaHuAx6SPlfc/jX36Fmldfk6Nqwj2dQMozIkbX+d9NdBG6vp8AsovN3R2IuXykxDFDVe0ssbe0xx/vslJxvUfQfDJSsonDyUjB7qL+6bLLkPz2W88a1bIylz4XzkVwRsnQHnFEGamCoECqFRAnNavJXdpzvDwA5yTGR8T4XGFDlNwAT0YqHJIZKdhCbc/g03QMg/tI5cigpIvNZTnDstPXIZdbs7vTLt2Dxa2RSqWaDWDE9uKAIrMXWcXmjiGn9KbJhXwd+ZX2kMVHyu3xko/YXHGJoMEsXs5EWkq/EI2UK5DyaKTESbm5wCdbaU90FqqKzDQEK+25MlLCcbk1SnvSrsArNleiEY+PlOK6Gg+yv4zSntCIBVmTzDyovh1UGduLC5NUEs7AYxVWMsWDFTvDGNT4NQN7/bkuoPKF2V17fP3pJ2LTE0AyWyMlG13sWaAyGxT2n/nWHGZDI5Lffy9/l6W9tM9Z4uuv0DBnDvR16/kNwk3dlZVBSJP6MZ6x9ynthbOIzU0zWEbKFDpTOyNl+mSk3F177vKn32eJ2c0+4pwhM1ImWCLh6ZZmug61pMQ1IsZyXbT6lfZCgT+/hBcKpFoDkx9wrLgrkNJdH2a4Ail7bh6/ks0UmysKuCEns2DpomtPiM3t0l6ymdJeOJS7ju8p7TmGnFxs7jXk9OiasmWk7BN6sxYIYnsRSAm3Xy3i260kzmmKLTZvVv+SZ3mG2aU9JUtGihWSkWLMI/5mpqu05zmAigCgELF5A3+eiONrE+QEnDGLSyBKe5rGLR+sgKU96SNlQIyuaFbHVgBuvZ68zbKghl1ic8PgJ5Eg3Ytyf97Snu8IkWyY/CJHWkY0u72tkUql+PfevihiyaTM+iiRSHCbjTSEmNh3XluBMPEaXR5QxrZtMLZvz8hIcfuDSo/OS3jaAeANLAWsq+H997Dp3vvk77K0l5aRYroBK5mAvm4dv0FmhC3vGnReSuOZO5/SXigMfdMmGbyZDY0Q4248JcJsF6m6IzbP6NpzaaTgaqCQ+9VCmXIPu2vaOZ4YsmtPZv3EtoYBtcwlNhdBok/5WWr8/ExAiWahQKoVYOLk2eTq2hNX/6Y3kGJxXtrjBpSZpT2A64YAwDJ0Xtpzic0VxRGb5xJF5rQ/cJX23EOL+Zcr5B0b4NI1ZX4ZeYZJUb0WCNunv+z73OkZKXHQULRsYnNHIxWoM01mFYIfGBTFjqSyiM0Ddeq4Efoi0+RZLiHkFvtIM5fMx5BTPMasq+f7ExkpOxMRXCOVlvkT5Q0xA1FmpIJppGBrQdwH/KJi+GeQuEbKyUipJSXB/kaucqB7f9n80vxwxLoBDTnFiVDYH4jyUoqX9gC4SnsFaqQ0rWgO4gAcT7pIBBtunYjvhh2L7444EhsnTszMSKVSiOy5J/pOmYLQLrvAqN7sKVupsRjWXjEeenV1fi+rts4ZzA3wCQqKkunBZxpgiST0dWv579IHz8nKKJrqBDQhO+BMK+0poRBqX5uBrU8/DQDYMGEC6u35lghyUeVqQmCW5TQbpVKyCuD2keKlOndGKr2hx5KBE9/e+Z6ljwljhgG11HHGl0Gi30WwYdhzECkjVQgUSLUGJhdD+5f2MjNSIl2b2aEhmunstLS4uilJM+SUrunZS3vIUcdnjMl0tlsjBdO0r9Yc+4OMTru01y3myKmuETmb7rsPxubNmU+clpGCYWekspT2nIyUFUhszmy367xKe0BWjZR4//kaA86zc/lucSdyyzel74yIycNHShhy1tUCgPSRQkgLNBvPylnaEzMQLWl22WwHnivAkVmsVpy15963Y38ggkORkQoiNucBQrpGKp9WcGFeG9iQUwZSjv2BoiiwkkmoIpCyS3uBukPT12ObqharOw4QF2Uh9H3ySZQcPAi7P/4YdnvwAVhNcR+NFC9RlhywP8J9+0Jfu5YP+rXLVrs9/BCUSARmTU1eazDramGlnEDKSiSglpVlZlEMAyyRgL52rVw7IDKNdmlP1eyMVDhHaY8H0+7sr1nL1xzkWCBLe7ZGytHjuTNSbtsOw1mfTzaRWRb/bru79sSFmmF4dYO67s1I2UGi4ifLkM78lJEqBPKRagVEK7oYI+AJpNypXUUBi8edk22Gs7mdKVKcjBREaa+pCdh1V0BVpKAyPaPFLIuXfEJa7i+7y0fKY38gBLSaq+zozkila7pcHTGKPSaGMeYdkePeXmSkAE/mKFtGSnz5VdOQLdU5YcivPOPu2vPNSKV37QUp7VmO+Ns0wcfxOBopmdIvSCPFBauWyEiJbJmqBRrBkbu0J+wPRAdeuNkAwZuRYl6RfRGRZWZP4MO4g7Zo6tB1KKUlYDXbA+yP+yPJkxljkHPJ8nE2D4V4ZiRA8OV0abrsD1QVLJGEErMziyIjVYghp1tsXqQxPaI0V3b4EJQdPgQAYGzaxD+7bv2PafJRSnaGVOvWDdA06Js2yrJauHdvKCWxvHVSVl295/2w4k18kHv6scgwYSWTMGpqvLIJt4+UnZESpT0rmfAp7dldbq5AhyWS0mcNaEYjJS6+bEdxKTZPpVzDy10lfrf2KttQ5ZCjLxMldDGLFa6AEYbh9ZFylfYyuwFFd7dGGakCoIxUa+AW/kpDTpcQF/bVQkWF9JHxK+1xjRQDwLvzLEMYcjpic17aE2VDn3Qt+BeyWbG5mik2l2MvsmWk0k8ypsmvaMBT91Yiwa+mLcv/QGM5GSxozpU802z7Az17RkqJRWE2NUJfty57OSzPrALfOe/a8z1/2mJ/AIG1K0w4KSuK3QLues1uI760Se2BMAxolZUw6+vkqAkAzmzF5taXrbQnnM1dthQ8Y2pAX7cO2/72d//X6g4KW9H+gNkXFJ7Pu2lyzxw5e82AWhJQbG4aUNx6KvHHz6O0B6knDFgasbexXBkpaEIjJTJShXftwTSdEq9poP7991ve1i7Kly5E9507IyXnyIkRKoqCSN++SK3+0fP4QsxGzXqntNc4bx7iiz5DuE+fjHIqszNSrCkOtaLC+9mUgUrIKYFmKe0hPZAyDO467zI4zdkRLUcHiTK5W2zu5yPlsj/w07fJ6oXLkFPMPtV1Zx3i2O8KpESQyLuw06sJ7q49ykjlCwVSrYAYWgwgZ2lPq6jgX/ZsGhTbR4oxfvVj2V8ar9hcdYnN0/yAxP5sjVTdG2/A2LLFZ73+GSlx0ncbcsLT5p2ekTKdjrSSErBEInv5COJqzc6iKIr8cmfNSNn/qpaJcO8+MLdsxcpTT0P1vfdm7Fu+sAJKe0oOHymEMjVSjDFsfvQx/xOVvQZxQmPu0l7EdSIRJ/M8nc21qipYtXX8pGmXeqE6TvZmQwPWXv0nVD/wQMbj5d8mIyNlO5vLTiNHbN64YCG2/T1bIOXoPOSVcivN2lPTSo2MMahl5WCii0tP8RJZkGxM+v5kZjT/0l7QE5FbIyUyUoqiOusGL/kgSEAMIP7V1979i2A4FIJZ34C1l18B/aefvNtYFowtWzJeY2L5cqwcdUpWryEPYsyRO0hIci8sqQECEO67O1KrV3seX8jgYquujncE6zrW33wLet5yC8qOOCIjYGeGDiuZhJVIQLMzVjJLIwI86WnlKu25NIziPrE//i8P0OAOpHJdVNnaIwgbCndFwl3iTySw+X//1w7IRVdh5ly8jKHx9jkhXSMl1sMvJhz7A6jiIpi69ooJBVKtgWlKU0SekXJlbyxvRgoAWCIur/jdcFsCQIECVePz9pRQiBteCmdzzeVs7pOuFTXx7mMvRvKHHxD/8ku579rNTc7zCAG06i3tcRGsY8jJByeHnfEhntdteTNS8YTjceUTIFiJBNQS25dGc05Aim3XUDfzHdS8+prn/QC42Dw2cB/8/IO56D3pNugbN/n+GWTnVT4+Uord9p+ta89PbK7r2PL4475diszODMiRGBbL2rXnScMHWa5hQO1SBbOuztFb2Ol52N49+rr1qJ85Ew1z5mY+PptppbA/UPgsMjHHj5kmUmvWQF+/3j8wllYOjti8Vbr2DJN7lbmDJJmREk7XBi/1BbQ/8OxPfF5C+Zf2AtsfyFl7tv2BfYKzEkle8oIrI+V6DQ0ffoj6997z7MusqcHqs8+G2dCAunf+a99oXwSFQkgsX8ZvcwU2ALD16Wfw3VG/Qs0r//TcXv/ee0itXIn4ki+8i3Z13QlEVkkE3ABgJZ2BvoLI7n2RWrXK8/ggDRHpmHX1YMkk6t5+G6Eeu6Jy1Mn2zLxMOwaWSMjSH0zDydIIzaL8zjhde0gbWiwzT+6MVDLhdNZBZKSy2x8oobAMyt0+Uu7SIABseeJJJyAHZBbLo2cS2WFxHhEXLIbBP6vuAdyhkMcSBJZldyVzE+fEN9+41unKSLWGie4ODgVSrYBnXEc47LkKY65Airc3R+QomYyrZ5GRAv9SWcLzJBrjXyg1rbSX/gUwHN+WkoMPRqRvX3myq9uSwGsPLLbX5PKRUlWX2NywDzIuQ047kOKDhnNkpGJRsETcCaR8TmhWvMm5+nZrruyMVHLFCtS/8w4AIP7110CSByqqZckxD1rXbjC3bfP7M/CgJRRcIyXsD5BtRIxbbO7OSOVy0RZ+PpqWccXL/WAs+2rStD1f8guktPIKnp10tWJD1eT6xP78nOazd+0J+wPV1juZtgGqgdSPPwKmCX3Dhqz744acwTr9CkFqmtz7ZhbU8nIZSEHXveW6XPuzjSY9GinYpZ88S3s8+AwQfIn3J5XkJ7+QrTt0l/bCYY8QGQC2/vVpNHz4oXdXqRRgmmiYMxfr/vhHNHzwgdNBq2lIfPkVf11p74XVwLV1VmOj5/bGjz5G9OcDsPG2iVgzdiy2vfgitzjQjczSXjgkS7ny2JZKSmmDIDrgZ4BlQevW3bkxhxC+4aOPkVqzJuN2s55npBLLv0H5r47mxy0tlJmR0g1eNo0noFaUc22TCKTSMlI8Y6zZ9gGWt2tPzKaT3mV80LyntBcOA7qO1Np12PzEE4jb7zcgMpWa0yln8vS/Z0RMNIpQ7958e9M1F9FnggSzTJnd5m+InZFKeju3xRQGTyBuZ8PV8nKsPu98rD73POcNEx2Z5GxeEBRItQZ2KzbglPbc9wGuzE5JCaymRt+TDjfa5md31Q5mlHDYyeLYpRwr6W9/4NYDAPB07hm6CUMXwsS00p57aHGat4jIyiiq6tO1585IlcCKJ1xCeJ8MRjwhW73dJThF1WT6Xfi3bLrzLlSu+AoKs6DYAnoA0Lp1hbE9WyDFTyZBTRUBngHMppHyiM1dV6Hp8/Iy1qDZfj6ytOdkj8TjMgaMBlmtYevsGhtdLd38YKiEI3YglYRSWuoEGO7H5yrtiY5Qy3K5hps8kAqHkVrzU+b+PBkp5ttAUQyYofMMkru0Z1pQy0odjZSeh0ZK7M/lNQTwi5cgxrJ8Hz5WITm354GzlUx5bEBYMim/3+kjYvTqajQtWgSrwRv4CK2buZ0L67e/NB2i8xLhEBJf2YGUroMxBn1Ttf2787lNLF+OTff/D9bf+Gckli9Hn/vvR9lRv0LVGaNR/9bb+P7oY9D06acZw4+l2aYrI8WSSSltEFSNHo19Pv8M3S+71PvYLKXX7dNfQuO8+Rm3W7V1sFIpWIm48z75ZAGZaYIlk7DicWjlFbL0JY9ngKNFCnEdK+yuPaTN2hPvkXjPrGRaaS8cRnzJF1h1+umoffU1NH78kbMQcfFrHy/FBYblNuRUVez1+n+cLj33iBjAe16wv1fMtKSdihKJuC5Ynb9peiDF7Gx4/1f/hd0efAAsHpcXWLJsS87mBUGBVGtgmh6NFFzpbJYWSKmxmMxI+Q0tVkQrWTwBZs+t0qqqAABqaanHkDOj688w01LQ/EtlJZNYc8VVTgmPMSj2gYhrpFxCRk248jptuyIjlVG/d2Wk+Ly9uJMR8SvtxeMyIwVVda4qba8aANDXr+cjUAwD0HWE4ehXACDUvTvMbf6dWYxZ+ZX2LAAKYNXXw9jsoyVLM+REKi0j5evjZQeXwo7AfcUrROi2xkQtKYGVT6u7YUCrKHesMGAf+F1O9iyVglZV5Tuyh9mdVdmdze1gWQrHeUaq9JBDkFrzo8/+Ura/l+F0+hWpY8yDyZ3tPRlcy+JaGKmR4j5SIuOXE0NkpFxdh4oCaBo23n4Hav75z4yHMNOEWVvr+l2cMIPZHzDTgFJWykt70muITylQ7IyUGol4Oroa580DFAVWQ4N3X/b9RvUmqBUVPGsjSsq6nUUED5gTS5di7eWXy9fA308DG26dCLO2BrH990e/F55HbN990fPGG1B1yij0e/7v2Gfx59j9icdResgh3heiaVIjJY4HVjIJNeLNSCmKArW01KObkuU0v/cnngBLZmZRzfp6HtzGE1DEuBqfchQzdMA0YdXXc7G5aTjfX7EEV0Cl2ONYRDZW4iM2Z3Fvaa/0F79A73vvwV5vvonKkSM8FyaeocUAoBtOcJPmVwXT5H//kLf0mO5vJp3N7b+fEg47F6ymE/BlDL22s+FaVRXKDjuMf1bszzB/b8hHqlAokCoy4mAi3YnTSnvO0Eo7IxWJwEomoUQyS3u81MQApkBNptDjzjuhhMMoO/poDJg7Bz1vudk7ay/9pOUaEgo4V4BWQwNS69bDsn2bjO012P7CC3zdqgImxOYW95GCpsoDlQykNJ+MlMWcg1Mkys0GxRVPc6U9VXWeVw1BCUegVlUh0q8fkitX8i+6kYK8ztVERqobLPvgmgEDP4gFtT8AAEWBvmEDEsuXZ+4umfJkGjNdyb2vMfXTT9w/S1UcYa3Lp0b6/OgpCBdi6HpwgbNuQC2v4B8UWQ6wDVFdpT2tqkpaUXgfb2fBspX2ZEbKvoqurwcYQ+mhh0D3yUjB4FojmJZLbN4KpT3dgBqNeV2cLStTI1VaIv8/5/7EusVnXAi1VQVmTQ2SK77NeMz2F1/Ct0MOd26wPddE8Jn87jtsnTIl+5OaFn/vk479gfguy0xL2qw9q64eWvduOQKpaoR69uAZK7ukbNbXI9KvHyL9+4MZOsyGBq6vBFx6GhMsmUDXM89Et4suRMn++2csVwmFUHHccdyzyXO7vT5PRiqVUdrzI9eMOise5+Oz3K/Tsvhn0DRhNTY4JVDNp2Xf3q9ZUwO1vAwwTKfcJS9kVPl4XtrTM7r2QrvsinCfPt6uvWTSk5lTy8pQeeKJCPfswS+YXMcBOf5HjKixj59M1+VFJ38vbFF7IumI4JVMF3LeQcu7qKVdjDsjJY9FKWf0TVppT6BVVUFfv543KrizddS1lzcUSBUbcZUQCVjas0+k2br2FIB3UDEGbY++fJ+KgnDPnrz8pWa3P0gv7YmDshVPgCkaTOlgbsFqbED8yy9hbNwAxgCjptbVyRFKy6TZB/30L5xbIxWN8tS6cCHOVtqLORkpp1uKa6SiAwYgOvBXaPp8FQ8KDQNhxQKD4+GiRiJQy8pgbPfJStk6ssClPeE6bBq+bfvmtm3QunV13stmNFJb//o0al99lZcqy8pg1dZm+tTYs7yYYUIpKfXdT9blGgbUinK+H5GR0kI8mAo72UetqopnDNL2y1Ipu5yow6yvR82/XuV3uEp7QiMV6t4Nlaediu6XjEO47x7SMXrb8y/ghzPOQGLFCrCUbmuX+IlVdRlkFhNmGlyDZ3qv1IVGijFmZ9tiTsavmf2p6aU9W39opVJIrVqV+SA7GHa6Ug3Z9WQ1NWH1BRdi65Rncz9nSSmMLVvQOH+BFJuzhFPu5hrKKMytW7Fm7FiwVBKhbt1hNqYFUqJcv3kzwj178WDD/uzv9cbr2Gvm23bArPMMmLwAcGYo8nFQ4Zzvkx9K2DW1QV4kBguk/LRNAise5yU0920NDTLIMWvrXI0qqk9Gyha+NzXx0p5heAcIA46Hne3z5FfaKxtyGHZ76EFnqLjs2vNqxZz3Iz2QsuUA6YFUKiUvOgE7w66qsBJxqcuSt6dlpCBK5q6MlHR7d9sfhP1LewKtqgq1//kPqu+91yWK5xkpP00lkR0KpIqMzEg1V9oTWqOQ5ny50jVOYBD1Js2yYPqlXFVFOv1m2B8YPhkpQwdLJmApGsAAy2J2W7CO1WeehR/P+i0AoH7eAk/Jwbl6FRkpnxZa9xy5KBfSirJj1tKenTVwe7EoKjf9637pJVDKf47kWl72U/QUYpYBI+2Ar3XLIji3LO/A5eYQYnND9+1cMbZtRcgWy8qMD2MuIWqamLepiWdIVBWxgQMRX7Ys06dGHOhMg39mhBA1yHJ1HVo57/z0dO15xOY864RwOKO8x52P+QiJ5HffYeuz9onfPpkITyTubB7Dbvffj13Hj0do111l6bN+9rtILlsOfd06J7MjMlLRYF1zeWMYGbMWmWXaDtc8YJQDvsOZfmR++0vXSMlsQCKB1OrVGQ/RynkAm7Q7n6SRoqrBrK2FVVsLs7bWd/g1AF7KLS2FuX07av/zHyglJbxjNk1sHu7ZA33uvx+p1T/CSiQR6t4tQyPl1lCFevWE2dDAv4uaBjUa5ZlPEVjH455MqhKN2oF8ZkdeEBTX+CuZkUolHZf95h6bzX8pHufGly7MunpolZXcEb2uTpb23Bd68vGu/bpLewiH+TFKdOfa68ha2gO8s/R03faR8g86M8w5TVM2EnAvOcMxWVXVzMfGE15Bf5oFB7OE3YFdshY2JWkNR/L84hGbe489WpcuSH77Hf++iIyq3T294uDB2HRPFlsZIgMKpIqNuEqI+nftyayHnrIDkhA/2UV8Rp5IEbgC1WIwfQICXg6wrwDTT/72l1hua+strHgCzL4asgyLx0OGwR2C6+sAgLcMu4cWp9sf+Dibuw021WiUd82kcnXtxT3jMOTBSlUR2XNPVAwbBiAMK17Kv+iGgRgzYIa9B2mtW1cYPoEUgz0OImjXHmBnMHTfA7y5dRu07t34ekULtSvTk9EVZV9VK5qK2P77I7FsmRSfC0QALduV/WYMZluvYUgLDScjpXkyUlz4G7XtKLIEUqkU/xFX3eJkotodaKbpWXNo113kyB+jejPUqiqwlM73J7rpbNPU1gikmG5AKfGW9oSTOsJhsKYmT8bXHeDq1dVI/uDNMDHDtEcOOb5gUmyfTELfsCHjCl1cGMS/WMpvkO3jPBBWbR1jehlOPqdpIbJXf/T5n//Bzz/8AH3u/gug8MBNiUY8OsGSgwfx71IyAa37LtlLe5uqeUaqoYF/F9NF0wZ35XaPlFJiUV7ac3eL5YESCnkukphl8dJXkNJeSMvajGDF43IgsZVKYeWoU7D1/55yBVK1Uj7hmbwgcP2uVfBjmRRg2/o/93cmW2mPr9NtmMkzUp4qg3vb9IyUe+SLbXcignsl43lCsOJxT5CW4bVlMX6/0Ei59VfwygyUUJqha9r4G62qCslvv+XrNRzjUFEm3fbCC77HVSITCqSKjKxbS7+hkHOl57b2Fwd6+2pCiH6ZrjsCQKGREoGUn97ELu15ShNiLWkGerKMlOSlPQCwTMafR08hduABvPufmTDiSVuwah9k0u0PfIwupYs3XBqpLD5SjDGweFyW9jyBlOI+SIUBMwKoJVAMHSUsMyMV6trNX3BusfyczRnjzgeGDqb7ZaS2IdTdbt8WmgZdd07AaUGDFW/iV9Wqhtj++yHx9TLfERR8H7awPxrNI5DSocai3qxnekZKT0GJhLmQPT2QEqU9+3MnA3HbkFN08DDL8pQhQrvuyo0cGePlpD59nCxQLCYP8mqspLDxJs29btPkGin3590WV4vXKUoq4n3YOm0a1oy7BN8ffQzWXX112vtojxxy++3Ys++YrgOMoXH+fE92Sfyta1591WUNYIvNU1yfolVVZZ8lZ3JjyKpTT4EaifDyq6bZesmInEYAcL0l77BKItS9e9ZAyqqvR6hHD1tD1OiUrgBpGmklE57SntSa+VgbBEILeYYIwzQDa6SQIyNlJRIyI2XV1kL/6Scww0TFiSdAiUZh1dQ6xw7X5AWBPJZoGs+M2maVXGxuN1II1bm7tJd2oQPYF6BujVQ+pT1XgKqo9kiaSIR/LzKsJMK8tBfyZqQ8GXU5ZcDO+roCQr4+HfElS1A38x0o0YjHLJQfB12BVJcqri+1M1KwB2fDtKBWVuJnM2ci1K2b7+skvFAgVWzskQOe7i53y7ywFvBopHR+ZZhKoX72e9hwyy18G3vmF6BAZf4ZKd61xyfGZ2ikdG9pTxy4rLhd2gNgijZa3TWygFmwkob/2ADZtecz5d42AAXcGil/Z3MhQne3essTmcc9OQQoBtSS3aDouqe0F1++Fdtf/Y6X9vwsEKx8nc1hl/YMX5G0uXUrnxsGWwgqDDWzZKRYk91erCqI7bcfkt9/z1+3ZyiqyEjxE78ajQbXJ+h2FqukxPnb2VfX4qpXukyXxDIMQ92lPU8WjonhpgoPeNOMGLUuXcAMA+aWLbDq6hDu3Vvug8+s48GXGgseFOYDM3SnO1DcZq9ZLSnBlieeROO8+Tw4ioShr1uHzQ8/gqrTf40uZ56JUK+e3v2Ztnmn+Ju7SnsAEOrZE2uvvArxJUucB+k6qs44A5Hdd8e2qdNcpRFukKuEQtC6dMkaSMk5li4URQFLJHhZLMQbLgBAicV4RiqRgNatG1gq5c0CuUqcakU51LIyj0krAJ6pS8tIydKeaTijRvJEDPWVa7EsX/sD38fm0EixpibZtWc1NkKtqkSfe+5Gj2uv5Y0PTU1e+4OMjmX+u1pSIr2upF5JUT1/X0VzlfaY90IH8JYgZUYqV2nP/Zl3VwU0DRZTYYZL7BEx/qU9j0eV8J8Tr8s1rskZb+Nsb9U3YPW558HYvBm9J03ylratzNIewC+oxHdclvNTKSm7IJqn6IHUpEmTeE3e9TNw4EB5fyKRwPjx49G9e3eUl5dj9OjR2LTJ35m6MyKuEtyjRKRTrauDTGZ27JOxautJrMYGmPYQWv4gVyDlkwYXhpxqzGeIr2l4S3shXpvnGSn+p7cMOyNl8Fb53R5+CIoKmKmkIzYPaTJoYildZj0y7Q+cjJQajcBKJeXBMDNbE4cSjboyWM6Vk1ujwFgIitYIRLtBMXRELQNGiB+k40u3IP7VFmjduvmnoOXg2eAZKcYY16b5XCl7MlJw6aRcHjPpr5ElElBUjZck7C4q9wGUa0x4q/Y2vZZrdRIJ6OvWNatREKUKNRp1OpDSDDmtVApqJGr7emXTSKX450IEEkJwK66GTW9GSlFVhLp3R+Kbb6B17eqUB90ZKcuCEsvPYNSsqUF8yZJAXXaqq8uOP9gEVA1qSQka5s5F90vGofy4Y6FGYzC2bYdWWYmqU09FxfDjuQ7FjW7IrAV/+ZYjtgew2wOTUX7UUdDXr5cPsVIpqLEoSg4exO0GEgn+eVZV7uztE0g1zJ0r9VbcKiQtq2HPr1QiEZ5Ni9gZqWhUZpm0inLbxNfRSbm/W1p5OdTycpg1tV6rgZAo9SYcbZ9pG5vaZpXZylW5yDCPNM08NVL+DvlCggAAZmMj1/nZyBEvUVHacyYvyH3Yx0qlJOaUd23dnLT2kBopx5DTv7QX4t20jJe5rWQyR2kvklnaE+cCVcX63kPxTcWRSLc/4I8N84sod4Ctad4LVmF/YGuk0jNSVkMDlHAYu/3P/Sg56CDP9IT08TfCRkdmo6VxqMUDvQIC652VVslI7b///tiwYYP8+egjx6DsT3/6E15//XW88sormDt3LtavX48zzjijNZbRPthZEPcoEWemk+Pk61fag91aK7QBspSgKFChwPTTm6i294yPi7Nfac/dtQfwjBRfD9fJqBUVUMFgJXVHbK46V0VyTIqvIWd6RipHaS8edzQOANRwBJYop7lO2rA0QK2HEqmCahiIWTqMUATMYkh8tx1W0oRa3tO3tMcYdzbPy6mXWQCz/Lv2XBkpwC+QygwWRZkIcAlz07r2eCnRwMy1s1ADnsVKrPgWDXMzx7p4lmrwg7RSUuLRYbiHFrMU7wj1Le0J+4OUKO05gYQiBLmm6fEHE4R22QWJZcsR2nVXVxlRdzQ3ATJSzDRR89oM/HT5Fah59TVsuG0SVp9zLpoWfZbzdUOMiEn311EVKKUlMKqrUfbLX/KOzpIYzO3bnbErsZKMjJ8cJ+MWm9ulPYD/jUI9e8JwjSJyG+qyprit9yvl35VUCghp0Lp0QcMHH2KbbS1S869X0fjJJ/I1IO09dTve89KeHYzYpXSzpgZKNMa7E13lPffnTi0rg1pRnpGREgJnaSlgGM77aDr6oXyRmXfhiSY0UpEgpT1/80dpEikuwpqaPLYLQjuWy5ATMiNVKufccR1iWM6klH/fUMgJttKCDb5OOyMlMs/xeNb3yre05zLLNbUojBAvp6dnpBAOwYo3NZORMu3KhmlrFzXP39lqavKM5/F07aXZH6iuQMrRj/HyozD6JILRKoFUKBRCr1695M8uu+wCAKitrcWUKVPw4IMP4rjjjsOhhx6KqVOnYt68eViwYEFrLKXNkVcJYXdpz/6gh0OyzOQp7aVSMhXOmpqcK2Ym/qNCY4Dp10pul/ZUv9Keb9eerZGSYnNHI2XpKW4CqABGUpfeOEoo05CT+z6lj4hJ10hlL+1Z8TgU11WmWyMlMlLMZADToKAOiFYhkay2M1Jh6BsboagKYvt0A9TuWUt7ippnac8up6a/NiuRgNXYiFDXrs6aRblElvZ8Aik4QnCIQEpLy0jpPGg1VaBOTYAlEjC3bW22xCc609RYzOOJ4xkRY+tVlJJYZtdeylXaszNKfOF2aU/T7Ktwb0YKALRdd0Fi2TJvIGXwzKrMSLm69tbfeCMaFyz07KPxo4+w+eGH7ZEfyx1X8pS3W8vvdasx74gYZl/AqLaFRKgnL98pJaUwt2+TnXBqSQwskfY+mKatkXJfuTsZKSUcRqhXT+ibNjqPsbUuItMnOlAVTbU1Utw4t+7119H40cdy3U7WK3MAsPjcOxkpO/OiKFCjUZi1tVCiER5IZclIqWVl0MrKYdXVZmY+7e8+f4/tDGI04syha0Eg5WQzgmuksjmbC58ry9ZImY2N0EpdgZRo5JFicz9DTttguKTEee0ujRTvohN+UtzElpnc/iC9a8/TEAJuOBpUIyX9xex1MkWFoUY8I2I8j40n0jRSaU75FrPNOy35mfdkpHIEUki3PxClPdG1Z/8NxXGHMlLBaZVA6rvvvkOfPn2w11574fzzz8cae2bSZ599Bl3XMXz4cLntwIEDsccee2D+/MxxAIJkMom6ujrPT4dFfLjFAcZT2gs7ZSZZ2nPsD6AoMBsbnSsyGUgBqqLA8BHuukt7GWnyDB8pnkp3a6S42FwB7IyUEolAVeyMlNBxuJyD+VojTkdX+vPJjBQ3ics2a8+KJxxXc0COIAHgCOETBqBYgFUHNdYdltGEmGVAD4Vh1qWgdYsh2q8CTC+DsTVLIJVl1p5fWzpj/DFgVkapwNy2DVpVlefgIq7ys9kfMGF86M5Ipmkj3FktUwVqWBOsRALGlq2+Y10AIGEk8MYPb0AaDJbEPGNnhFDZyUiFoZaUZhoc6inub6Wn5MHUamqCsWWLU/4wTaRrpAA7I7V8GTRXIIWU0C7xg7xaEpMZKX3detnpJ9/TunrE9tsPZUcM5Z9dlw4lF1Icnu6voyjyMxXq0QMAF2rXbFwDNRZDfaoeyxpWZr4PtmjfM2svLZAK9+wFwx6twl+QPZmgVARStrmsqnGNkKu055glOq8RhpnxnsrPidRIuT5rJSUwa3mnmlpe5s1IGekZqQqYtXWe0pEs9Sac7yMzDbtbuPCMlNR/qi4D13w0Uj4ZKWnim3BppMoyAynZ8etjyMkMA0ppKdSYU9pznM3tbKuSWdpjWUp77kCKd7gFzEjprgBVU8EUFabCdVSZovYI/857MlJp75FlcRmE1Eip3oyULZlwr0dMYODaRyfbFura1R7WrXs9tnSdn7fSM2ZEVor+Tg0ZMgTTpk3DzJkz8eSTT2LVqlX41a9+hfr6emzcuBGRSARd7EhY0LNnT2zcuNF/hwDuueceVFVVyZ++ffsWe9nFQ2SkXGJzZ6ZTWmkvwoMsnubl7c5WQ6O8MucbWlCgQIUKw88PR9Ok2NzvqizT2Vznw4TdYnPADqTsQcoKYKV0R4DoGmTJA6kQLxU1pfnZeDRSUa6RSiXtzsLMjjZ3aY9npGyNlP0FtuIGoDEwswFqSTcouoGoyUt7iaYm1KEeWtcYmBFGYks16lJ1mPXjLDTpTbbnFuNXmj6lvW/23Q9Nny/23sgYD6IsA8xwHmM1NmLj3Xd7ynqAKwjyEZszxpxASBy8Qho21KzB/y55DPd9ch/eWf2O7KSEYUILRRAPMTyz6AkYW7eCxeNo/OQTbH/lFbnfvyz4C0557RRM+HACTNu9WI2VuIYWc8Gz0JyxVBKqsD9Iz8TYpT2kHLF57etvoHryZO5srihZM1KhXXaFvuYnfKtWe4JBNeYYcipRJ5ByW2HI99WelyZPdGJOWHNjZWTbvp0hsBgaIt2haFwjpVVVOZMFSkow56v/gMWi+Hj9x3j6u+c8mb6UmQIME59u/8IjNhc+WuLvHOrVE8bGjdI6wbI1JGpJCfc8aorz76Btf6Bomrzit1wWIPI12pouN7LUJLr2XJkFJyMVg1ZaBjNbaU9opGprvZlP8TcSwUkq5ZT2RCmnkIyUCDjdGSk9xXVdzT02i0ZKfG+sbIGUrR2TAYNvRopPClBKS1ylPeFsnq6Rskt7pn9pT4xvcb/PwUt7TuZR0ULcCFm1t/HJfCFdjmFfzMj92T5SjkZK8xzjeUYq7WLPMHDfJ/fh+23feoKj2IEHYo9nnna69sT7AEClbFReFD2QOumkk3DmmWfioIMOwogRI/DWW2+hpqYG//jHPwre54QJE1BbWyt/fvrJZzxFB4H5aKTgEZv7d+3BHuthNTbK0t6cNXOQMOKAokJVANMnkGowGmEkE3a3VLpGynuVKU7aViLpZH1cpT0nIwWYSZ2fQMUB0pUtUMJhhPv0hr5hA5758hkYlv28rpOD0EhZyST3p0ofQxKP84OcWFskgqZGe3aZKO3FDSiaBZhxwEgghiiilg5dC2Nl9XdY3rACWlUULKWgvnotjnn5GFwz5xp8tukzHPfKcbBMWxOQljmrTfLnafggTYPE+N+PWTrgOi6n1q5FfNFn6HHjDZ7NHeuCTPsDlkzKv7XIFjFNg5lMYvieJ2BD4wb8Z+V/gHBIBiGWpuKg3Q/FD5uWI7llE1gqhcXvvYwmV0ls0aZFuOLgKxAWB+NQ2C7tCR0G70BSwnwivWX/TZXSktylPfuqlCUTTmZRnBh9NFJVp56Cz0/bB6uO3FN2KjFbqwfTsmcHOoGUx+VefgZsF2+7xCO8tJpzQxcjYvgQWAvrvtmOrwZcyLv2SktkWQ8AEIugvJGBxSLY3LQZm616z/tw5ewr0ZSox99X/xNM563jcPtogX82wz17IrFiBX4YNcq2O7AvOjylvVIoqgZLTwHhkFM6EbMwdacMLMcvuXEFbkp6RioW43PjRGmvwVvaU22DULWsDJqtkfLYH9jvqwwi7ZOnGotKB/FCxOZi3zIjZeapkfLRIjLbxFYGfU1NfHySjRqJQonFnMDTz+LEMKCVltkXGbbGSYrN+UWCMyom5Lisp+mIxOsD4O16DVDa+59P/weJRINzIa3yjJQB+5ifnpGSF9+uIM2++K7516tIrV0HObQ4q0aq0SP0F+vZEt+ChB4HXPYHiqoitu++jkbKVSYkfVR+tHrurkuXLth7773x/fffo1evXkilUqhJawnetGkTevXqlXUf0WgUlZWVnp8OizgJuTNS4iQXDkuBtijLLKj+1C73cPdhq6lJHuzW1q+FbqWgQIGmaDB8xOYLN32CZFN9pkGhWIv7Cy9OWIm4o5GyM1LyRBiJQFEBSzfShhZ7uw1DvXtDX7ceu179IGrrecmGuTxYhEaKJVN8mKxvac85OCISxoLVoinBHr8RN6CEGBfJNm1FiVKKqF3aq2+oQ1xNQquKwmywUJ5wAhkGhm2JbfxgE/K2ZwP85AkAtV8u8dwuh+1qqqcaaDU2ItSzp20Q6iAtBsTzujIpnrKcuMLVVIRNYP8eB+K0n52GpJl09BemAUOxUFbeDeUsipRdBlu9erHM5Gy4bRL2+L4O+3TbBxGNj19RwsL+wNW1p7lm7SVTUGTXnr/9gWWXAMGYE+yotobEp2sPAKIDBmDu8B6o7VUuZ31J8boddMtsB8D9i9KE51Y8zk90IUeD4tt9mgbvDrRP1KaJmuomGFqEn8xLvIEUi0VRGWdg0Qiqm6pRbdZ45g7WpmphGjpqoxZKJ16PNZf9jgvC3RmLcBihXr34iZQxpL7/Xn4PnNKebS6r2Qa5obArkHLmoDHDQOMnn/ASW9p7KnVukQg3VXVnpESGLZYpNoeu8w4sW1elllfArKv1Le25Z18yw5B+bwAK0kgB4jOnyQ6z4Bop/nePG3HM+H6GvN2Kx6F16SI/i1ZjI1S3RioS8Waz08eoQGSkymyNlOY4m4vSnstHSnj9ydKej7M5AE8mM6v9gav7eNaPs9CYqHOV9jSekYIo8WdqpOTrcb8200T1Qw9h9ejR3GfKtorx00ixprjTpAAAdrdmykjCsgzfTkEwxj+jrqCMAqn8aPVAqqGhAStXrkTv3r1x6KGHIhwOY/bs2fL+FStWYM2aNRg6dGhrL6VNYBZzOn7sq0pvac8ZWoxwGI2W3dmlqE5bsy1gTpkpWMzWfij+XXuKyk/OaklpxpW8MHmU24YcnYTjI8WHIsMVSKkqYKZ0e+ixKzNh2ldB4TDCffqg6bPPsPc6hmRdDeydyZODKkbEJBJ8RENGac/btcdCGkIiDrRPclbcgBKGHZDVIYwoIqYOQ4ugqbGeB1IVEbCUCb2kFAOUXgirYTTptmiZiVKjNyPVoPOTkLF8hfP8jGHzAw/C2L4NSjTkyWKllxbk+ymuPmW2zpWRanLKszIjJV6joiKqRZE0kvJvAsNASrWgxmKotCIwtm0FAMTqnEyO/tMaVGxPIqyGEVJDjv1BLJY2tDhdIyW69pw1mQ2N9gnKHpQsMkd2sKUoqgyK+dVq5qGiJlmDlJmyLwB4hkQtKZUnEtVlLso7OFNgjGHr1Gm8uythC7SFBsW0HctdJ0V9/Xr89LvfY8tTT/HfN1VD37hBfnaYYaB2cxymGrF9pEoR6tlD+qOxaASVTYAVDWNT0ybUq0n+ObXX2G1tHZSGRpgqoJx0LHreeCOq7/8fXtpTnAyRVl4OrWtXRAb8DInvvpPt4WpJCe+QM02ux7ENchVNQ8kB+6Pq16elBVI6Ntx8CxJff52RAXKLzSO790Vo112c+0QgFY1CLS+DWe/oRJlhQOvSBWpZGReml5dxw0pPIBWSXcGAKO0Z0m7D7fSdN7aeRmSkgmukeICzunY1Hvn8EXm7FY9D69pVZg6txqYMjZTi0lfCz4rFNKGWl7vsD0zHikB4SHmczUOyJJ1R2lO4FYj7QiSIs7lu6bAM3VXa05yMVBaxOQBvQCvKkokEHz1UUwulpIT/HW0ZSc6uvQgPlHggZWa8NmEsLEq7lJEqjKIHUtdddx3mzp2L1atXY968efjNb34DTdNw7rnnoqqqCuPGjcM111yD999/H5999hkuvvhiDB06FIcffnjzO+8MWKZ37lk44viC+PhIpUQNyc4iiCtNK5FAykyB2bP2VEXzLe2VRSqgMgAxvxExaV17wv7ApZGyPBopftLVVMDQLXiGFrvEljyQ2g2JpUvBH2qfKNwZqWgUVjIFKyVKez4aKVdpj4U0REzF3o/YxoASAu8yTDUijAgipg49FEYiHkeTmoCiKdAqItC774Lf7XEuBu06CI16o1wPtMyhxbIUua0GVjKJ+Jdf4dshh0NfvxGhrl0Q7tMLzHQOOLkCKRH0ir+p8/pcGSnxN9A0hA0AqsIDKTsjVT35AdTPmQNdsaCVlKLMCoNt5XYOJfUpmTFgKR1qykBIDSGkhLj/UThsi835+97tggtRdsRQV0bKZcjpOhGsu+ZPsOrqEOm7u3yNAJxBsS7DQuHUnc725HboFv8cm/UN/ITqOpEosRgs8d4keEaKJZOovu8+WHZ3qhKLySYI6AZ3Q3dl9pIrf0DTZ59h+8tcGlD9wGSEe/ZC6WGHyZNM7eY4LJVnpEp/+QuUH3MMZj3zNX78ciusWBiVTZClPVNTPJ1Jv/7XBhilUWwv5ye+6N4/51487tKefbL52TszUXXqad6MVEkJzO3bZTZI2B8ooRDCu+2G7pdd5gw2tstL3C+uMbM8JDPXEfR96klE99pL3iUCRzUaRahbN5jba+R9TNcR3n13xPbbl29TVgazvj7TkDM9IyVLe8nChOY2srwkMlK2Lq/Zx9nBnW7paEg5GTYeSKVlpDyBVMSzf/fkBQEzeLmT2x8IQ073iBhn1p509M5S2uPPEfJ0e2abS+gbSHm69jQYTIOZSnrGtYjHiueSt9mfce6mzkfIaGVlXJcnzJ/TxebuQMrel5lKwBKBl/s5FUUGUwplpAqm6IHU2rVrce6552KfffbBWWedhe7du2PBggXYddddAQAPPfQQTjnlFIwePRpHH300evXqhVdffbXYy2g3mOl8ERX7xJKttIeQhqRqz+ZzaaQAwGqKI2XoPKuiKNCydO2FbXPKOiWRaUfg27Vnuxu7NVJwde2FI4hGgGRSaKw0qCUxXg7RdYghmeE+vWXmyEjaB5gMjRQv7anlZRmBlNTH2FhhDVHD/jjagY+VMKBEeBs00xsRVnhGStfC0ONJxBV+UtCqotCrdkGkPs4zUoadkbIsfjWYdrWqWzos+xhmNTRA/2kNYvvth9733gOte3dEB/SHu6mvuYyUX9eeO5ASB0wWUhEyecZSBlKhEIxNm2Cs3wBTYdBiJSjXQ0BdA/TKUpTW656MhqqbCKthhLWwKyNVIg+AZYcPQbh3b37iTOnSWkNN808ya2rR5/77ENlzTyAchtnATWDloFhXhsKKx51Wcxc1iRoYliEvANRIhAeuIiMVyxSbi/eFJRKu0h4PCkVpzyPa13XEBg6EVV8Pfd06WPUNqDr9dGgVFfwko+uorW6CqUXAFAUVxx2HyhNOQENNEk31KVjRMMImYEZCqG6qhqqoYLGIzC6EUxZ+uOIk1JYrPLsmTtBppT0A0CorEf35ADnolQeoJbYeTHSQ2eVQYX/izsrZfmFM13mwll7as59PjWSWjRRXaU/r6h3SzVI6wrvvhn5Tp/LHl5RyC4F0B/2ULoMTaX8QifLgqiWBVCgkNUfMNLkhaRCNlK1L0i0dCTMB3XR8mrQuXaTAm3//vFYp6Rmp9C5bGCa6nn0Wul1wPsQcPelsrqqymYK/NyEsWVcPI6VnjHByv0ZPaTyA2NywDFiurj2hkWJQYSX0zGYDtyeXfI94qRh21hGM8XJ8IuGrkRIXTnKftszETCWzvjbVlQmjjFRhFP7tycL06dNz3h+LxfD444/j8ccfL/ZTtyvGli08xZ+RkXJ8pJRQCNtffAmpH3+ElUxAD2uwxOdaUaVGCgBYIs4zUswEoEDVQtB9MlKmXbbawurRzTBQP2cONt1zD1g8ASuRQPlRR8ltHcEpYKn8QMS79hSI8pcaCSMaAVJNqnS75Z1JziBYAPxkbZNKicDFESWrMpBK8jbwujokf/gBay4eyzuukilUjhwp92GFNER1Ed0IQb4FJcTHZjCrEeGyLohYBuKhGMykgcYwf16tKgKrojtCtY2IVEQyS3tp9ge6noTKuH6GJRIw6+qkH5KiAEpY4+VOsba0A7l8P8NhWCmXRsodSDXF+ZWe7hwwmaZBs/jfOhrigZRbs2BogFZaiu51FlgkDL0ihvKaWljdnK4vLWUiBA2nvFsPpFJAKMQ73/w8aWy3ejUSsbU8TmmPiXZ9+29l1YtMqPC+cmWk0sqwABA3/j97/xku2XWW+cO/tXOlc+rk0zmoW2qFVrYkB8k5YQ+2McaEvw0MxuCBAWbghRleZoDBDDBjsoch2H4NOIxxwAnbSLItS5ZkBUvqbkktdU6n++SqU3HHtd4Pa+9dVSe0JI+//fu5Li6s06fq7Nq19173uu/7uZ8ufuL3pL1mU7NLZi9JOQuZzVriZRDkkqf0A1Qq7WWBh9kQ5gGJNIoQnkfhhhvoPPYYKvDzIEYsCxnFrCzqhoxEGWRnIejERH6ClYIS6drMd+bZNbQL6V7I2QU7lLRN/b1FMsIoaNN2v7SXyx+Au3s3wcmTeNdcnTNS0GvFzxaqXM5J/WPZZ8lyx3So4/rSXv/fy8pIPWGG6+oh3X25af33pT4WL5V9+s3m6fXQ7ZIN5iaO8w3P/xUjlXmkpNQNAKsW84u9TqWMFEAzajJqjiK7PubQMBiGzm9bFcipk/r7PVLrj4ixt23H2bmT4OhR/SzLzOYZ25h/Vya/8E+H+N+dgKocjAjoP9b+rtfnE38QJREq6Ul7mCYqfeBHwdoGjvWkPWFaek0QArNSIVlcxCgW9cY280hlUQ5ph9/qc589p+RGn209b9YlIPWC6vsOpP7fWvVPf5rw1GlG3vWuHNWPv+/nsTdvGtDIw3PniM5fQHV9AkuRK0iG0B6p1GSspT09lkAIgWEY60p7CRok+EXdOTXzS7/M5j/+AN7evSgp14w00d06EiX0giGTtLMsAxu2jesJgtjomc2LRWR7EEgZhQJidAS1XCMK051anylZuK4GGWnXXry0RHjqNNb0FJt++7fpHjyUSxEAiWXgpYxULsXFGgjJwEepNpYxjZNErJhgxyZtQz/YzCEXilXsxlpGar1kc5l12ZU0S5OsNDArlRRLCoRjgeoLuduIkfI8ze6tk2wuux09tHZxsec1MoUeCm32GKnoQt/YEQNMr8BwPSIeLhK7FuVO0pP24hgzSuDwUV53z0r+nYo+Rqr/u1ZZ156ru5z6u9Vkp4tIzf6i4OWem1z+65O2ss/aX3W/DmjwIRyHpN3SQ1LTQEr62vdlp6MX2DDsMVJhgOz6iOcwm2fXnHfN1XQPHkL6QT4aRNg27VoXM51vl0S97znoRERBjOvp67VjxsQyZs/IHhJnPmfn7EjSMZP8s+Sm7uzz2/bAqBVjOB30mnqksvMywEjRYxeyDYX+A3HeIam7tlY9ftNu3/6/1zv/6ftn0l5fkr8+b33SVwbq1ok/kEGgwepqae977NgDwLYQ6IVcJcnz90ilklzGRLXCFqPeaG7cz/xba+MPnB6YhvVHxGSgKf13lSS9TCcB/TlSmBaJYWDIjaU9bHuga++5pD2llGa+06YiSGU6pV8Xx6xhh3Ig1Q9oDEMPoPa8PJ3fSKU9+qU608RIZxCuB6Q0I2Wu/9kcO1casiaMS2GcL6wuJW59nyo8dSrNY+kxUqPvfncaCNeT9mQY6F2W7xPYkKT3TBaimHmkVLebe6S0tGeuazaXKQBq7p3Wd6dhMPTa1+Ls3Im7e3c+TwnIu/YGPFJxj5HSGVIC1zMIE6Mn7RWLegFctfMt/e2fcn4E4iwtuY+RyocWhyFmRXukkloNe3oT3lVXMfKj76Rw7bX5eyWWgROvYqRizUjJIEBFHSzTw44jfDuhqAq0RcqeeCaJ42KtdAbM5hslm+dAynM0kGqsYAwPaalSgOFY9N8aGwGpLJtpva491e32zn0W55AtbH3SXnjqdO81ph66W675hGWX2DE1c9bHaJhRQnxvL7w2M5uvOwC132yeguH8M6VJ3ACG6xGt1AF4+vzj+TGKvsVmdRdWLdALec5ItdoYjqsXrSzOwzQ1q9BMZcMgzOWRXNorZB6pdHBzYa20J2wbc2QE2Whog3rGzngeYaOL45mYSZjPvFZKEXRiQj8htvV1XhNdxgpjjBfGiWwjB5VuqGiZPU+Lb8r882eRJAPfeUHPD1R+kN8volDopfRnLJBlca55Tt8HkZaMMrCYM3arGYl0M7VeZZ/5fLTIBadLsrQ0eI76usiyFPf+hO5ehpxPXHT4yGN/kwebXmzkyfMpYdl9HimpfZHPwyOFZdFoL/cYqVBfJ5l/0nA1yFvTtee6vTl7ZIyUBsPx4qL+Yd9Uh7wjL9Zmc3fnTqZ+49f7pFuLPdPDmDJBJheT9ro9tvA5pL1EJShUb5g15MnmAInpsib+IGVPf/eR9w+cI9lu6yDWLJ2/WOwNru4bP5MBaLFKGu4BKe23Xe+Yc/kxZbZWv8elunhdAlLfpwpSIKXWMfTlOwzb0gyG30X5XQJbkayS9rKHbNhuIaXMpT1hWuvGH4zO6wWhPZaOxlgVGtlf+c7fD1DpgzdJtEdKpMNSAbyiSZjYA9Ke7KaAoS/jRG6fJjYh7mekzB4jlQ1aNcoVVBiS1Ot5S/jqSmyxxiOlEoWwNL2vwjaWWcBOIkJTUFIF2kIDA2GbSNvBbLSwzbWM1GppT4YRsSmQrt5lykZTSwl6PjTCGZT2knYbM83pGTifaTZTniO1Stozs5iO9IEpswdnX9dezlagaXzD9SjUuvhlh8hJAVhfMrYZSYJ7H6Bd6snFZnV4YKir/nm/2dzFXDVWJG/XB4TnUl9MmbGsFT6TAAxDL1yrWJIBRirdAOgh1Noj1e+1SDIgFYa5vCj9QEuG2QiPaH2zuYqy7rhiOgQ6yNkZw/OI2l1MS2DIkDhKPXuhRCaKKEiIXX2e2mZExakw6o0S2iKPQHAiaIo0fT2JONQ6kn9+YYg1wYTCdcEwdE5THzubS3vpeWvJDu+96735PZV5kvq7PFeziBjmhkBKeAWEbfMnj/0pP/WdX7q4tJc1cazXaBIEREWHVqeuN0quoxfk7xFIHVg4wOn2WVaiZu6Ret7xB6bJt898i2Vff5ZmlF4nWRPCACM16JEaZKR0V3G8sMCJN/8b/R59I2+yeITcbO44DL3hDb1r1DQZKnuYSlJvBxtKe8r3e4zlc0h7GTjsZx4zjxRoILXGI5ce79HG8d779TFSGZgWhQIIoX/ez0hlx7aakbIsHXEie5MnVh/zoC9r4+vwUq1fl4DU96GUUoQnM0ZKrrlY+0fEyG5XgyQ/wDdlD0ilOVJZ+a16+t56F2Ea5rrJ5lvPaRDjox/OZp+Ut7qyBUv6XXD0TScTnZsiVG9IpVu0CJWdS3tGsagfaMHgRPAoiUhMiPOuvR6IzH4vWVrCrFb1Lu1iQMoycJJM2kvPayzBNjTwC9uYVjEFUgZF6dEU7fRvGUjbwVhpYRs23bg39FmsSjZXSqHiEJkCKZl6pMyhoRRICYRrA70Hi2xtxEjpbKaeR2qway9jpLJzkjFSIu3aC2XIzn/+HJfddaf+99TYb0hFp2jmQCrv+gojnBiS2VlO7R3Kv9OhN76R6f/6Xwa/6wFGytadXO2U7ZRSg5gUfCnXQaZm8zFRAWCmfYEn5p9AGMYafxRoRsoQBqHU7y/bbb14pgbw/jDLnJEKg5wJUikzK7ws/iBiXbN5ZqgvaPavn5ESxSJJN8A0BWYSkkSSp+8/zxN3nwEg8vuBVIxruox4I/iWTp1PwgBT6fmGoEFhZOjNjR7abGjZo/+8pmNoksbKukAqW5ASQ4/yyZpIVKAl4H6f2prFeNUzYOCfPC3Pbi1vpVXQYCOXSVcBqdyYvkGOVFJ082TzTEr9Xhmpkysn6RLiqzBnpNbz1K1XiQlGovIu26xzT3Y6GMWSZny7az1S5lAFoy9LMOtsSxoNkpUVfY8nSe8zWfZAsnmvMmnPJJACS0manWDDrj3Z7QNSF2GkiKKecb4/FNkycyUgXo+RSr/D+XCZI7UjnG2cBcvUQNJ1e/Jumpcm2x2wLOp+Xf8sk5nXkfZUFCLTwd7rHbNYJSeufo9LdfG65JH6PlRSqyEbjR6QWpNY20u2JY45v3SSST+ha6m8e0wYRm9IqW3jtxsIBEolOpDTtHS206o6P2XT3jRMkAKpizJSTh8jNaQXo56vpI+RKtmE2L0RMZ6nd0DNxsADO1YxsQFxmHXt9TFSQiBcl6Rex962NWWkajiXXbbuscWm6LEeWctcojQtHwSgWhhWETsOCS1BQXp0RBepJMIxUKaNUW9iGVb+YEalcQx90l6sYsxE+5WkY6Vm8xXM4SHtDxBoICX6gNRG0l6WzRTHAyNuoOeR0r9o8tR9M0SGjQO5tAegpsdxLQ8xUgVT5g/DVsmg0Ek7PPu69pxYg7TFzdPwRNp2L9YuwD2PlJZZlGnm0l4GZrK/ldgmRT9tNgj0Z7jQucDi/GO8pO8B3V/1oM6YN0aURIiCzqox0tEmGzFSMghyaU/2SXsqSfKuPS3t9V3nUZTOCiygOhkj1fMlxZ0Aw7IxZUgUJpw8sEi7nuZuBQmRkwIpQwOpolUktLW0GLabxAY0lT4fkYyQShLYguIG0h5oJlLWV/L7xSgWeiyQkTEOglBqACxSiUpFEarTH4uxuhXd2JiRcj2Ep8F3YgqiskuyvIyxZUsazNpvNs9kxsEcKdlpg5TERQcVNdJhzSko/R49UkEcIAxIhNL3WpKQdNa/X1ZXhMKQvVy3XNrrdHRKvOehgrUeqerb3z4AtrPQStnpgFK6OaUPHGovVp/ZPD9RRn7/+CkD3e0E60t7tjab5/6zi3ikAKL0mdgv7QnDzIOQNSO1PpBKDPhP9/0nbp66mXeZ1hpGinRzkzFSf/DwH/AuEpwM5NlrgZSMQs1IrfvZnDXZVavf41JdvC4xUt+HCk+dArJsFrmWsk29IjnICEJU16drJsRmjqR6O9zhYYJOA5RAokAIjA0Yqd9/3yj3/twthGgWYPU8uP4aGBNhp0AqnSnXL+0Vyg4hbg6MMh9Iv5wBPUYqM8H3M1IyiCm/8S8xN12NNTb2nIxUbPWmsat+j5Rt6s63qKMZqTgkNMFLHDpGQCxjDNtEmTYiZaTyrj0pNa3ex0hFSYQptcyWOJZe0FcaAztcw7V5Ph4pnc3U1SNLCoVBk7Qf5O9519mv88AXjtI20+/GMDANE8uwdOcewMQoWD16vukpAieNTQgCPbsvCimGAqKY+uYyyjTWNSZDPyOlzeBGqTfoVna7A2no0rHIrUGh/gwxUs+hM81einhftcIWVa+aS3vQk71U1OfdcOy8I1CFUV/8Qb+01282L6xrNhepvCz75BXD84gzRkpGxGHC4tkmS+f13wv9mMjWn7FphDimg2d6BLZA+gFBawXfgW6kjylMQv1/lsqlvfWAVBY6mn9ur9Dzp2RAykjn+KXnJZP2BmIx1jObb+SRKngYjvbVVZwKQcUjTiMQ9LFYA7+r33+QkZLNFpgmsdsbS5R5mQYAxgsoP/HBNEmEyoMxVwdoblSRIbEk+cZnNZAyXHddRqq/WxLI88SyjYLsdAZYNmHqZ8jAAGE0M5wByAxI+d31pT0sG9V9bmkve//IT5nHOO7LkTMGgNSa+IM+IHW0dpSaX9Obhdqy9kF6PbCeASlMk1bUQhqix0Suw0gRpkno67FtzlpG6pK098LqEpD6PlR0/kKPkZDJ2p1mGviWPWSNQHsV2macxx8IswekzKEhwnZTW8BTac8wLZJ1ZpD5KqTsVnQmkWlijV0cSBHFesdm2ZiGIk4ZKeHYucHQqzhEhqcZqfQGMwoFkpXGwE4lktprlGQhjlLlD43GXVpesae25ecmrtWwRkbWPbbYpLdbGjCb658FqoMwHSJ5Dt+McKVD1/DTHCMDIWxEvTHgkUKptBOlD0jJCFeZKNMgccw8/sAc1h4pIQTCs0H0ecFWmV2z0r4dLe2JYnHQ2xMGua9jMVgkDiSxmTKO6XXgmV4OpIyf/QnObi/kD8O6JwmyQ1AqBZMRwx39YGxMlVEb7IqBvqHFqdk89Uhlw5T7F6LE7VuEU0ZKKqWN5ELkJtf+CmVIxa7kXXugGa5MPu5l9Ni5bKiCIJe2cmmvUMjN5mSMVLQWSPU8Un5vwSgWiP0wB1KtWkCrFiBjzSxqRkqf64YR4Jmejp2wFMrvEnVbhBb59RLLmCAJCGxQQgxsbga/90L+2bL/7rFAaROHKXJ5R7iO7viKojzeBHpMdf7fFzGba0bKI4gDRr1RumU7z5JaG3+QLbh9729ZOuvL80gsAWEv/gBY20H4PCtIAp1TJFSaIRajUiD0XBUZmpHKNj6ZRyoDTkaxSLK8BFLSNNYZ2J7WACMFuZTcS/vvD+Ts+z5FD0iF6TMn9C8i7fndvHNuQ2lP6O8wyrL14iT/m9nQYsNIGak1ykUPSAEaSFUqxAsLgx4pw9CsaKuFMAz82EcZYkOPFHY6dHmd1Ha45JH6ftQlIPV9KNlqYo6ObshICSsFUekNanf1otg2oj6PVB+QqlQIOy0KViEN5ATTsknCtQ+TKNEm2jAJwbYxRy/ikUopXtluoxwX01C5tGcWCz1pb9jTQCrudSAaxaKW9voeILHU0l4ey9BntE/qaVjmyKgGUs9hNo9Mel1GfWbz+Vh34fiWREYdPDwiO8JUBpGVpIyIgRAWrDSxMQe69lgl7UUywlP2ACOVNLL4g7Rrz0sTqtNOoI2lPU8v7pm3p0/ay+cWOg6RUsgIQqMv7BFwTCcHUvKlNxIMefnCVvNiAhu6jv59mTIaQ139XbSmh1j8xbdv9FX3GKkg0GNFisXcvyI7q4CU3bcbTeXjGH1uN2KkwiSkaBeJkoivnb1bfyzXSRmpqHfdOA5Jo2c2z8d+5IGcXm7kBe07W69rzyh4aU6b7DFShSJJVwMpQ0VcOL7C8IT+XKVhlyhICG29cDRSRso1XXxbIbs+YbtFYPcYkUhqk3BgoZlgw1hX4shAwvoeqYyREsQqRiqJ4bg5EzU4g3Eds/lGHqmCh+FqRmrUG6VdMonTCIQ1Hqm8g3AwkDNpNBCFArEpNOBJkl6UxPfokfJjH8OytbRnmMh2S5+3wlrwvboiEsw+Rir3SKWji4xymWhuHt+GRtza+I0yRioFUpmU3JP2NCudzTfNSxh5F14kdc5b7G8g7VlWykil3/PFNjG2nTfgDHbtaUbK8YyLMlKjpUmuHrua5WAZc0gDqX6PlGakCnk6vp/4SIMeyFsNgiwLK1HaJrKB2XyQqbvESL3QugSkvg8lWy09G2oDRgrToj8p2W2FYBi0CQa79jLPxfAQcbtFySqnzmuBYa4dWqyUIpQhZbus2QPTxBxdn/EB9K50pZH+bwfLkDmQMkpFjHTRcCseCkGkrF4eTs5I9Ul7MpX2+kbEZAuoSvOpzOHRXktwrY65ASMVWVrC1O/Ty5F6bOkJAM0SBE0K5jBYgsiIMU0zBVImtrLBsSm2k1WM1Fppz8NCWSaxbegh0c0mxlAWVSAwPAdh9DooL+aRUmn8gVEYBAAyDcIUjkOYygaxcPK/ASkjFQfpR9WjX7IFecmJ8C1F16EX6hjFlDsKUSxi2S61V1637rmEFEh19RxHPYjaSCMQ2jqMs288T+L0Aam0ay8RssdIuWs9UkES6OtOhtw794B+reP2AjnzpgNtZNfJ2j2PlPL9ga49mQMpdw2Q0qGj6SgWswc2DM8j9iMMU2DKkPlTDTbtreJ4JuURl8hPCNLLtS46eJaHZ3r4pkL6XeIUSGXXSyT1fMvQBinURaS9rM08ZeLW80iJlOFI09LziQXdjRkpnouRcl3CJGTUG6VVNEiy4e/pqKD8d21bg5n+QE7bJl5awqwOE5sgoiidD5iyHN8jkAqSAMO2kSkjlTQa2t+0geTcX5GhMKU2mxvCGJT2ShpIBfMX8J3ed7ReZUPVs3mPSaOh2aa+rjwAFfiDEmY/IxXLNAE8Qq6X45Veo7mJ/iLnS9g2URZsG/dM78LQ8QeuZ6ZAav0RMa+77A380R1/pBmpcoVkYXENI6WlPZ2OH8QBqu8+XX0NZTM+1UbRDrY9+P1fYqRecF0CUt+HSpotrBRIXYyRyn5uxXpX3Y47mNmOt++hbQ4NE3fblKySzpFCYJr2Go9UtuMtO+U+ae85GKl2W8s8wtTSXixBScxCj5EyXA877hIqe5W0t7IGSMUmyD5GKk/DThRKRhhD1XQRfW5GKr8cUxylEoVvaDAT2CDrpymVdiIMRWQlWMLS0p5jYEsLUR2m0Iryrj1UalZfLe1hoUyD2DFIFpf0Dq9UzP+ucC0w7d54kw09UgVkRzNSoriKSeljpGKV+ibEoLHXMR0CGeTHZRlW7lmZd7r4lsJ3ANfRTIZSlLsKo1jEMqzezMB1Stg2Sbud/29Ad+61WqlHqie9ZD4iAPyQrmeQKKnN0oaR73T7K0xCyk6ZSEa0CdLzlsoV4VqzuTE0pGcvpkAiY6mE54GluydJd8KDyebpPMFiUS/8fW31RrFAEkY6wkjF1Oc7VEY9yqMe5RGPMIgJ0turTlczUpZL15Kork/caWsglTKYURIRypAwY6TE+nk6orhK2uvzSGXXf5w+AiIZaSCV5cN1+j1Sq6W9jfN7vKuvZvhtb80ZqaanSNLsrwxs5u+TdhYOBHJaei6kVR0hNgVWkOTfGbChefq5SgMph4SUkWo0n5c/CiBEN360ozZVt7rWI1UqEc7O0nXo3dPrVRpvkEt7jUHmPDs3susPzrHr80iFiR4n5aiERrD2vlptNt/QI0XGSPWNzcqTzQ2UMHELFrHlrV0nsqkRtu4urft1/azudNZ4pEShoO9v0yRIAs1IZUBr1TWkLANLpjaRdfCtsJ1Bj5RpXsqReoF1CUh9H+q5GSmzZzhPS3genaiD66QygTHokfKeOMLlz7QwUmbHMO01XXuZByNjpLCt5zSbAxiVMgoDSySE84sIpRfnfIft2JhJl0SZPdNwcbDlG3rSnszN5rJ3QyYSZIRZHh4Yk2FUKuseW2QCQqCQA2bzbprx49uQLJ+gWN6NaRqElmZwMmnPkTbGSJVCM8Sr6e4dpDbArpb2HGWCZRLbJvHCPObQkN5BZ117poEwewnFq82uWfXna2UG5KxU0Aek0iiFHiOVeqSstYxU9qBesH26ttRAyukFtYKWlmzDzrNq1v2ubRu5soI5PJyzA9on1ckXqvycpPIXto1Qik5BDJjN12OkwqTHhHbITNXOQCAnkMYftDArlQFpL6nX9fkxTc0SZLKLZa1jNnd6LFCfZCQKBZIgToFUhIwV5RGXyphHeVRLe4EJsQHLooNrunimR8fS+WZRp0Vgi/w8ZoxUYIvUPL2RR2pQ2hv9qZ9i+E1v0j/L4w96jJThOH2M1DrDrPM33pgJcLZuYeRHfoQgCRjxRljxZM5IrZb2snOzOv4AwBypEpvgZN7IzGxufW8LZ5AEmLZDnDFSzcbzB1KGxJSabRr1RvPuvRxIlUtE8/OakYqeDyOVgvSVxhpgiWmiglUzBYWR5+JFic6cKwhJI1g1tw8IhSRoNXrm/Ocp7ZHIXteeaaGEgVexic3CmnVC2BbSFNiWQ8WugICgmLJZA117uilFtnTXXjfukhj0ZMdV15DMGCm5wUBm2x4E0uYlae+F1iUg9X2oAY+UlAOJwqBvIJ0Y2zdqwvPoxB1ct9eqnD3sht78JpZu3MXobAcn1pKXadsoJZF9g4nDJMQ27DyTaOrXfg13794NjzN/mJbKKGEg2g2a3z0ASIxSqY+RcrFin7hf2iuWkI3mwI4uZ6SynKMk5p6Ze9P/rRCmwhybwCgUKN56K+7ll29I+YeGZgCUUANm825qMo1NDaTskd0YlknoxNiGnZrNzRRIjeC2Qj7woYRXHlQ5I9X5zneo/Z9P5efMUxbKNAkdQTQ7l8cUqCyQ0zbAsHSAZKul5b7iWs+HUSjoZPM4SvOPVnukXM3IpIxUInrsIwx6pHJGqlAAw6DhKWp06TqgHHsgTNMoFJ4XIwVg9c1EzDr3VnukMiCV/aztGdojlUSp+X6tRypIAkp2aYCRMtYL5LRtvbgOD6Vmcx+jUiGp1XrgqM/LooNE1+nac139PfQzUl6BOIx1Q6zSrylXXS67YYLtV40iY0UgY/7De01qpo9rurimy4orSVZWiLvtXPoDbaDPpL0EyUa5TqulPe+Ky7E3b05PfMpIpY+AjJHK2MF+mXlN5IAhnjO/J5P26m5MUl8ZOEdrjnFA2tPn2KxWiUyFGzHwzPm/iT/QQEoz8bLZet5AKiDGlNobNeKNrAFSZrlMsrBA9zmkPT20OMnnOCarvJzZ55N+sI7ZPAVSsURYFraMiVZNQgA4151lsT6jgdcqT9HqEradT3sQiezrHtQeKa/iEluFdRkpaRo4hk7MH3FH6GSPjDRHDFImreDlHqkgCZCix0itvoYyaY+NBjLb9gDDJi7i1btU69clIPV9qKTVxhod0VJQn08oK2GZadde34OtUKAbd/Fc/dDpN/i5e/dy9O030Z0Y0kysAmHoC7tf3guSANd08wV5+C1vueiDuMdIVZAYmEmAjBIdfdBnNheOg5kERDGD0t7q+AOpzfIyC6RMEr5y+mvpSVHYWyaxJqcRpsmOv/8ou//5cxseW2DJFEjJHoOUKDrpIp2YIFfOIopjjIgSoZPkYELYBo6yMatVvJUuFR9+8usSkWizfLKyQvuh7+THnDFSkS2Izp8fYPGEELpTMPVIRefOYW/evP5OztPZRkSRBlrROtKebaN0ehQR6aK1TtdeLGMsoYHU7i99EbdY4fHJNnfdYGzISD0fIGVPTfVeVy4jO209gqMPSIXWIJB6ZqfJmS12bjZfl5FKvXlREtEkXTScvkDOPP4gY6SG8ll75siIZqRWASlSr8Z6ZvN8FEvfcWtpL9YeqTRHrTTicuVLNrP9qjEMSxAFCXMjqTfRdPEsj2VPjytKOh3CvvUwSnpm8wSlc52eh9l84LynLEO8gUdq8I1WS3vPvYD5ic+oN8qyE/UYqTheC6Q8b038AYBZHSE20UDKNAcN2d9D+YmPbbsaeGaM1PPo2AMIRZIzUsPOMJ2oo5+hUZRLeyws4zviotKesExQiiSL91i14QN0554/KO3RJ+1Fie7wtWTCendVZEhEEKVg37q4tOfYuW90QNpLPVKFIQ2k1gQ32zbKEDhpd++IN0LTTSVYr9DzZ/WZzYWRASm1MSNlipyRen7J5pcCOV9oXQJS34eSzWYu7W04IsY0Bi5iw3XpRB0KbjZtvm936DjaaGg5iMy3Y1lYtkPc17kXyl4nUpZZc7HKgVS5hMLAiH2SBAQqN0Znv2cmIXEi8ofAeh6pWMaDHikpCWTGTkntNYrX0uTrVWhoICUNNSDtdYTfO4cqIYobbA2HiPuBlGPgShurWsW7UOP+PZsxYgMz6vnVlJ8a4j/2OXaeDVMgZRDPz/ciI9K/Kyyhd9d+QHjmLM72beses1HUQ49VFCMK63mkbJRtIkgzu8i2l2u79mKpGTYA97LLKDtlLgwlPHy1g7KtQUYq9Ug9l7QHYG2a7r0uZaRUt5v7fICclcke1A/tM3jkajf1SIkNPVIlu0QoQ1oqBVKe23sgZ3PMHIek2cAcqugJ9N0OZrWqGalVKdHCsnpRCNl5XDUou5+REoUCSSQx+xmpkd6x2q5J7Peuv4yRqnuSuF4n6Xa0dJpWv9lcM1IbSHtFPaJjjTQHOTiKjH4g5QwCqb4ZcIOvXR+49VeYhIx4Iyw6waC0t0qaE8XCAPvQA1JVQkP1gFT2Gf4vzOaW4/UYqRfgkQpUlHftDbvDtKM2Sbudb0CMUhniWDNSF5P2sjy0NK8saTbWeL40IzVoNu8mAYFIdNNO0s9IrWXNIyExQn2eNZi6CINn2/m0B2NA2tPJ5l7ZIbGLa+MPbFtLe+lzYMQbYcXW9/ggI2XojuGW7pDsxl2SPkZqNZBKLANHGroDfL34A2d1194ls/kLrUtA6vtQ2iM12pdsvvomtvTF2d+OXCjQiTsUUkaqP7NG2DZHakfwvDIic0CbBqZjDwwujpII27BxTOf5AansYVquIBEYkU9iWFoCs50Bg6GlQmKzN3DZKBboLM9zpnt+4O/Hph6NopRCKP1wBC3tGZ6px7w8jwoMqT1Shuozm0ta/UAKaKsmW6MqsSt7YMI0MDAwhkdwzy/TKHo0C72xDKA7dgDEo4fYfCEA09RshJSDkRGC3Lug/JDo7BnsrRsAKc/b2COVMlLYFggXUEi1cY5U5pHKquxogF1ySkjHynfboBfJ52Sk0gejPd2T9sxyCdlupzlSPdbAt1K/TMok+ELnKYVJiDDWZ6SCJKDslJFK5sZqIx0Roz/jICNlVIZ0jlK7jVkdJpqd7Y0zyq77dLc/aDbvtawbhcJAyrrhFUiiJJf2bE8bebNyXIs4lHmKfAakWgWI6zU9rqmfkZLabK4ZqY2lPZ19Za8vU6f3eGzocxrKUMcftHpAykx9giHJwEsvliOVVWY2r3nJIJByVjNSq83mqbQ3MkJo6hmDWGa+gD6+dID3f+f9+RD051t+7OM4BWKhUIahGwueL5BKGakgCai6VTpxZyCDyijr93murr3smkuajXS4dXMtsFyHkTpSP8pCuEycb6AsTJmsu/cLhcQM4h4j9RzSXhJm0p7q/W46tNgr2cR2cd34A9nHSI26o9SsLIvMG2CkhKdzpLIcwsS4OCNVxFl3fJn+u84aRuoSkHphdQlIfR8qabUwR6o9Rmq9ETGGkd842hjo4cc+XspIiezitW2UgGdrz1LyhrTshgGmrRmpi0h7z1nZzr6szeZG0EEaNgKZG6OzsojSFt3U61IsIpptakkz/51M2lNRrClswE+BFIlCuC8MSAlhaJNuzkgpWiJtI06ZsRWryZZojNhVOZhIREJEjD08hnV+ESUEvmsOvE6mjBR+gBfoVucsYyiPjMhm7RkCJWOkH12UkRKFAqrT0TlShcEZcTJKTca2hRAuFGMSdXFGqh9IVWy92JbtMtK2kO0OqpjmJ70QRmq6T9rLuvZWeaT8NNY8e1AHIslTvvVDe61HKkoiSrZe6DIgpeMPMlSVmc1tzdgO6c8jVxpYIyMky8t5h+mAvJSGxmal4jgHCUahT94glfZiiWkoTGLK1cHjtD3NSGXH6ZjaexKUHGS9jup2CZ3evZoxUsp1iJGptLe+2XzDmAIzayxQ+XuulvaM9Fwsh/VVb/zcTEBm8g+KzkXN5kZh0IPTz0hFhsKLtDk8O/dN2eFTz36K043TF/37qytIAmzXQwpQhu6Y6x8wfNHXijhP1K+6VTpRhyTNkALyQeH+c3Xt9TFS1vi4tiCsZgstExkEA8xLqCJCYh19ABiWhZXERGqtRyo0EswwQdgpiHqOrr1M2hOJ7A0tTrv2CmU7lfZWAXHLIlnFSC2b2TinHiOVD5LvdHpASqheov0qVjNJgZQegfXc0t4lRuqF1yUg9T2WShLmP/AB3dXVaukZd+k8pzVBe1mqeXrjdDwd5x8kwRpGStg2M60ZTGHiOEVQUqcsGyZxKIiD/wtpL5UjjEpZM1JBB2lYCPTN1K+Lu2PDOn03ZwOKmLHUElxaWtoTevxCaqINyBgpieGaqHjtQ2m98g09B0qaPWmPRNIifZBYFr/3owbHR1pMRVWkSy7txSomMEKsShUWdEhh4KQAKvNNpLkuKgjwfAWWRWDpv2NljFTatZd+AJQfEp49g71tO0vdpTXHbBSLaeilv1baC7Q3RlkmAg9ZipCZtLde155an5GqOBWkberdZx+Qei5GKgPN/YyUUdLp5trM2wek0vOQgavYhHbc1iAg9WOsriAJKFgFTGHqRVSQj4jRH7FnNpedjvY2WRbJykoegWGNj/d+1zBys3mUdTwBKuoNyharGCnheSSxwjDBlR1GNg0yIZZjEkcJRauYn2+AqOLpuX3NFtJN0/xNT3ukEt04EJNcRNorbuxlSj93lDFSfR6pfHFKGZu29Fe9duOhxVkFSaAB4VA5HSQerOuREgVvkH3IGKlqldBIcCP0iCHDACHwiXEMBz/uHVPoxzSXVx3jOsdj2rrJQApeECPlE+VAqmKXufZ4Qv3eb+ZALHuf55T20uda0mxgTYxvYDa3tKTdx1RFKiYgJkokjmkgLBMziQnXZaQSrDDR59G2uNhIHWHbeQOOISXCtqjNtnm8dUWPkTLc9c3mBgMeqQXSZpc+j5SOt0jnZKbPq0SoXrjqamnPFHjYqdl8/eOl//NcmrX3gusSkPoeS3Y6LH3ow7qdPPVIgWY+1jJSgyNiOp6O89dAKvNI6YeoYds8u/ws+0b3aT0ezUiFOIS+IvR7zFPWtecYTj4g9blKew9K+EmEkfhIw4Z0YHH/DVjau1NnnfSZzYEBIBXJCMPWc9IyRirzSMVRTGglL4CRSgBBYg4yUk3Vzs/hoV0GNauJgYH0+oCUjAmMCLNcJftrUQqkopkZ/V7peRN+iBvonWWYPlMHQkxzuSZh5Wt3Ejx7hKUxmzf/85vXgFXhOCAESbOVSnu9f8+kPWmbCBxkMUDKzGyedu0Z63ukQDNRACW7lAMpZesdq1F4HoyUEGDb2KsYqe53H8N/+ukBQ3DXTA2tKbiShkAqeVFGKlvQHVOfA2kZGK4zIGPk5wgt+xmOZlGye8WaGO8db7pAYZkcW3yWkysn9Xlc7ZHqZ6QKRZJEYQqYCM7wxp/bP3CMlm2QRCoHpdkCZTsFKBYw5pch/WxFu5hLe3axRJxJe+vszI1iYUPAk+cSCX0lRkmEkXqkMqO8LOv/35KD4EDPFFwro/ZXmIRaovRKUCyQ1OtrE7vTc7Ou2XykSph27ancH2USEDFRnNCz89I69t157v/00YseTxZ/gGEgDe0Xfb5mc19FpJce1QOn+I3PSGp/+pe5xGykjFT3OczmkHqgmi3MsXEdOrzaI2VZyCAYAEChjAhFwkrQxjYFWDZmEhOt88gKSDBTmU5Y9lrGq/9v2TbVT97FL3wF7EAHci6ebbEcDWsgVbaRhk2yurvbtkkMgWOk0p43Si2qY5TLPY9UtkFJNzdZ8Gvcz0itumZjU1BQNki1YfzBYNfeJWnvhdYlIPU9VpaLFC/Mo6IIc2gIDEP/fNVOw5qaonTrLZpZAlqe3jH6sU/R0zR/FsYnHIej9aPsHdmrdz9KgRIEygVhEXYHgVS2mD0fRgr0AyUoWHTjEDMJU2lPUbj+erxrr81/r3zFZcjCUH5DlW67lW+9qMCRa3sdbvnA2ijWqbn0PFLdoMOxzvHnD6SIWayaOZBSUv//Jh1iQ9PuAHUrHTfiGXmWUiITQiPEKFaI08UjTB+Y5Zffgb1jez6ChCDE8XU3n2+mjFQqMak+Sl/LSQaV17yG5UmPVtTi0blHB89lGnwoGw39EFuna+/si3+YxLmMpBiglKvtX0YfI7WRtOfo66Jkl0hsQ3fbWSaJbTyvQE6ATb/z29jberJk+RUvx9m5E3vzZgo33ZT/vGPo98mYJyNddDOzeT94ySqSEY7h5MecWCbCdTErFUSxmPuAMlbBKJXzYNbMG2X2hcdmC1RTdlBxRM1fO/5kjUeqWOjZPtZZIDSQkj1GytSv9SwPhiuYC7UekLKKubRnFyuEKrqItFfYeKFJF8dI9DxSwtGMVHYek6J+bSsZBFKjP/mTjL773eu/L+Tsq2u62p82VO4BqXW69gbjD/TfNKtVAkPihaDSgenCtEgMwag3OsBIRUFCt7UxWAcdf2DZWtL9nhip9JYrnJrj6ctdSBLM7Jrpk/Yu6pGClJFqammvuY5HyjTXeKRCFZEYgrn2PLZl6MkQSUy0Donui9SrlJrNLybtdR78Dt6xGeanPf75XbsxR0dp1QMSDCQGlmNgqIhYrTpG2yZZxUjV/Jq+p7zUI5UCOO+qqyi/4hXIF9+AQPCNW7z8+b3aL+dPV3nRt+fZNStRGzBSA9Kebfcyqy7V86rvrVXjUuVAKpo5r4e1prKcDPw12rc9Ocmm3/s9zv/JBwBouSof91Dw+rv2NCt0auUUN07emN6s+oHsKxcw1zBSmYH2eXmk0AtW6JmAmQIpC4Fi6A2vH/g9p+xRevNbe9LeZTv5q9fE3DzdW8hiGWPaDqodg0yQBr0hvFLQMfzn37WnIs5s87jMTAM5U2DWlm3tKUsfjCtm6tEqGFh+T9oLRYxRKJFkZt/0uIu33ML2D32IUz/6Y/rz+yFOlBDYdi5pmSMpOOxNqcEaGWL0x38JZ3OZp09/HYDPH/08U8UpLqte1jufhQLJ0tKaETEqDBG2w+x8lU2tCu3CSVwMzQAafcnmq3KksirbZRxDy7aJZZC0WijLILHNVNpTzwmkqm9/OwCJTJjtzLJl3z42/d5/W/N7HTNB9e1CDcsBotRs7g6Al6xyf166e5amQDgu1sQEV3z30ZyhHH/vexn+gR/A2bmT2d/5Hf25d+zQ53h8oveGafTBme55nS2UZgoNmM2LhYEHvOF5urvckGtDcAHTNpCxZpuy8w3gWi5ySOGcPod82VZgOZ8bGCYhe6avZvnxL3Ouc55to7vXvG9mNl+vMhYoB1KptJe0mjmrG9kGmNBKBlmWjQZ6Z5VtlmzDpmgVSaplzvzkT2EOD+egI6vK616r4yjyc+VSfvnLMYeGaDtQ7oIaSpsqTBPTtgeAPUAcJvjtiwMpP/G1tGeYWmZKkucNpLoqxEq1KffMPCf3VLhm1sF30jiO9H1EsXhRaQ9SRqqlPVKy0UBMTw/+gqVz4QaAlIxwDJhrz2GbRi8KYV1GSt9rz8dsfugtV3Gm6PPAFT5DTgkhBO1agFQ6J08YAltFRGrwPbx9+7jzTdP8YAakXA2kjKGhNNncyxscCvuvYdtf/28OLRyicneF+69MsCcnYZVFA2DhDTfywOgiztfuZ//ey1hdq2ftbfrv/x1n29YNP9+lWluXGKnvsTINPDo/g1FJDeO2jfKDNdp3VlEKitoe4Ln4iU/RXcVI2TanGqfYMbwjz0cxREQj9EBYRP1ASobY5vPv2gPAtgg8C4GBKcNU2lvn1zyT0O8t1IudRRSKbtR7+EcywnBcRJzooaFC5BKjoQxaooNa76m03rlJImxsYiFBpbP6DD08NzH00GboMVJ4ppa3VEQsY0IzQrglkmzWWfZgEEJ7lbJZbkGI4+vum9wjNdYDUjmSMkXOptWCGruGd/HQ7EP84cN/OHDc/Ynb63XtBU0NKCIrALNJpziVS3vP1bXnmq72QtmG9jaZBtI2MYqF55T2+uvRuUf5j/f8xw3/vW1G4Fj5QpLtaKMkSjNr1o8/cEwH29S/m5iiNwtMiIFOO3fv3hx4eFddlb/famlPWBZnOjOYCfm4kH62RXuk+pPNi7pJVrAmBBdSRirumc1zRsr0kJUSRhgzd+Uk0MdIyZDyddcz9LrX8eB4jcIN1695X3fPHobf+tb1T2a2GGfSnowwyiWS+kounUaG5NMvM6h7L6xDLgOvQghKdonZ/++72P73f8+eu+5c8x2VbruN4o035P8tLIttf/PXCNOk5UicRINffcwGpq03ZP2MVBxJgucAUln8gTBNpJv6sEol/s8z/+c5N3dd0WOk7LPz1DeVOT1tcDzQcrxwHKRpYJcrzyntZX4za3xsXalzvZiHMG2WmevM45i9lPPVHimlFDVXPwvN4SHKd9yOvXVjoHHnHRXuusLP5WIgZ6SUMDAMA0vERGpwnTAKBZ7c5+US/6g3yrK/zKbf+z0KN92ENTHBlj/9k4HX+InPsDucey3FOnPywiSku2uaf3ithdi+Zc3xZhMGsnJ377oUyPkC6xKQ+h4rm8MWzZzHLPUBqcBfd3cMehBsbOhxJ9LRslSpMKT/MTW2ZozUzqGdetwGEkN1qPseApO4b0xMmIQ4hpb2Ihk9r9ZlYdv4ngBMjCTIpb3V5bgWUdBrz57rzAEMeCgiGWE6LiKKQUqk0ds1m9KgRTsfXvxcFcoQW1gkRqLn9MV6hTSEgTRFPlC5kXWxFM0Bj1RoxGA5xKk3Iu7rHjM8T5typcQIUxnLtnXbvxB98/96ZnNhGzkIrAd1Xrzpxfzxy/+YlWBl4LjN4WHsbduwN21aM7QY2yJqph4GMwB3nkZlZy5DFaxCb86bjLDEYNdeJtvGloFsaSCVOCbPZ0RMfy12F2kEjQ3/vWXGaVpz6oezetKeMIzcxNpfuaycMlKJJXpz24DH5x/nA498YM3rSi99Sf5+1hppz+JU+yxWmnatT0y/tFccZKSKBRIl6Nx/L86uXWv+lmkbqIgcSPXHIMRDRRpXbMao6lT73COVhJi7dlB4y5t4bJ9N5RWvWPO+1ugo4z/33vVOZc4YhCLJz5OZJbl7mc9Q8fmXGMxGi3zkyY+s+z7rVQakQC+yC2WJd8XlLzhMMwt5lKZBEkckpsCyHQpWYeD+jkOJ344HJO/+Ukrprj3HwzAtuv/2bUz++q/j3ngDf/jwH/LM8jMXPQ5fhpiJnkBgnZ2lvWWEZydjOulXLIQgLtg4leGLSnsrwQptMwbDwJpIWc5VZvBeZ2gPIAQqQpgGC50FHMvASBm81cnmfuLzhVvh1/7zFMNvfzuTv/ZrOFvXApKsWmGLZX85B+edqEO7HpAoQ3dLmwLHiInk2u8tktEaac+75mo9NUAIKq9+9eCxxT5Vt0qsYiIZMf6+9+VNHFllyoVt2PlYsf4yPPeSJ+r/si4Bqe+xMmkvPHkyN88Kx9Fm8w0YqVhJYktwepNFskuPlCh5QyAM2k/6GKUySdFDoZgqTunsExRCtWn4zlpGKr1BssUsAzGdqMNnjnxm3WMwCkU6JQuBiRX7SNNhvTgc2zMHgNR8Z56JwsTAzjCWMZatfQ2akdLHIBOJicGKaD5vj1SYaCAVi4R22NLdfqbANV2kIfLhzl0nleM8O38wxDImMmKIFEna8ZMxU3rEiTcw1BT0A7VeFkz/zu/0FqK+56ewjFyWrPk1qm6VYXd4DZDa/pEPc9nXvopZ1fEX3UOHuPC7v4sKQ2JloSQkIiYyQxJ3lpWhnbmPpuJUcglrI0bKMRxiS+iuPUsQFR3MkZHn5ZHKqh7U87+zXl2oxKgP/Ga+yGTSQJiEVH/kR/D2XTHw+9kCmj2cTWFy6MXTONu3579zZPkIj88/PvC6HZ/4OOO/+Is5GDLHBxkpbIuz3Qs4yqQZZYxUnHcgjvz4jzP8Qz+Uv8YolTA3b8U0BdO///41n8u0TS3tWWulvfur89y5v8dW9TNSjukwUZxgvjOfv9fzzldKAXwgEgpWQTNSlYqWvNLPHaQg67tz3+UvHvuLdRe39Sq73wGmSlP55uaFVtPRn0Ua8M2//xBnK4WckcqYDYAkTEhiSdzHKp9tns2BVcY4FbZuozlW4MHwGbrveC0rQyaJSjhRP3HR4+gQYkp41zf0+6vxET55k8+3X7+595kLFt7wKJ2ow8mVk/zOA7+z5n2O1Y/xG//WpPW5v8C76ioqb3wDpVtuGfidXkZf7x47ekWZB9+4nUV/HtsUOQgLV+HGdtRGCUHNDhFC8IFHPsBMa4Y/eOgP1t3MtKIW3bhL0Sqy3F3mNf/0Glp1H6lEykgJbFP1Zm/2VbY5Bhh2h4lVTCfu8DN//wjv/spPEyQBy+2Qrx66kH8HFaeCQBDEAeM/9941oChIAmzDxjbX33wNvfGNTP7ar675+aV6/nUJSF2klFJ5W/+af0uBVHDkCHaaHq2lvY0ZqZiExBTce2uR4PYb9Zw8p4AojOEfDPCuu476772PHUM7EEKgUo+UkTSQSrNI0TrJ5qZhYgkrl9UOLR7iLx77i3WPwfndD7KyuQoY2Okub73pd1ra6wGp2fYsO4Z2DACpSEZYroeIE5CSRCgUijiVuFbU8wdSkYwwhcVyVOOphSc1iDEFnumhTAPTSoGUq/j7iS9iu9roHKuYRCVEZoyKJLI6TGglvY4YkbaUC5Hn7oBmpEJiRt75I72D6JP2VjNSVU8DqXrQew/QjJQwTZ0a3m4TnjxJ98ABiGM6XTBKirnyKQKnTVyYpTG0K/fRVJwKjVAzRau79ipOJZfOwoJFUqshLYN7f+2VePv3vyBGqubXaEWtDZkFXwYUrrs+p/cty6VgFQhlyMiPvnPNDjdWMQqVH9+wO8y3XzPVx+zBcrBMLajx7PKzHK3pzq/ijTciHIf/ferjJFfvHfByZGM36nETRxk5I9Uv7bm7d+H0SSrCMDC37eBLt0h+6r73DRzj105+ja5qo2LWlfb+5opzfPqyhdw/lXmkoiTCNm0mC5PMd+bzc/ajX/5Rnl56+rlPdgrgQxHnQ50z472wHTBNAiOhZJc4Vj9GohJOLh1jZf65QVHWKQkwVZxirr32NU8tPcUnDn/iou+z4mgALg1Bu7aMbxkIw2Po3lk6nb6cuPT675f33vOv7+FI7Uh+PJZhUX3Tm/nuG3fzdwf/ji+f+DKz7VmAvPNydX3jzDc41zxHV+ln6IsPK5JffQ9Fp0TXEyy4vWfcN3/+Rci9O+nGXQ4uHOSR2UfWvN/x+nGaRUGjoM30W//0T5n4pV8a+J3J3/h1SrffjtU3MqnmxXDFZTTDBrZp5P8WrmLRO1EHy7DwE58oifjkM5/kycUn+cQzn+Bs8+ya48k2LSW7RNyGH3zoP9Kua4+UxECYgvJVezCvuWHNa8MkzOVyQxhU3SrL/jKPnJ7j8YVHWQlWePxMjf/9reOAztfKRh/1s4n91b/pWe+ZYZRK2Ks9ZZfqBdUlIHWRmj12hM/+wW+v+28yzXMKT5/Gmprm84/PsBRI3WK7ESOF1HH9hkMzbOKZHsKyMQqa0XrvV9/DWZbZVtGdVsow9IM8SVkQYbHUWODff/3f67+dxh8AAz6p863z1ILaujfNPZ8/T/1ckDJSKUOzDpJyXIvIj1nqLvG/nvhfnGudY+/I3sGuniTCdgqIWBJGPtlkhTAOkEgaqvH8gVQSYWHRVT5JnCDjBGWmxmDTwLAshLJwrTL/Z/xrOIaTZyllHikZxFjv+hGaxYQk/VA6WFGzUkmtnv89w1qbw6RUv7RnIqMeIzXijjDsaolhXXq8VAKliGbnSJaWAeh0FKIUc/d1H6Y5Mk9gL9ApTubdmxWnknuBVjNS06VppkpTOiKhaOmRJoZAlIoIIV4wIxXLeMOIDD/28SxP79aFlnkqdoVYxusyMWESIhBYwsIxHIbd4TUevZpfo+bX+NwDX+VLD92V/7wbd/nQqU/y02+7MHh9pkGH9aSJJcUqs/nGfo120OWJ5cfXsB8fO/wxZrrnULEYCOSEnsQHDDBS2dBix3AY9UYJk5B21CZIAp6tPctTS09teBxZZe3lITIfoWNUhgY+oy9itpS35J//wIPf4O4P/9Vzvnc/IzVdml6XkXps7jHuOXvPmp8nccRnfv+/EHY7hCIhcgwSE8Jum8gwaNQFzsEFurOLvdeEachuCqSUUlomTsF/kAQ5OHUtF4XidON0DqROrKzPSP31gb/moQsP0VX6mnnwSoH1hlflzGE76oWXXtjsMVocoxt3Od04nd8v/XW8rkFFdlygn4Hfnftu/t/FG29k+9/97YChvxt3mSxO0o5aGkhNar/cao9UO2oz5o0RyYinl58mlCHnW3rCw5nGmTXHk20CinaR7fWrKIXV3lSLlJGqTJaZXaytuW9C2WOkQBvOl7vLdNL7oRN1aIcJ7UDf+0ES4FkenukNPJv7a74zz2Rx8gVtvi7VC6tLQOoi1Wms0Fmpr/tvmUcKpbA3TTPX8AmEmTJSg0DqTOMM773zvUQkSNvANm0aYQPXcnVSbgqknpl/hrPNs2wq6RBFYQi9sEd6YRaYNNp17p25l07UGXiwZp17rYcvMNPUZs2l7hLHasc4tHAoP5Y4lHQaIQIDO8oYqbVMRSbtPbX0FB998qOcbZ5lT3UP3bib79JjGWM5Hkac0A6aKCM9jtAnFgn1pLF+C8w6pT1SJl3ZBQWdoI00lX5QmwaGbSMw8Uy9u7fNQWmvYwfIToyKE9peTLapPFY/Bugco0FGyln7UOnL4zQcA5UuJBkj5ZqaqVkJB+U9/V0ZGJUK0fkZ4uVlME06zQiKMWW3TChDIisEYZCRnEPO0IZA6vKRy/nQ6z6Ebdr4nglRRGKJ/HdeiNk8ixJYbxGC3sM4G2JrWw4lRwOM9f5Gv+nZMiyGnfWBVCtqET7rIY/2OspaUYuSXWLYHR5gLISlO4fqSWut2dzZGEiFYcS26lbacXtgAV7oLLCS1CDRQMpMBHMHNRDKgjmhD0jZg9KeaZiMFcaY78xzauUUUsl8wb5oZdKeEWsglYSYWTOKpZtJfBGzuazlK0tYzNVm8Ftrv5s/f+zPB7rV/MTvSXsbMFJzy3OIWYFcxaS3lpc5ffBxnr73m4RJSFR0kEKwMl+n7VR0k2XZJVzpY6RSROG3Y8JuTDvoEMowP89B3PNsZYDq1Mop5jpz7Bvdx4mVEyilqPfdd7GMOV4/Tj2o00kN4o9fptO8s++i/zrtxl1GPS3tnW6cphk11zCrx+vHGfVGOdc6x09/7acB+NzRz23Iyve/92RxknbcxLEMrCkNpFYnm3fiDiOefkZ/5/R3EEow09LP2NVJ8JGMcmaoYBXYuXwNj2z7CrvfWMyfs4YhGJkq8sDT3+WbZ7858PpYxjkjBdonNd9ZRqYTHjpxh04Q0wkTjtWO8eD5B/FMD9fauHP7TOMM24e2P3eI76p6/3fe3/MqXqqL1iUgdZFKojCXqVaXCnsXrTU1TRBLImGiwmBN6Nkzy8/wxMITxMRIy8Q1XZphUy9GppkzUqNWlYMLB3MgJdNlXcUaSCEswjBAKskzy8/ktC5oYBFGAfXPHWO5tgBok/GffPdP+Kcj/5QfSxxJgqa+maxUplvPI+Wk0t6F1ix+4vPY3GPsHdmLQuXMRiQjHLeAEUu6QRtlGDimQzfoEouYlaSR50s9V4VJiImFT4CJQb1dQxkK10zTwU0bgU0xA1KGnUt7sUqBVDtChjEdLyGWEgUcWnpSf0bPWyPtretNyYftmjmQyhgpYF2fVFZmuUx0/rw2SDuOpvOLIRW7olvrjRghYzJP+gAjpQalvfx7MBy6nj6mxOiNj3ghD8VMjmyEjTWfWSlFN+5qdtS0wNYBrwWrgCGMNQDp8NJhfuPe38jZHcd0qLrVNQ/xDLy1Om3ioHcNZEDqytErB8zIwrJITDSYS+QgI3WRDqIwihkrjTJeGM+BhVKK+e48tWgZp75MwfDYsuDx4D/+A0AOiEEDAIEGW1n8QcYITBYmme/O891v/AtV3+NY7dhznuvs3g+UBlKRjDCGNCPVQZHYFl0itpS1WfmGqRs4s3SSZrM28D4XWhf40KEPcabZYzw6HZ9yoK/DqaL2SCml8GOfP//un9NY7FI/VWf6xDRf+9rXBt6vVVvGME0O3PUVwiQkLrokhqLbbONbBWQiMMaHiBq9hTNOr/+gHXH3R5/msXs0w5QBqX5g55ounulxqnGK2fYst226jZnWDCdPneRjH/tY/p5nGmcIZchKsEKQBBz+9bfw1A6BbfaAVL+frxt3mShMIJXk4OJBYhmvkbDmOnPsHdnL00tP8+jco/zQ/76PgwsHeWb5mZxRDYKAr33ta3T6fJKduMNkcZJO3MIxDexU2uuzhuaft2SXuKx9Gef/5Tw7/Z2caZwD4ER9EEi1wx6YL9pFRqTNqdEnKF4XYqaDrIUpGJkuYjdKLHQWBl7vdl0ee/Cx/L8ni5OcacxA2mTTz0jddeYu7jx9Z37uN5L2zjTPsL2yHdu0OXBukSBOaDab/O3f/i3t/mHaqz7zZ458ZmDTcak2rktA6iIVRxFJtL4cooM39emzp6fwo4RImHqm2yogda51jm7cpRV3kLaZS3uu6YJpIQq6/X6rt4WDCweZLmm9WgkdxkmwBCgs1yFMh+8+ufgk55rn2FrRnhHXdAlT39ZSYxGB4NDiIb49820Wuz26Po4SwoZCIREqxjTBnhj0wADYrolSirm6Ntx24o6+GQ07j0DQQKqISCSdoIVKU3mb3QaxSFiJV1DrpdutU2ESYmESiQRDGax0VpCGwrM8RopjbB/ZOcBIOaYz0LXXdQJkJ0KGER1XC3uRZXJg4QCwPiO1BogMBHKa+F3NvtWDOlW3CsCwszGQMoaGNJBCG7bbKyGJp4f7RjIiMiRmEq4BUkqpNYxU/j1kjBR874xUoBfpDx/6MP/z0f858G+Pzj3KVHEql/aEZeVp+Y6h5WKlFP/+6/+egwsHOVo/ysOzD/dSwg2bIXdoDeBaDjT4j4KEfkWxE3Uo22WuGL1iDZCKhKRQqCCSZF2P1HqVRAlj5VGmS9O5pFQLasQyZjGaZ/j0k3C+wWTNJUojMDzTY9fwLka9Ue3zSnOZIhkRyShnBCaKEyx0Fpi9/7u8TF2Ts5sXrfTe90WcgzOjWAQheKKxwLmhIm1CNpc0I/Xq7a/mfO0s9cbiwNs8cP4BfR795fxnCwdC9hy8HdCA3hAGtaDGnafv5LMPf4nP/fF3CVYCzo2d44knnqDR6EldreUltlxxFcvnz6HCGFnySAxIoq4eOKwkljdB0ugBjSSSuCULvx2xfL7NzNP6us8ZqSTAtVJGyvK4fvJ6Yhnz1NJT7BreRckucXb+7MBinfmr6kGdelDHevlLUKLHSE2XpmlH7RwA+YnPkDvEK7a9gtn2LAKxhiVpR202lzbn8u6Z+gJPLj5JohJONU4B8IUvfIGHH36YZ599Nn9dN+4yVZyiE7e02TyV9kR8cuCYO1FHH1t3GqEEW72tnFrR3qgMSCmlSGSSN0kAeLJIVFhgLBrm6Lmj1Ib09S4EVKdKFNrVgdFTiUwY8od46P6H8NNrdffwbo7XTiAM/d/9jFQG2hKVaI/UOtLeqZlTqIairMq4yuVP7j7Mo6dqnD59mvPnz3PXXXeteQ3ATGuGqeLUus+kS7W2Lp2li1QchsTh+kBKBgHW2BjxwgLW9CaCs4sEGDo91zS4f+Z+bpq6Cc/yONfUu5elsMa0beKYPSAlLBOjqHeZm9xp/K7fY6SEQgBOnLB5e8C5BQ8/bGMJiycXn+Rk4yTvuOIdQA9IlYBaa5k9I3v41DOfYro0nd+sUipkrJBLDqGxggBsR2D0ta1nZZgGQ2Mex+b1cRrCYNQbHTA1xjLGcYuQKDpBC1JGquk38ETynIxUkASYQscYhDLExCAWMSYGzW6DouHgmR4Fr0zRqyCwKFl9jJTQQCqRCV071IyUDIktiWVbRJaVG4QzRip2TKwwwdxA2uuPP/jcU5/igeQZWlGLqlcF9HDV1YbzrMxKhe6TKQPmOHQbIVGhS9kus9BdIBQJhgxJUt2xZJeQStKNuxsCKcdwWEo3hYnBuoxUIhMiGa27e4xlTM2vMeQMcXj5MFvKW5iZP8u/ztxJS7X59sy3+elrfhpDGOmMLZ1Llqgk7/JZ9pf51rlv8dj8Y/z0NT+NVDJnIhwz9Uit8l/V/ToVp4KVuKioR3m2ohZlu8yVo1fy8Wc+nv9cWBaRoSgXhhFykVpniQ888gHetM4cuf5KYsV4aYzpcJrZjgZSC50FxrwxVoJFDJlgLHSYqheIfA2MXctle2V7Hh1im/ZA/EEGEieLk/zD0//ANc02VxRezJ3hQU7UTzDTmuH2rbfnx/CVE1/hc0c+Syfu8P6b/gugU7unbS3pHlg8CAWL5WAFw0hYjJrsSxmpN+x8A4Ud5zl24h5OrZzioQsPIYTgyye+DPSYPYCgFVOujaOUQgjBVHGK+c48nz3yWZykgN+KMJoGM+MzvHnrmzlw4AC3366P89iJ4wxNTtGqLzPcOgflEvPtGWKzhMIBbEwxgmxeyP9eFCaUqy6dRkhjyUfUFcaImTNGGZMJ+vmze3g3Nb/GgYUDvHf/e5koTDC7NIvv+5xZOcNcd45na88yXhjnfPs8QRIwWZzMr+eCVWBHZQcLnQXuOn0XT8w/wbnmOQpWgbfueSv3n7+fkl2iGTWZoBfm2opabCpv4nxbb2La4jgl0+a6yet4eulpptjC7Ows1157LceOHeOGG7TJ2499JouT+EmLpvEEf3ry67zetjGI+auH/4ryaJldw7s0I2VpmbZjdhi3xnmg+xAyHON4/Vk+8shHeLD2IBOFCd511bt0ZIuSuL72fF3WvIxHjz/KtL0FobRn0ytbJCJiZbEHvEIZ4kqXJEn4/Oc/z4033sju6m6+deY7CHMvoEFdK4yJpaKZAsrH5x+nbJf56wN/zWRxkla7RedYh5uvuZn5e+e5zbqNz3zqM0wYExzp+iy2AlbOn+FFL3oRBw8e5CUveQmTKYjMaqY5k8vPl+q56xIjdZFKoo2BlApCzIlxsCys8TH8KCEQesL4scZJfv7un887TLLOjlPNM1huAdu0tdnc8nS3UspIbXI1EzVV0hSzAoQSlCOTK66sY7sucRhy09RNPDr3KKdWTrFrWOfneKZHp6N3KO1Oi2vHr+X4ynFevf3VOSOVpMZvc7lIZOrdqu0Y6w0EB/SuqT0fcfP0zWytbEUIQcEq5J17OgdrGJFIFtvzCFPLlm2/hTQUsSEh6RtCvKp++4Hf5rNHPgvoh5qJSZwyUq1uk8SUesebjg/ZEv4MWwu6FT9bACOpPVK+EyLbMZEfEJsKx3aIbZOZ1oxeeDzNSAWlNL17QyClF/0V1cBMDN6656384e1/mAOHIXdoY0aqUkF1U7nUcei2QiKnS9nR3VshCWYSkKnFhjAoO2Utua1KNs9q1Btl3tAPzMQk/51+4+gXj3+R/3r/f13z2vnOPK/59Guo+TW2VrZyeuU0y/4yz37ifpIDdRSKV257JW/fqxPQs/EX2bnNGKnZzizbKtsIkzBnFDKw8artr+LW6VsHpD2lFLWgxu7h3djSQYW9C6wdapnkhqkbeHLxyR5baluEIqFU0LlOZ1ZO8Q9PfhSS5KJASiWKycr4ACM135lnx9AOKuk+UZ6vMd5wkUlCHIW8dPNLecuet/D2y9/O1WNX4xgORbtIkAQkKsmlvf/nyv+Hd17xToYps8Pewruvfjfv+NI7+IWv/8JANMI95+7him/HjM3A4bpmPEJ6Hqk7T9/J8kiFxPIILIv9m2/gRZtexE9f89N6cyJtzETw94f+f3z+2Of57tx32VzezEu3vDQHUsdnj3Pk7FOYkcPKvL7Gdg/v5u7Td/PM8jNsdbcTRwlu4DJvzDM6NpozUmEY8sjRk4hShZGt2xhpOkxN7Wbn6B4ECkkAwkVEw6i25G//9m+J45gkkpSqHrMnGhQqNkYlYbK1g5VghT96+I84uXIyZ8R/dN+P8u6r380v3vCL/Mw1P8P+if1MFCZYri+jlOJfjvwLH3j0Azw29xi3b7k99zVlEqtt2Ny26TZ+4sqfoGSX+ODjH6QRNvilG36Jy0cu52VbXsbH3vixAV8hwNe//nVuPnszY/QyyaR7jL3Vy9k/vp8n5p/g3k8eodlocd1113Hs+DGeeOIJHZkiIyZLkwSyy5z4BgvhMp10zp8ZmdT8Gr99/29zePkwWytbcaRD225TNaskKiTpbufFhddx5u4zjLgjHK0fpRW1cnBodm2QBqWoRH25jjRiQOuGnbhDvTBPZ6GnI4ZJSCEpMD09zezsLE8//TS7h3dztnUKYfR7pPRrVoIWL970Yn7rtt/iV278D7xm+2vYP76ffe19bF3aygPPPsDIjhEc4XD+/Hns2KYTBSy2Qs6cOcO+ffu45ZZbuPfee9fcV+fb53P5+VI9d10CUhepi0p7YYh72R5G3/UuhGkSxDJnpL678DiTxUkWulr/Ptc8x86hncx15/E8PfqjGTX1YmSaCG8E4RqMGxNsa13OqKeBlUxiBAalyKCjAkzbJokirpu8Tj/wTYcxTz9Arp+8nkOzBwGYtMbZPqQzfV61/VUs+8tIJUlS86jdKaIcTeHbrpmHCCql+M37fjM3p49MF4mXDd55+Tt5zzXvAVgDpAqFCq40OTR/ANPSWSWtbotESNw0eLG/cy+u+XQOzCOV5MHzD+Y+j3akmbZIRJiYtP30PUw3bY03Kcg9uCnrks15y0bE+E5E0omIAh9lGziuS2yaSCVZ9pcxXM1I+aV0eOs6QEr1uc3P+jNsdqd529638abdb8p/p+pWB7qD+susVGiVNnFi55s0kGpG+Habsq2lvVAkmDIijnvAMlsYMiD1f37vIfy++WZbK1s5kWjvT7wBI3WsfoyTjbWt5vfP3M+Sr9nITaVNhDJkubvMUKPAi4dv5Zdv/GXed/37ciZLZGZzw8Y1XBzT4YvHv8izy8+yqbSJTeVNHFw4mJ9/gB+87AfZP7F/QNrLDMHbK9uxExcR9x4zmUdq1BvlldtemQNpYdkEIqGSAikrASu9bPoDJ6WSg+NCpMFUZXKgi22+M08pGOPW0esBwdEH7mfb5VdjuS5Rt8v1k9dz8/D1/MDW13PF6BW5tJdJVhlI3Dm8kx++/IcRfkzc7vAL1/8Cv3Xbb3HH1ju4+/Td1C7McPrQEzSCBu5ixDYmmElZka7oAamzzbOcvuIaguoUiePyqt2vZcgZ4j/e9B/1vRfphfHgzOP87LU/yx/d8Uf84e1/yOUjl+fS3n1P3Efs6+tu7qQG8q/a/io+/OSHuX3r7UwaUyRWl8AISKwEy7NyP9DcXOodcz2qWzYz1nIpVMcYKfWiAIThoTpDSCqcP3+eEydOEIUJ264c4ezTS4xMFVFDAeVghJMrJ/nY4Y/xheNf4OqxqwHYVtnGlvIWXrHtFfziDb9IxakwUZygtaI3AeeWzxEfj6mdrPH6na9nsbvIRGEiv45s02b70HZeuf2VOhZkocHbt7+dd+57J47pIIRgz8geynZ5QNo7evwok/4kbrd/HM55xrwpXrvjtfzrqX+l3e4SxSGnjdMcKBzgC1/8AvVWHUMYVOwKprDoqvP8xJU/wcpP/SwAb9j6Bn7z1t9ksjjJ5499Lkd0IQAAdYhJREFUnpdsfglWYtGxOpREibfeu4mpqMhV8lYI4Of2/Rxnm2dphS2mi2mUQFcHcApXUOqWQCgUEV879TVqQY2WU8Nv9OwFkYzwlMf111/Pa1/7WprNJtsr22lENYRdBzKPlH5NM2zxQ3t/iJumbuLP/iVim/1q3rH3HXROdlBSodoK3/JxrnLYvXs3ZmyxV3U5d++naTabbN26ldtuu40jR44MNASAlvYuAannX5eA1EUqCUNknBB31nZDqDDAGh1h6jd+HYCF8BihGdAJJO0k4lXbXsV8Z55m2ORC+wI3Td2ENKBQHM6lPd2RZiKcIkbZYmhljJed+mEtswBSxhhCUIgEzaSDZdskccyQM8Rtm25j9/DuHAS9YtsreOK8DkDcVdjBRGGCglXghskbsA2belAn7EtFFwX9mWzXys3mXz/zdb504kscXNSLZXWqgNkoct3kdfzA7h8ANJDKtPgskNPD4uD8AUxTL8DtQDNSJaeEMhiYtxeeatD89nmO1Y+x7C+zEqzQjbskKsHCIhIJrnDo+G1ikaQRERbCMlGoAXN9Ju3FMiZ0E2Q7IvZ9lG3ieB6RZbK5vJnzrfM5I+WX0jEWtkssYx6be4xfv/fXeWrpKZIkRqC7gJ6oHWDKGqS7gTxLKkqiAf/K105+jSeDU7RKm5mfuhkcm04zJLA7VJwKkYwIhGak4r7+6swnFcsYE4vl822atZ7XYUt5C6eDCwjHITZ7QKo//uBM40zeqfmVE1/heP04UeDz5Cc/y0smbqPqVvMhyCt+nbHuEKWkN2olL8vMGans//7m4N/w6Wc/zVRpis3lzXm3Un+EgGu6uZcKegGmo94onipiRD0glAEpgLfvfXsuYQnLIiBm2K2CZWJKuHroCj1kta8L9re+/Vvc+olbuffcvZw+cxoSwfTQFJtLm3MJfb47T+GpIq2axC1vRSnJi97yw1AZIex2qdfrfO2jf8dDn/sUoE3B2eYFyO8/SOX9KKTbbGAZFm/b+zZ+YNcPcPeZu3nmwft4+EufpdlZIao3GJJFznU0kPJVpJlIGXKueQ6/WCIyTXxDrGHYMu/WhaWzeqJBWqPuaO5vqy/XMYWkMh5y6snjKKXZRKUUL598OcVzkm7xPG2vqwMaHcGJhRM8NvcYjx7Vw7Y7MmFo8yYmay5JsUhsCBDp9WR6JJ0y0hthz549HHjicTq1gxyuPEzLrrPkXiB0u1TlWM6wH1w4yFVjV629jtKaKEzQbXURQtA62eKa2jVcnlyes1hjhbEBr11WJbvEvto+mmfWdjL2N2gAdDodfMvHStLkckxM9wJVe4K9I3vZXN7MUnMRCXz82Y/zVPUpQjdkZm6GglVACIFrlAioMVmcJNijJbRu6o988cSLMYTBdRPXYcUWqqBQvqTactgTmNRn9Aamea5GlEScbZ5lPBmnqIqojsC1PArlAiNpk4AUAf/5vv/MPx/9ZwKnQ9xWHD16FCklYRLiJR6W65GYHo1GA9u0GXM2YRZ000E/I9UKW3kO2uELTU4vdTh9+jSO41CpVBgKhlhOltmyawv79+/HjC2uUQGdqatYeNECWFAqlbjmmmt44IEHBs7zJWnvhdUlIHWRiqOIraV91D57dM2/ySDIh4I+dOEhHo/fjyzOcnTyNUwU3pAvOm/+5zdz+9bbU9BjUEqBVCNspIuRgRAGRsFgkzXNmNXT/lWSIDDwQkUjaWHaDjLWO903734zr9nxmvx3b5y6kXYaprejsJ29I3t5w843YBkWY4UxFruLzK705AinqBc927PyjJPPHf0cm0ub8+4na1Qy3J3IO9aAgbySbESMK00a3TqWrVmMTtBGGYqKU0FZ6JTy/LwlyJWAhy88nAO8dtSmaBUxlCAWMa7hcuHsWZ5ceZpIRnrmoGkhFQMP3n5pL3YkSEXix9yw9SaKxQqRZWpPUHsmZ6QaXjpfz3Hpxl1+4eu/QNEq8u/u/nd8/tgXUAJ++Zu/jLANJu2+obppjXljPDL7CG//0tt55T+9knvO3sOyv8xvfvs3aTgxiVXA90ZZSBp0mj53z/8r06VpDfZEgpGEA4xU2S73gJS0UAr8Zg/wjnqjemEvl4j7pL1+s/mpximaUZOVYIVPPvNJHpl9hAc/+0mKT9X5xb0/y4de9yHKtm7BL3VcbGVRiNf64oRlIRy75x1KF7cnl55kujSdG6R3Du3MvwfQ7JSiN0R5obPAaGGUqlfVQMpfobGYNi1EHcqOPpYrvKspnJniQusC8zKiHvkMUQTLxpEm77r8x4hTDLXYXeR04zQPXXiIl215GY9ceISPfvSjCCOhWhji6vGreWL+EL/35Sc5OnuUSmTR9ZuE1Sl+9Pc+gKxUWRnbRNDt8MUvfpHjcwuce0b75z7y+o9w9djVTFpjXH2iMnBOglQuH6oNI7v68904dSMzc2c4d/gkJ08/TbzYAAXFxMmBVCAiPOmh5hQzrRl8t0BimPiCtUAq8FFAMXawWlbODmQjQgDaK/o4YnGIx47fxYMPPkjVq/LBV3+Q64euBwV+8QKGW2TP8g1EZsR8fZ5H5x7l7ifvhiRmIVhhbN9eQhe+eOoohwoFhEg9h7aLt9lFmRbX7d3D8WPHaLXu4eSZIxzY9g1qU+fo2i0mxSZm67PcNncbhjIuCqTGvDGSbsL4+Dh2zcYddZliimFHs47j3XFEOrQ4u67PPr3Mjrn9lGSJYJ0NbNkpDxi6/a5P4AYYKes5ZG5m3B+n8i9X8OS9M7xy2ytpdldQSvCdC9/htTtey4K5wLGzx3JZ0RElQDBRmCBMn6GdTodHHnkE+xGbt+16G61GC6EEVskibOnn31QrJqhrxvfok4fYUtnC4fnDDB0a4rLuZSS+pOAUKZQLFBMNeKQR8u+u+3d87ujncMsmqmPyqU99iqWlJU41TuFKl0fOtvnww7M0m/pYRp1tmIVzCKwBRqqdmuDbQcxiK2Cu4XP48GGuuuoqyuUy1bDKmeAMm0qbKBaLWLFDAckMHb56+qs8OqsB9stf/nIOHz7Mk6m/E7S0t7m4acPv9lIN1iUgdZFK4gjPLJC01nZHqSDMZ4sdWDjAiLyNxPaJDZeqt4nJ4iQPX9DdTX/5qr9kqjSFNzGFMzXVC+S0PIgFKg4QtomdOLiqxxRoaU/g+An1uIlp26hEJybfvvV2fvLqn8x/1zZsbhl/EQCb3U3sG93Hf3vpfwPIgdTZ+jlkOp7CTaN97IKNEFrWe3LxSV6383VcaGvDqRz2GfLHc9YLVkl7SYTleNhSYEiwrRRI+R2UodkbaagBaU8FMUkz5ETtBNeMX8NKsEIzalJ2ygggFgnjnWHe2nw1By8/pXdF6Rw2pRSO0TM552ZzlWCYBkbBIlrp8nMv+gWK5SEi02BrPMaJe76NKHhE9Rozpn44ZSNn9o/v53de8jt88FUfZL49x5K/hFSSn7rhp/Hk2hEOb9v7NvaN7uONu97IO6rv4tTCGY7Xj3NZ9TJeeeWbiU0PKSxq1giGYXDnj3+V12x/DVESERBjykEglaWbxzLGjPUC2231ZDIhBFsrW0lK3rrSXixjzrXOUXWrzLRmONc6Rz2oc+ieu5BCMS6qWhJxytiGzd5Ee+qscDDzIgxDTrY7GsT0MVJZTZem8x3qVWNXDfybZVh6REXqk3pk7hFumLiBN+9+M2VRwWo+zaFv6u6gfkZq/niLW2bfyP3n7+dU0GahHeB+9jBzwyX++pUf5BXTLyM2BGeaZ/ifj/xPfv6un6cTd3jrnrfyzMwzKKmQpo/pmJgdk931Pdy3+AnOnZlBKgiTLo0yfO0TJzl3dgZpmJw5c4YTJ07QDQLmjh8hDkMmihMIIbjNuJobnx1BJj3fit/WMtKOcB/hOX3tTBWnuL5xBXsblyMaAcayvh/c2GQmDWqMDUgWEswTGgl2LIvEtIgEfOErn2P+VC+sMuh28DfvZn/3Jh68/0Huu+8+YBBIRc0IoSzqVpfAhmee0R1gL9vyMvyOj2na2MEI2xrXcvWxV/Lw0sNYicX51nnsto3VXqHeboFr8dhLY/zKEIcLRZRdBBycQonh6yQisbj/7/8GP4yIhqsER5uoq5aZnThK26pTleOMNkfZ0tnCG4feyLA7PHAdHT58OO94GzHSyJCRYUpBiVuuvoWknWjGTAnMAyZ3/fNd2Ng5C3jiiQWmz1xJQRZyINFfFbvCd+e+y7dnvq1ZnCAkLsSodK5LSWxlpDuFqsHhx49zzfg1RHGIofR9c/PUzQyPDfP06adzIDXd3sTW7i5s06bbbuJjU6/X+cY3voHf8rlq4So+85nPoCxFuVgm6ARsqV7FcK1L0mliI5k5d5ZtlW0sH1lGhIKKrJD4Csd2qaTJ9iiBMGOuGb+GJX+J0rBLMSoTxzFf+Kf7+Pk7fx4jMlj0BRfa4Ps+YRgybG3hl+bezki0hXbUppPGUrRjbRs4vaQl3PmGzzPPPIPrtykWCljS4kJ8gU1lDaQKYQGBYibS1959M/o6Gx4e5pWvfCWHDvXyBufb8zz4m/+D7jr5ZpdqbV0CUhepOAyxhIsK1ub1qDAktnRo3omVE9jJdkI5jDRcqt4Uk8VJzrfPs6e6B4A7tt7Bu3/+g0z/1/+KYzq0whaO6aASULGPsA1kGOfZLaClPSEMrDBhJWlh2Q4qTvKFaHXdOq7nS007UwM/H/fGWeoucX7lAkkq6ZWHHaQAu6AZqZnWDLGKuWX6lhxIhXYHO3GJ+o7Jszy6SZdlfxk/8bFcD0uCocBJGalu2EGZesENRcSJpeO57CP9BBQ0l2tcOXqlngMXtnj3+TcjfDjpzbDyCos9v34Hf/SOP+M/3PQfEKaW9qSCIVc//JQ0c1YmljGWsEjMhIJTYXLnbrxymcg0GZmRdO4+SGRZ+PVlSkOjYNtYKZv4omkNPncN76Lur3CmeYa37nkrhmvlyeb9ZRz1+eXop3jfde9j5Il9LD0bcKx+jMuql2EOVYjTh3PdncYuGVS9qs74kmEq7YUbSntGrHfl3eYgcN9S3kJY0F1tqxmpC+0LlO0y+0b3cbx+nMXuIivdOn6jSTziEKRAoGyXmSxOslfuoGG1iRo+3/rYR+g0tN/mzJkzfP38DIFlYrWSPDl+e0V77aaLmpEyhMG+0X0DQEoIPRMx69z79rlvc/vW25kuTaNCgVARpw4dpbHYpR21c3Ys7MaU4iEeuvAQoZJ0oxi50GKmUuDyym49esi2+PqZr/PNs9+kHtS5duJarpu4jtnZlF29vo5pGpw5c4a9tctY8b/CDRf2sBS5SCFBQL1e5+xpLUkePnqMqYkJlO0wPDnN7PEj+ee41t6LqQQr87NIKYmiiKDdplIYxxYOSSPMP+/lxi6GqWJIePHCzUxOXo0VKuY6c5R/9qfxXYHsSIzAwIkmiYRAmhYWgvmFWQ7e/VVaNS0NN6KEeGiEkqzQbDY5fPgwSZJQO1qj2W4SxzGqo3DDURpKUpidYWZmhieffJJ2u02r1aLgDVGt7WeoO0mxU+XBU4/gJZ5mSIIh7PoynU5XxztYNuXpnRgSmjuniMamKYyNkRQCIuEShw4iCogrU+ArLh+5nMXuInVjiVI8zP7Fm6EIt4pbB67Thx9+mE996lN5xIDdtem6XeaiOQSCXTt3EYYhp56aZ5PcBhJMYfKy5GX5e9Rm23jLI1iRxcrKWi9ixanwLyf+hQ8f+jDdbhfDNBCeIAkS7pi/g/1nNuNGBfzyHGcaT3L12NUIBbYqMOqNct3EdezdupfW+RbbF/S1va0+xeUN/ZzutJrUVIlTp04xNDTE9u3beeKJJzh//jzKVgyXh4n8kJdU38RYx4HIR5anaLY7bA3HGZkfwd3hUopLJEGC67qMVNNZrJGLMmP2jmj50CvbDCUaiDaOxBSiMm7iMu/DQjuiVCrxmc98hrHmOK+vv5Rd3d104g7NcAVv6DDbno2Ze/gAp5c0cF1eXiaKIr7zD3/L7DOaXfJNP2ekCGN8M2DZvJc7tt7BV058hf9033/iN+79DY7II5w7dw6lFFJJgkYTFHilMpfquesSkLpIJVGIbTjI1QltaI/UYrzChw59iEdmH8GIJgjCHSSmS6LMvHNjb1XfNAWrwL7RfQADHikVKUgChGUgAzkwKFgmMYbQO9p63MRyHEiSXBpZXXvL+mEwbo0O/HyiOMGD5x9kpn4Bu2hgOLB5aozYNqgnyxxfOc4D5x/gmrFr2FzenHc/NeMmkePTbfQYEs/y+MaZb/ADn/sBZlozFL0hzEQx7U1gmFaebI4J109cT0u2+I1v/n841TjFU0tP8cXDXwAgqHe4cuxKVsIVWlGLl81fi9lS+CLAuGkYo9iTP8zhYYyhIRRQ8UqQlKl3ktwnFIUBphK0ujWufNEdCMPASxmpYl0iIsk/nzjAY1OjjA1vA9fFtDWQunn6ZkBLBmW7xExrhhdvevFAIGd/hacb+EfrANixS7PR5Xj9OHuqezDKFSJXg9y2M01pKGXP0u63LiGGjAaA1FhhjD977M94ZPYRHKlN393mYIPDtso26nZEPWnmYzSKVpFm2ORHvvQj7B7ezZbyFh668JD+3laWUaagODqaJ2aX7TIThQm2hlNcKC9y/MJRHvmXLzBz+Cm+8IH3c9/nPkU7ivhXM8D61kmG3CEc0+GWTbcwVZxi+9B2tlS2MO6N8+LNL+ZV21615ty84bNv4KWffCnP1p7llulbkFLpgbcyZPH0WQ584+wAIxV0Y1TX5PDSYWpRE99PMAyDhYJD0GqhogjTdvhfj/8v7th6Bz+278e4Y+sdTJemmYz1ZuGbp7q0gphms4kjTW46djVJN2F05VzegZlYXebmZzGAmbl5xisllO2w/ZrrOf7dh/Pj3xLr+2Zp5iyf+cxn+MpXvsLciQU2jen7Kmn2pKZtcjO2cBCuh2GP0hwfJ+74VN0qP7/rWxTMImErxJEOXnsTlmWhLIuRrdu4+o5XcfDuf+XvfuHfIpOEtjJwIp+iKtNoNIjjmG995cs8/q3H2XlsJ8vLyyR2gu1XceIIc2WWkcooX/7yl/nwhz/M4uIiDg5R5x6SmoGSPoWzFQSw/V5FZAVYMkR2Fe+9871aTvcDXtTZTKUeEVareKUKjVqb48NHSeQ+ROgjXQOBzd7qXsbvWSQ4fxS7XsZTBtXpzRw5cmQgZfzgwYNMTU2xtJRmIzVh3pzndFdnLY2NjTEyMsJD/3qYvSv7cQsub37Tm5menc6T2GuzHRARAsHS/GBIKZA/+55aeopDFw4hHIHlWiwtLrE53AzKYjQaQroBQdKh6lYxUFiJx6ev+QeuGrmSV1/7aqQrmZ6fpj6zRLVTZLw9jD/ToNlYYUkWWVpaYmxsjG1bt+nvTimELRguDiMTqTtud7ycrlPi/uUCuAVGDyjMgsm+ffvY4ezAkTae57FrSrPAMiogzZhRd5RhZ5jisMOYoTP8pBHy8Vf8E7ayOd9MWGgGVCoVjhw5QnWlSETCttoYftdnRRzkqvgu9j/tsfDkYU4tddg9UcKvz7N5aorScBU3bdCIrIjxwrgGUoBwykjnLD+x7yf49Vt+nRsnb+Tqsav582f/nCiKaDQaNIIGwx2H6tSmATXiUm1cl4DURSqOImzDRQVrmQkZBNRVSql25lHhFFKUSUyXSBpMFLS/5rLqZWteW7SKuUdKhQkqDlNGKkEmiiTNXlIyQaSUdy1uYDk2SLkhI2Wk674RDV7879n/HmZaM9x76j48z+Hdv/dSKlWPyDY41T1BO27z4fv+hldWXsbww4pyTYdVNsMm0gvp9C3sRavIdy58h7981V9y3zvvY8vIdkQY81+qPwamiW3YGkgZgusnr2dFtCjEHidXTvLU4lOEXe0vUI2Yq8auYiVYodVt4Saa4ZBC5QbKrDb9/vupvPa1KKUoWkXGl9/PYktPNH9k9hEOfeFLjN67QKO5yOYdGqwWhjWQspdCxm7bz0i5SGgZHDtV58JIBcO2+ctX/SXXTVyX/51xbxwlYN/YPgzHREWSbrc7cCzxSkCy7Kfn2aLbDDleP87u4d2YQxWkW0ERsXnoGvakMxdt09ZGebeIqSKiMEFJSfvUIu8d+Un++S3/zFd+6CtcVdEdUN1WhN9q8bW/+jPu/6eP8xNX/gQzoo7puNyx7Q4Aql6Ve37kHj77g5/lg6/+ILuHd3PvOd3G3K7XCDzF6MgUfqvFuaefpP3JB3jjrjeyabFMx1/mcfMc7rZdnH7yAOcOP4U7qq/XPYUq1Y7Le/e/F8dw2Dm0k3/5oX9hx9AO9o/v5w9u/ANmHp/hbXvfNnBe/MRnx4UCn3jjJ/jbV/01zXMXNLsqQOET+0sceXiWtq8DORuNBo89cx8qhvmVJYLUDzi18zJcpfiHv/hLjv/MeyiMTfKe/e/h91/2+7xsdgdXntIyyatHX4tQJkUpOF/vslRbIVGCSjxNVBzGlgkkCVZYJrabtLsthmyTIIo48c1/RWGwq3MNz3z7W7mUV5+dxbBsnnrqaU6ePMmpkyc58MBTOEIvduFyr1twMjUPxyMVGlbEkurS6HT5xx/4R/7bDf+Fn7h3F6Kr70Nv/kWMjY6CMHjFe36BV/3bn+ff/OpvIr0CfrtFYNqMuTZxJGk2m1x77bU88NDDjFaHcEOXI0eP0LV9CvEU5vkzgMGe6h7e93M/h20aPP3001hhQhI8hoybBOZ32HtWYaAYlpNY0qdYKCKVZNKcRMWKRtBmm7WZUqI7h1XJplVvU3eXaY5OEFbSTDJhsLu0G6sW4tWbhN0uRuJQWtyClJKVFc1oJknC7Ows+/fvZ2lpiYceeojWQou33/h23rn/nRiGwdDQEKOjo7TaDbbbO6FRQPhFTNOkXq8TdCL8dsTYXhehTD0tQSmeeOIJkvQ7GnKG9FgiMcx//8Z/p6EabAsmuXDhAtVqlZnSMNWkQGx2iVSXOEwYcRJKsUv8uQv4R2qM3JvwP371f7C7vJW7/vFLWMrEFQ6Hv/EEnXabnYm+xkZHR9llTnOjt5dyuUyxWGRvdTcyBY9edxsdp0JSqJIoxfLCCq++8dVcNn4TUScmCiMKRY+R4REkBlPWMHHB4Bvf+Aa3Nm5hqFzMO1qVERE3NIN1vhHSCmJK5Ur6d0wOWKcwpULOSUJmuOak4PCOJt1anTPLbW7dNYrZWWJidASvVGb3/utAKa4y9mIZFq7rohCMlDcTzL2Jy6v7efPuN/MjV/wI77763dyx7Q46xQ7HTh9jOVhmKhxiePLSIOPnW5eA1EUqCTUjtWaKJdojVVMtPNOjYlcIwxKO55IYDokyKdpFKk6FPSN78tf861Oz/M4Xn+Ky6mUkKkmBlMTeNI5RdFGplBSnrJRMIqyhYdSPv4Wjwx1MxwEpc2lkzTGlr1erJKnp0jQffcNH+Q/X/yqjpRFKwy7u1m3c9fpxTndPsXdkDx+3/oLXPnMjwbfnuTK6jIXOgk7dLsQDjNRPXf1TfOpNn+JF0y+i6lUxhoYo3nYrnTu/TvGGG1JGKkCYglFvFFUQXFO8kpMrJzleP86kNU4sEsaiYXYN7aIbd1npG48hWfv5hKkjGqTSAaUT5SKLLT0qZ6G7wOKFMxSeWcEoWlhS78SKm7eitm9j6dwZfvgnf40f/qlf4dU79nHl9TfTcfVct1dse8VAh9a4N86oN4pt2AjbIA4i/uRP/oRHH320d03UA+K6r/05gSBsS56tPcvekb3YW7fCyCSJu8yEO8p4KglbQh/TyMhm3JEh4iDhmQfu5eH/8XFmPvsoW8pb2FTelM826zZDnvrW3cweP8LBu7/K5tJm7njbv+dH3/yfsQ0bpRSPfvmfqTrDbC5vpuJUeNPuN9GKWmwubcZfWaHpBIyNTNNtNTj0zTtZPnKcd+59B0NxmTYNuoQUxic59cSjjG3djlPVbEz5sr3U5y5gGRav3/l6XrblZbTqLZRSGMJALSkeeeSRNfPOhIJbH61gz3cZW7L46gf/mChIsB0TVADEOJ5P4dgmSnaJubk5zi0fI7Ka7PX24dsadIxu3oqzfRfzE+P4P/LrXPaZz/K+69+npcNDK1y46xBSSrrNDq4YoSRCZupdFmaXcESVgiVIkoTiq3+CY84+Cp2thG6NijVO2dVg/aY7Xk0Jl243ZFd5P8e/q5m8C+fOccbdzNFzM7zuda+jXq9zJjrFoUKNhXiOsNbmnnvuwfd97LbJYXWSYmkSEOyv7GbRcNhW2cZEVCVotmittJDCoCoDXK+AkAmV6c2Y0sad2kxz+xXMnDlDZLtMjQyjlMKyLK6+6mpiy2asUsF3fQ48dYC26OIVbUS3RVSYJlha5gt/+Nu0jp2gVqsh0qkGSXQazDpOBJZSxJVhvDCgVBli++btvP+69/P5132eklVgSAxTLE8w4Q7hjVfoNlq0vSUWKhfYUbkepImIQkaTEbyhKxixdxPZLSIgPu0xPT3NhQvaBrC4uEihUGDHjh2cOXOGr371qzz11FNcteMqisUi1WoVwzCYmJigFdbY7m5lKPY4d2iRiYkJFhYWqM12cKsuxp4SE+MTSClZXFzk85//PLOzmiUf8Ua4zXoFL569gyvmr6BDh1tOX04QBFSrVRbUJmwliGmiREJzpYVjxVRwkO2IBz79DJ3vzhHPd7i8Nsnh7mmmZBV7rMJTp5+h7JX4caUBjOFVOPpok6vrW5iYmOCKqSuoHYqRQqBQOLGgKCLe99prCHCQpSEWnnmST//Fn9FqNvGDLqVSgbHxCYx4C3sMFylCzp49yxXLu5i+d5oo0Bs124xp33sCL7GZa/jcbNkMMcTk6AR2N+CIeYGyGsVetBlrnkcZBvObPFpLS5xa7PCinaMMxyuMLrh4hSFUNIklBT975gf1ZzEMpGFTqVQYjl7DSmdws/2bt/4mbtHiI9/8MMtfOMre7haq05fM5s+3LgGpi1QchViGC/HaUEkVBCzKBm/b+zbeue+dhLFiectuosIQjGlZ7yOv/whXjfa6Ws4sdTgy1+TK0SsBuOLZaaLZNvbWTQOenChlwFSSYFWGGP3VX+GcqmHbDuIijJRKF+L1JCkhBDtKO3FcLZkVikN85soGvmgzbJUIjtfxj9RQYcJWcxOnm3pAqFGUA56dncM72Ta0Lf9vw3HY/jd/w65/+hQTv/yrTLarhGEAlr60rt9xI7cOv4hTjVMcXznO7sIuzjsL7BBbsE2bsl1mabnXTSiF2vjzKT3wc7zisNgMee3O1/LLN/4yRd9COSblTRPItgYvheEqNb+NaduURkYpv+ylXPaXf8n09TfRcXTA5+q6ZuwaLh+9XJ8vx2QpqmPbNnfddRfLy9rPkjRCiBVJMyD2FSKwmCxMsrW8lbA8ibH3KkZeXmTIASeUxMs+pmFiCpPx0S2Mv/OHiENJ7cIMU5WdBEtaenvizq+wcPoEhiHwWxHPPnAfL3nHj5PEEY2FOWqT0yRbtqXXh8+3/vHDdJs9D8lYYYy37307L978Ypq1JTpuQnV4nNbyEsceeRDb9Vg8c5oyFWQQ0xURyi6xMj/H6Kat1Ot1RkZGMF/+CgSCdr3G2/a+jd3Du/m7v/s7/v53f5Mo8Jmbm8P3fe69914efrgni/1/rvoVyuYwM888RbfWoNgpEQUJlmuCDBDmMIc3fZnpJ/fjRsXcSOwXZ7nc2Ycdm4xu3opfGscvVwFon26i+iKjvJZHRzrc+fF/ZaVRxzBGKIqImVqX7nKDPapK0a1gqYQb9+3k6XAcO0p39cEEpUIBEUdsj3dRtorEewrs3XUL3/7kP9L8znnaC/NcKG+hE0bs37+fAmDYBQq4PGOfoFFf4Z577uHTn/40B6JT3F84QeSNMCGHuKl4BaHlcPToUT76yU8RF7XfqUaFzUYTZTiYStFaaTL7x4/ywNfvw1CSu755DyIOqVZHIAywAkX7kRaGVAxh4Q67LFxYoKN8ygXBmDVGvbCTC0fvpzE/x/6iTulOOk1MexgZnQLVxk4UxDFKCAq1FbxyhU1Tm5ifn2d5aZkRq4xAsHX7y7jM3UljpUvcbfOW+h3IYRe5WMKIS6gkYOngWURhBGGV6JRPEjptXufZjA6Nc+HCBVqtFgcOHGDz5s2MjY3R6XQYGdGM3dKxhPppyeSIziTasWMHHZa5MLvINqPA8tNLTExMMHtihu6/nqJmSj77+AlGxqsY0uHRh/XcuRNHTnP6ySVese0VvCJ6F1bDohSXcJVNMdESerFtEnVGcFUVpWLsxGX+7DyB8BlJvYtXdPQzsv3YPFNDm3mVfxubk8u4ev8NnI7mKPsOAZpJPrEkcea7GJGEpkPtfMh3v3mPfj0JxZKBIxL+zU27CAyXyDBpnjvNs8YmkAmdcJ5ipcinHpvl9uQyqrKEEE1mz12gHfjsanlU3RihBLYTs1xboBoW2GRb/BvH48anR7h6fgo7bBOIiB3RdrwVj8lOm2TzPvY3bmaxNMqZhRWusATDImD0tMtUcDVHH2xSNctMtas89a2v0z68RJSYbJ+H24aKHJ9voRJJcEY/Q4bdYV6vXsq++m6mny6y09/CtvO7kJ3nN4bq/+11CUhdpOIowhZ6F6vChMY3z+IfraX/HbIYr3Dz1M388o2/jB8lnL/hZcR2gVjq07pvdN+AxtzwI5bbIXtG9mAKky0nhwhOrGA4BsIy8mC+zHAuZYJhWox5Y1pmsxV22OWeD36Qez/x0TWp6ypKwBLrAin9vhLL1sc2XZrmhqkbeNPlb2QkTHB2DuHuGgZTsMvdweHjh2j4DeySoNMI132/1dV+dI5bn9yLpUw8Rz+4jJLNpBjj5MpJTtRPUFElusMxm6SWkobdYeqNHiOlUHk3zeqSaV7mRNlloRUw5Azxmu2voeSb+G+/gi3XX53f+F65TNBus++lLx/4DoYnp+japp5/tqqmS1NMlbX3RjgGC8kKu3bt4uabb+ZrX/oqC595hmQlwBhyCBa6KKmoJFVeu/O1PPi543zid75D0I151Z6XULIsCleO8vhHPsfpQ0/gmA6bS5uxHJMoTGjOLSJNl1rSJfJ9Dt79VR79wl9TGjFp1pZYPHuaXTe+iE17ruALH/h97v7QX+V+Hj8FId1mk3CmxfJnjtB9aolfsd/De/a/B9nyMUoehcoQpw89QWVsgsuvfDH1+05hK4e5C3MooVicDTGFxZVnrmN5ZoGdW3ewvLxMdWqa+pxmGlZWVvB9n9nz52kuLTE3N4dt23zrW9/i8OHD+bl7beV23rj1Z5l/6hjylM+1xTsIuyGWrYAE4Y5x+/mrcJwurWdmWZy9gBNKAneRF3m38LLJt3H7LT/G350uMJ9ebg3R5cJjZzlwIJ2XGBmcrAQcPnKQRrvGjqBMRQScnV0gDLvsiIfpWpq1vPmyKVbCGFd6DDsjyKVhRiplNkdDFJY9RjaP0/R8Cn6Ry+wbWfn8ccrGCJcPKwrL81iWxYRfYns4hN/1qRNTbzYYHx8n9EOOGhe41h6lEpfYJSexYxOrsczdd9+lA/K3XYNjOyzGDkURshw5WChqR+e4K3qM87Pn2SwjarU6W5YjQmVixCFl6WGcqPOa8FqmmiUmxydBgWHY7EkS7ph+B2fcK2jXzrDz2huZlBqwJO0a1embqIiAUmJQFRWk3yUyFlHLbbxymcnJSebn57lw4QJjhh6kXDIEQ22XY7OnsOwK71x+PQVvGrVUZHP3ciQhhw4eppK4VMMW0oy4Qk7gCkExLnP+/HnuufMbHHziAJdffrnuDisUeMlLXsKbX/3DPPX1eTozFuLMNs4stgmMKrHVQgZ1ynh0LrQZGx1jfmYOc6bFskyIgy612MSzixx44nECHO6/8wBf+Og9zBxZ4sjJYyRK3+cjSZnlbRptewvw4y3BmBqhhMcoRRaPzVIz2myix3IrYOWJBQLbZLnrcDx2uGrvTiKRML5lkkfTZfHsTMx2YdBRiu1yJ35jkl1BDQeLA/Ysp+1jlItD2LbNaFWbxl/xjl/h4cJVxMIhMkPapsU/fuMYewyLrj1CLEKSOKFBhy/iU7JihlQBYcfMmiuM2KP8TNth0jA4N+Xy5K4R5kQDzylyvRyhmpTYr65FmQZHpo8jCmXe1DlF53OPI4wCv1s/wHZrK1tUhbfI2/Aocv/HPs7ip55lu3Io1RS3Og7HFlqce2KOxQ89iYy01WC0VWBFdolIGI3GubN1gE6yNoLiUq2tS0DqIqXN5nq3I4OE4OQK4YzugpJhwFxcy9Nfg1gyUXZQsRowjPfXSjdiqR3imi67hndhtSzCxS7CMRG2kccEZK+XMkIYlg5l88aoxdqPUKqOsnD6JP/yF/9j4P1VJDGL9hppr/d5JGYKpIbdYT70ug9xzZar8KTC2VJh9Mf3MfTKbWw1N/PSr+3ixv9/e+8dJ1lV5/2/b6ocu6qrqnOanPMwDHlGhoyoCMgqi1lhjRt0ddX10dVHd13U5RF3DairkhQVhCGNDDBMZnLsmemcu6srx3vv+f1xZxpGjAgM+Lvv16te1V331Klzvufc8/2cc0/Y0oTTq7xo8vPvo9KbwVt0ogqVGk8N92zvI69A2AhwJHmEyfIkDkOltqGeesl6/h5yhshlnj9yZWF80e+d4HjqjLGIV2OiyzpANuaqxV1SkGp8KF4HRt5qYAOxOAvWXsJ5f3MzmVKVwZQ1hB6MxSmFQ7gXL3pR/PnJ1NQqNklTGJOy1MUTtDS30X+kk5/tXQ8SmEFBeaTAak+VuWaEc3vnsOvxXoQpSI8V0fJV5BoHGSNJ+vgQ4709qJLKmj0LURUJvWJgjpU5qg6x1d3HQOcR8qlJSrkUTleS7PgQihZBrsrUz5iNllc4e+0N5E+u8jo1EvXc+iNUh3IUdo2SfaqfzMY+XLoXd1nBGfTj9vlJjwwTaWqhzZiL+5BGycwjVGuVjzOo4VED6A6TgigTGXLSNzRKKFFPaniIg5sGOXbo5On2Ti+55Dijo6NMDzaDCUO9A+R2Wo9ciocnUCSFXPco0riBRw2QPzhMvaQjJBXhcDHfmEtA0dnzg28zMtCPlBlDlhQ8R8vUudsJSnES435KpozT1JiQijy1YQs/++WDpPIVCsKkoOhkRBFVN1hlhHBoPiq7H6ZEhajpByScOAi4HdQ5Vdb6Nd6SXULE4yZshrnIXIzv+lYWnr2Ep/dsoWdygJg8neFiN+WaRWimhjw2QDY5zvxiAsdYmtrmIHkTctUS0UiUdcoSzldmEmn2sVqeQdTtRxQN1GKekZFROkIx5hjNHB/30iZ7QFZ4dF+Sqm7wzNbtDKtprg+uYZbWwfXGalb5zsU9NItczTSC+PClTZqJIQ9IOPZYK8uuyq2ipiozUU3yfleE8xv/lnnTLyAke1GFjKtcYUbtIs6qXUM70zgrcgHOgRMsmTcXTBO3L4DmC7P1YBf9A4NETD9Vl4q3ahAuuTGEQdA8Ka7KDdQ5Zc7XAgjVYMhMMl00cKXjGjrUGKtLc8irEvqIi97eXvYfOMAVkdXE2maTKVY4//zzmT17NpkhB9E5YS74m1mkRgo8csceOv/7EFHTT05J49J9+F0qY1mN3tF++swRsuUqyxIae0cqzIwsxld24Ks0UnKMkPTt4567/xfDPETIqEFTXLRW6hkrWZ3d+EUzWGeqNBm1eOQEAeFm5EQvZXRipotBYaILwagQyKkSRRmGVIUBWSERj1mPHmfUM70txuxSB6W+CqYiMVoxcWRkxnv7WVC7moqkc0g5ginrnD3nEgDmtMRRhcbQowPc4PFQMGpBljgykuGNjTW4El6GAk68ehi/6ccpOcmEDQypSlh4qYoKI2KSTMZNmyERNSW+NjTBYVlFSCYufxA3MpJiUtE8RLQw7xy5nJWVFhxKlmd8R5k1u5VbL6yn19XLCq+CIcnIfgdtvtWMTB7HTw0dre20SQr37eznv+87gKgYPPK9X3Pbpz6HKwmKS+FnoQ0cd1dwCy8V6fcfz2TzPLaQ+gPolSrayR2cRUnHLFQxT+4pJcplRqpJ6n31CCEoVQ1awh4koFr63UIqU6wymbd2gH7rjLei6RLGZAnJqVgjUif3Fzo1IiUMA0Wx5tcsiS/hufwBypEZzD3/eqKt1zJ07Cgndm2fil9UTWSv9ieNSJ2ibWGUxkYfSsiJ4nOgBJxEjRAuXaNlKErA7WRypMBwV5p8Pk82m2X9+vU88sgjHDlyBF1/fmuISm8Wd0FDQ8HAySd+vpcDkwXcFQfvnv9uPrfqc4iSQUfbTGKmdbRNjauG/Av2i/k/53z+95aHENZCrECmH8cT3+Vrjx3FyBUxNFBdTmSvxqHx45RKJRwuN/Pf+m5ue+I4n/reDr77v9aoRrA2Tj6VojKRP22ejxCCI88+xWiPtceKJEuMKWnqauvYd3yAuRMaE1KWcTVF18BBygcmiDo81FTLBDdB3FsgVuNCrhgYTw8wLg2y99n1uFUfhUyKqBmm/oQfZ9mw5g5lVbKeMmVJZ/uWLUSNempq2nG4q3j9RQJSMwNf2Ur74nMJtaxiZFynfLTC4F2HKU5YQurQs12UJ0pgCCq9GdKjk2z/wTN4yyqeUBjVYY26JWrakAsqVSoMG6OUNQ2XqaEbJSKuVtKeCn6vH8egzPDICCV3kCe372LzY3s4uq8bp1BRvGEGevvQVI1pw2EWSg0YukH3th72PNGH3lXAFAKH6cZI6dbcs31J4qaEpDio9cQxMNH9WQyHi8x4ioXeFdQqtfSM9DFS6acwkKO9Ai5Noc2oZdhVZkIbRzar/Mtdz9CvpokZAYQKMRFGCLjCcw61ZgBDkkAT+IQLn3BS6c/yCeFi2BCIBh+Nfg1HysVg8TiBhjizZs1i5cqVHHck+bFSYUusQMTpoQ4fbk8D/et3EXBGKGodJP11CI9GnhJD/RWyo2XKNSP4o7Xsmd9PV8sYZr6KIy+QhURo1M0io5W1coKLq35aqzV8tr4NR1ZlrDqGFG3FHCzQWOxgf+EQm/MPEk9VkQsOHIaMEILx0gBhKUyo6EOSJOaLNjqdaR4tbuYZNzjUWvzpAJpH45LSTALCgU9341WDuJUAYUctC8PnsbLJOrTY5fOxf0zgruTp7erFX/LQXdUxB7N4cCILlfqih7RbwZEzmD0vgluWaJAjXFyaT1s1ikM4mZWtJYODg7qOv69Mc7kWRZcRYzK3/Mcm9ty2k4ZyPRd+fQtPbuzl20cG+dRDB5BkiVUZnRYhEcvMpmZsJSMVDyC455ExQtkantQO4KGCszDGkYKXaNXLuZVlXGc24kRFqrbiNWSuLK7mrPIsEhUfFaXK8FEPCJlsWmICQYfpp0AbqvByvNSHZnhQkTGFxGMZnWTJOjj48EieftkgKiuoqko8HqempoaOljALjRZayhIVp0rGAG+6RKDcT72jHYCZvtmcpy4ktitDNlkkjIuw8OCfLPOOisaccisIwd7dh1gW9KBGXOghF+lyHYF4B2ndSaheoShVcSs+sqJAXpRw6wGiLoVARVAT9/KV660tbRobahlocbI1uBMhCZq0euoqNcTkGLoUIZ3LkEgkKBfyjGt5nsnq/DqhMYBJh3M6R905StJxostb8HbnGRnJM13IFBwyhcNp1IFB8kKgu4JM6EVKssHKxGLC3hfvpWfzYmwh9Qc4NSIlFGHtyF3QMU+OeFSLBUyHQsgZomoI4lWJyMjJa2VjauXdKSrFAtXhbnRTMHkizZsDVyIjIRkC2akgaQqc/M6pfZskw0A+uW/QWXVnsTu1l2D9BSSHCgwdL7D2XR/k4W/+B99679/wyB1fp5jOIns1zKJO6Yg1ejFyYJz+rUOIqole0VE15bR0qZqCVKiihCzBKHtUGKvyuGMffdoINZqLvoNJNvzgEBs2bODxxx/n8OHDDA4Osn79en7961/T3d2Nni5jlgwkUyKkBzg4kqMu6KYzW8Is6Lxv4fu4etrViIqBGnVhntx0clHtIrSqlaYiFetIkJOUdYPcC/bwEgh23/ElpN6DaHqR7z3VSWp0lLJbZjyro3g1ns3s5+hRa2+gL/9sE5Nb72fBaI7LBsqYhonmcuENhBn5z52Ue1OWjU4c4zt/924K6dTUvkvj4+PkpTIN0QTHekcJqGHq5QgPsYuNHKPQP0nFLGOqZYQk0eRQWVquktAklJCTAe0EzSsWE090oA3IzC1Yiw7UQpVqRcdbDZBVyzSbUYaGRpgbWk3C3Y5EiY4lTiL+BIf0Pu79yb305ofpLA0yW55P5VCSao8lPIUoURwpILlUtAYfG+Q97EnuwWd4uXxkHZvu7KHqD/FEzzF+4djOQPYoe1yDlGON1Ag3Bb3EnKaLOV4dRwQSxE03mCbHx/KUUhX6jZ0MjfTQZsTQHS5OPNVPa6QRv8dB97GHqA1H+OXwYzy6/n6UUYl9lSH0YA2/knYzVhkiN5nGI8Dp9DEvNJet2hEmRJJi8wwKxTI+yc1MvYaklqLbGOCp9E7Mmt1E8eMsQM5Mk5HyaBUvxZ4jHFGHWV2djSpkPFWJbcUTJEZL5ESUnNCoSgW8OHHhYOy7+1GCTvZXTNTWIFFZQstpFNUcQkgc3DSIRw5xopJEcRxjvDrEiDpMHB/t3sU49gtcspcxpZ5Hh2WKwiBJmvaUys/Huujq6+PhrhLTz1lE/QWzEGWDhKuVN1QX0F625kgudIZJ1HUQyMwhoWss0mYjG9N5uhQh+rfz6PSf4MTQUfKGySGnxDsqHURzQZLlQU4UjpEVk5yreFhZOpt+h4OHRw4RioU5HncxVDHIHU8xYprks6OEPTNxZ6uokobfmaA7d4CYq40Tm6y6sqfLIL91nDalHlmYBEsO+iWJGiTwO5grNTPNjFBo9ePO60wWyqQkg5WVc3EWizyS289vvGVi1FINOzgmDFoVhbPKHaypzEPOVLnIdFGbqpJb383Nc+tpkFV++IlzGclW8CoCWcDWnEEKD7LpwBlwIgyDi4NhFlWmETfDRDxdqIrC2y6YjzGUY6dpUlzeyPLiat5hdDAtvZiI5KBOdrBw3mqSSgCtTjBZredn60cYdUh4gZJPoy8XIU8Ft8MaadOrgtrZYfrdViNTyOrMmRcldrKz+ta3vpVZs2aRBzyKxDK3kyzQUzExTFjiqccjuYkPn8PCxkU4smVc+SqP/p9t+PdU6WifTo2i4NcFs3U3l5aWMKtYpkPTUGvczGzwM6u2mZtvvZJZS2ZTow9T9gtSDh+6ZFBXbkB4nAQVCbcu+PR1C3G5XKiqSrSmhtYbF5AZu4Raw8/8QhORqh+38OGkQFtbG01NTZRyOUzDQcaEX3aOM66AJkmse9clGMNdjOcqeHWTWkNmidPJ+myJxVodrc5GskaF/v46HLqHmUYdiZYae/uDPxFbSP0B9GoFTXJgOgWibGAWqlOPjqqlPNFgPZIkUdYN2nWF4hHrsVC1YnD/vz/H8InnH1l1bttM/a77AMg+0UN2Y9/UtVOP9jAEkiyhn5xs3l5JUCes3aRX1a3CkHXCWoRCpsLkRJHbT7h461e/zXkf/gya00X3jh0kJ4ap9GaZ+OkRhBAMP3KCiYc7Gf/hAbxdaRSHzLZt204bSTJSZdSTQkpyq0ymJumVxzkqD+KRHOBRSI0WOLj/CIf2HyWTyfD2t7+dd73zXUwcH+bHP/4x3b/YQ7XDgSPk5m3xaxkvVrhhRRN7kznMfBUjV2HirsOYZQM16sYs6AjD5A2bF/CG9FlUVJ2fOp/h+3f/cGqk6L82HGPx5x/lb7+/jRNjOSS9wuTxgyS3bwCgrjjEo/fcTU520NsJumZSFGV6e3v51P37GBsYwinpeLVuQkKie9cwQgjmz74I2ZAZ2mLtDj3QeRhXop6FF11GpzHGgQMH2LdvH+1yAsWUGBgcxauF8ITDYFYR5QL3SLt4QGxkq/cEW9VO4qabjJSnVpVxNHjJpyfxtyRwGA5iEwneX7oeADVfZXJojLAzQaaco0WNkStX8KlB3HKAY4U+BgcHCAdq6fGkGDfSjMoZDFlwzOgmpcgM9I5QCUapuHNUJor0zy1zn7GLcTWHv+rE7WrFWXCSDPZRTbSxpm45iqawl6NMqNbWDWVyOBUNykW6S0M8PaYhnCplyUNZFFhjLCKaM6iUM8w0GqhKJoPOSdoqMdLGJHqlTMjhplb3oLuy3KdtYXvgEMe8BQwEG9xH+ZljK3uVLvCGKBtljshDXFhZgGTo5GWTyXwfzZUwebnE0UARDZVEoZ1L9cX05o5RVH0sqE4jkkvTKI2yoNJEQHiImQEGx3cwYlijh4pH5Zh7DtnyOD7Ng8flQXYoLH3vIg6rBt8aHMNdqKLmVEY0J9/68EY2/OgwO55IoytZZHOS2XPnMynncZkeWl1tOE03eVNH82n8103nYogKg/owbqcD78C9jPX18ovOPNWBBo7tj1BB0BBcTr0RIqBaE9z9hotUyUAOu5FyggZHhPYlC+nJwnd6x/h1zyDCmCRbUCgIhUMVOFyEZ0Z+Tm8xw/rh+zguwTzhYudojlbzGJdeuY76mIecLlAKOgWnRkafpM0zE92nYbhNIlqEI5m9bEpvIjRqUOfu4KrsdK5KCVZdeiHzpBY0WQZkpIQX74waVpbaKGoemqeFObfWjzxZonJBM02Lmxk2uhnyVNgdcKNICrEGJze/xVpEk6kNkBcBPCbUFAzcQMGvcVFJoWVWmJqgi/+5aRk1mkT/ySkHwZg1BzIc89AWcpMbLuKWJVpKrbhFiRlmPTevaKFZknH5XegBF4HWGlQJjhuCpC7QBezbmcM70MIFF87lrW+5nPmyh7OWW1MtLqzppqYmSNTdSo3XErZlIahvC3LDexZiAqWyyerl9eQnywhTEA6HUVWVQk6n7NOoM0xGMqPImszhkkmrt5WMoWMi4ww5kU72ledoEqFgAk3uoKDK6EIQUSUapBqWaDJquowaceFwqDhOPhG44fKLmBwfISPyXL1mMSuq04jlW1l0tXV+qgAa6/xIkmQd9xIKEQ+4+I/LpnOB6CBQcqIg45Q0pJ5NXPeWN9PW1kY5n0OvasiazKywl5VL6nA2B4h2tKBXKxzY3YVTgltaYwSrJk6hciSzi8WRNZSMNOfEm5hwdTFXb0KNuv4cd/n/a2wh9QcwqwaypGBoBmZRR5SMqZEUvVyiNlRPtWxQqpoEkSkmyxQka45UaqTAeH+GB277v+SSE4z1duMqpQlUM0iD+am5VmAJqVIpRzXXh8zBqREpt3DgwXo80xRo4mPLP4oDJ4V0BaNo8MtdA1zznZ1ce/cJ/mVkOpH2eQz2WKMxoqRj5qoczRxlr3GQSncG33AeqiUeeuihqYnCwhAYmfILRqQ0BqQkCjJjUpbkuM7jWhG/v0y1VKKil/A6g6iqijqqc/HoHGbWtvPzrif4VWoTWtiNnDJIlapcMi/BiVyZaq5K6WCS4u4xMASyV0NyKlSHC2g9VWYWW0n5yrhwkExNTp01tuXEBF944zwaw26+9tAenCVLmJp6FRSVc8zjJA/uwi+aOWf3Sp5+1BJGnSe6eezgCG9p9tChx+mqjLDDI7H5/qP84qf7meZciK7pFI6NnQzfRZehkioU6PIU2bl9G89ueIJmNcrmHx0iP5bEp4bIVyrovd24HF6K5TFSLokrKss4oYxwTBniPucWnvFt5u6j68mnU7hjQQrFMjuVXv534nE2eA6QmZgkWeokpVYxTEHMFaWqKghJoiIp5MwKx7JlnB4XI9VxioqXoqSycPo8dnOUgUyap9OHMH0hSrVVJlJJHty/mdFkP1pVsLBUj+kJ84BjJ61ShLfra6ifCBKNTmc8EkSUKyjlIqOlEpFghGeUQxSlEo3RRlw1LrzOIA6hMjS5l+VGM7NGVSKmj7XVBdSYPmr7NPYPnaDX20Jy7x4uKM9kXXEBtXlYlpjHfL2FxpxCVtU5rzqXg0o/k6Eg66VdqPksNYYHNWeVY6YwjOkQ1JthTCGIGR0slmtJV8poapntjoXouTwz9SizxqfTUg5SkgTLs3FEqYJhDmEudSLv+wm3v/tChlPdzKxvZWasFfeiWmIBF//8+XMxaj3s06t4UBgOLaPS5GFbi4I0JlDw4C034qlYj5r9vjA+xU3ZKOIIe5jeHKStrgZFkag6NTLBbgxRwWMUuOLsOfzsJwc59HAvVUWmyR2mF6tOTVatx68jyTKz1jajCZWA5GGu38ftb1vCA3uGmF8fQ5hJfGoUSVMZKpho0XoqQlBVo6iVAu62IAKIulOookTH0pV89OKZZLA6G0pSZ+5Vb8KrqMRX1OGOB63OnWyQkgqoDpVVsavYnOrDuLqd6cvbOTu+CNmtkUuVCb15OsGLWwCYMT9OqN5PAzL1psTCVY1Er59NdO1M3nTJ2XzuncsQCAx5kkC9H0mTWfzhJSz5xAoKpqBWhgIS05bWUT40wdyBLOlHu/E5VWZ4nVDrxht0EIpbbZoScKCenBfqkmCs4OXGK97G4lILhU2DaLVu9KJJIV1GNPqoffd8ovV+JnRBijK5ZD/XfXoFoViGvl/ehqplGc9mMITB7qd+haOyn3p5Hg2R6aDJVEwIJ7w4GnyMhi2REK7zIknW3m2nyKfLFAIVZEmif+heQnGFolOmaGQpeRwEY25cJ0VG2RT4ZYlj4yVGuzMcz1bprAp8ijWSoxVUhncfJm+kUTR56lxTh8PBO9/5Tj70oQ8RjkVYYLQwe00L05cnUGNuSi9YJT5t2jQaGiyBmBzoB7/lttVaN1qNm/YF89i1/gHAOtKoWlGJNflYJZzsPJwicFkbAonG2fPp2ruddMTNqoECueYAHQv9HJx8muxa2DFwD8b4EB2BCJqkoEZ+96IfmxdjC6kXIIRg5/puykWdQqZCNadjYGAoBsaktXrhhXOkYto0fvTpZylVdQJCwqialBVAQLmgM9o9jHbI5JE7vslYTxem7OQKKY9cMjAmSlMbu8lOhfTECDJQymyemmzuFg5c4vlewezYLAzdpJCpIAHrhJs1wsXez17M2/xBBseq6OrMqfDV0TwFI0e/PIFjTg2ZkAvzqDV5eOfOnQAY2QqSQ0F2WcPbskdlQE4yM9hE2TQZ6TvIm5w96OoY9UaEaCSGmXVhGiY9T/eBBNOTESRVJpPNUvKYVCdK5HWT1oiX8xfXUc6UGd09gkBQUQ0kRUbxO8hvGwJZQkam4oOQ6aEunmBgYJChdJF9fWnWzIzxkYs68J54krnVg6jxRloXLaVxxiwCmX72xVfSGHkT60MVjhwaIGoGSE8meW9AJjkyRkuwHqfiIFlMsUoozNk7yTFDZ38xh5yyynwimcTpcHBP16N4kOnq6qIqyWRHRtGH88wpVXEpXg71n8BZynD+hecguzQkU6dWBIgWFbaqnUyXGzlHn0VZ6PQqXr63/hF+7thKFZ0rKksZqOr8bPIJFG+OR5x7UUw3hzImTlPhYccuuuQxnLogWvGwvrgdVzVA0VHPsOnjR90eih4Xh7UjxPUQLZMS7WaMbeY+HHqBmTWr8E9OEpEDNE7oXFBcynKjjYopIybL/LrfjTZmoBZ04tU843nYW5mGGwfz1JX847kzUYNO2uUgUTPM8eIAMVcLYdXNmD5JsxnlgtIsVCFTqfTxlve9l3Ilg0vxEVUClFODJCIxFhmtiIl+avMKagWCeAjKHub4FqAOdyHJglrDOmstX9XBX2WOaMQ9atIdcpLQZEarZWTKDCVzZLMHmOZfwmpfI2WjjOJxkK6MkQo1IrJJuisHMA0Dc/AEPfkDLLt5LYtuOJfAGmuSdq3fyRffOI/mKzoYlCRmeN28cV073/7YapxeleUdF3L9u69keI+OLFQijTGEEKRrsgifC0/AgSRJhIM1eIowvGcHsqIgqRqfftMyOiSNuqqEJEsokkTNCmsVXbJqrSTr67mdgc4HKJol8kaJsf4c582o5ZGPnkfw5IGX5167kus+vRxPwEF9cxDNs5TmjrloDgciCgPTw+TGtjL7nIuRFYWIz4mnxnJyuaLBgDXfH9/iGFrUa825dDqIhcIUFsd5ePh/Udv8DI+Veex7B5CjLnApyIqMp9GHEnQie1W0Oi9qrRt9ogSShOy3JhqvfOO1nP2Gtfj9TsrBCoOTx9DqvcRuXYSkynhDTqqaTEvQQdYwKfs0ako6jiY/hR0jFPeP4yzpzL6inVDcQyDqRpJADbuQizqXBlQ0WSJlCAJL4gTWNJN5rAfXtBC5VJlcqow35MLVEcJf46JbwJ7cbxD6FiQ5zf3/93Moqkox+QueefS/yRlF3vKpzzPe8xjZZAbNpaH4Hcg+lUiDD9mlUmy1Vtl5/A78ERfZk5vsPvqd/fQdPMyzW+8gWR2jaGTAPIzLU+BQZgdGY4i3/NMy4jOtcnbOj4IqM1jQSQ0X6KsI0icFiOzTmDlnNQFnlCfv/z6GXkRWnn9UFolEcLvdyD7Lzu2rrJ3EnQ0+ysCBp55l5MQxrrjiCmprrVXOycF+tFoPQpXpT5bIVU1KhXnsWv8Qhq5TyueoFBVqm/wkB/Oc6EyxddMQz/78GG2LL6SSfw7PG5p4zlvmhAlm9RiqswY1OAPZvYjJwUeYp02jUF/E0WAfD/OnYgupFyBJEj37J+g7mGSkO4NsylTNKgYG+mQJNBkjX6U6NoZcrBDW2ilmqyRHinhN6waRHDKSav1d6RllXvgcsv0THB8awV/7Bj6ozqTgtARU/uTQ8PaHfs7EcD+q4sGoZqgUS/Ts3IWGZp0gr5tM/PQwsm5i6IJCxhJ1S2QHM0oy+3/TD/vS+MomFSxBNEiRn/7qMHmKlKUqT5oHOexNM2mmmVU/jdHRUfr6+jDSzz/WAyiaZQblJAub5jIZGKbFrGFQmmBY7WO2maDsr0M2Ivz7D3ajH06yyQWRlJv3rf0b4tE6Dg73Q9nA41ZRFZlPvWkBDiTME2k6E5P8TN2MYRjIfo3CrlG8K6zVe1mtTEB4qEvUseG5w1z3hSd5b8rJofW9dB05gNMXJJd1kwnHmbXmJnw1EczsJDdftIRq3qB2WoRNSpqA6UUutzE6/ixj+QliC1vxeRJMSEcZjGXpiTn5sWbQlVd4wtXJXV/9Xwo5GEiFuMa8gOyoiTAFEwQYTx8kLGdJODRKooiU7EOVYd5ZZyOXi4iiTsnIo2ZzVCWDrJyg0YywfdiBnM8w4pvG2ZVFtGccBISPRSvWcJZvDnPTQQ7qDZD34q3xUiuCZCjQr03gyFZYxyqWVztQnIuZO1jPtMASIrITXzKJ4S0xXzTh9LQwzagjKefwDpxAHzExU/14VT9NZoIJw8Xu6QEOFw1MIfin82YSkZpZuXQ+Qb+fS5e2c8lFs7hAn0s0FiM9WkAJOjg3X8cMYy6JJYvI+8q0+uZTclpOpiu3F0Po5HIDrFo8m/OvvwUhQcnMky8MsvPpNMPKJKliP8ZElb2Tu1ngama1MZNrbroEj9PBEWk3a/yXsKrSQVULkJXSuI0qHrmZOdNjDEfdDFZ1hFHiP8/xkPbk6F3Qw7g+YB2TkvCREmNcfsEyVIfGgY1P4HB7OLrlGcJ19UiyjOLVkB3PzwWUJIl5qxvZWzQYPpGmpt6L26nStrCW6fNaaJhWQ9O0BDUjK/E0BijJEvFrLmAs4cXttybb3njdTfgyIcr5HNNXnE1Noo5CuoJcMZl/XgOlqok6s4a65bMwhUEp4KcqqgRbrubQ0xsoUCBrFhntzlKtGPz833eSS1rtQKShCUmSiLcF8IWchOouoG7adOLt0yjluhnOpCjnj7Fg7bqpPDkCTnRZQvY72P/cGLs1BUetByXkRA07cXp8aLKbfc8Os/jqa+lYOofnHunh+HNjdHVnMVUZf41rag6MGvPgbAmg+BzEPriQ0OXtv3N+jPPqOL3d+5AkCS3+/H5v7jov/oqJ4Xewd++E9UhqZYLglR0k7z6CGnbRtLCWhplhog0+HB4VZ8CB+9wG+gUYTgWnV0NRZXyr6qm5fiaB1Q1oDpmx3iyegFUOvhonDp9KNt2JXu7hoW98lWWXX8MVH/kn3AEPRc+F7FT9JKbNwB9pIz28CcUBY9V+EksyDB7dzFDnEbxhJw63iqLJ+GpcZCdKTAzk6NwxSmZ0DxW5zGP938MdPo+R4xswqycYdyWJn1WHy6uheDSQJRJXtBO9aQ4tC2sJ13uJNPoI1nlRgg48C2rRBwqoPhfh9kY2fOfvGen8CcI8ff6scrKOjYx0W2Xb4MdwKWz84bfY8P1vnxY2OdCHpylCQYKCKpMxBbVtM0DysfOhBymkMlRLKtGmk5uKKhIHnh6gc9sI1Wo9bn+Q33zvX+jcfxsntv+I4zsfpH7mOk7sHiPWfh7CGKNz2xbkZf7Tjumy+cOoZzoBrzVa50fp2TdOuM6LQ9bQhUGxXMKYLFECnKZg8+f/niMLnDQqDYxRYKIvi9eQcEngcSgI00RX0jjTBhXVQ3jGIroneymX69gtHSc1cogLQleQFyX8uBnsOow63s085xpUp4/s2AijO59lhrEQJw5ymwYo7hlDa/SdHJEyQBY40hVSZoWtD3Qx94IEW/c/ilqdTpMhoUbyzMx4eEoqoogQfUP95POH8TrcLJhoJhaZwwM//DlXB1dTDIGRKlIfcrNzz3M0iyimM8xQdQazjUbKAThQ6CLsjeOblPB4BZNDRfwujcM1MqsHqrhaQihbAuxKdpKMNdGnOCmXyzz3UB+Fpkm2pPox05M4kPnFkzuYI5z4qibDs0L4Ng+xPznOTOGmvq6Ox3c+yht8EareKicOweTgXhbMXkX/gacoGQY//9W9zKxxWWfvqWHirQ6+dO1sNm8cQ96f5W/SjWyWi3SqgyiuAL5qI2WHyZOZ3XzoQ7fSeCDL/T2bcSsSvfk+dIfMVfkmwhWF899wOVv3P8ui+jaMYgs1ko857mkMSzkS+gTBaAxPIIirUMDvS3BofCv5UhVfJoO/uIVK4EJWjD2JMHRu/7s30veN5zhwYB8z37aGS5Y2skvtZMRd4Ccf/Bj3fGEbtbV+ZowuYNw7yXa9m4ReQENhttHARR9dychwgfX/vY8Lz63nwICLhqBKYy5CIKIhlSXeapzFg6U9TA4dxBHwUjXLJNzNFFpDtK1t4xfbJ2iq83H46UGEPIM1bz+fB2/7Mg2JKEuXNpKryLgmyqRGi7TGXGgVGCtLXHrT29GMKj1ffopRvYzPCV2VLih78YaC1rmPci2Go0QqNYosB5lx1nQ8zUOI/xJEGpoZOf4ox/rHmHfRxWgxD8FYnM7BzRwVaYzSLgINl3F4bDPFsQzBpncw0p0h1hGmzlvh+NYCpX1Pc84VV9I4ex73b/gc05acRdt7F/Dkx75FeyTCFR/6R574/h3MOOsc9m94lPlr1v3e+1pRZBpnhunZP0Gg1hoxWPOO2VPXE+0Bjj83imdOlKNH00SHi/QfS7P8cuuctEDEjW5YoxDDvS2svOpNHH9ulERHkPNumElxYRQt4UUJO+lethNnZQY7to0yc+1y9j3+OBO5Y7SsOI/Mzjx7N/QxdCyNeXKaYk2jNXo299wGJBnG+rKE4h6CkfM5+PRm0mM+FMd0wnXRqfRGG32MDGaJnx2nIeGlfZE1YqHVutEjbmJSjBO70rQs8rHqzecyMZBj0329XPbB+Tx3Xyd5h4y/5vkOVOx9zx+V5Kj34aj/3aMRifbpTA4NMNR5hLrpMzENg0qxSNMbp1E6nKQoSTx37zGaFtRQPyeC7FJRQ07Mks54bzfNsw3i7XG2/OoELr+DyHmNnLW2ma6tI3ie7J/a4sSzyJrXFG8L0Lu/B7MaoZRz4ws7kaUhNJcbl68B1eFgxTXXIssKN331NnY/1ju16rlt2TXs+vVXOfxUEpcX5L0qLq+Xp493UtMwG1luploqkR56jE33aLj9MTzePpKpA1zwjvey+5H7aVl0CZiN7Hn0x8w9fw2tC6wykBSZxN8vQw27UMMuFjhVJgZzTAzk8YWcuONuPEviFI8kqXnzdN7QvpKzr7uR+77waZ76yZ3WaQIuF4pmHSw+Fj7Kji8+yMI3XIbD7eFE9hiyEmC8f5C7PvclJgePo6gKuclhBksODqbTXPdvZ+P2OchNlji0aQ1P/+SHIKpc+M75BGrdeIIO2hZEGexMYegmux/r48Kb/5lq8TDbHuhicuBB3vqZ/6D3oMyuR3tpmR8B823AMIHa6aRGCgRr3VOPI21+P7aQ+i0SB8Y5MljAFKZ1tIcmkUnn0b1lilUTRQb/jm4OfnwBMwpBZKVIsjvLNFVisUdl0KmQrBTZEdhHudzOT5xPEzOiIEnknQc54HYzsOB6zt2bIVPqJOadR92c2ZzYtw05oTI9vJzIsQKHh8dIOUep8TTQ9fgBvK0hJrp6mBQ9ZMUwqzwLaJA0NtWOEXP7yStdjCtpKp4hjEknLUYvcx21lJwVunOLaKi48MhZ8vI+fPE4j3SVkL0mP0g9TmFc56mv93HT6nYGtjzLWnMx393dz1XnXYOrp8Q58zroeKaBRGucK7YPY6gyZV3gbg9wQV2SQ4MmP9nVg3TMQ6U2yPFUEp+rwFe+8lXcqWYq4QFWnn8hP3t2iPnFIhs3bSZTaCOmmvzku3fxQVc7ZT1HUIT50AMDtAk3dULQPDPBvsNPE3fEcfe5GZKzLIjHUOPTONy7HdExj+eOHMUfCFEYDzI2NMDKNcsxn9RpCS6CQcFE0qA0rnLt+9/IT757P9/8xu04zRCyw8CfWUpOe5qSs8J0NYDsVBjaazArvIrBXVnaV89geHA70dE4z2WSzDn3YpIDfXTtGSNQ8ZAI1zOae5Ylb1jL5nt/RM5Xw6HsZoSh4z154ntoSZzJQ6Mc7t/EkgVXMd7XQ7S5FUWWaJwZZsczgyxoGKV2aTPrHotQdaXJ+FIESmFkr0bdtCAun4NDTw+y8JJ3cGL7Txkt9hGnhe3p9bR5FxCIzaWQPkEwFqNQyhHUInjmRamp81I/p4Z575vP/i9sIxTzICsySy6/Gn+NNSfIt6qe0M5R9t59lJxpMsclk65IeEMOJMnJJuNBCrkVpIMSK278J3Y8+Aw1jTMQQtB3KMk8r4NSvkjdjMUsXddCariMrCiseeebOfh0Ex2L4zTOmQfA9BVn88xdP0Tz1pGYpXLZrW9h/e1fpX7pbCq6n9GeLG0La1l26RIOPVlg4PBBLr3147i8Pv7mP74+1ZNvWbCIeNs04u3TeNfX/4dDzzzJ7kceZNG6y//gvd08p4b0WBFFefFAfKLdetTjDTsJtAXoOTBBcrhA4yyrHFVNoXXBDDo3wbnXrWDnw6MUMhWu+vAiANxzIlNxLbn2jRx6dogDTw9z4eIY2bEljHV3seZvl7N7eAfbHuhizuo69j81icPtwR+xnHPLPCuOUq5KvC2I5lzNxv/9PtWSQSBxPfILHNqqN3XwVNlgxup6wokXjAwtqMU1J8K8g0VqWwpMW24dml5T5+X8t82kdX6EcMLDzvU9TJsW+uMN4m+huVyse/+Hue+LnybS0MzkyBDlfI5oUwtti5fRtWsHDs3DgGcOqYePUsxl8YbCmLrOcw//CqNaZfrK1ZjlEt27jjLR66VaKjLRP4hRTPP1t38Zf00Uf7QWzeUiOTBIOTvKo//toVoq4vIFyaeSLL38KhZdbIkO+eSZlrIssWRdy1RaF140D7P6Hty+LEsvvxSX1xKHhXSKZ+/7GcmtG/nGTXdTN30++ck02fFDTFu+lFVv/mdmnb2UJZdefHJUbh4t85px+wOn2UKteX7aRW2zn9pm/4vslfj7ZVMje95QmCs+8k9s/tldTA4NUi0VEaaJ0+vFEw7xti/+BweefBxZkWleOIP0RBOyXGFy8AANc66imCkia0dJDgmalsRw+06O0oVdzD1nPoHo52ieGybS0IRpmFzz8SXoFYPWBVGqJQPTMJmxIoEkNTD3fEExewOegBenp0AuVaZtfhRfTQt7nujjoTuOIssSN3x2JS6vPTL1x5DEbx+a9Togk8kQDAZJp9MEAoE//oU/ESEEu7/4FMNFmZ5MiXjhN8ydcSHdQ73Mcs9guGwSkHV2lu+kKDmJNL8FRauhv/Mg57rb2e8dQDYK1BoBnnIcIFBRyDis3lFDSxuD3d3IiswvjMX8VArTOfIs03yLuD9wAMaP80bn1ZTlMkk5x0jlBPGin0CgkfXu/QgEPslNviThE05Upcry6mwed+3AIamUhc7ZlZls85+gRp+J3vML5iy/jmeG9yBmX05w4xi6V2Wbq0yfV+Edq1rQ8xlOHDlAfW2YytBRslWo+Ou5OdvC8MoY553fiqpY+9pYhysLRNUkeTRJ5efH0Ocq/OzBf6P++o+ybYfCHENlbFEAzzPj+ANOCuIIE85e4t5mPvAP7yQzNkrnjm1sPNxJKZ3B1E1Ms4KsONBliWsrq/D83SpUSeLXX9zJu792Lj/62noK44Km5kYk8zEaZ89m9jnreOj/3UPnofWo8YtoWRhicLSPuro6rr76ahwOq4E5vmWIbY/2khop8L5vnE/njlF6enroPH6YpUuWsfP+ERauCaOrx2k41IyRr7JFF9z4+VX8+LNbWP2WaRQmn+OJ7/w/2ld+jPSYQiGbIRiNkk9nWHHldOo7wOH28J2/exeX3vpxmuct5OHbv4ZeLnPD//kqAD/4h1tJjQzRNHsexVyWs6+9kbZFSylkKlSK+tTk26M/3Iu8b4jSeRLtLYvxLLBGGQ5uGiQ9WuCsqzsY7T7OXf/8j1xxyYf55cP/zso3X8/EgKBz671MX74S35gPb32CZbe85TTB0HcwyWhvhqWXtL6o3o/1Zbnni9s5/5oOjj/eixHz8KZ/WApAdmKcX33zGBLwxo8tYcdD3RzdNsyMFQm6945z1dpG+scO0XThQoKxBOnREe77wqd51zf+58X37fgo/3PLO7nw5s+z+OLFp/V0H7/zID37JnjzPy4lGHPz/Y99gItueg+ti5b+0fs2N5lk3xOPsOotN/zBcJWSzuRQgXjbi9sMQzfZ/mAXZ72xg4nBHL/8z10k2oNc9oEFp4Xr2beblvmLMAyTSlGfcmYvzmuRJ398mCs/tIhyPk+1UsJfE6WQqWDoJi6vxoYfHmTFFVHCdb//TLPkYD/PPfQ00dbVLFrb/EdtcRqlNGheUP7M/rJRBeUPO89iLsvgkUOE6xoIxuKc2LmNwc7DJDpmkJ+cIDMxjlGt4vJ6KaTTSIpComM6tc2t9B3cR6VYoFwoYBo6sqLij0SplkvMu/ANFNJpMuOj6KUSvkiUWOt0nB4XhXSK8b4eGufMmxJPfwnCNK2V2c5XeXXaKZf7249OS2lwBV96vMP7oXbWn1/erzKvlP8+k9hC6rd4/EPfRou0U5PVmCjuo27+LE6kDjE/tZi+qo4mBD08zeDkEEa1QqFjFbGu7ZxfdyP3ercgGToGJmYxhenxE1B8yLrggpqVDIz2MdpRYVzXcPWlycp5NN1FwV1FSvaCP4IMRA0fVdlkUsqhqhq+ug602AIu2zyBbgrGDYNHvScwpQGaYvVUZJ1pDW0sLrRwpH6Cp57ehJSvUFSqxKL1fPBD7+P+r/6MgU5ounYxatzNpfMSZEaHcQeCONxufvRDa9uBt7/jHVA1rS0ZTt7op4bbT73rVYODn3yGvalfU/IUUB1RNO8KLvvA+YTiHu78xCbKhQq5sf+m3NKOO5nlnKv+jn1PfJPUUDezrryFPVt+hWOsD1kJIkkw+/xrKZ8Y5fL/87fserSPYzv2Eqw5hi86j7Geoyxcs4JdjzzIojdcxvSVZzNw5BAPfO2/cNe8jXf829m/cz5HpaTz089vRdUUbvzXs067VspX+e7Hn+baTy4j1hJg4tlB+p/sQ6yoY9HaZkr5Kk6Pymj3Cf73Ex/m0r/7L565r4cbP3cW3pCTSklHUWUUVcbQdb7/sfdz47/9J26fn833/ZSxni6u+vg/AzDUeQR/tJZf/fsXGTp2hPd+6078NdEXpVcIwW03XsPbvvDvxNunvej6KQ49/RtaFizm7s99ghu+8O+Ui/DQN75M46xpTAz007F0BfMvuvhPrvPCFPQeStIyN0LfoST5dJlZZ5107hu+CPOvhdoZU+FP7B7j6LZhll7S+jt74YZeRfkdZxkCdG7fTMeSFcjK6Y4wPVZAkiQC0T+yUqjzcQi3QvT32+floFzUEYbA5Xsd98bvvAJazoYL//lP/87wfvjh1fB3O8Adfv7zIw9DZPqfZndDf80785fMgV+A0w8dF0E5A3oFfFaHh6E9lghtXAa5MXB4LUF69BGY6IQD98O1d8JD/wiaG679AcgnOzuHHoR73g5L/xYu/Qp0Pgr922HmZRBogEA9ZAbBX/f8dwCKk3DsCdBL8KsPwZrPWGFbz4VAnSXanvlPK+w5H7XCbfwKqE4Y2Q/z3gKJ+VDJgy9mpbV/O2ge8Cdg5fusfLyM2ELqNcIrWRCPfu5OWovNeCSNilmkslimc2Qn7cNnkU32MuRyEZST7C83UM3cTdEhMze8mEGnRsoxzvJyIyPZPrZJbiLRIp50PSuZjuRV8EgS+uUa+/btw1+uIxQJcXhwF57JaSxeM5Nnf3mYTkeKNxcFjZ5G7hJluhqK+CJ1xMM+ZlclvG4Hclon2OyjODLGvHOa8Pv9aJo2JSYO7T/KL+//Fc7JQYLRINe+/xZ+8Pe3UD9jNudc/w4C0Ri9+3fz8P/7T5xuD22Ll7PvyceYuepcrvzwPwLWOX9DnUfJjo/y7L0/pnXhUoY6D3Plx/4Z78CTfP/2PVTFOL7EVYwe/RYOl5Pa1nYiDc2kx2tRNCd9u+/hsmvfygP3/hpFrSLw4PRGKGUncLhyJNraSI37qZvWQOeWn1Etl3D6ZlAp9OJwqSxadxm71j+AomoIrBPMr/77T1E/YzZCCFIjWdJjFVrnv0CUnNr+/CSDnSmGu9IsObnEm+IkyCo4/ZzYPUbb/AiSUQKzajkAYYKswPhRqJ2FqfnYdv/drLhgJfm0jj900kE4feCNWb9VnIThfRCfB8kTFEsVSsUq4doaQIDqgrHD5A5sYOv+JBetWYTUvNJqdJtWwMRxqyHLDnG8P0/b+Vcj6wXIj1uNs+qEyS7wRKDrKahfDDUdVgM32Q1zrkZM9iCyIxSTIzgjDaiJWVYD2nGR1VDmRq3GsftpyI9B7xaYczUsvRmG98LoQUgsgOwwDD4Hy98D/dvgpzdA+wVw432WXTIDllOd7IaaNojOBIcHup+BuoWW/Y8+YjkEzQWSbPW0fQnrNxQNfHEwDagWoFq03v11MHIASimYfSUgWWFzI1aY2lmQPAHfWQvxOfCm/7HSmpgPfdsgNgtkzUqzw2v9nrcWtn8HZqyzfq8wAS2roFqy8hyZZuWhkLR+2xOxyis2xyrX3Kjl8MpZcPjAFbDy17/DcmZ1i593aqYJ2UHw10M5bdl3ssey14WfAuXkyJUkQbrfcnZgpcMThVCTFXeqx0qH86RANQ3LFoUJ8Eafj6OUseqP9+QjxWrRSuspkl3wX8ssO3xkLxgVKw3JLoh0PH+PmCZk+q0yURxw//vhwM+t8nf6rHQ2LHve7pd+xQqbHbJ+X1Zhx3etvC79Wyvuu95m1avmlVa5eaKWHcCq0+NHoKYd9LKVr2rRqk91C8Dht+7BSs4qb3/CChebbd0H6QHren7Mukf1kpWGxuVg6vDcD62ycnhh7jVW/IUJ2HevVVcblsDATuu+8tfBWR+w7Dt+BFJ9Vj1oXAqhZtj6bat+6WUINlrvJ35jlY2sWmmRZKvs9LIlrCTFssHIAavs/HErrMMLDUthx/egYw0Uk1b7kR204kh2wRX/CTvvtNKbGYT5b4Fjj1v1MNQM453We7jVqkONy+HIQ5bdkt3WfbPldsvmk93gDFhxOzxW3arkrTKuaYNwi2WPg7+w7OwKQnbEuodnXwl60bq/Lv6idR+/jNhC6jXCK1kQB/7nToLHOzAlkAVIbw5zz7e/TFiK0h/zoisKDsmBIQmEMJGAiPBTFpMYo/24KkX80Tjz3vMpfn33t9HU5SxfMJ0T63upDTjIyTL5VBlhCC66aTYzVsTZu6Gf3Y/3UtvsZ9HFzez95XHaOkI0nt+I9wUr6v4ovzUkX62UefQb/0bnrt00zlnAyIlOMA30ShlF1bjs8uWMZBWO7jnA1det5e7v/ZJg2I+BSiGTplzWqZQrtLVGGR5KMqvFw77jOYRp4Pd7uKJuP7GmRkpKGLn7N3Q3vI2UCLFrRyelQoFzYn0sbSww2Ppenn7kES47v5kKXtZvS9Kg9rO6OYd01vth4jh3PXSc9sYQW3b3c+GyOD6nwfT2CN0947icKpM5g2xeZ0kijVqZtBqlZBe4Q1ZmhWkJoe6nrcbXE7EaDUWzrhUnrcZk4rjV+IIlDISwRJSkWP9LshU+1GI1VkYFhGE5g1O2FcJqNI0qIKz/Ix1WQxedbsWvlwHJitOoWMKn4yKrpz7eCYO7rPjGjp4UZbVWjzAzZPVeNa/lGJvPsn7HH7ca+sR8Kw/ljJUnX9wSV06f1XN1+CwnkzwOC66D0UOWnfxxy2E1LIHgycb42W9aTjTQeFKQbLXS2rAEujdZjuvy/7DCjR+1RigqBahfZH0/N2p9R9Fg+sUwuBsqWWhcYfWokSxbesJWoxyZbtk3N2yVjea2xJ3mholjVvpr2i3nIClWufgSVjpSPaA4Ye1nYd99Jxv/AKR6re9kh63fCrdZjkgvWgIoPs+ylz9h1ZXhfZZji8+1bKNoUM5BdIb1PWFY/58qV9VpOWhTt9KvaFa+T+Uj0GDFO3bEcpyRDktUJOZZdUYvWkLPqIJRtkQ1WLaUTo7KldKWsyskreua2xLYuVFL1LprLMcryZYTbzvPKvNyDmpnWt/LDFhOtpC00ljJw4JrLdHnClrvDp9VvqEmy/6VnDWiUj55RJMwrPJ4w+fhgQ/DkrdbdbVvG5zzEes93WfZOtho/Y5etsq+bhHs/L5lh+XvsgSAEM+LHVfISr83apXR6EHLbv466/NgI4wdtgQiWNcC9ZbwUl1WPKZufWYaVvpbzrZspZegd6uV52U3nxQ5/XB8g5V3X8wKmxmy7ou6hZY4HNgB+39u3aPRGdY9H+mAnk2WEF51q3UvSZIl6Ms5aD3H6lh0bYT6JVbahvdatg01W3Ww+2nrftI8lmBrv+D0tkOSrLie/Yb1u76YdR/XzrRE/oknLaETO7kYolqyxG3HGus+mey2wo8dho4Lrbp8it6tVtsoDMsGQlgjU2DlPzdsCTD1d/iV3+qEvlLYQuo1witWEKbBA5+5kVrzevoqnQhniP7SYUqqSlUvMegdwjsR4ibXdUw6qxzwFGiv7uecdRewfeeThKM11LoLeMNRwo2tDHbuo+743UhLbkQPtDN+bAjMMoGWFoxiEd/QeiRRtRr7U42S6rIcRG7MatiH91lOK9hg9VIUDYqpkz2tpNVQn+qxFpNWXKd6rNUi6CXGSm48ik6+UMYf9GE2n8vwwR20z56GlO5HKA4kd4iJqpdkuoqzNIISiFHnypHRnQRjCcqh6bg8XvKDnYimVfhWvNVqWLPD1ijArCthz08hO0w1PUIxPYn/8k8jpXpg4Dnr8VC632r0JrutRkMIy1GE26y8O33kDTdet2Lls1q0HIcQVgOFsBpS1WUNP8fnWU5Akq08S7LViBRTzwsd4+SBy54aK57odMuJVYsn4+T5npswnm9MTjlMRbMaxN9ueISwhMwp5yYrllNS/8yzqYqTlkA4eS4e8CfNUTmNSt7Ky6lRDLAa3z/WkzwlCE/NyyhnLcdR0/7isIWk5UyiM6y8niI/btnmhb99CvNkmZ0SrH+okX7h9ULSStMLf6ecs647vM+HFcKqS+HW0+M2Ti6Hmzhm5UXRnr9enLTKyR+36lxm0BJZp0ZzTNNyNrJmOfOJ41ZaNLd1L2aHrJE8xWGlM3nCEiSxOVYdO/hLSwSFmp+PLzNwUjC6rLLyRE6OWFQtZ1wtWCLZF7N+a3CXlXZXyBKtuVEr/lIaCuOWo43PtRzi8d9Y90S4xRI9/oRV5w3dik8vW+FbzrbSWdNh3a9GxRLrsmLdM+l+K0++U6Osqec7KX8JpmHVsRc+JrT5/zW2kHqZuf322/nqV7/K8PAwCxcu5Jvf/CYrVqz4o997JQvito/fiuRMUC6NU2MoHPYcYFNHH9OMKm/L66wrV5k026gJlJAy/ZbAkV8wH6Cm3Wrw9JLVa5h1ORx6wPos3GY5nbHD1nvHRZZjGN4HSJZAKKetsIFGS1Al5luNan7c6r0Jw2qUPBHrpboAYfVaPTWWaFE0y7FpHisNiJOPV+J/noO2sbGxsbF5GbGF1MvI3XffzTve8Q7uuOMOVq5cyW233ca9997LkSNHiMVif/C7f40FYWNjY2Nj89fOX6P/PmM7m3/ta1/jPe95DzfffDNz5szhjjvuwOPx8L3vfe9MJcnGxsbGxsbG5s/ijAipSqXCzp07Wbt27fMJkWXWrl3L5s2bXxS+XC6TyWROe9nY2NjY2NjYnGnOiJAaHx/HMAzi8fhpn8fjcYaHh18U/ktf+hLBYHDq1dTU9Gol1cbGxsbGxsbm9/K6OLT4k5/8JOl0eurV19d3ppNkY2NjY2NjY3NmztqLRqMoisLIyMhpn4+MjJBIJF4U3ul04nT+Gfsp2djY2NjY2Ni8CpyRESmHw8HSpUt54oknpj4zTZMnnniCVatWnYkk2djY2NjY2Nj82ZyxA5E+9rGPcdNNN7Fs2TJWrFjBbbfdRj6f5+abbz5TSbKxsbGxsbGx+bM4Y0LquuuuY2xsjM985jMMDw+zaNEi1q9f/6IJ6DY2NjY2NjY2r1XsI2JsbGxsbGxsXhX+Gv3362LVno2NjY2NjY3NaxFbSNnY2NjY2NjYvERsIWVjY2NjY2Nj8xKxhZSNjY2NjY2NzUvEFlI2NjY2NjY2Ni+RM7b9wV/CqYWG9uHFNjY2NjY2rx9O+e3X4YYBv5fXpZDKZrMA9uHFNjY2NjY2r0Oy2SzBYPBMJ+Nl4XW5j5RpmgwODuL3+5Ek6WWNO5PJ0NTURF9f31/NHhevRWw7vzrYdn71sG396mDb+dXhlbKzEIJsNkt9fT2y/Ncxu+h1OSIlyzKNjY2v6G8EAgH7Jn0VsO386mDb+dXDtvWrg23nV4dXws5/LSNRp/jrkIM2NjY2NjY2NmcAW0jZ2NjY2NjY2LxEbCH1WzidTj772c/idDrPdFL+qrHt/Opg2/nVw7b1q4Nt51cH285/Oq/LyeY2NjY2NjY2Nq8F7BEpGxsbGxsbG5uXiC2kbGxsbGxsbGxeIraQsrGxsbGxsbF5idhCysbGxsbGxsbmJWILKRsbGxsbGxubl4gtpF7A7bffTmtrKy6Xi5UrV7Jt27YznaTXFU899RRXXnkl9fX1SJLEL37xi9OuCyH4zGc+Q11dHW63m7Vr19LZ2XlamGQyyY033kggECAUCvGud72LXC73Kubitc+XvvQlli9fjt/vJxaL8cY3vpEjR46cFqZUKnHLLbcQiUTw+Xy8+c1vZmRk5LQwvb29XH755Xg8HmKxGP/wD/+AruuvZlZe83zrW99iwYIFU7s7r1q1iocffnjqum3nV4Yvf/nLSJLERz7ykanPbFv/5Xzuc59DkqTTXrNmzZq6btv4pWELqZPcfffdfOxjH+Ozn/0szz33HAsXLmTdunWMjo6e6aS9bsjn8yxcuJDbb7/9d17/yle+wje+8Q3uuOMOtm7ditfrZd26dZRKpakwN954IwcOHOCxxx7jwQcf5KmnnuK9733vq5WF1wUbN27klltuYcuWLTz22GNUq1Uuvvhi8vn8VJiPfvSjPPDAA9x7771s3LiRwcFB3vSmN01dNwyDyy+/nEqlwrPPPssPfvAD7rzzTj7zmc+ciSy9ZmlsbOTLX/4yO3fuZMeOHVx00UVcffXVHDhwALDt/Eqwfft2vv3tb7NgwYLTPrdt/fIwd+5choaGpl7PPPPM1DXbxi8RYSOEEGLFihXilltumfrfMAxRX18vvvSlL53BVL1+AcT9998/9b9pmiKRSIivfvWrU5+lUinhdDrFT3/6UyGEEAcPHhSA2L59+1SYhx9+WEiSJAYGBl61tL/eGB0dFYDYuHGjEMKyq6Zp4t57750Kc+jQIQGIzZs3CyGEeOihh4Qsy2J4eHgqzLe+9S0RCAREuVx+dTPwOiMcDovvfOc7tp1fAbLZrJg+fbp47LHHxPnnny8+/OEPCyHsOv1y8dnPflYsXLjwd16zbfzSsUekgEqlws6dO1m7du3UZ7Iss3btWjZv3nwGU/bXQ1dXF8PDw6fZOBgMsnLlyikbb968mVAoxLJly6bCrF27FlmW2bp166ue5tcL6XQagJqaGgB27txJtVo9zdazZs2iubn5NFvPnz+feDw+FWbdunVkMpmp0Rab0zEMg7vuuot8Ps+qVatsO78C3HLLLVx++eWn2RTsOv1y0tnZSX19Pe3t7dx444309vYCto3/EtQznYDXAuPj4xiGcVrlAIjH4xw+fPgMpeqvi+HhYYDfaeNT14aHh4nFYqddV1WVmpqaqTA2p2OaJh/5yEdYvXo18+bNAyw7OhwOQqHQaWF/29a/qyxOXbN5nn379rFq1SpKpRI+n4/777+fOXPmsHv3btvOLyN33XUXzz33HNu3b3/RNbtOvzysXLmSO++8k5kzZzI0NMS//uu/cu6557J//37bxn8BtpCysXkdc8stt7B///7T5jnYvLzMnDmT3bt3k06nue+++7jpppvYuHHjmU7WXxV9fX18+MMf5rHHHsPlcp3p5PzVcumll079vWDBAlauXElLSwv33HMPbrf7DKbs9Y39aA+IRqMoivKi1QkjIyMkEokzlKq/Lk7Z8Q/ZOJFIvGhyv67rJJNJuxx+B7feeisPPvggv/nNb2hsbJz6PJFIUKlUSKVSp4X/bVv/rrI4dc3meRwOB9OmTWPp0qV86UtfYuHChXz961+37fwysnPnTkZHR1myZAmqqqKqKhs3buQb3/gGqqoSj8dtW78ChEIhZsyYwbFjx+z6/BdgCymshnLp0qU88cQTU5+ZpskTTzzBqlWrzmDK/npoa2sjkUicZuNMJsPWrVunbLxq1SpSqRQ7d+6cCrNhwwZM02TlypWveppfqwghuPXWW7n//vvZsGEDbW1tp11funQpmqadZusjR47Q29t7mq337dt3mnB97LHHCAQCzJkz59XJyOsU0zQpl8u2nV9G1qxZw759+9i9e/fUa9myZdx4441Tf9u2fvnJ5XIcP36curo6uz7/JZzp2e6vFe666y7hdDrFnXfeKQ4ePCje+973ilAodNrqBJs/TDabFbt27RK7du0SgPja174mdu3aJXp6eoQQQnz5y18WoVBI/PKXvxR79+4VV199tWhraxPFYnEqjksuuUQsXrxYbN26VTzzzDNi+vTp4oYbbjhTWXpN8oEPfEAEg0Hx5JNPiqGhoalXoVCYCvP+979fNDc3iw0bNogdO3aIVatWiVWrVk1d13VdzJs3T1x88cVi9+7dYv369aK2tlZ88pOfPBNZes3yiU98QmzcuFF0dXWJvXv3ik984hNCkiTx6KOPCiFsO7+SvHDVnhC2rV8OPv7xj4snn3xSdHV1iU2bNom1a9eKaDQqRkdHhRC2jV8qtpB6Ad/85jdFc3OzcDgcYsWKFWLLli1nOkmvK37zm98I4EWvm266SQhhbYHwL//yLyIejwun0ynWrFkjjhw5clocExMT4oYbbhA+n08EAgFx8803i2w2ewZy89rld9kYEN///venwhSLRfHBD35QhMNh4fF4xDXXXCOGhoZOi6e7u1tceumlwu12i2g0Kj7+8Y+LarX6Kufmtc073/lO0dLSIhwOh6itrRVr1qyZElFC2HZ+JfltIWXb+i/nuuuuE3V1dcLhcIiGhgZx3XXXiWPHjk1dt2380pCEEOLMjIXZ2NjY2NjY2Ly+sedI2djY2NjY2Ni8RGwhZWNjY2NjY2PzErGFlI2NjY2NjY3NS8QWUjY2NjY2NjY2LxFbSNnY2NjY2NjYvERsIWVjY2NjY2Nj8xKxhZSNjY2NjY2NzUvEFlI2NjY2NjY2Ni8RW0jZ2NjY2NjY2LxEbCFlY2NjY2NjY/MSsYWUjY2NjY2Njc1L5P8Dww35xxTFVYQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the validation loss over the epochs\n",
    "plt.plot(np.array(range(len(histories['MANN'].history['loss']))), histories['MANN'].history['val_loss'], label='MANN', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['MANN_dropout'].history['loss']))), histories['MANN_dropout'].history['val_loss'], label='MANN_dropout', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['Sigmoid'].history['loss']))), histories['Sigmoid'].history['val_loss'], label='Sigmoid', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['Tanh'].history['loss']))), histories['Tanh'].history['val_loss'], label='Tanh', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['LeakyReLU'].history['loss']))), histories['LeakyReLU'].history['val_loss'], label='Leaky ReLU', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['ELU'].history['loss']))), histories['ELU'].history['val_loss'], label='ELU', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['Swish'].history['loss']))), histories['Swish'].history['val_loss'], label='Swish', linewidth=0.75)\n",
    "plt.plot(np.array(range(len(histories['Sequential'].history['loss']))), histories['Sequential'].history['val_loss'], label='Sequential', linewidth=0.75)\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33ea1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "train_hist_df = pd.DataFrame()\n",
    "val_hist_df = pd.DataFrame()\n",
    "for name, callback in histories.items():\n",
    "    train_hist_df = pd.concat((train_hist_df, pd.DataFrame(callback.history['loss'], columns=[name])), axis=1, join='inner', ignore_index=True)\n",
    "    val_hist_df = pd.concat((val_hist_df, pd.DataFrame(callback.history['val_loss'], columns=[name])), axis=1, join='inner', ignore_index=True)\n",
    "    \n",
    "train_hist_df.to_csv('NLP.training_hist.csv')\n",
    "val_hist_df.to_csv('NLP.validation_hist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4220b853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.load_weights(f'NLP.{name}.tf')\n",
    "    \n",
    "# Convert to tf-idf for traditional models\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "    \n",
    "# Traditional Models as a baseline comparison\n",
    "nb = MultinomialNB()\n",
    "nb.fit(vectorizer.transform(X_train), one_hot.inverse_transform(y_train).ravel())\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(vectorizer.transform(X_train), one_hot.inverse_transform(y_train).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9f19973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 9ms/step - loss: 2.8113 - categorical_accuracy: 0.1472\n",
      "49/49 [==============================] - 1s 8ms/step - loss: 2.5671 - categorical_accuracy: 0.1606\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 2.5883 - categorical_accuracy: 0.1036\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 2.7050 - categorical_accuracy: 0.0736\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 3.0901 - categorical_accuracy: 0.1305\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 2.7982 - categorical_accuracy: 0.0435\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 2.7351 - categorical_accuracy: 0.0979\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 2.7325 - categorical_accuracy: 0.0736\n"
     ]
    }
   ],
   "source": [
    "# Get performance metrics for each model\n",
    "# Get the testing loss for each model\n",
    "metric = keras.metrics.CategoricalAccuracy()\n",
    "metric.update_state(y_test.to_numpy(), one_hot.transform(log_reg.predict(vectorizer.transform(X_test)).reshape(-1,1)))\n",
    "log_reg_loss = metric.result().numpy()\n",
    "metric.update_state(y_test.to_numpy(), one_hot.transform(nb.predict(vectorizer.transform(X_test)).reshape(-1,1)))\n",
    "nb_loss = metric.result().numpy()\n",
    "MANN_loss = models['MANN'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['categorical_accuracy']\n",
    "MANN_dropout_loss = models['MANN_Dropout'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['categorical_accuracy']\n",
    "Sigmoid_loss = models['Sigmoid'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['categorical_accuracy']\n",
    "Tanh_loss = models['Tanh'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['categorical_accuracy']\n",
    "LeakyReLU_loss = models['LeakyReLU'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['categorical_accuracy']\n",
    "ELU_loss = models['ELU'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['categorical_accuracy']\n",
    "Swish_loss = models['Swish'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['categorical_accuracy']\n",
    "Sequential_loss = models['Sequential'].evaluate(X_test, y_test.to_numpy(),return_dict=True)['categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ef8fb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorical Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.264875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.218170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANN w/ Dropout</th>\n",
       "      <td>0.160589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANN</th>\n",
       "      <td>0.147153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leaky ReLU NN</th>\n",
       "      <td>0.130518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sigmoid NN</th>\n",
       "      <td>0.103647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swish NN</th>\n",
       "      <td>0.097889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanh NN</th>\n",
       "      <td>0.073576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sequential NN</th>\n",
       "      <td>0.073576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU NN</th>\n",
       "      <td>0.043506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Categorical Accuracy\n",
       "Logistic Regression              0.264875\n",
       "Naive Bayes                      0.218170\n",
       "MANN w/ Dropout                  0.160589\n",
       "MANN                             0.147153\n",
       "Leaky ReLU NN                    0.130518\n",
       "Sigmoid NN                       0.103647\n",
       "Swish NN                         0.097889\n",
       "Tanh NN                          0.073576\n",
       "Sequential NN                    0.073576\n",
       "ELU NN                           0.043506"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save metrics to a table and display results\n",
    "# Save testing loss to table and display results\n",
    "results = pd.DataFrame([log_reg_loss, nb_loss, MANN_loss, MANN_dropout_loss, Sigmoid_loss, Tanh_loss, LeakyReLU_loss, ELU_loss, Swish_loss, Sequential_loss],\n",
    "                      index=['Logistic Regression', 'Naive Bayes', 'MANN', 'MANN w/ Dropout', 'Sigmoid NN', 'Tanh NN', 'Leaky ReLU NN', 'ELU NN', 'Swish NN', 'Sequential NN'],\n",
    "                      columns=['Categorical Accuracy'])\n",
    "results.sort_values('Categorical Accuracy', inplace=True, ascending=False)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24d4b8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/49 [========>.....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 8ms/step\n",
      "10/49 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 6ms/step\n",
      " 1/49 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 6ms/step\n",
      " 1/49 [..............................] - ETA: 4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 6ms/step\n",
      " 8/49 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 6ms/step\n",
      "10/49 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 6ms/step\n",
      "10/49 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Visual results with confusion matrix\n",
    "logreg_metrics = classification_report(y_test.to_numpy(), one_hot.transform(log_reg.predict(vectorizer.transform(X_test)).reshape(-1,1)))\n",
    "nb_metrics = classification_report(y_test.to_numpy(), one_hot.transform(nb.predict(vectorizer.transform(X_test)).reshape(-1,1)))\n",
    "MANN_metrics = classification_report(y_test.to_numpy(), keras.utils.to_categorical(np.argmax(models['MANN'].predict(X_test), axis=1), len(one_hot.categories_[0])))\n",
    "MANN_drop_metrics = classification_report(y_test.to_numpy(), keras.utils.to_categorical(np.argmax(models['MANN_Dropout'].predict(X_test), axis=1), len(one_hot.categories_[0])))\n",
    "Sigmoid_metrics = classification_report(y_test.to_numpy(), keras.utils.to_categorical(np.argmax(models['Sigmoid'].predict(X_test), axis=1), len(one_hot.categories_[0])))\n",
    "Tanh_metrics = classification_report(y_test.to_numpy(), keras.utils.to_categorical(np.argmax(models['Tanh'].predict(X_test), axis=1), len(one_hot.categories_[0])))\n",
    "LeakyReLU_metrics = classification_report(y_test.to_numpy(), keras.utils.to_categorical(np.argmax(models['LeakyReLU'].predict(X_test), axis=1), len(one_hot.categories_[0])))\n",
    "ELU_metrics = classification_report(y_test.to_numpy(), keras.utils.to_categorical(np.argmax(models['ELU'].predict(X_test), axis=1), len(one_hot.categories_[0])))\n",
    "Swish_metrics = classification_report(y_test.to_numpy(), keras.utils.to_categorical(np.argmax(models['Swish'].predict(X_test), axis=1), len(one_hot.categories_[0])))\n",
    "Sequential_metrics = classification_report(y_test.to_numpy(), keras.utils.to_categorical(np.argmax(models['Sequential'].predict(X_test), axis=1), len(one_hot.categories_[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "587eff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.11       104\n",
      "           1       0.36      0.09      0.14       146\n",
      "           2       1.00      0.02      0.04        56\n",
      "           3       0.47      0.24      0.32       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.24      0.52      0.33       212\n",
      "           9       0.23      0.67      0.34       257\n",
      "          10       0.33      0.28      0.30       156\n",
      "          11       0.33      0.20      0.25       162\n",
      "          12       0.67      0.03      0.05        73\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       1.00      0.05      0.09        65\n",
      "\n",
      "   micro avg       0.26      0.26      0.26      1563\n",
      "   macro avg       0.35      0.14      0.12      1563\n",
      "weighted avg       0.38      0.26      0.21      1563\n",
      " samples avg       0.26      0.26      0.26      1563\n",
      "\n",
      "\n",
      "Naive Bayes Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       104\n",
      "           1       0.00      0.00      0.00       146\n",
      "           2       0.00      0.00      0.00        56\n",
      "           3       0.00      0.00      0.00       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.37      0.05      0.08       212\n",
      "           9       0.17      1.00      0.29       257\n",
      "          10       1.00      0.01      0.01       156\n",
      "          11       0.00      0.00      0.00       162\n",
      "          12       0.00      0.00      0.00        73\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        65\n",
      "\n",
      "   micro avg       0.17      0.17      0.17      1563\n",
      "   macro avg       0.10      0.07      0.02      1563\n",
      "weighted avg       0.18      0.17      0.06      1563\n",
      " samples avg       0.17      0.17      0.17      1563\n",
      "\n",
      "\n",
      "Multi-Activation Neural Network Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       104\n",
      "           1       0.00      0.00      0.00       146\n",
      "           2       0.00      0.00      0.00        56\n",
      "           3       0.06      0.03      0.04       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.20      0.04      0.06       212\n",
      "           9       0.17      0.66      0.27       257\n",
      "          10       0.00      0.00      0.00       156\n",
      "          11       0.11      0.31      0.17       162\n",
      "          12       0.00      0.00      0.00        73\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        65\n",
      "\n",
      "   micro avg       0.15      0.15      0.15      1563\n",
      "   macro avg       0.03      0.06      0.03      1563\n",
      "weighted avg       0.07      0.15      0.07      1563\n",
      " samples avg       0.15      0.15      0.15      1563\n",
      "\n",
      "\n",
      "Multi-Activation Neural Network w/ Dropout Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       104\n",
      "           1       1.00      0.01      0.01       146\n",
      "           2       0.00      0.00      0.00        56\n",
      "           3       0.00      0.00      0.00       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.13      0.25      0.17       212\n",
      "           9       0.17      0.77      0.28       257\n",
      "          10       0.00      0.00      0.00       156\n",
      "          11       0.00      0.00      0.00       162\n",
      "          12       0.00      0.00      0.00        73\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        65\n",
      "\n",
      "   micro avg       0.16      0.16      0.16      1563\n",
      "   macro avg       0.08      0.06      0.03      1563\n",
      "weighted avg       0.14      0.16      0.07      1563\n",
      " samples avg       0.16      0.16      0.16      1563\n",
      "\n",
      "\n",
      "Sigmoid Neural Network Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       104\n",
      "           1       0.00      0.00      0.00       146\n",
      "           2       0.00      0.00      0.00        56\n",
      "           3       0.00      0.00      0.00       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.00      0.00      0.00       212\n",
      "           9       0.00      0.00      0.00       257\n",
      "          10       0.00      0.00      0.00       156\n",
      "          11       0.10      1.00      0.19       162\n",
      "          12       0.00      0.00      0.00        73\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        65\n",
      "\n",
      "   micro avg       0.10      0.10      0.10      1563\n",
      "   macro avg       0.01      0.06      0.01      1563\n",
      "weighted avg       0.01      0.10      0.02      1563\n",
      " samples avg       0.10      0.10      0.10      1563\n",
      "\n",
      "\n",
      "Tanh Neural Network Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       104\n",
      "           1       0.00      0.00      0.00       146\n",
      "           2       0.00      0.00      0.00        56\n",
      "           3       0.07      1.00      0.14       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.00      0.00      0.00       212\n",
      "           9       0.00      0.00      0.00       257\n",
      "          10       0.00      0.00      0.00       156\n",
      "          11       0.00      0.00      0.00       162\n",
      "          12       0.00      0.00      0.00        73\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        65\n",
      "\n",
      "   micro avg       0.07      0.07      0.07      1563\n",
      "   macro avg       0.00      0.06      0.01      1563\n",
      "weighted avg       0.01      0.07      0.01      1563\n",
      " samples avg       0.07      0.07      0.07      1563\n",
      "\n",
      "\n",
      "LeakyReLU Neural Network Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.05      0.09       104\n",
      "           1       1.00      0.01      0.03       146\n",
      "           2       0.07      0.12      0.09        56\n",
      "           3       0.19      0.06      0.09       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.15      0.21      0.17       212\n",
      "           9       0.19      0.14      0.16       257\n",
      "          10       0.34      0.07      0.12       156\n",
      "          11       0.13      0.35      0.19       162\n",
      "          12       0.50      0.01      0.03        73\n",
      "          13       0.06      0.22      0.10        73\n",
      "          14       0.06      0.21      0.09        52\n",
      "          15       0.70      0.11      0.19        65\n",
      "\n",
      "   micro avg       0.13      0.13      0.13      1563\n",
      "   macro avg       0.25      0.10      0.08      1563\n",
      "weighted avg       0.31      0.13      0.12      1563\n",
      " samples avg       0.13      0.13      0.13      1563\n",
      "\n",
      "\n",
      "ELU Neural Network Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       104\n",
      "           1       0.00      0.00      0.00       146\n",
      "           2       0.00      0.00      0.00        56\n",
      "           3       0.00      0.00      0.00       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.00      0.00      0.00       212\n",
      "           9       0.15      0.07      0.09       257\n",
      "          10       1.00      0.02      0.04       156\n",
      "          11       0.00      0.00      0.00       162\n",
      "          12       0.00      0.00      0.00        73\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.03      0.92      0.06        52\n",
      "          15       0.00      0.00      0.00        65\n",
      "\n",
      "   micro avg       0.04      0.04      0.04      1563\n",
      "   macro avg       0.07      0.06      0.01      1563\n",
      "weighted avg       0.13      0.04      0.02      1563\n",
      " samples avg       0.04      0.04      0.04      1563\n",
      "\n",
      "\n",
      "Swish Neural Network Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       104\n",
      "           1       0.09      0.75      0.17       146\n",
      "           2       0.00      0.00      0.00        56\n",
      "           3       0.00      0.00      0.00       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.00      0.00      0.00       212\n",
      "           9       0.00      0.00      0.00       257\n",
      "          10       0.00      0.00      0.00       156\n",
      "          11       0.11      0.27      0.16       162\n",
      "          12       0.00      0.00      0.00        73\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        65\n",
      "\n",
      "   micro avg       0.10      0.10      0.10      1563\n",
      "   macro avg       0.01      0.06      0.02      1563\n",
      "weighted avg       0.02      0.10      0.03      1563\n",
      " samples avg       0.10      0.10      0.10      1563\n",
      "\n",
      "\n",
      "Sequential Neural Network Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       104\n",
      "           1       0.00      0.00      0.00       146\n",
      "           2       0.00      0.00      0.00        56\n",
      "           3       0.07      1.00      0.14       115\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.00      0.00      0.00       212\n",
      "           9       0.00      0.00      0.00       257\n",
      "          10       0.00      0.00      0.00       156\n",
      "          11       0.00      0.00      0.00       162\n",
      "          12       0.00      0.00      0.00        73\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        65\n",
      "\n",
      "   micro avg       0.07      0.07      0.07      1563\n",
      "   macro avg       0.00      0.06      0.01      1563\n",
      "weighted avg       0.01      0.07      0.01      1563\n",
      " samples avg       0.07      0.07      0.07      1563\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Metrics:\")\n",
    "print(logreg_metrics)\n",
    "print()\n",
    "\n",
    "print(\"Naive Bayes Metrics:\")\n",
    "print(nb_metrics)\n",
    "print()\n",
    "\n",
    "print(\"Multi-Activation Neural Network Metrics:\")\n",
    "print(MANN_metrics)\n",
    "print()\n",
    "\n",
    "print(\"Multi-Activation Neural Network w/ Dropout Metrics:\")\n",
    "print(MANN_drop_metrics)\n",
    "print()\n",
    "\n",
    "print(\"Sigmoid Neural Network Metrics:\")\n",
    "print(Sigmoid_metrics)\n",
    "print()\n",
    "\n",
    "print(\"Tanh Neural Network Metrics:\")\n",
    "print(Tanh_metrics)\n",
    "print()\n",
    "\n",
    "print(\"LeakyReLU Neural Network Metrics:\")\n",
    "print(LeakyReLU_metrics)\n",
    "print()\n",
    "\n",
    "print(\"ELU Neural Network Metrics:\")\n",
    "print(ELU_metrics)\n",
    "print()\n",
    "\n",
    "print(\"Swish Neural Network Metrics:\")\n",
    "print(Swish_metrics)\n",
    "print()\n",
    "\n",
    "print(\"Sequential Neural Network Metrics:\")\n",
    "print(Sequential_metrics)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2b272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
